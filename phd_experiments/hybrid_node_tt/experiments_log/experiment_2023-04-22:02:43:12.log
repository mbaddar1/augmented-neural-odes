[experiments_sandbox.py:440 -   <module>()] 2023-04-22 02:43:12,846 INFO SEED = 42
[experiments_sandbox.py:492 -   <module>()] 2023-04-22 02:43:12,847 INFO model = 
***
RBF
in_dim=2
n_centres=20
out_dim=1
basis_fn=matern52
numel_learnable=81
***

[experiments_sandbox.py:493 -   <module>()] 2023-04-22 02:43:12,847 INFO optimizer  = Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: False
    lr: 0.7
    maximize: False
    weight_decay: 0
)
[experiments_sandbox.py:500 -   <module>()] 2023-04-22 02:43:12,847 INFO lr_scheduler = <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7fb829374d90>
[experiments_sandbox.py:509 -   <module>()] 2023-04-22 02:43:12,848 INFO data = <__main__.ToyData1 object at 0x7fb829374d30>
[experiments_sandbox.py:510 -   <module>()] 2023-04-22 02:43:12,848 INFO epochs = 1000
[experiments_sandbox.py:514 -   <module>()] 2023-04-22 02:43:12,848 INFO epochs_losses_window = 10
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:14,588 INFO epoch # 0 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.7-> 0.7 - loss = 7.399526325985789
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:14,762 INFO epoch # 1 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.7-> 0.7 - loss = 1.314233459532261
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:14,936 INFO epoch # 2 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.7-> 0.7 - loss = 0.30328873079270124
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:15,110 INFO epoch # 3 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.7-> 0.7 - loss = 0.1672862358391285
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:15,284 INFO epoch # 4 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.7-> 0.7 - loss = 0.15438945102505386
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:15,456 INFO epoch # 5 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.7-> 0.7 - loss = 0.13259977288544178
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:15,637 INFO epoch # 6 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.7-> 0.7 - loss = 0.06423414871096611
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:15,811 INFO epoch # 7 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.7-> 0.7 - loss = 0.03613780718296766
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:15,987 INFO epoch # 8 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.7-> 0.7 - loss = 0.05651418585330248
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:16,160 INFO epoch # 9 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.7-> 0.7 - loss = 0.025483158184215426
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:16,334 INFO epoch # 10 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.7-> 0.7 - loss = 0.019778733694693074
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:43:16,334 INFO *** epoch 10, rolling-avg-loss (window=10)= 0.2273945683700731
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:16,508 INFO epoch # 11 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.7-> 0.7 - loss = 0.023354504955932498
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:16,684 INFO epoch # 12 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.7-> 0.7 - loss = 0.01415999059099704
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:16,857 INFO epoch # 13 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.7-> 0.7 - loss = 0.01343023986555636
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:17,033 INFO epoch # 14 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.7-> 0.7 - loss = 0.009887008462101221
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:17,224 INFO epoch # 15 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.7-> 0.7 - loss = 0.010678738006390631
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:17,398 INFO epoch # 16 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.7-> 0.7 - loss = 0.007600449724122882
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:17,572 INFO epoch # 17 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.7-> 0.7 - loss = 0.008604805509094149
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:17,746 INFO epoch # 18 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.7-> 0.7 - loss = 0.00889594724867493
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:17,920 INFO epoch # 19 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.7-> 0.7 - loss = 0.007371307467110455
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:18,095 INFO epoch # 20 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.7-> 0.7 - loss = 0.006437559437472373
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:43:18,095 INFO *** epoch 20, rolling-avg-loss (window=10)= 0.011042055126745253
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:18,270 INFO epoch # 21 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.7-> 0.7 - loss = 0.008469887892715633
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:18,443 INFO epoch # 22 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.7-> 0.7 - loss = 0.008626483846455812
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:18,616 INFO epoch # 23 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.7-> 0.7 - loss = 0.007076798414345831
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:18,789 INFO epoch # 24 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.7-> 0.7 - loss = 0.009721825830638409
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:18,965 INFO epoch # 25 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.7-> 0.7 - loss = 0.01061650668270886
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:19,140 INFO epoch # 26 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.7-> 0.7 - loss = 0.007686790311709046
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:19,313 INFO epoch # 27 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.7-> 0.7 - loss = 0.008144478080794215
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:19,487 INFO epoch # 28 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.7-> 0.7 - loss = 0.009539671009406447
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:19,661 INFO epoch # 29 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.7-> 0.7 - loss = 0.006579805922228843
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:19,835 INFO epoch # 30 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.7-> 0.7 - loss = 0.009408748243004084
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:43:19,835 INFO *** epoch 30, rolling-avg-loss (window=10)= 0.008587099623400717
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:20,009 INFO epoch # 31 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.7-> 0.7 - loss = 0.005853999638929963
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:20,184 INFO epoch # 32 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.7-> 0.7 - loss = 0.009372484171763062
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:20,357 INFO epoch # 33 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.7-> 0.7 - loss = 0.008367910049855709
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:20,531 INFO epoch # 34 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.7-> 0.7 - loss = 0.005706961383111775
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:20,703 INFO epoch # 35 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.7-> 0.7 - loss = 0.006437860894948244
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:20,877 INFO epoch # 36 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.7-> 0.7 - loss = 0.005856800067704171
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:21,052 INFO epoch # 37 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.7-> 0.7 - loss = 0.005409795689047314
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:21,226 INFO epoch # 38 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.7-> 0.7 - loss = 0.006096827157307416
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:21,399 INFO epoch # 39 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.7-> 0.7 - loss = 0.006132105423603207
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:21,575 INFO epoch # 40 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.7-> 0.7 - loss = 0.006805103155784309
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:43:21,575 INFO *** epoch 40, rolling-avg-loss (window=10)= 0.006603984763205517
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:21,747 INFO epoch # 41 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.7-> 0.7 - loss = 0.005712921731173992
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:21,922 INFO epoch # 42 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.7-> 0.7 - loss = 0.005626143480185419
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:22,096 INFO epoch # 43 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.7-> 0.7 - loss = 0.007095423643477261
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:22,270 INFO epoch # 44 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.7-> 0.7 - loss = 0.0072983987629413605
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:22,442 INFO epoch # 45 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.7-> 0.7 - loss = 0.005549320776481181
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:22,617 INFO epoch # 46 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.7-> 0.7 - loss = 0.005143142378074117
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:22,789 INFO epoch # 47 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.7-> 0.7 - loss = 0.008727069129236042
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:22,963 INFO epoch # 48 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.7-> 0.7 - loss = 0.01487468951381743
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:23,135 INFO epoch # 49 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.7-> 0.7 - loss = 0.0180664190556854
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:23,309 INFO epoch # 50 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.7-> 0.7 - loss = 0.0064914856338873506
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:43:23,309 INFO *** epoch 50, rolling-avg-loss (window=10)= 0.008458501410495955
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:23,482 INFO epoch # 51 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.7-> 0.7 - loss = 0.00888038077391684
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:23,656 INFO epoch # 52 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.7-> 0.7 - loss = 0.006206700287293643
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:23,840 INFO epoch # 53 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.7-> 0.7 - loss = 0.004906892136204988
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:24,019 INFO epoch # 54 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.7-> 0.7 - loss = 0.005960237933322787
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:24,192 INFO epoch # 55 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.7-> 0.7 - loss = 0.005784411681815982
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:24,365 INFO epoch # 56 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.7-> 0.7 - loss = 0.006673019379377365
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:24,538 INFO epoch # 57 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.7-> 0.7 - loss = 0.006192055414430797
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:24,711 INFO epoch # 58 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.7-> 0.7 - loss = 0.009530825424008071
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:24,883 INFO epoch # 59 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.7-> 0.7 - loss = 0.006537802400998771
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:25,057 INFO epoch # 60 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.7-> 0.7 - loss = 0.006720894714817405
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:43:25,057 INFO *** epoch 60, rolling-avg-loss (window=10)= 0.006739322014618665
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:25,230 INFO epoch # 61 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.7-> 0.7 - loss = 0.008913144818507135
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:25,404 INFO epoch # 62 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.7-> 0.7 - loss = 0.007960516319144517
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:25,577 INFO epoch # 63 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.7-> 0.7 - loss = 0.008108624373562634
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:25,752 INFO epoch # 64 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.7-> 0.5599999999999999 - loss = 0.005829230154631659
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:25,924 INFO epoch # 65 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.5599999999999999-> 0.5599999999999999 - loss = 0.005227174318861216
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:26,098 INFO epoch # 66 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.5599999999999999-> 0.5599999999999999 - loss = 0.006089689559303224
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:26,270 INFO epoch # 67 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.5599999999999999-> 0.5599999999999999 - loss = 0.008073615550529212
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:26,444 INFO epoch # 68 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.5599999999999999-> 0.5599999999999999 - loss = 0.011364691657945514
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:26,618 INFO epoch # 69 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.5599999999999999-> 0.5599999999999999 - loss = 0.005324398283846676
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:26,790 INFO epoch # 70 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.5599999999999999-> 0.5599999999999999 - loss = 0.008236553287133574
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:43:26,791 INFO *** epoch 70, rolling-avg-loss (window=10)= 0.007512763832346536
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:26,964 INFO epoch # 71 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.5599999999999999-> 0.5599999999999999 - loss = 0.006931666226591915
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:27,142 INFO epoch # 72 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.5599999999999999-> 0.5599999999999999 - loss = 0.01535686303395778
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:27,314 INFO epoch # 73 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.5599999999999999-> 0.5599999999999999 - loss = 0.012361592031084001
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:27,488 INFO epoch # 74 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.5599999999999999-> 0.5599999999999999 - loss = 0.0048787865962367505
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:27,661 INFO epoch # 75 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.5599999999999999-> 0.5599999999999999 - loss = 0.006347512011416256
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:27,834 INFO epoch # 76 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.5599999999999999-> 0.5599999999999999 - loss = 0.0059860373148694634
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:28,008 INFO epoch # 77 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.5599999999999999-> 0.5599999999999999 - loss = 0.005281424557324499
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:28,184 INFO epoch # 78 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.5599999999999999-> 0.5599999999999999 - loss = 0.005268772249110043
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:28,355 INFO epoch # 79 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.5599999999999999-> 0.5599999999999999 - loss = 0.006907501840032637
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:28,529 INFO epoch # 80 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.5599999999999999-> 0.5599999999999999 - loss = 0.006831656442955136
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:43:28,530 INFO *** epoch 80, rolling-avg-loss (window=10)= 0.007615181230357848
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:28,702 INFO epoch # 81 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.5599999999999999-> 0.5599999999999999 - loss = 0.005132757010869682
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:28,876 INFO epoch # 82 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.5599999999999999-> 0.5599999999999999 - loss = 0.00503599812509492
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:29,050 INFO epoch # 83 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.5599999999999999-> 0.5599999999999999 - loss = 0.005104957497678697
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:29,223 INFO epoch # 84 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.5599999999999999-> 0.5599999999999999 - loss = 0.004533602448645979
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:29,396 INFO epoch # 85 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.5599999999999999-> 0.5599999999999999 - loss = 0.011726203258149326
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:29,569 INFO epoch # 86 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.5599999999999999-> 0.5599999999999999 - loss = 0.009079837880562991
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:29,741 INFO epoch # 87 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.5599999999999999-> 0.5599999999999999 - loss = 0.003861245175357908
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:29,914 INFO epoch # 88 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.5599999999999999-> 0.5599999999999999 - loss = 0.008049493713770062
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:30,087 INFO epoch # 89 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.5599999999999999-> 0.5599999999999999 - loss = 0.006708447996061295
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:30,261 INFO epoch # 90 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.5599999999999999-> 0.5599999999999999 - loss = 0.011774870159570128
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:43:30,261 INFO *** epoch 90, rolling-avg-loss (window=10)= 0.0071007413265760985
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:30,433 INFO epoch # 91 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.5599999999999999-> 0.5599999999999999 - loss = 0.008055545389652252
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:30,607 INFO epoch # 92 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.5599999999999999-> 0.5599999999999999 - loss = 0.01024325704202056
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:30,780 INFO epoch # 93 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.5599999999999999-> 0.5599999999999999 - loss = 0.00418585907027591
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:30,953 INFO epoch # 94 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.5599999999999999-> 0.5599999999999999 - loss = 0.004045516834594309
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:31,127 INFO epoch # 95 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.5599999999999999-> 0.5599999999999999 - loss = 0.004426567116752267
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:31,301 INFO epoch # 96 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.5599999999999999-> 0.5599999999999999 - loss = 0.004185237048659474
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:31,473 INFO epoch # 97 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.5599999999999999-> 0.5599999999999999 - loss = 0.006322509492747486
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:31,646 INFO epoch # 98 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.5599999999999999-> 0.44799999999999995 - loss = 0.008405009226407856
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:31,818 INFO epoch # 99 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.44799999999999995-> 0.44799999999999995 - loss = 0.006505905883386731
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:31,991 INFO epoch # 100 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.44799999999999995-> 0.44799999999999995 - loss = 0.008867648197337985
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:43:31,991 INFO *** epoch 100, rolling-avg-loss (window=10)= 0.006524305530183483
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:32,165 INFO epoch # 101 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.44799999999999995-> 0.44799999999999995 - loss = 0.0071572953020222485
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:32,338 INFO epoch # 102 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.44799999999999995-> 0.44799999999999995 - loss = 0.004948829591739923
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:32,517 INFO epoch # 103 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.44799999999999995-> 0.44799999999999995 - loss = 0.003661087714135647
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:32,689 INFO epoch # 104 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.44799999999999995-> 0.44799999999999995 - loss = 0.00396154192276299
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:32,861 INFO epoch # 105 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.44799999999999995-> 0.44799999999999995 - loss = 0.006323353562038392
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:33,036 INFO epoch # 106 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.44799999999999995-> 0.44799999999999995 - loss = 0.01304789527785033
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:33,209 INFO epoch # 107 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.44799999999999995-> 0.44799999999999995 - loss = 0.013577450881712139
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:33,382 INFO epoch # 108 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.44799999999999995-> 0.44799999999999995 - loss = 0.008704317093361169
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:33,555 INFO epoch # 109 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.44799999999999995-> 0.44799999999999995 - loss = 0.006855014828033745
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:33,728 INFO epoch # 110 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.44799999999999995-> 0.44799999999999995 - loss = 0.015898133744485676
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:43:33,728 INFO *** epoch 110, rolling-avg-loss (window=10)= 0.008413491991814227
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:33,915 INFO epoch # 111 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.44799999999999995-> 0.44799999999999995 - loss = 0.0102230942575261
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:34,102 INFO epoch # 112 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.44799999999999995-> 0.44799999999999995 - loss = 0.011042084195651114
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:34,280 INFO epoch # 113 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.44799999999999995-> 0.44799999999999995 - loss = 0.011359870550222695
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:34,453 INFO epoch # 114 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.44799999999999995-> 0.3584 - loss = 0.005345523823052645
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:34,627 INFO epoch # 115 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.3584-> 0.3584 - loss = 0.008963347296230495
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:34,802 INFO epoch # 116 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.3584-> 0.3584 - loss = 0.006512033520266414
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:34,974 INFO epoch # 117 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.3584-> 0.3584 - loss = 0.005606214865110815
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:35,148 INFO epoch # 118 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.3584-> 0.3584 - loss = 0.004452272958587855
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:35,321 INFO epoch # 119 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.3584-> 0.3584 - loss = 0.0035751560353673995
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:35,495 INFO epoch # 120 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.3584-> 0.3584 - loss = 0.00549364578910172
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:43:35,495 INFO *** epoch 120, rolling-avg-loss (window=10)= 0.007257324329111725
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:35,669 INFO epoch # 121 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.3584-> 0.3584 - loss = 0.0035367037635296583
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:35,843 INFO epoch # 122 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.3584-> 0.3584 - loss = 0.004790735896676779
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:36,017 INFO epoch # 123 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.3584-> 0.3584 - loss = 0.004167176899500191
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:36,190 INFO epoch # 124 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.3584-> 0.3584 - loss = 0.005569405737333
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:36,362 INFO epoch # 125 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.3584-> 0.3584 - loss = 0.0051266319351270795
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:36,536 INFO epoch # 126 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.3584-> 0.3584 - loss = 0.004899579449556768
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:36,708 INFO epoch # 127 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.3584-> 0.3584 - loss = 0.006115961470641196
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:36,881 INFO epoch # 128 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.3584-> 0.3584 - loss = 0.010774477617815137
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:37,054 INFO epoch # 129 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.3584-> 0.3584 - loss = 0.006441559002269059
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:37,230 INFO epoch # 130 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.3584-> 0.3584 - loss = 0.00457797764101997
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:43:37,230 INFO *** epoch 130, rolling-avg-loss (window=10)= 0.005600020941346884
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:37,403 INFO epoch # 131 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.3584-> 0.3584 - loss = 0.0053134841145947576
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:37,576 INFO epoch # 132 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.3584-> 0.28672000000000003 - loss = 0.006514530803542584
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:37,748 INFO epoch # 133 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.28672000000000003-> 0.28672000000000003 - loss = 0.009910182445310056
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:37,922 INFO epoch # 134 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.28672000000000003-> 0.28672000000000003 - loss = 0.002940488135209307
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:38,095 INFO epoch # 135 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.28672000000000003-> 0.28672000000000003 - loss = 0.0026732094993349165
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:38,269 INFO epoch # 136 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.28672000000000003-> 0.28672000000000003 - loss = 0.004361733153928071
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:38,442 INFO epoch # 137 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.28672000000000003-> 0.28672000000000003 - loss = 0.004789192753378302
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:38,616 INFO epoch # 138 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.28672000000000003-> 0.28672000000000003 - loss = 0.004354024073109031
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:38,790 INFO epoch # 139 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.28672000000000003-> 0.28672000000000003 - loss = 0.004100280304555781
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:38,976 INFO epoch # 140 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.28672000000000003-> 0.28672000000000003 - loss = 0.0038687430787831545
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:43:38,976 INFO *** epoch 140, rolling-avg-loss (window=10)= 0.004882586836174596
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:39,148 INFO epoch # 141 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.28672000000000003-> 0.28672000000000003 - loss = 0.004621989617589861
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:39,323 INFO epoch # 142 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.28672000000000003-> 0.28672000000000003 - loss = 0.0053323638858273625
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:39,498 INFO epoch # 143 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.28672000000000003-> 0.28672000000000003 - loss = 0.005333868582965806
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:39,674 INFO epoch # 144 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.28672000000000003-> 0.28672000000000003 - loss = 0.005847967870067805
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:39,847 INFO epoch # 145 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.28672000000000003-> 0.28672000000000003 - loss = 0.006401340913726017
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:40,024 INFO epoch # 146 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.28672000000000003-> 0.22937600000000002 - loss = 0.00775475543923676
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:40,197 INFO epoch # 147 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.22937600000000002-> 0.22937600000000002 - loss = 0.00760594371240586
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:40,371 INFO epoch # 148 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.22937600000000002-> 0.22937600000000002 - loss = 0.008963231462985277
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:40,544 INFO epoch # 149 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.22937600000000002-> 0.22937600000000002 - loss = 0.007537588593550026
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:40,718 INFO epoch # 150 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.22937600000000002-> 0.22937600000000002 - loss = 0.00519298727158457
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:43:40,718 INFO *** epoch 150, rolling-avg-loss (window=10)= 0.006459203734993935
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:40,891 INFO epoch # 151 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.22937600000000002-> 0.22937600000000002 - loss = 0.00505865243030712
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:41,065 INFO epoch # 152 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.22937600000000002-> 0.22937600000000002 - loss = 0.005095728673040867
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:41,238 INFO epoch # 153 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.22937600000000002-> 0.22937600000000002 - loss = 0.004446995561011136
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:41,413 INFO epoch # 154 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.22937600000000002-> 0.22937600000000002 - loss = 0.003905592660885304
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:41,586 INFO epoch # 155 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.22937600000000002-> 0.22937600000000002 - loss = 0.003082361363340169
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:41,760 INFO epoch # 156 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.22937600000000002-> 0.22937600000000002 - loss = 0.0029433449963107705
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:41,933 INFO epoch # 157 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.22937600000000002-> 0.18350080000000002 - loss = 0.005335473571904004
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:42,107 INFO epoch # 158 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.18350080000000002-> 0.18350080000000002 - loss = 0.0031751453643664718
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:42,282 INFO epoch # 159 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.18350080000000002-> 0.18350080000000002 - loss = 0.005872545123565942
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:42,455 INFO epoch # 160 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.18350080000000002-> 0.18350080000000002 - loss = 0.004414001887198538
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:43:42,456 INFO *** epoch 160, rolling-avg-loss (window=10)= 0.004332984163193032
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:42,628 INFO epoch # 161 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.18350080000000002-> 0.18350080000000002 - loss = 0.0037773847579956055
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:42,801 INFO epoch # 162 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.18350080000000002-> 0.18350080000000002 - loss = 0.0037258565425872803
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:42,973 INFO epoch # 163 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.18350080000000002-> 0.18350080000000002 - loss = 0.0029492519970517606
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:43,147 INFO epoch # 164 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.18350080000000002-> 0.18350080000000002 - loss = 0.005629630584735423
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:43,320 INFO epoch # 165 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.18350080000000002-> 0.18350080000000002 - loss = 0.008824658812955022
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:43,494 INFO epoch # 166 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.18350080000000002-> 0.18350080000000002 - loss = 0.006911371950991452
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:43,666 INFO epoch # 167 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.18350080000000002-> 0.18350080000000002 - loss = 0.0033864036668092012
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:43,840 INFO epoch # 168 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.18350080000000002-> 0.14680064 - loss = 0.004783894342835993
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:44,014 INFO epoch # 169 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.14680064-> 0.14680064 - loss = 0.007829447160474956
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:44,188 INFO epoch # 170 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.14680064-> 0.14680064 - loss = 0.006196032511070371
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:43:44,188 INFO *** epoch 170, rolling-avg-loss (window=10)= 0.005401393232750707
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:44,361 INFO epoch # 171 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.14680064-> 0.14680064 - loss = 0.006892713950946927
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:44,536 INFO epoch # 172 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.14680064-> 0.14680064 - loss = 0.003023577737621963
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:44,708 INFO epoch # 173 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.14680064-> 0.14680064 - loss = 0.004144295409787446
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:44,893 INFO epoch # 174 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.14680064-> 0.14680064 - loss = 0.005972798739094287
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:45,067 INFO epoch # 175 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.14680064-> 0.14680064 - loss = 0.004045746172778308
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:45,241 INFO epoch # 176 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.14680064-> 0.14680064 - loss = 0.004083280044142157
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:45,413 INFO epoch # 177 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.14680064-> 0.14680064 - loss = 0.004319604253396392
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:45,588 INFO epoch # 178 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.14680064-> 0.14680064 - loss = 0.004680321202613413
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:45,762 INFO epoch # 179 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.14680064-> 0.11744051200000001 - loss = 0.003592049819417298
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:45,936 INFO epoch # 180 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.11744051200000001-> 0.11744051200000001 - loss = 0.00390743714524433
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:43:45,936 INFO *** epoch 180, rolling-avg-loss (window=10)= 0.004466182447504252
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:46,109 INFO epoch # 181 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.11744051200000001-> 0.11744051200000001 - loss = 0.002845752169378102
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:46,284 INFO epoch # 182 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.11744051200000001-> 0.11744051200000001 - loss = 0.0037104421644471586
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:46,459 INFO epoch # 183 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.11744051200000001-> 0.11744051200000001 - loss = 0.0033837624068837613
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:46,634 INFO epoch # 184 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.11744051200000001-> 0.11744051200000001 - loss = 0.002595627593109384
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:46,806 INFO epoch # 185 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.11744051200000001-> 0.11744051200000001 - loss = 0.003788767382502556
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:46,981 INFO epoch # 186 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.11744051200000001-> 0.11744051200000001 - loss = 0.0036076322430744767
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:47,154 INFO epoch # 187 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.11744051200000001-> 0.11744051200000001 - loss = 0.003852628287859261
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:47,327 INFO epoch # 188 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.11744051200000001-> 0.11744051200000001 - loss = 0.00674318743404001
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:47,501 INFO epoch # 189 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.11744051200000001-> 0.11744051200000001 - loss = 0.0053355779382400215
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:47,677 INFO epoch # 190 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.11744051200000001-> 0.11744051200000001 - loss = 0.004645246255677193
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:43:47,677 INFO *** epoch 190, rolling-avg-loss (window=10)= 0.004050862387521193
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:47,849 INFO epoch # 191 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.11744051200000001-> 0.11744051200000001 - loss = 0.0033192038245033473
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:48,024 INFO epoch # 192 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.11744051200000001-> 0.11744051200000001 - loss = 0.0041103503899648786
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:48,197 INFO epoch # 193 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.11744051200000001-> 0.11744051200000001 - loss = 0.004885097965598106
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:48,370 INFO epoch # 194 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.11744051200000001-> 0.11744051200000001 - loss = 0.00427786132786423
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:48,543 INFO epoch # 195 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.11744051200000001-> 0.09395240960000001 - loss = 0.003570633300114423
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:48,716 INFO epoch # 196 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.09395240960000001-> 0.09395240960000001 - loss = 0.0069459599908441305
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:48,889 INFO epoch # 197 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.09395240960000001-> 0.09395240960000001 - loss = 0.008302047965116799
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:49,064 INFO epoch # 198 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.09395240960000001-> 0.09395240960000001 - loss = 0.006370900839101523
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:49,235 INFO epoch # 199 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.09395240960000001-> 0.09395240960000001 - loss = 0.0031441367464140058
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:49,408 INFO epoch # 200 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.09395240960000001-> 0.09395240960000001 - loss = 0.004514092579483986
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:43:49,408 INFO *** epoch 200, rolling-avg-loss (window=10)= 0.004944028492900543
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:49,580 INFO epoch # 201 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.09395240960000001-> 0.09395240960000001 - loss = 0.0031866871286183596
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:49,754 INFO epoch # 202 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.09395240960000001-> 0.09395240960000001 - loss = 0.00496965495403856
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:49,926 INFO epoch # 203 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.09395240960000001-> 0.09395240960000001 - loss = 0.00264383977628313
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:50,103 INFO epoch # 204 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.09395240960000001-> 0.09395240960000001 - loss = 0.0034239633823744953
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:50,275 INFO epoch # 205 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.09395240960000001-> 0.09395240960000001 - loss = 0.004101711179828271
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:50,451 INFO epoch # 206 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.09395240960000001-> 0.07516192768000002 - loss = 0.0045486376620829105
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:50,625 INFO epoch # 207 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.07516192768000002-> 0.07516192768000002 - loss = 0.0027522548334673047
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:50,798 INFO epoch # 208 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.07516192768000002-> 0.07516192768000002 - loss = 0.003404811315704137
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:50,970 INFO epoch # 209 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.07516192768000002-> 0.07516192768000002 - loss = 0.003311614040285349
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:51,144 INFO epoch # 210 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.07516192768000002-> 0.07516192768000002 - loss = 0.004536197986453772
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:43:51,144 INFO *** epoch 210, rolling-avg-loss (window=10)= 0.003687937225913629
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:51,318 INFO epoch # 211 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.07516192768000002-> 0.07516192768000002 - loss = 0.002901142870541662
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:51,491 INFO epoch # 212 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.07516192768000002-> 0.07516192768000002 - loss = 0.0033728477428667247
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:51,665 INFO epoch # 213 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.07516192768000002-> 0.07516192768000002 - loss = 0.003100901551079005
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:51,839 INFO epoch # 214 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.07516192768000002-> 0.07516192768000002 - loss = 0.004690475296229124
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:52,014 INFO epoch # 215 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.07516192768000002-> 0.07516192768000002 - loss = 0.003199163591489196
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:52,188 INFO epoch # 216 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.07516192768000002-> 0.07516192768000002 - loss = 0.0021992676047375426
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:52,360 INFO epoch # 217 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.07516192768000002-> 0.07516192768000002 - loss = 0.0029265289194881916
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:52,537 INFO epoch # 218 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.07516192768000002-> 0.07516192768000002 - loss = 0.00312093150569126
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:52,710 INFO epoch # 219 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.07516192768000002-> 0.07516192768000002 - loss = 0.0027599255372479092
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:52,889 INFO epoch # 220 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.07516192768000002-> 0.07516192768000002 - loss = 0.0021952428069198504
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:43:52,890 INFO *** epoch 220, rolling-avg-loss (window=10)= 0.0030466427426290464
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:53,095 INFO epoch # 221 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.07516192768000002-> 0.07516192768000002 - loss = 0.0033428656752221286
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:53,297 INFO epoch # 222 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.07516192768000002-> 0.07516192768000002 - loss = 0.0038107442669570446
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:53,472 INFO epoch # 223 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.07516192768000002-> 0.07516192768000002 - loss = 0.005371374485548586
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:53,644 INFO epoch # 224 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.07516192768000002-> 0.07516192768000002 - loss = 0.0022277764801401645
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:53,818 INFO epoch # 225 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.07516192768000002-> 0.07516192768000002 - loss = 0.0030423612042795867
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:53,993 INFO epoch # 226 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.07516192768000002-> 0.07516192768000002 - loss = 0.0025888350210152566
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:54,166 INFO epoch # 227 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.07516192768000002-> 0.07516192768000002 - loss = 0.0030690315761603415
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:54,340 INFO epoch # 228 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.07516192768000002-> 0.07516192768000002 - loss = 0.002310100186150521
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:54,513 INFO epoch # 229 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.07516192768000002-> 0.07516192768000002 - loss = 0.002752806118223816
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:54,685 INFO epoch # 230 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.07516192768000002-> 0.07516192768000002 - loss = 0.0034934209543280303
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:43:54,685 INFO *** epoch 230, rolling-avg-loss (window=10)= 0.0032009315968025477
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:54,873 INFO epoch # 231 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.07516192768000002-> 0.060129542144000014 - loss = 0.0022799646540079266
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:55,046 INFO epoch # 232 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.060129542144000014-> 0.060129542144000014 - loss = 0.003804168140050024
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:55,220 INFO epoch # 233 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.060129542144000014-> 0.060129542144000014 - loss = 0.0029413009178824723
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:55,393 INFO epoch # 234 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.060129542144000014-> 0.060129542144000014 - loss = 0.007425208168569952
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:55,568 INFO epoch # 235 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.060129542144000014-> 0.060129542144000014 - loss = 0.005301417404552922
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:55,740 INFO epoch # 236 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.060129542144000014-> 0.060129542144000014 - loss = 0.00470849045086652
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:55,915 INFO epoch # 237 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.060129542144000014-> 0.060129542144000014 - loss = 0.003793660900555551
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:56,090 INFO epoch # 238 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.060129542144000014-> 0.060129542144000014 - loss = 0.0029490109300240874
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:56,265 INFO epoch # 239 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.060129542144000014-> 0.060129542144000014 - loss = 0.005059681774582714
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:56,438 INFO epoch # 240 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.060129542144000014-> 0.060129542144000014 - loss = 0.0023868826683610678
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:43:56,438 INFO *** epoch 240, rolling-avg-loss (window=10)= 0.004064978600945323
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:56,612 INFO epoch # 241 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.060129542144000014-> 0.060129542144000014 - loss = 0.008872137550497428
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:56,785 INFO epoch # 242 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.060129542144000014-> 0.04810363371520002 - loss = 0.004272966994903982
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:56,959 INFO epoch # 243 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.04810363371520002-> 0.04810363371520002 - loss = 0.0031993687371141277
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:57,132 INFO epoch # 244 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.04810363371520002-> 0.04810363371520002 - loss = 0.0038383047212846577
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:57,305 INFO epoch # 245 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.04810363371520002-> 0.04810363371520002 - loss = 0.007561333128251135
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:57,478 INFO epoch # 246 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.04810363371520002-> 0.04810363371520002 - loss = 0.003706177230924368
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:57,653 INFO epoch # 247 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.04810363371520002-> 0.04810363371520002 - loss = 0.0034800376161001623
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:57,826 INFO epoch # 248 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.04810363371520002-> 0.04810363371520002 - loss = 0.006938756909221411
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:58,001 INFO epoch # 249 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.04810363371520002-> 0.04810363371520002 - loss = 0.0031765400781296194
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:58,174 INFO epoch # 250 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.04810363371520002-> 0.04810363371520002 - loss = 0.005235410004388541
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:43:58,174 INFO *** epoch 250, rolling-avg-loss (window=10)= 0.005028103297081543
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:58,348 INFO epoch # 251 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.04810363371520002-> 0.04810363371520002 - loss = 0.002696686984563712
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:58,521 INFO epoch # 252 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.04810363371520002-> 0.04810363371520002 - loss = 0.0035698094579856843
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:58,695 INFO epoch # 253 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.04810363371520002-> 0.038482906972160016 - loss = 0.004833029757719487
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:58,866 INFO epoch # 254 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.038482906972160016-> 0.038482906972160016 - loss = 0.004031138378195465
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:59,041 INFO epoch # 255 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.038482906972160016-> 0.038482906972160016 - loss = 0.003917401772923768
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:59,214 INFO epoch # 256 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.038482906972160016-> 0.038482906972160016 - loss = 0.003286070888862014
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:59,388 INFO epoch # 257 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.038482906972160016-> 0.038482906972160016 - loss = 0.0032532301265746355
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:59,562 INFO epoch # 258 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.038482906972160016-> 0.038482906972160016 - loss = 0.0039581890450790524
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:59,735 INFO epoch # 259 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.038482906972160016-> 0.038482906972160016 - loss = 0.0029702112078666687
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:43:59,908 INFO epoch # 260 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.038482906972160016-> 0.038482906972160016 - loss = 0.005413163511548191
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:43:59,908 INFO *** epoch 260, rolling-avg-loss (window=10)= 0.003792893113131868
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:00,097 INFO epoch # 261 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.038482906972160016-> 0.038482906972160016 - loss = 0.003084140771534294
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:00,269 INFO epoch # 262 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.038482906972160016-> 0.038482906972160016 - loss = 0.005504748085513711
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:00,442 INFO epoch # 263 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.038482906972160016-> 0.038482906972160016 - loss = 0.003513181523885578
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:00,616 INFO epoch # 264 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.038482906972160016-> 0.030786325577728015 - loss = 0.0035233238013461232
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:00,790 INFO epoch # 265 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.030786325577728015-> 0.030786325577728015 - loss = 0.0028355132089927793
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:00,963 INFO epoch # 266 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.030786325577728015-> 0.030786325577728015 - loss = 0.0028292119677644223
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:01,136 INFO epoch # 267 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.030786325577728015-> 0.030786325577728015 - loss = 0.007162247959058732
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:01,308 INFO epoch # 268 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.030786325577728015-> 0.030786325577728015 - loss = 0.006512169959023595
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:01,481 INFO epoch # 269 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.030786325577728015-> 0.030786325577728015 - loss = 0.004132156085688621
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:01,654 INFO epoch # 270 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.030786325577728015-> 0.030786325577728015 - loss = 0.0031521081982646137
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:44:01,654 INFO *** epoch 270, rolling-avg-loss (window=10)= 0.004224880156107247
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:01,828 INFO epoch # 271 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.030786325577728015-> 0.030786325577728015 - loss = 0.0027185073704458773
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:02,001 INFO epoch # 272 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.030786325577728015-> 0.030786325577728015 - loss = 0.0033190702670253813
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:02,175 INFO epoch # 273 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.030786325577728015-> 0.030786325577728015 - loss = 0.0027445072773844004
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:02,347 INFO epoch # 274 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.030786325577728015-> 0.030786325577728015 - loss = 0.0034526505041867495
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:02,521 INFO epoch # 275 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.030786325577728015-> 0.02462906046218241 - loss = 0.0027083182940259576
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:02,694 INFO epoch # 276 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.02462906046218241-> 0.02462906046218241 - loss = 0.002756036148639396
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:02,868 INFO epoch # 277 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.02462906046218241-> 0.02462906046218241 - loss = 0.005674905958585441
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:03,043 INFO epoch # 278 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.02462906046218241-> 0.02462906046218241 - loss = 0.002647187531692907
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:03,216 INFO epoch # 279 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.02462906046218241-> 0.02462906046218241 - loss = 0.002848190604709089
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:03,390 INFO epoch # 280 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.02462906046218241-> 0.02462906046218241 - loss = 0.0022128946002339944
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:44:03,390 INFO *** epoch 280, rolling-avg-loss (window=10)= 0.0031082268556929193
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:03,605 INFO epoch # 281 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.02462906046218241-> 0.02462906046218241 - loss = 0.003131061908788979
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:03,787 INFO epoch # 282 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.02462906046218241-> 0.02462906046218241 - loss = 0.00240035995375365
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:03,960 INFO epoch # 283 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.02462906046218241-> 0.02462906046218241 - loss = 0.0033583820331841707
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:04,134 INFO epoch # 284 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.02462906046218241-> 0.02462906046218241 - loss = 0.0028518796898424625
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:04,307 INFO epoch # 285 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.02462906046218241-> 0.02462906046218241 - loss = 0.0061203413642942905
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:04,479 INFO epoch # 286 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.02462906046218241-> 0.01970324836974593 - loss = 0.0030624796054325998
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:04,659 INFO epoch # 287 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.01970324836974593-> 0.01970324836974593 - loss = 0.0033300572831649333
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:04,831 INFO epoch # 288 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.01970324836974593-> 0.01970324836974593 - loss = 0.004039381572511047
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:05,005 INFO epoch # 289 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.01970324836974593-> 0.01970324836974593 - loss = 0.0027340620290488005
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:05,179 INFO epoch # 290 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.01970324836974593-> 0.01970324836974593 - loss = 0.0031037595472298563
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:44:05,179 INFO *** epoch 290, rolling-avg-loss (window=10)= 0.003413176498725079
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:05,353 INFO epoch # 291 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.01970324836974593-> 0.01970324836974593 - loss = 0.004670642374549061
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:05,529 INFO epoch # 292 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.01970324836974593-> 0.01970324836974593 - loss = 0.004226411052513868
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:05,703 INFO epoch # 293 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.01970324836974593-> 0.01970324836974593 - loss = 0.00384553027106449
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:05,886 INFO epoch # 294 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.01970324836974593-> 0.01970324836974593 - loss = 0.002601304484414868
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:06,062 INFO epoch # 295 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.01970324836974593-> 0.01970324836974593 - loss = 0.005928177561145276
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:06,235 INFO epoch # 296 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.01970324836974593-> 0.01970324836974593 - loss = 0.004510002676397562
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:06,409 INFO epoch # 297 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.01970324836974593-> 0.015762598695796746 - loss = 0.004291267192456871
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:06,588 INFO epoch # 298 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.015762598695796746-> 0.015762598695796746 - loss = 0.0030398924718610942
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:06,762 INFO epoch # 299 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.015762598695796746-> 0.015762598695796746 - loss = 0.0022625897254329175
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:06,935 INFO epoch # 300 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.015762598695796746-> 0.015762598695796746 - loss = 0.003718895255587995
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:44:06,935 INFO *** epoch 300, rolling-avg-loss (window=10)= 0.0039094713065424
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:07,121 INFO epoch # 301 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.015762598695796746-> 0.015762598695796746 - loss = 0.004702177480794489
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:07,294 INFO epoch # 302 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.015762598695796746-> 0.015762598695796746 - loss = 0.00319818127900362
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:07,467 INFO epoch # 303 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.015762598695796746-> 0.015762598695796746 - loss = 0.003736173763172701
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:07,641 INFO epoch # 304 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.015762598695796746-> 0.015762598695796746 - loss = 0.00325608451385051
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:07,815 INFO epoch # 305 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.015762598695796746-> 0.015762598695796746 - loss = 0.004453906847629696
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:07,988 INFO epoch # 306 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.015762598695796746-> 0.015762598695796746 - loss = 0.005281313962768763
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:08,162 INFO epoch # 307 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.015762598695796746-> 0.015762598695796746 - loss = 0.0030801397806499153
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:08,333 INFO epoch # 308 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.015762598695796746-> 0.012610078956637398 - loss = 0.006766871840227395
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:08,506 INFO epoch # 309 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.012610078956637398-> 0.012610078956637398 - loss = 0.003508353780489415
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:08,680 INFO epoch # 310 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.012610078956637398-> 0.012610078956637398 - loss = 0.004253795312251896
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:44:08,680 INFO *** epoch 310, rolling-avg-loss (window=10)= 0.00422369985608384
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:08,856 INFO epoch # 311 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.012610078956637398-> 0.012610078956637398 - loss = 0.002391309360973537
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:09,030 INFO epoch # 312 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.012610078956637398-> 0.012610078956637398 - loss = 0.003382178721949458
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:09,203 INFO epoch # 313 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.012610078956637398-> 0.012610078956637398 - loss = 0.007194762700237334
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:09,376 INFO epoch # 314 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.012610078956637398-> 0.012610078956637398 - loss = 0.0029906867421232164
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:09,549 INFO epoch # 315 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.012610078956637398-> 0.012610078956637398 - loss = 0.005533882707823068
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:09,723 INFO epoch # 316 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.012610078956637398-> 0.012610078956637398 - loss = 0.005052680324297398
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:09,896 INFO epoch # 317 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.012610078956637398-> 0.012610078956637398 - loss = 0.004018951352918521
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:10,069 INFO epoch # 318 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.012610078956637398-> 0.012610078956637398 - loss = 0.0031955617596395314
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:10,243 INFO epoch # 319 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.012610078956637398-> 0.01008806316530992 - loss = 0.0031489631510339677
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:10,416 INFO epoch # 320 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.01008806316530992-> 0.01008806316530992 - loss = 0.0030226443777792156
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:44:10,417 INFO *** epoch 320, rolling-avg-loss (window=10)= 0.003993162119877524
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:10,592 INFO epoch # 321 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.01008806316530992-> 0.01008806316530992 - loss = 0.004890758835244924
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:10,764 INFO epoch # 322 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.01008806316530992-> 0.01008806316530992 - loss = 0.0023794021108187735
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:10,942 INFO epoch # 323 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.01008806316530992-> 0.01008806316530992 - loss = 0.0025115608295891434
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:11,116 INFO epoch # 324 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.01008806316530992-> 0.01008806316530992 - loss = 0.0025900457985699177
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:11,289 INFO epoch # 325 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.01008806316530992-> 0.01008806316530992 - loss = 0.002507408382371068
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:11,463 INFO epoch # 326 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.01008806316530992-> 0.01008806316530992 - loss = 0.002936671837233007
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:11,639 INFO epoch # 327 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.01008806316530992-> 0.01008806316530992 - loss = 0.0023592843208462
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:11,815 INFO epoch # 328 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.01008806316530992-> 0.01008806316530992 - loss = 0.0031759902485646307
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:11,990 INFO epoch # 329 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.01008806316530992-> 0.01008806316530992 - loss = 0.0035088604781776667
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:12,162 INFO epoch # 330 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.01008806316530992-> 0.008070450532247937 - loss = 0.0035079479566775262
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:44:12,162 INFO *** epoch 330, rolling-avg-loss (window=10)= 0.003036793079809286
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:12,339 INFO epoch # 331 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.008070450532247937-> 0.008070450532247937 - loss = 0.002922677871538326
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:12,512 INFO epoch # 332 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.008070450532247937-> 0.008070450532247937 - loss = 0.0027108060312457383
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:12,688 INFO epoch # 333 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.008070450532247937-> 0.008070450532247937 - loss = 0.0036119259311817586
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:12,864 INFO epoch # 334 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.008070450532247937-> 0.008070450532247937 - loss = 0.0033329298603348434
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:13,042 INFO epoch # 335 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.008070450532247937-> 0.008070450532247937 - loss = 0.003532148548401892
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:13,215 INFO epoch # 336 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.008070450532247937-> 0.008070450532247937 - loss = 0.0027186413644813
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:13,390 INFO epoch # 337 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.008070450532247937-> 0.008070450532247937 - loss = 0.005747302377130836
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:13,563 INFO epoch # 338 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.008070450532247937-> 0.008070450532247937 - loss = 0.0031568410631734878
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:13,738 INFO epoch # 339 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.008070450532247937-> 0.008070450532247937 - loss = 0.002632064337376505
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:13,911 INFO epoch # 340 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.008070450532247937-> 0.008070450532247937 - loss = 0.0026792241842485964
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:44:13,912 INFO *** epoch 340, rolling-avg-loss (window=10)= 0.0033044561569113284
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:14,087 INFO epoch # 341 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.008070450532247937-> 0.006456360425798349 - loss = 0.002817646774929017
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:14,263 INFO epoch # 342 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.006456360425798349-> 0.006456360425798349 - loss = 0.0041359454626217484
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:14,437 INFO epoch # 343 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.006456360425798349-> 0.006456360425798349 - loss = 0.0024234763404820114
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:14,614 INFO epoch # 344 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.006456360425798349-> 0.006456360425798349 - loss = 0.0025319935230072588
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:14,793 INFO epoch # 345 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.006456360425798349-> 0.006456360425798349 - loss = 0.002901261148508638
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:14,967 INFO epoch # 346 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.006456360425798349-> 0.006456360425798349 - loss = 0.004485771467443556
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:15,143 INFO epoch # 347 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.006456360425798349-> 0.006456360425798349 - loss = 0.003622382879257202
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:15,316 INFO epoch # 348 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.006456360425798349-> 0.006456360425798349 - loss = 0.0028337048133835196
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:15,490 INFO epoch # 349 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.006456360425798349-> 0.006456360425798349 - loss = 0.003399659413844347
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:15,664 INFO epoch # 350 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.006456360425798349-> 0.006456360425798349 - loss = 0.004665771091822535
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:44:15,664 INFO *** epoch 350, rolling-avg-loss (window=10)= 0.0033817612915299834
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:15,852 INFO epoch # 351 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.006456360425798349-> 0.006456360425798349 - loss = 0.0031338089029304683
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:16,035 INFO epoch # 352 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.006456360425798349-> 0.0051650883406386796 - loss = 0.0028853186522610486
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:16,211 INFO epoch # 353 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0051650883406386796-> 0.0051650883406386796 - loss = 0.00563322874950245
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:16,384 INFO epoch # 354 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0051650883406386796-> 0.0051650883406386796 - loss = 0.004175085428869352
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:16,558 INFO epoch # 355 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0051650883406386796-> 0.0051650883406386796 - loss = 0.0038107463624328375
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:16,730 INFO epoch # 356 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0051650883406386796-> 0.0051650883406386796 - loss = 0.005996509862598032
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:16,904 INFO epoch # 357 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0051650883406386796-> 0.0051650883406386796 - loss = 0.003022448276169598
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:17,079 INFO epoch # 358 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0051650883406386796-> 0.0051650883406386796 - loss = 0.003150709468172863
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:17,255 INFO epoch # 359 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0051650883406386796-> 0.0051650883406386796 - loss = 0.00797485065413639
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:17,428 INFO epoch # 360 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0051650883406386796-> 0.0051650883406386796 - loss = 0.005594077723799273
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:44:17,428 INFO *** epoch 360, rolling-avg-loss (window=10)= 0.004537678408087231
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:17,604 INFO epoch # 361 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0051650883406386796-> 0.0051650883406386796 - loss = 0.0034047116641886532
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:17,777 INFO epoch # 362 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0051650883406386796-> 0.0051650883406386796 - loss = 0.002428633684758097
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:17,952 INFO epoch # 363 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0051650883406386796-> 0.0041320706725109435 - loss = 0.0028992784791626036
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:18,127 INFO epoch # 364 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0041320706725109435-> 0.0041320706725109435 - loss = 0.0022946061799302697
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:18,302 INFO epoch # 365 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0041320706725109435-> 0.0041320706725109435 - loss = 0.0027225141529925168
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:18,476 INFO epoch # 366 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0041320706725109435-> 0.0041320706725109435 - loss = 0.002372654911596328
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:18,654 INFO epoch # 367 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0041320706725109435-> 0.0041320706725109435 - loss = 0.002889769442845136
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:18,834 INFO epoch # 368 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0041320706725109435-> 0.0041320706725109435 - loss = 0.005309228959959
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:19,012 INFO epoch # 369 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0041320706725109435-> 0.0041320706725109435 - loss = 0.0056968090939335525
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:19,187 INFO epoch # 370 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0041320706725109435-> 0.0041320706725109435 - loss = 0.0035547110601328313
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:44:19,187 INFO *** epoch 370, rolling-avg-loss (window=10)= 0.0033572917629498987
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:19,363 INFO epoch # 371 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0041320706725109435-> 0.0041320706725109435 - loss = 0.0025736272509675473
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:19,538 INFO epoch # 372 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0041320706725109435-> 0.0041320706725109435 - loss = 0.003655534063000232
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:19,713 INFO epoch # 373 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0041320706725109435-> 0.0041320706725109435 - loss = 0.002400677098194137
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:19,888 INFO epoch # 374 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0041320706725109435-> 0.003305656538008755 - loss = 0.00331975583685562
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:20,065 INFO epoch # 375 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.003305656538008755-> 0.003305656538008755 - loss = 0.0035052171151619405
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:20,238 INFO epoch # 376 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.003305656538008755-> 0.003305656538008755 - loss = 0.007523912121541798
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:20,412 INFO epoch # 377 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.003305656538008755-> 0.003305656538008755 - loss = 0.0022994947503320873
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:20,585 INFO epoch # 378 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.003305656538008755-> 0.003305656538008755 - loss = 0.002789304358884692
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:20,760 INFO epoch # 379 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.003305656538008755-> 0.003305656538008755 - loss = 0.0025586452684365213
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:20,934 INFO epoch # 380 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.003305656538008755-> 0.003305656538008755 - loss = 0.0023445175029337406
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:44:20,934 INFO *** epoch 380, rolling-avg-loss (window=10)= 0.0032970685366308316
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:21,114 INFO epoch # 381 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.003305656538008755-> 0.003305656538008755 - loss = 0.002285740862134844
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:21,287 INFO epoch # 382 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.003305656538008755-> 0.003305656538008755 - loss = 0.004639450926333666
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:21,461 INFO epoch # 383 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.003305656538008755-> 0.003305656538008755 - loss = 0.0026069243904203176
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:21,651 INFO epoch # 384 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.003305656538008755-> 0.003305656538008755 - loss = 0.004341507679782808
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:21,840 INFO epoch # 385 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.003305656538008755-> 0.0026445252304070042 - loss = 0.002838045416865498
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:22,012 INFO epoch # 386 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0026445252304070042-> 0.0026445252304070042 - loss = 0.002443952893372625
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:22,187 INFO epoch # 387 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0026445252304070042-> 0.0026445252304070042 - loss = 0.002476245746947825
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:22,360 INFO epoch # 388 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0026445252304070042-> 0.0026445252304070042 - loss = 0.003926266625057906
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:22,535 INFO epoch # 389 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0026445252304070042-> 0.0026445252304070042 - loss = 0.0027340661035850644
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:22,709 INFO epoch # 390 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0026445252304070042-> 0.0026445252304070042 - loss = 0.004152411769609898
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:44:22,710 INFO *** epoch 390, rolling-avg-loss (window=10)= 0.0032444612414110454
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:22,883 INFO epoch # 391 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0026445252304070042-> 0.0026445252304070042 - loss = 0.005430446180980653
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:23,056 INFO epoch # 392 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0026445252304070042-> 0.0026445252304070042 - loss = 0.004783093987498432
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:23,229 INFO epoch # 393 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0026445252304070042-> 0.0026445252304070042 - loss = 0.002282758505316451
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:23,402 INFO epoch # 394 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0026445252304070042-> 0.0026445252304070042 - loss = 0.0027577614528127015
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:23,577 INFO epoch # 395 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0026445252304070042-> 0.0026445252304070042 - loss = 0.005791350908111781
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:23,753 INFO epoch # 396 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0026445252304070042-> 0.0021156201843256033 - loss = 0.004854405182413757
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:23,926 INFO epoch # 397 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0021156201843256033-> 0.0021156201843256033 - loss = 0.004119857359910384
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:24,100 INFO epoch # 398 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0021156201843256033-> 0.0021156201843256033 - loss = 0.004527173761744052
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:24,274 INFO epoch # 399 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0021156201843256033-> 0.0021156201843256033 - loss = 0.0027555236301850528
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:24,446 INFO epoch # 400 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0021156201843256033-> 0.0021156201843256033 - loss = 0.00401990843238309
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:44:24,447 INFO *** epoch 400, rolling-avg-loss (window=10)= 0.004132227940135636
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:24,622 INFO epoch # 401 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0021156201843256033-> 0.0021156201843256033 - loss = 0.0027067234041169286
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:24,796 INFO epoch # 402 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0021156201843256033-> 0.0021156201843256033 - loss = 0.0059024922957178205
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:24,969 INFO epoch # 403 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0021156201843256033-> 0.0021156201843256033 - loss = 0.004569827695377171
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:25,142 INFO epoch # 404 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0021156201843256033-> 0.0021156201843256033 - loss = 0.002513671643100679
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:25,315 INFO epoch # 405 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0021156201843256033-> 0.0021156201843256033 - loss = 0.002664005442056805
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:25,486 INFO epoch # 406 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0021156201843256033-> 0.0021156201843256033 - loss = 0.0030985468765720725
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:25,660 INFO epoch # 407 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0021156201843256033-> 0.0016924961474604828 - loss = 0.004328756360337138
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:25,848 INFO epoch # 408 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0016924961474604828-> 0.0016924961474604828 - loss = 0.0024952098610810935
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:26,021 INFO epoch # 409 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0016924961474604828-> 0.0016924961474604828 - loss = 0.0035337655572220683
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:26,194 INFO epoch # 410 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0016924961474604828-> 0.0016924961474604828 - loss = 0.004130020388402045
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:44:26,194 INFO *** epoch 410, rolling-avg-loss (window=10)= 0.003594301952398382
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:26,368 INFO epoch # 411 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0016924961474604828-> 0.0016924961474604828 - loss = 0.0022333304077619687
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:26,541 INFO epoch # 412 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0016924961474604828-> 0.0016924961474604828 - loss = 0.0024459385313093662
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:26,715 INFO epoch # 413 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0016924961474604828-> 0.0016924961474604828 - loss = 0.0027367903385311365
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:26,888 INFO epoch # 414 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0016924961474604828-> 0.0016924961474604828 - loss = 0.002384697727393359
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:27,063 INFO epoch # 415 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0016924961474604828-> 0.0016924961474604828 - loss = 0.003421587578486651
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:27,236 INFO epoch # 416 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0016924961474604828-> 0.0016924961474604828 - loss = 0.0028146381955593824
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:27,409 INFO epoch # 417 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0016924961474604828-> 0.0016924961474604828 - loss = 0.0022590310545638204
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:27,581 INFO epoch # 418 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0016924961474604828-> 0.0013539969179683863 - loss = 0.002878910454455763
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:27,755 INFO epoch # 419 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0013539969179683863-> 0.0013539969179683863 - loss = 0.004971345246303827
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:27,928 INFO epoch # 420 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0013539969179683863-> 0.0013539969179683863 - loss = 0.002730150066781789
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:44:27,928 INFO *** epoch 420, rolling-avg-loss (window=10)= 0.0028876419601147063
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:28,114 INFO epoch # 421 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0013539969179683863-> 0.0013539969179683863 - loss = 0.005548746790736914
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:28,310 INFO epoch # 422 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0013539969179683863-> 0.0013539969179683863 - loss = 0.002606908790767193
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:28,483 INFO epoch # 423 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0013539969179683863-> 0.0013539969179683863 - loss = 0.0030629849643446505
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:28,658 INFO epoch # 424 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0013539969179683863-> 0.0013539969179683863 - loss = 0.0031485141371376812
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:28,833 INFO epoch # 425 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0013539969179683863-> 0.0013539969179683863 - loss = 0.0024650772684253752
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:29,007 INFO epoch # 426 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0013539969179683863-> 0.0013539969179683863 - loss = 0.0039054781082086265
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:29,180 INFO epoch # 427 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0013539969179683863-> 0.0013539969179683863 - loss = 0.0026755118742585182
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:29,353 INFO epoch # 428 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0013539969179683863-> 0.0013539969179683863 - loss = 0.003177600563503802
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:29,527 INFO epoch # 429 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0013539969179683863-> 0.0010831975343747091 - loss = 0.0035428564297035336
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:29,700 INFO epoch # 430 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0010831975343747091-> 0.0010831975343747091 - loss = 0.0026333872228860855
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:44:29,700 INFO *** epoch 430, rolling-avg-loss (window=10)= 0.003276706614997238
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:29,878 INFO epoch # 431 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0010831975343747091-> 0.0010831975343747091 - loss = 0.002425285230856389
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:30,050 INFO epoch # 432 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0010831975343747091-> 0.0010831975343747091 - loss = 0.002680426900042221
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:30,224 INFO epoch # 433 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0010831975343747091-> 0.0010831975343747091 - loss = 0.0029676996055059135
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:30,396 INFO epoch # 434 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0010831975343747091-> 0.0010831975343747091 - loss = 0.0026751512195914984
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:30,569 INFO epoch # 435 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0010831975343747091-> 0.0010831975343747091 - loss = 0.003497975878417492
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:30,742 INFO epoch # 436 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0010831975343747091-> 0.0010831975343747091 - loss = 0.002847747935447842
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:30,916 INFO epoch # 437 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0010831975343747091-> 0.0010831975343747091 - loss = 0.0039031532942317426
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:31,088 INFO epoch # 438 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0010831975343747091-> 0.0010831975343747091 - loss = 0.0025767470069695264
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:31,262 INFO epoch # 439 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0010831975343747091-> 0.0010831975343747091 - loss = 0.005328304774593562
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:31,435 INFO epoch # 440 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0010831975343747091-> 0.0008665580274997673 - loss = 0.002426728082355112
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:44:31,435 INFO *** epoch 440, rolling-avg-loss (window=10)= 0.00313292199280113
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:31,608 INFO epoch # 441 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0008665580274997673-> 0.0008665580274997673 - loss = 0.003713162790518254
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:31,786 INFO epoch # 442 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0008665580274997673-> 0.0008665580274997673 - loss = 0.0027135988930240273
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:31,976 INFO epoch # 443 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0008665580274997673-> 0.0008665580274997673 - loss = 0.0026655561523512006
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:32,149 INFO epoch # 444 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0008665580274997673-> 0.0008665580274997673 - loss = 0.002342902109376155
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:32,323 INFO epoch # 445 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0008665580274997673-> 0.0008665580274997673 - loss = 0.002621614112285897
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:32,497 INFO epoch # 446 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0008665580274997673-> 0.0008665580274997673 - loss = 0.002176695124944672
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:32,671 INFO epoch # 447 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0008665580274997673-> 0.0008665580274997673 - loss = 0.005476254096720368
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:32,845 INFO epoch # 448 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0008665580274997673-> 0.0008665580274997673 - loss = 0.0027138174627907574
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:33,020 INFO epoch # 449 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0008665580274997673-> 0.0008665580274997673 - loss = 0.0033210734836757183
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:33,195 INFO epoch # 450 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0008665580274997673-> 0.0008665580274997673 - loss = 0.0022119412606116384
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:44:33,195 INFO *** epoch 450, rolling-avg-loss (window=10)= 0.0029956615486298687
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:33,369 INFO epoch # 451 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0008665580274997673-> 0.0008665580274997673 - loss = 0.0024900714633986354
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:33,543 INFO epoch # 452 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0008665580274997673-> 0.0008665580274997673 - loss = 0.002722380682826042
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:33,717 INFO epoch # 453 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0008665580274997673-> 0.0008665580274997673 - loss = 0.003497536003123969
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:33,889 INFO epoch # 454 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0008665580274997673-> 0.0008665580274997673 - loss = 0.0034941371995955706
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:34,063 INFO epoch # 455 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0008665580274997673-> 0.0008665580274997673 - loss = 0.002317012447747402
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:34,236 INFO epoch # 456 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0008665580274997673-> 0.0008665580274997673 - loss = 0.0038245661999098957
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:34,410 INFO epoch # 457 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0008665580274997673-> 0.0006932464219998139 - loss = 0.0033498350239824504
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:34,583 INFO epoch # 458 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0006932464219998139-> 0.0006932464219998139 - loss = 0.0037212290917523205
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:34,758 INFO epoch # 459 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0006932464219998139-> 0.0006932464219998139 - loss = 0.0029407053953036666
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:34,934 INFO epoch # 460 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0006932464219998139-> 0.0006932464219998139 - loss = 0.0036552008241415024
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:44:34,934 INFO *** epoch 460, rolling-avg-loss (window=10)= 0.0032012674331781455
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:35,108 INFO epoch # 461 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0006932464219998139-> 0.0006932464219998139 - loss = 0.0022249008325161412
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:35,281 INFO epoch # 462 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0006932464219998139-> 0.0006932464219998139 - loss = 0.0020569060870911926
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:35,455 INFO epoch # 463 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0006932464219998139-> 0.0006932464219998139 - loss = 0.0028341616271063685
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:35,628 INFO epoch # 464 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0006932464219998139-> 0.0006932464219998139 - loss = 0.005607876693829894
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:35,809 INFO epoch # 465 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0006932464219998139-> 0.0006932464219998139 - loss = 0.003574698930606246
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:35,989 INFO epoch # 466 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0006932464219998139-> 0.0006932464219998139 - loss = 0.002637327299453318
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:36,163 INFO epoch # 467 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0006932464219998139-> 0.0006932464219998139 - loss = 0.0024614561698399484
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:36,335 INFO epoch # 468 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0006932464219998139-> 0.0006932464219998139 - loss = 0.004400384612381458
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:36,509 INFO epoch # 469 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0006932464219998139-> 0.0006932464219998139 - loss = 0.0025462971534579992
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:36,682 INFO epoch # 470 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0006932464219998139-> 0.0006932464219998139 - loss = 0.002678380551515147
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:44:36,682 INFO *** epoch 470, rolling-avg-loss (window=10)= 0.0031022389957797714
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:36,858 INFO epoch # 471 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0006932464219998139-> 0.0006932464219998139 - loss = 0.005848141387104988
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:37,031 INFO epoch # 472 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0006932464219998139-> 0.0006932464219998139 - loss = 0.002367013192269951
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:37,205 INFO epoch # 473 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0006932464219998139-> 0.0005545971375998511 - loss = 0.004380324913654476
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:37,377 INFO epoch # 474 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0005545971375998511-> 0.0005545971375998511 - loss = 0.004188691847957671
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:37,550 INFO epoch # 475 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0005545971375998511-> 0.0005545971375998511 - loss = 0.003481782681774348
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:37,723 INFO epoch # 476 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0005545971375998511-> 0.0005545971375998511 - loss = 0.0023899335647001863
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:37,897 INFO epoch # 477 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0005545971375998511-> 0.0005545971375998511 - loss = 0.003859211632516235
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:38,071 INFO epoch # 478 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0005545971375998511-> 0.0005545971375998511 - loss = 0.0027302902890369296
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:38,245 INFO epoch # 479 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0005545971375998511-> 0.0005545971375998511 - loss = 0.004636750614736229
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:38,418 INFO epoch # 480 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0005545971375998511-> 0.0005545971375998511 - loss = 0.002334647986572236
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:44:38,418 INFO *** epoch 480, rolling-avg-loss (window=10)= 0.003621678811032325
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:38,593 INFO epoch # 481 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0005545971375998511-> 0.0005545971375998511 - loss = 0.0033922238799277693
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:38,766 INFO epoch # 482 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0005545971375998511-> 0.0005545971375998511 - loss = 0.0026212346565444022
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:38,965 INFO epoch # 483 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0005545971375998511-> 0.0005545971375998511 - loss = 0.0024614458379801363
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:39,139 INFO epoch # 484 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0005545971375998511-> 0.0004436777100798809 - loss = 0.002973685448523611
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:39,312 INFO epoch # 485 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0004436777100798809-> 0.0004436777100798809 - loss = 0.0027287366683594882
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:39,485 INFO epoch # 486 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0004436777100798809-> 0.0004436777100798809 - loss = 0.002912650059442967
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:39,660 INFO epoch # 487 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0004436777100798809-> 0.0004436777100798809 - loss = 0.00224511293345131
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:39,833 INFO epoch # 488 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0004436777100798809-> 0.0004436777100798809 - loss = 0.0034427380305714905
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:40,007 INFO epoch # 489 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0004436777100798809-> 0.0004436777100798809 - loss = 0.0025008684606291354
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:40,181 INFO epoch # 490 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0004436777100798809-> 0.0004436777100798809 - loss = 0.003501662635244429
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:44:40,181 INFO *** epoch 490, rolling-avg-loss (window=10)= 0.002878035861067474
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:40,360 INFO epoch # 491 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0004436777100798809-> 0.0004436777100798809 - loss = 0.0037043343181721866
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:40,533 INFO epoch # 492 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0004436777100798809-> 0.0004436777100798809 - loss = 0.00674389663618058
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:40,708 INFO epoch # 493 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0004436777100798809-> 0.0004436777100798809 - loss = 0.0038760663010179996
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:40,882 INFO epoch # 494 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0004436777100798809-> 0.0004436777100798809 - loss = 0.003504654741846025
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:41,057 INFO epoch # 495 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0004436777100798809-> 0.00035494216806390477 - loss = 0.004316776234190911
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:41,232 INFO epoch # 496 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00035494216806390477-> 0.00035494216806390477 - loss = 0.0022043079079594463
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:41,406 INFO epoch # 497 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00035494216806390477-> 0.00035494216806390477 - loss = 0.0024597070296294987
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:41,579 INFO epoch # 498 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00035494216806390477-> 0.00035494216806390477 - loss = 0.003502017236314714
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:41,752 INFO epoch # 499 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00035494216806390477-> 0.00035494216806390477 - loss = 0.0033022071002051234
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:41,929 INFO epoch # 500 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00035494216806390477-> 0.00035494216806390477 - loss = 0.002375730953644961
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:44:41,929 INFO *** epoch 500, rolling-avg-loss (window=10)= 0.0035989698459161445
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:42,107 INFO epoch # 501 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00035494216806390477-> 0.00035494216806390477 - loss = 0.0038655048119835556
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:42,279 INFO epoch # 502 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00035494216806390477-> 0.00035494216806390477 - loss = 0.0024720636138226837
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:42,454 INFO epoch # 503 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00035494216806390477-> 0.00035494216806390477 - loss = 0.005871630739420652
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:42,627 INFO epoch # 504 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00035494216806390477-> 0.00035494216806390477 - loss = 0.0057936678058467805
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:42,806 INFO epoch # 505 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00035494216806390477-> 0.00035494216806390477 - loss = 0.0025807522470131516
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:42,982 INFO epoch # 506 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00035494216806390477-> 0.0002839537344511238 - loss = 0.0038146075676195323
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:43,155 INFO epoch # 507 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0002839537344511238-> 0.0002839537344511238 - loss = 0.003988945332821459
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:43,328 INFO epoch # 508 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0002839537344511238-> 0.0002839537344511238 - loss = 0.002414024987956509
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:43,502 INFO epoch # 509 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0002839537344511238-> 0.0002839537344511238 - loss = 0.002702940400922671
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:43,675 INFO epoch # 510 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0002839537344511238-> 0.0002839537344511238 - loss = 0.002857417333871126
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:44:43,676 INFO *** epoch 510, rolling-avg-loss (window=10)= 0.003636155484127812
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:43,850 INFO epoch # 511 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0002839537344511238-> 0.0002839537344511238 - loss = 0.004945480730384588
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:44,024 INFO epoch # 512 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0002839537344511238-> 0.0002839537344511238 - loss = 0.003526891232468188
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:44,197 INFO epoch # 513 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0002839537344511238-> 0.0002839537344511238 - loss = 0.007284946623258293
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:44,369 INFO epoch # 514 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0002839537344511238-> 0.0002839537344511238 - loss = 0.008263424941105768
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:44,546 INFO epoch # 515 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0002839537344511238-> 0.0002839537344511238 - loss = 0.0031653003534302115
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:44,719 INFO epoch # 516 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0002839537344511238-> 0.0002839537344511238 - loss = 0.002313720469828695
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:44,894 INFO epoch # 517 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0002839537344511238-> 0.00022716298756089907 - loss = 0.0029106182046234608
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:45,068 INFO epoch # 518 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00022716298756089907-> 0.00022716298756089907 - loss = 0.0027308970456942916
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:45,241 INFO epoch # 519 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00022716298756089907-> 0.00022716298756089907 - loss = 0.0024277527118101716
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:45,414 INFO epoch # 520 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00022716298756089907-> 0.00022716298756089907 - loss = 0.0023574404476676136
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:44:45,414 INFO *** epoch 520, rolling-avg-loss (window=10)= 0.0039926472760271284
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:45,588 INFO epoch # 521 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00022716298756089907-> 0.00022716298756089907 - loss = 0.004488900420255959
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:45,761 INFO epoch # 522 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00022716298756089907-> 0.00022716298756089907 - loss = 0.002862020453903824
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:45,935 INFO epoch # 523 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00022716298756089907-> 0.00022716298756089907 - loss = 0.0025367429188918322
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:46,109 INFO epoch # 524 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00022716298756089907-> 0.00022716298756089907 - loss = 0.006124775653006509
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:46,282 INFO epoch # 525 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00022716298756089907-> 0.00022716298756089907 - loss = 0.0026728390366770327
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:46,455 INFO epoch # 526 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00022716298756089907-> 0.00022716298756089907 - loss = 0.004131251771468669
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:46,634 INFO epoch # 527 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00022716298756089907-> 0.00022716298756089907 - loss = 0.0032420699135400355
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:46,806 INFO epoch # 528 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00022716298756089907-> 0.00018173039004871927 - loss = 0.0027348751900717616
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:46,983 INFO epoch # 529 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00018173039004871927-> 0.00018173039004871927 - loss = 0.0036052463692612946
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:47,157 INFO epoch # 530 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00018173039004871927-> 0.00018173039004871927 - loss = 0.0026245116314385086
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:44:47,157 INFO *** epoch 530, rolling-avg-loss (window=10)= 0.0035023233358515427
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:47,331 INFO epoch # 531 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00018173039004871927-> 0.00018173039004871927 - loss = 0.008322648471221328
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:47,506 INFO epoch # 532 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00018173039004871927-> 0.00018173039004871927 - loss = 0.0028103263466618955
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:47,679 INFO epoch # 533 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00018173039004871927-> 0.00018173039004871927 - loss = 0.0024598289746791124
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:47,864 INFO epoch # 534 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00018173039004871927-> 0.00018173039004871927 - loss = 0.0022087061661295593
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:48,041 INFO epoch # 535 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00018173039004871927-> 0.00018173039004871927 - loss = 0.002952998911496252
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:48,213 INFO epoch # 536 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00018173039004871927-> 0.00018173039004871927 - loss = 0.002480536248185672
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:48,387 INFO epoch # 537 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00018173039004871927-> 0.00018173039004871927 - loss = 0.003979807952418923
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:48,561 INFO epoch # 538 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00018173039004871927-> 0.00018173039004871927 - loss = 0.0035638288827612996
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:48,736 INFO epoch # 539 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00018173039004871927-> 0.00014538431203897542 - loss = 0.00573998226900585
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:48,908 INFO epoch # 540 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00014538431203897542-> 0.00014538431203897542 - loss = 0.0028918037423864007
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:44:48,908 INFO *** epoch 540, rolling-avg-loss (window=10)= 0.0037410467964946294
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:49,091 INFO epoch # 541 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00014538431203897542-> 0.00014538431203897542 - loss = 0.0025545359239913523
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:49,264 INFO epoch # 542 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00014538431203897542-> 0.00014538431203897542 - loss = 0.007282855571247637
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:49,438 INFO epoch # 543 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00014538431203897542-> 0.00014538431203897542 - loss = 0.004047485010232776
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:49,611 INFO epoch # 544 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00014538431203897542-> 0.00014538431203897542 - loss = 0.007440188404871151
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:49,790 INFO epoch # 545 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00014538431203897542-> 0.00014538431203897542 - loss = 0.0033562369062565267
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:49,964 INFO epoch # 546 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00014538431203897542-> 0.00014538431203897542 - loss = 0.0036922721774317324
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:50,139 INFO epoch # 547 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00014538431203897542-> 0.00014538431203897542 - loss = 0.0056277900584973395
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:50,311 INFO epoch # 548 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00014538431203897542-> 0.00014538431203897542 - loss = 0.002394128910964355
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:50,486 INFO epoch # 549 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00014538431203897542-> 0.00014538431203897542 - loss = 0.007035386690404266
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:50,659 INFO epoch # 550 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00014538431203897542-> 0.00011630744963118033 - loss = 0.002344718130188994
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:44:50,659 INFO *** epoch 550, rolling-avg-loss (window=10)= 0.004577559778408613
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:50,834 INFO epoch # 551 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00011630744963118033-> 0.00011630744963118033 - loss = 0.0035562997218221426
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:51,008 INFO epoch # 552 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00011630744963118033-> 0.00011630744963118033 - loss = 0.004252481914591044
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:51,182 INFO epoch # 553 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00011630744963118033-> 0.00011630744963118033 - loss = 0.003520646598190069
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:51,355 INFO epoch # 554 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00011630744963118033-> 0.00011630744963118033 - loss = 0.003235607349779457
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:51,529 INFO epoch # 555 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00011630744963118033-> 0.00011630744963118033 - loss = 0.0042633264092728496
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:51,702 INFO epoch # 556 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00011630744963118033-> 0.00011630744963118033 - loss = 0.0025164377584587783
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:51,877 INFO epoch # 557 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00011630744963118033-> 0.00011630744963118033 - loss = 0.0030297055491246283
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:52,054 INFO epoch # 558 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00011630744963118033-> 0.00011630744963118033 - loss = 0.003532755479682237
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:52,228 INFO epoch # 559 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00011630744963118033-> 0.00011630744963118033 - loss = 0.002502439951058477
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:52,400 INFO epoch # 560 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00011630744963118033-> 0.00011630744963118033 - loss = 0.0031257534865289927
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:44:52,400 INFO *** epoch 560, rolling-avg-loss (window=10)= 0.0033535454218508675
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:52,576 INFO epoch # 561 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00011630744963118033-> 9.304595970494427e-05 - loss = 0.0022839649172965437
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:52,749 INFO epoch # 562 - for optimizer <class 'torch.optim.adam.Adam'> lr : 9.304595970494427e-05-> 9.304595970494427e-05 - loss = 0.0029706977074965835
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:52,923 INFO epoch # 563 - for optimizer <class 'torch.optim.adam.Adam'> lr : 9.304595970494427e-05-> 9.304595970494427e-05 - loss = 0.0030174031271599233
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:53,098 INFO epoch # 564 - for optimizer <class 'torch.optim.adam.Adam'> lr : 9.304595970494427e-05-> 9.304595970494427e-05 - loss = 0.002240936883026734
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:53,272 INFO epoch # 565 - for optimizer <class 'torch.optim.adam.Adam'> lr : 9.304595970494427e-05-> 9.304595970494427e-05 - loss = 0.0025514258595649153
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:53,444 INFO epoch # 566 - for optimizer <class 'torch.optim.adam.Adam'> lr : 9.304595970494427e-05-> 9.304595970494427e-05 - loss = 0.0025099159975070506
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:53,620 INFO epoch # 567 - for optimizer <class 'torch.optim.adam.Adam'> lr : 9.304595970494427e-05-> 9.304595970494427e-05 - loss = 0.003403028007596731
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:53,793 INFO epoch # 568 - for optimizer <class 'torch.optim.adam.Adam'> lr : 9.304595970494427e-05-> 9.304595970494427e-05 - loss = 0.00753061450086534
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:53,967 INFO epoch # 569 - for optimizer <class 'torch.optim.adam.Adam'> lr : 9.304595970494427e-05-> 9.304595970494427e-05 - loss = 0.0025949898990802467
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:54,141 INFO epoch # 570 - for optimizer <class 'torch.optim.adam.Adam'> lr : 9.304595970494427e-05-> 9.304595970494427e-05 - loss = 0.0026139761321246624
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:44:54,141 INFO *** epoch 570, rolling-avg-loss (window=10)= 0.003171695303171873
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:54,317 INFO epoch # 571 - for optimizer <class 'torch.optim.adam.Adam'> lr : 9.304595970494427e-05-> 9.304595970494427e-05 - loss = 0.002584260917501524
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:54,490 INFO epoch # 572 - for optimizer <class 'torch.optim.adam.Adam'> lr : 9.304595970494427e-05-> 7.443676776395543e-05 - loss = 0.0037993257865309715
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:54,663 INFO epoch # 573 - for optimizer <class 'torch.optim.adam.Adam'> lr : 7.443676776395543e-05-> 7.443676776395543e-05 - loss = 0.003492100164294243
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:54,835 INFO epoch # 574 - for optimizer <class 'torch.optim.adam.Adam'> lr : 7.443676776395543e-05-> 7.443676776395543e-05 - loss = 0.0030211343546397984
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:55,010 INFO epoch # 575 - for optimizer <class 'torch.optim.adam.Adam'> lr : 7.443676776395543e-05-> 7.443676776395543e-05 - loss = 0.0026676650741137564
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:55,183 INFO epoch # 576 - for optimizer <class 'torch.optim.adam.Adam'> lr : 7.443676776395543e-05-> 7.443676776395543e-05 - loss = 0.003175536112394184
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:55,356 INFO epoch # 577 - for optimizer <class 'torch.optim.adam.Adam'> lr : 7.443676776395543e-05-> 7.443676776395543e-05 - loss = 0.003796330012846738
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:55,530 INFO epoch # 578 - for optimizer <class 'torch.optim.adam.Adam'> lr : 7.443676776395543e-05-> 7.443676776395543e-05 - loss = 0.0021906651090830564
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:55,704 INFO epoch # 579 - for optimizer <class 'torch.optim.adam.Adam'> lr : 7.443676776395543e-05-> 7.443676776395543e-05 - loss = 0.0025940710329450667
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:55,876 INFO epoch # 580 - for optimizer <class 'torch.optim.adam.Adam'> lr : 7.443676776395543e-05-> 7.443676776395543e-05 - loss = 0.002976287854835391
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:44:55,876 INFO *** epoch 580, rolling-avg-loss (window=10)= 0.003029737641918473
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:56,050 INFO epoch # 581 - for optimizer <class 'torch.optim.adam.Adam'> lr : 7.443676776395543e-05-> 7.443676776395543e-05 - loss = 0.003849453409202397
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:56,224 INFO epoch # 582 - for optimizer <class 'torch.optim.adam.Adam'> lr : 7.443676776395543e-05-> 7.443676776395543e-05 - loss = 0.002341020037420094
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:56,397 INFO epoch # 583 - for optimizer <class 'torch.optim.adam.Adam'> lr : 7.443676776395543e-05-> 5.9549414211164346e-05 - loss = 0.0027144119958393276
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:56,571 INFO epoch # 584 - for optimizer <class 'torch.optim.adam.Adam'> lr : 5.9549414211164346e-05-> 5.9549414211164346e-05 - loss = 0.002504320873413235
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:56,744 INFO epoch # 585 - for optimizer <class 'torch.optim.adam.Adam'> lr : 5.9549414211164346e-05-> 5.9549414211164346e-05 - loss = 0.004467607999686152
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:56,917 INFO epoch # 586 - for optimizer <class 'torch.optim.adam.Adam'> lr : 5.9549414211164346e-05-> 5.9549414211164346e-05 - loss = 0.0027316196938045323
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:57,091 INFO epoch # 587 - for optimizer <class 'torch.optim.adam.Adam'> lr : 5.9549414211164346e-05-> 5.9549414211164346e-05 - loss = 0.002749680366832763
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:57,264 INFO epoch # 588 - for optimizer <class 'torch.optim.adam.Adam'> lr : 5.9549414211164346e-05-> 5.9549414211164346e-05 - loss = 0.0023888717114459723
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:57,438 INFO epoch # 589 - for optimizer <class 'torch.optim.adam.Adam'> lr : 5.9549414211164346e-05-> 5.9549414211164346e-05 - loss = 0.0033364880364388227
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:57,611 INFO epoch # 590 - for optimizer <class 'torch.optim.adam.Adam'> lr : 5.9549414211164346e-05-> 5.9549414211164346e-05 - loss = 0.0027237291214987636
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:44:57,611 INFO *** epoch 590, rolling-avg-loss (window=10)= 0.002980720324558206
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:57,791 INFO epoch # 591 - for optimizer <class 'torch.optim.adam.Adam'> lr : 5.9549414211164346e-05-> 5.9549414211164346e-05 - loss = 0.0034133607987314463
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:57,970 INFO epoch # 592 - for optimizer <class 'torch.optim.adam.Adam'> lr : 5.9549414211164346e-05-> 5.9549414211164346e-05 - loss = 0.0023631464864593
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:58,147 INFO epoch # 593 - for optimizer <class 'torch.optim.adam.Adam'> lr : 5.9549414211164346e-05-> 5.9549414211164346e-05 - loss = 0.002965408843010664
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:58,319 INFO epoch # 594 - for optimizer <class 'torch.optim.adam.Adam'> lr : 5.9549414211164346e-05-> 4.763953136893148e-05 - loss = 0.003345295728649944
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:58,491 INFO epoch # 595 - for optimizer <class 'torch.optim.adam.Adam'> lr : 4.763953136893148e-05-> 4.763953136893148e-05 - loss = 0.0023548368480987847
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:58,664 INFO epoch # 596 - for optimizer <class 'torch.optim.adam.Adam'> lr : 4.763953136893148e-05-> 4.763953136893148e-05 - loss = 0.0028970629791729152
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:58,839 INFO epoch # 597 - for optimizer <class 'torch.optim.adam.Adam'> lr : 4.763953136893148e-05-> 4.763953136893148e-05 - loss = 0.005066261684987694
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:59,012 INFO epoch # 598 - for optimizer <class 'torch.optim.adam.Adam'> lr : 4.763953136893148e-05-> 4.763953136893148e-05 - loss = 0.0039281241479329765
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:59,188 INFO epoch # 599 - for optimizer <class 'torch.optim.adam.Adam'> lr : 4.763953136893148e-05-> 4.763953136893148e-05 - loss = 0.0027689000125974417
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:59,361 INFO epoch # 600 - for optimizer <class 'torch.optim.adam.Adam'> lr : 4.763953136893148e-05-> 4.763953136893148e-05 - loss = 0.0024921283911680803
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:44:59,362 INFO *** epoch 600, rolling-avg-loss (window=10)= 0.0031594525920809247
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:59,537 INFO epoch # 601 - for optimizer <class 'torch.optim.adam.Adam'> lr : 4.763953136893148e-05-> 4.763953136893148e-05 - loss = 0.002430185384582728
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:59,710 INFO epoch # 602 - for optimizer <class 'torch.optim.adam.Adam'> lr : 4.763953136893148e-05-> 4.763953136893148e-05 - loss = 0.004051529103890061
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:44:59,885 INFO epoch # 603 - for optimizer <class 'torch.optim.adam.Adam'> lr : 4.763953136893148e-05-> 4.763953136893148e-05 - loss = 0.002544793125707656
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:00,058 INFO epoch # 604 - for optimizer <class 'torch.optim.adam.Adam'> lr : 4.763953136893148e-05-> 4.763953136893148e-05 - loss = 0.004541930626146495
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:00,236 INFO epoch # 605 - for optimizer <class 'torch.optim.adam.Adam'> lr : 4.763953136893148e-05-> 3.811162509514518e-05 - loss = 0.00300236587645486
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:00,409 INFO epoch # 606 - for optimizer <class 'torch.optim.adam.Adam'> lr : 3.811162509514518e-05-> 3.811162509514518e-05 - loss = 0.002606930851470679
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:00,584 INFO epoch # 607 - for optimizer <class 'torch.optim.adam.Adam'> lr : 3.811162509514518e-05-> 3.811162509514518e-05 - loss = 0.0022655280772596598
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:00,757 INFO epoch # 608 - for optimizer <class 'torch.optim.adam.Adam'> lr : 3.811162509514518e-05-> 3.811162509514518e-05 - loss = 0.002977564523462206
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:00,930 INFO epoch # 609 - for optimizer <class 'torch.optim.adam.Adam'> lr : 3.811162509514518e-05-> 3.811162509514518e-05 - loss = 0.00721542164683342
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:01,103 INFO epoch # 610 - for optimizer <class 'torch.optim.adam.Adam'> lr : 3.811162509514518e-05-> 3.811162509514518e-05 - loss = 0.002265316841658205
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:45:01,103 INFO *** epoch 610, rolling-avg-loss (window=10)= 0.003390156605746597
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:01,278 INFO epoch # 611 - for optimizer <class 'torch.optim.adam.Adam'> lr : 3.811162509514518e-05-> 3.811162509514518e-05 - loss = 0.007721402507741004
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:01,450 INFO epoch # 612 - for optimizer <class 'torch.optim.adam.Adam'> lr : 3.811162509514518e-05-> 3.811162509514518e-05 - loss = 0.0023290134995477274
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:01,625 INFO epoch # 613 - for optimizer <class 'torch.optim.adam.Adam'> lr : 3.811162509514518e-05-> 3.811162509514518e-05 - loss = 0.0065559594659134746
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:01,797 INFO epoch # 614 - for optimizer <class 'torch.optim.adam.Adam'> lr : 3.811162509514518e-05-> 3.811162509514518e-05 - loss = 0.002581302251201123
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:01,972 INFO epoch # 615 - for optimizer <class 'torch.optim.adam.Adam'> lr : 3.811162509514518e-05-> 3.811162509514518e-05 - loss = 0.0023099335085134953
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:02,151 INFO epoch # 616 - for optimizer <class 'torch.optim.adam.Adam'> lr : 3.811162509514518e-05-> 3.048930007611615e-05 - loss = 0.0024289267712447327
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:02,324 INFO epoch # 617 - for optimizer <class 'torch.optim.adam.Adam'> lr : 3.048930007611615e-05-> 3.048930007611615e-05 - loss = 0.0031270820763893425
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:02,497 INFO epoch # 618 - for optimizer <class 'torch.optim.adam.Adam'> lr : 3.048930007611615e-05-> 3.048930007611615e-05 - loss = 0.0031073655118234456
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:02,671 INFO epoch # 619 - for optimizer <class 'torch.optim.adam.Adam'> lr : 3.048930007611615e-05-> 3.048930007611615e-05 - loss = 0.003135856590233743
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:02,843 INFO epoch # 620 - for optimizer <class 'torch.optim.adam.Adam'> lr : 3.048930007611615e-05-> 3.048930007611615e-05 - loss = 0.0040247091092169285
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:45:02,844 INFO *** epoch 620, rolling-avg-loss (window=10)= 0.0037321551291825015
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:03,018 INFO epoch # 621 - for optimizer <class 'torch.optim.adam.Adam'> lr : 3.048930007611615e-05-> 3.048930007611615e-05 - loss = 0.005640173621941358
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:03,195 INFO epoch # 622 - for optimizer <class 'torch.optim.adam.Adam'> lr : 3.048930007611615e-05-> 3.048930007611615e-05 - loss = 0.004995738680008799
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:03,369 INFO epoch # 623 - for optimizer <class 'torch.optim.adam.Adam'> lr : 3.048930007611615e-05-> 3.048930007611615e-05 - loss = 0.002290099597303197
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:03,542 INFO epoch # 624 - for optimizer <class 'torch.optim.adam.Adam'> lr : 3.048930007611615e-05-> 3.048930007611615e-05 - loss = 0.003478225175058469
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:03,716 INFO epoch # 625 - for optimizer <class 'torch.optim.adam.Adam'> lr : 3.048930007611615e-05-> 3.048930007611615e-05 - loss = 0.0026141238049604
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:03,889 INFO epoch # 626 - for optimizer <class 'torch.optim.adam.Adam'> lr : 3.048930007611615e-05-> 3.048930007611615e-05 - loss = 0.0029515011701732874
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:04,064 INFO epoch # 627 - for optimizer <class 'torch.optim.adam.Adam'> lr : 3.048930007611615e-05-> 2.4391440060892922e-05 - loss = 0.0025989084679167718
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:04,240 INFO epoch # 628 - for optimizer <class 'torch.optim.adam.Adam'> lr : 2.4391440060892922e-05-> 2.4391440060892922e-05 - loss = 0.006137484568171203
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:04,413 INFO epoch # 629 - for optimizer <class 'torch.optim.adam.Adam'> lr : 2.4391440060892922e-05-> 2.4391440060892922e-05 - loss = 0.003265548322815448
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:04,586 INFO epoch # 630 - for optimizer <class 'torch.optim.adam.Adam'> lr : 2.4391440060892922e-05-> 2.4391440060892922e-05 - loss = 0.002937363926321268
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:45:04,586 INFO *** epoch 630, rolling-avg-loss (window=10)= 0.00369091673346702
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:04,760 INFO epoch # 631 - for optimizer <class 'torch.optim.adam.Adam'> lr : 2.4391440060892922e-05-> 2.4391440060892922e-05 - loss = 0.002452173561323434
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:04,933 INFO epoch # 632 - for optimizer <class 'torch.optim.adam.Adam'> lr : 2.4391440060892922e-05-> 2.4391440060892922e-05 - loss = 0.00234895377070643
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:05,108 INFO epoch # 633 - for optimizer <class 'torch.optim.adam.Adam'> lr : 2.4391440060892922e-05-> 2.4391440060892922e-05 - loss = 0.002434056339552626
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:05,282 INFO epoch # 634 - for optimizer <class 'torch.optim.adam.Adam'> lr : 2.4391440060892922e-05-> 2.4391440060892922e-05 - loss = 0.0029959618696011603
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:05,455 INFO epoch # 635 - for optimizer <class 'torch.optim.adam.Adam'> lr : 2.4391440060892922e-05-> 2.4391440060892922e-05 - loss = 0.0024867875908967108
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:05,628 INFO epoch # 636 - for optimizer <class 'torch.optim.adam.Adam'> lr : 2.4391440060892922e-05-> 2.4391440060892922e-05 - loss = 0.003543523547705263
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:05,807 INFO epoch # 637 - for optimizer <class 'torch.optim.adam.Adam'> lr : 2.4391440060892922e-05-> 2.4391440060892922e-05 - loss = 0.002268983284011483
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:05,979 INFO epoch # 638 - for optimizer <class 'torch.optim.adam.Adam'> lr : 2.4391440060892922e-05-> 1.951315204871434e-05 - loss = 0.002912255673436448
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:06,153 INFO epoch # 639 - for optimizer <class 'torch.optim.adam.Adam'> lr : 1.951315204871434e-05-> 1.951315204871434e-05 - loss = 0.0038508203579112887
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:06,325 INFO epoch # 640 - for optimizer <class 'torch.optim.adam.Adam'> lr : 1.951315204871434e-05-> 1.951315204871434e-05 - loss = 0.003743416687939316
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:45:06,326 INFO *** epoch 640, rolling-avg-loss (window=10)= 0.002903693268308416
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:06,500 INFO epoch # 641 - for optimizer <class 'torch.optim.adam.Adam'> lr : 1.951315204871434e-05-> 1.951315204871434e-05 - loss = 0.0026653257373254746
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:06,673 INFO epoch # 642 - for optimizer <class 'torch.optim.adam.Adam'> lr : 1.951315204871434e-05-> 1.951315204871434e-05 - loss = 0.0023065256391419098
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:06,847 INFO epoch # 643 - for optimizer <class 'torch.optim.adam.Adam'> lr : 1.951315204871434e-05-> 1.951315204871434e-05 - loss = 0.0025164299877360463
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:07,020 INFO epoch # 644 - for optimizer <class 'torch.optim.adam.Adam'> lr : 1.951315204871434e-05-> 1.951315204871434e-05 - loss = 0.0025195765192620456
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:07,195 INFO epoch # 645 - for optimizer <class 'torch.optim.adam.Adam'> lr : 1.951315204871434e-05-> 1.951315204871434e-05 - loss = 0.0038171071209944785
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:07,367 INFO epoch # 646 - for optimizer <class 'torch.optim.adam.Adam'> lr : 1.951315204871434e-05-> 1.951315204871434e-05 - loss = 0.002054747790680267
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:07,542 INFO epoch # 647 - for optimizer <class 'torch.optim.adam.Adam'> lr : 1.951315204871434e-05-> 1.951315204871434e-05 - loss = 0.00526861083926633
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:07,715 INFO epoch # 648 - for optimizer <class 'torch.optim.adam.Adam'> lr : 1.951315204871434e-05-> 1.951315204871434e-05 - loss = 0.005705262301489711
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:07,901 INFO epoch # 649 - for optimizer <class 'torch.optim.adam.Adam'> lr : 1.951315204871434e-05-> 1.951315204871434e-05 - loss = 0.005740683467593044
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:08,074 INFO epoch # 650 - for optimizer <class 'torch.optim.adam.Adam'> lr : 1.951315204871434e-05-> 1.951315204871434e-05 - loss = 0.003633308253483847
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:45:08,074 INFO *** epoch 650, rolling-avg-loss (window=10)= 0.0036227577656973153
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:08,250 INFO epoch # 651 - for optimizer <class 'torch.optim.adam.Adam'> lr : 1.951315204871434e-05-> 1.951315204871434e-05 - loss = 0.0031550595303997397
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:08,424 INFO epoch # 652 - for optimizer <class 'torch.optim.adam.Adam'> lr : 1.951315204871434e-05-> 1.951315204871434e-05 - loss = 0.0025727528845891356
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:08,597 INFO epoch # 653 - for optimizer <class 'torch.optim.adam.Adam'> lr : 1.951315204871434e-05-> 1.951315204871434e-05 - loss = 0.003437497594859451
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:08,770 INFO epoch # 654 - for optimizer <class 'torch.optim.adam.Adam'> lr : 1.951315204871434e-05-> 1.951315204871434e-05 - loss = 0.0025932215503416955
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:08,944 INFO epoch # 655 - for optimizer <class 'torch.optim.adam.Adam'> lr : 1.951315204871434e-05-> 1.951315204871434e-05 - loss = 0.003359416499733925
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:09,117 INFO epoch # 656 - for optimizer <class 'torch.optim.adam.Adam'> lr : 1.951315204871434e-05-> 1.951315204871434e-05 - loss = 0.0023285502538783476
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:09,292 INFO epoch # 657 - for optimizer <class 'torch.optim.adam.Adam'> lr : 1.951315204871434e-05-> 1.561052163897147e-05 - loss = 0.0037206002743914723
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:09,465 INFO epoch # 658 - for optimizer <class 'torch.optim.adam.Adam'> lr : 1.561052163897147e-05-> 1.561052163897147e-05 - loss = 0.0038195749511942267
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:09,639 INFO epoch # 659 - for optimizer <class 'torch.optim.adam.Adam'> lr : 1.561052163897147e-05-> 1.561052163897147e-05 - loss = 0.0024449651536997408
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:09,812 INFO epoch # 660 - for optimizer <class 'torch.optim.adam.Adam'> lr : 1.561052163897147e-05-> 1.561052163897147e-05 - loss = 0.002541491121519357
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:45:09,812 INFO *** epoch 660, rolling-avg-loss (window=10)= 0.002997312981460709
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:09,986 INFO epoch # 661 - for optimizer <class 'torch.optim.adam.Adam'> lr : 1.561052163897147e-05-> 1.561052163897147e-05 - loss = 0.004578123218379915
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:10,159 INFO epoch # 662 - for optimizer <class 'torch.optim.adam.Adam'> lr : 1.561052163897147e-05-> 1.561052163897147e-05 - loss = 0.003025027283001691
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:10,337 INFO epoch # 663 - for optimizer <class 'torch.optim.adam.Adam'> lr : 1.561052163897147e-05-> 1.561052163897147e-05 - loss = 0.0022969987767282873
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:10,509 INFO epoch # 664 - for optimizer <class 'torch.optim.adam.Adam'> lr : 1.561052163897147e-05-> 1.561052163897147e-05 - loss = 0.004024085705168545
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:10,683 INFO epoch # 665 - for optimizer <class 'torch.optim.adam.Adam'> lr : 1.561052163897147e-05-> 1.561052163897147e-05 - loss = 0.0038894275785423815
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:10,857 INFO epoch # 666 - for optimizer <class 'torch.optim.adam.Adam'> lr : 1.561052163897147e-05-> 1.561052163897147e-05 - loss = 0.0031369127391371876
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:11,030 INFO epoch # 667 - for optimizer <class 'torch.optim.adam.Adam'> lr : 1.561052163897147e-05-> 1.561052163897147e-05 - loss = 0.004235902393702418
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:11,202 INFO epoch # 668 - for optimizer <class 'torch.optim.adam.Adam'> lr : 1.561052163897147e-05-> 1.2488417311177178e-05 - loss = 0.00288637907942757
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:11,375 INFO epoch # 669 - for optimizer <class 'torch.optim.adam.Adam'> lr : 1.2488417311177178e-05-> 1.2488417311177178e-05 - loss = 0.0027629551477730274
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:11,548 INFO epoch # 670 - for optimizer <class 'torch.optim.adam.Adam'> lr : 1.2488417311177178e-05-> 1.2488417311177178e-05 - loss = 0.0036045125452801585
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:45:11,549 INFO *** epoch 670, rolling-avg-loss (window=10)= 0.003444032446714118
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:11,722 INFO epoch # 671 - for optimizer <class 'torch.optim.adam.Adam'> lr : 1.2488417311177178e-05-> 1.2488417311177178e-05 - loss = 0.004113892384339124
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:11,894 INFO epoch # 672 - for optimizer <class 'torch.optim.adam.Adam'> lr : 1.2488417311177178e-05-> 1.2488417311177178e-05 - loss = 0.0026238788850605488
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:12,069 INFO epoch # 673 - for optimizer <class 'torch.optim.adam.Adam'> lr : 1.2488417311177178e-05-> 1.2488417311177178e-05 - loss = 0.0039023715653456748
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:12,247 INFO epoch # 674 - for optimizer <class 'torch.optim.adam.Adam'> lr : 1.2488417311177178e-05-> 1.2488417311177178e-05 - loss = 0.0027481155120767653
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:12,421 INFO epoch # 675 - for optimizer <class 'torch.optim.adam.Adam'> lr : 1.2488417311177178e-05-> 1.2488417311177178e-05 - loss = 0.0022816879936726764
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:12,593 INFO epoch # 676 - for optimizer <class 'torch.optim.adam.Adam'> lr : 1.2488417311177178e-05-> 1.2488417311177178e-05 - loss = 0.002015179838053882
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:12,766 INFO epoch # 677 - for optimizer <class 'torch.optim.adam.Adam'> lr : 1.2488417311177178e-05-> 1.2488417311177178e-05 - loss = 0.0025024048518389463
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:12,939 INFO epoch # 678 - for optimizer <class 'torch.optim.adam.Adam'> lr : 1.2488417311177178e-05-> 1.2488417311177178e-05 - loss = 0.004157183924689889
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:13,112 INFO epoch # 679 - for optimizer <class 'torch.optim.adam.Adam'> lr : 1.2488417311177178e-05-> 1.2488417311177178e-05 - loss = 0.004514581291005015
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:13,288 INFO epoch # 680 - for optimizer <class 'torch.optim.adam.Adam'> lr : 1.2488417311177178e-05-> 1.2488417311177178e-05 - loss = 0.0031170540023595095
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:45:13,288 INFO *** epoch 680, rolling-avg-loss (window=10)= 0.003197635024844203
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:13,462 INFO epoch # 681 - for optimizer <class 'torch.optim.adam.Adam'> lr : 1.2488417311177178e-05-> 1.2488417311177178e-05 - loss = 0.002260520006529987
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:13,634 INFO epoch # 682 - for optimizer <class 'torch.optim.adam.Adam'> lr : 1.2488417311177178e-05-> 1.2488417311177178e-05 - loss = 0.0032255391706712544
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:13,808 INFO epoch # 683 - for optimizer <class 'torch.optim.adam.Adam'> lr : 1.2488417311177178e-05-> 1.2488417311177178e-05 - loss = 0.0023766483936924487
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:13,980 INFO epoch # 684 - for optimizer <class 'torch.optim.adam.Adam'> lr : 1.2488417311177178e-05-> 1.2488417311177178e-05 - loss = 0.0024858346150722355
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:14,154 INFO epoch # 685 - for optimizer <class 'torch.optim.adam.Adam'> lr : 1.2488417311177178e-05-> 1.2488417311177178e-05 - loss = 0.0025090961207752116
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:14,327 INFO epoch # 686 - for optimizer <class 'torch.optim.adam.Adam'> lr : 1.2488417311177178e-05-> 1.2488417311177178e-05 - loss = 0.002903618849813938
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:14,500 INFO epoch # 687 - for optimizer <class 'torch.optim.adam.Adam'> lr : 1.2488417311177178e-05-> 9.990733848941742e-06 - loss = 0.007187099719885737
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:14,674 INFO epoch # 688 - for optimizer <class 'torch.optim.adam.Adam'> lr : 9.990733848941742e-06-> 9.990733848941742e-06 - loss = 0.004037398437503725
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:14,848 INFO epoch # 689 - for optimizer <class 'torch.optim.adam.Adam'> lr : 9.990733848941742e-06-> 9.990733848941742e-06 - loss = 0.0023600359563715756
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:15,023 INFO epoch # 690 - for optimizer <class 'torch.optim.adam.Adam'> lr : 9.990733848941742e-06-> 9.990733848941742e-06 - loss = 0.002625133842229843
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:45:15,023 INFO *** epoch 690, rolling-avg-loss (window=10)= 0.0031970925112545954
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:15,199 INFO epoch # 691 - for optimizer <class 'torch.optim.adam.Adam'> lr : 9.990733848941742e-06-> 9.990733848941742e-06 - loss = 0.005349080311134458
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:15,373 INFO epoch # 692 - for optimizer <class 'torch.optim.adam.Adam'> lr : 9.990733848941742e-06-> 9.990733848941742e-06 - loss = 0.0026895109040196985
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:15,547 INFO epoch # 693 - for optimizer <class 'torch.optim.adam.Adam'> lr : 9.990733848941742e-06-> 9.990733848941742e-06 - loss = 0.004674203577451408
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:15,722 INFO epoch # 694 - for optimizer <class 'torch.optim.adam.Adam'> lr : 9.990733848941742e-06-> 9.990733848941742e-06 - loss = 0.0028824868495576084
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:15,895 INFO epoch # 695 - for optimizer <class 'torch.optim.adam.Adam'> lr : 9.990733848941742e-06-> 9.990733848941742e-06 - loss = 0.003164186899084598
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:16,070 INFO epoch # 696 - for optimizer <class 'torch.optim.adam.Adam'> lr : 9.990733848941742e-06-> 9.990733848941742e-06 - loss = 0.0022740134445484728
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:16,244 INFO epoch # 697 - for optimizer <class 'torch.optim.adam.Adam'> lr : 9.990733848941742e-06-> 9.990733848941742e-06 - loss = 0.0030709487036801875
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:16,420 INFO epoch # 698 - for optimizer <class 'torch.optim.adam.Adam'> lr : 9.990733848941742e-06-> 7.992587079153394e-06 - loss = 0.002488149970304221
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:16,594 INFO epoch # 699 - for optimizer <class 'torch.optim.adam.Adam'> lr : 7.992587079153394e-06-> 7.992587079153394e-06 - loss = 0.004014144011307508
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:16,766 INFO epoch # 700 - for optimizer <class 'torch.optim.adam.Adam'> lr : 7.992587079153394e-06-> 7.992587079153394e-06 - loss = 0.005198619473958388
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:45:16,766 INFO *** epoch 700, rolling-avg-loss (window=10)= 0.003580534414504655
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:16,940 INFO epoch # 701 - for optimizer <class 'torch.optim.adam.Adam'> lr : 7.992587079153394e-06-> 7.992587079153394e-06 - loss = 0.002550053148297593
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:17,113 INFO epoch # 702 - for optimizer <class 'torch.optim.adam.Adam'> lr : 7.992587079153394e-06-> 7.992587079153394e-06 - loss = 0.002969522203784436
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:17,292 INFO epoch # 703 - for optimizer <class 'torch.optim.adam.Adam'> lr : 7.992587079153394e-06-> 7.992587079153394e-06 - loss = 0.002490774932084605
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:17,467 INFO epoch # 704 - for optimizer <class 'torch.optim.adam.Adam'> lr : 7.992587079153394e-06-> 7.992587079153394e-06 - loss = 0.00313773745438084
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:17,640 INFO epoch # 705 - for optimizer <class 'torch.optim.adam.Adam'> lr : 7.992587079153394e-06-> 7.992587079153394e-06 - loss = 0.00279893382685259
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:17,820 INFO epoch # 706 - for optimizer <class 'torch.optim.adam.Adam'> lr : 7.992587079153394e-06-> 7.992587079153394e-06 - loss = 0.003536827687639743
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:17,993 INFO epoch # 707 - for optimizer <class 'torch.optim.adam.Adam'> lr : 7.992587079153394e-06-> 7.992587079153394e-06 - loss = 0.004942749044857919
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:18,165 INFO epoch # 708 - for optimizer <class 'torch.optim.adam.Adam'> lr : 7.992587079153394e-06-> 7.992587079153394e-06 - loss = 0.002387131651630625
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:18,338 INFO epoch # 709 - for optimizer <class 'torch.optim.adam.Adam'> lr : 7.992587079153394e-06-> 6.394069663322715e-06 - loss = 0.002667244989424944
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:18,511 INFO epoch # 710 - for optimizer <class 'torch.optim.adam.Adam'> lr : 6.394069663322715e-06-> 6.394069663322715e-06 - loss = 0.0026133065402973443
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:45:18,511 INFO *** epoch 710, rolling-avg-loss (window=10)= 0.003009428147925064
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:18,686 INFO epoch # 711 - for optimizer <class 'torch.optim.adam.Adam'> lr : 6.394069663322715e-06-> 6.394069663322715e-06 - loss = 0.004464771249331534
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:18,860 INFO epoch # 712 - for optimizer <class 'torch.optim.adam.Adam'> lr : 6.394069663322715e-06-> 6.394069663322715e-06 - loss = 0.0032585253939032555
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:19,033 INFO epoch # 713 - for optimizer <class 'torch.optim.adam.Adam'> lr : 6.394069663322715e-06-> 6.394069663322715e-06 - loss = 0.0024371182080358267
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:19,205 INFO epoch # 714 - for optimizer <class 'torch.optim.adam.Adam'> lr : 6.394069663322715e-06-> 6.394069663322715e-06 - loss = 0.0020320613839430735
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:19,381 INFO epoch # 715 - for optimizer <class 'torch.optim.adam.Adam'> lr : 6.394069663322715e-06-> 6.394069663322715e-06 - loss = 0.0025900572654791176
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:19,554 INFO epoch # 716 - for optimizer <class 'torch.optim.adam.Adam'> lr : 6.394069663322715e-06-> 6.394069663322715e-06 - loss = 0.0023359838960459456
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:19,727 INFO epoch # 717 - for optimizer <class 'torch.optim.adam.Adam'> lr : 6.394069663322715e-06-> 6.394069663322715e-06 - loss = 0.0027515034889802337
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:19,899 INFO epoch # 718 - for optimizer <class 'torch.optim.adam.Adam'> lr : 6.394069663322715e-06-> 6.394069663322715e-06 - loss = 0.002336851815925911
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:20,074 INFO epoch # 719 - for optimizer <class 'torch.optim.adam.Adam'> lr : 6.394069663322715e-06-> 6.394069663322715e-06 - loss = 0.003230396192520857
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:20,247 INFO epoch # 720 - for optimizer <class 'torch.optim.adam.Adam'> lr : 6.394069663322715e-06-> 5.115255730658173e-06 - loss = 0.003047615406103432
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:45:20,247 INFO *** epoch 720, rolling-avg-loss (window=10)= 0.0028484884300269187
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:20,421 INFO epoch # 721 - for optimizer <class 'torch.optim.adam.Adam'> lr : 5.115255730658173e-06-> 5.115255730658173e-06 - loss = 0.0039046380552463233
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:20,595 INFO epoch # 722 - for optimizer <class 'torch.optim.adam.Adam'> lr : 5.115255730658173e-06-> 5.115255730658173e-06 - loss = 0.003001074190251529
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:20,768 INFO epoch # 723 - for optimizer <class 'torch.optim.adam.Adam'> lr : 5.115255730658173e-06-> 5.115255730658173e-06 - loss = 0.002295734971994534
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:20,941 INFO epoch # 724 - for optimizer <class 'torch.optim.adam.Adam'> lr : 5.115255730658173e-06-> 5.115255730658173e-06 - loss = 0.005341578274965286
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:21,115 INFO epoch # 725 - for optimizer <class 'torch.optim.adam.Adam'> lr : 5.115255730658173e-06-> 5.115255730658173e-06 - loss = 0.0051438300288282335
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:21,288 INFO epoch # 726 - for optimizer <class 'torch.optim.adam.Adam'> lr : 5.115255730658173e-06-> 5.115255730658173e-06 - loss = 0.0028440876631066203
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:21,463 INFO epoch # 727 - for optimizer <class 'torch.optim.adam.Adam'> lr : 5.115255730658173e-06-> 5.115255730658173e-06 - loss = 0.0032230477081611753
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:21,635 INFO epoch # 728 - for optimizer <class 'torch.optim.adam.Adam'> lr : 5.115255730658173e-06-> 5.115255730658173e-06 - loss = 0.002396648342255503
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:21,809 INFO epoch # 729 - for optimizer <class 'torch.optim.adam.Adam'> lr : 5.115255730658173e-06-> 5.115255730658173e-06 - loss = 0.0036581591120921075
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:21,981 INFO epoch # 730 - for optimizer <class 'torch.optim.adam.Adam'> lr : 5.115255730658173e-06-> 5.115255730658173e-06 - loss = 0.0031961825443431735
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:45:21,981 INFO *** epoch 730, rolling-avg-loss (window=10)= 0.0035004980891244486
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:22,155 INFO epoch # 731 - for optimizer <class 'torch.optim.adam.Adam'> lr : 5.115255730658173e-06-> 4.092204584526539e-06 - loss = 0.0042708320543169975
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:22,333 INFO epoch # 732 - for optimizer <class 'torch.optim.adam.Adam'> lr : 4.092204584526539e-06-> 4.092204584526539e-06 - loss = 0.00274136831285432
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:22,507 INFO epoch # 733 - for optimizer <class 'torch.optim.adam.Adam'> lr : 4.092204584526539e-06-> 4.092204584526539e-06 - loss = 0.0027738522039726377
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:22,679 INFO epoch # 734 - for optimizer <class 'torch.optim.adam.Adam'> lr : 4.092204584526539e-06-> 4.092204584526539e-06 - loss = 0.0055156637681648135
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:22,854 INFO epoch # 735 - for optimizer <class 'torch.optim.adam.Adam'> lr : 4.092204584526539e-06-> 4.092204584526539e-06 - loss = 0.005139561893884093
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:23,027 INFO epoch # 736 - for optimizer <class 'torch.optim.adam.Adam'> lr : 4.092204584526539e-06-> 4.092204584526539e-06 - loss = 0.003277336247265339
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:23,200 INFO epoch # 737 - for optimizer <class 'torch.optim.adam.Adam'> lr : 4.092204584526539e-06-> 4.092204584526539e-06 - loss = 0.0059478997136466205
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:23,373 INFO epoch # 738 - for optimizer <class 'torch.optim.adam.Adam'> lr : 4.092204584526539e-06-> 4.092204584526539e-06 - loss = 0.003056878224015236
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:23,549 INFO epoch # 739 - for optimizer <class 'torch.optim.adam.Adam'> lr : 4.092204584526539e-06-> 4.092204584526539e-06 - loss = 0.0031431603711098433
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:23,722 INFO epoch # 740 - for optimizer <class 'torch.optim.adam.Adam'> lr : 4.092204584526539e-06-> 4.092204584526539e-06 - loss = 0.0025759064592421055
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:45:23,722 INFO *** epoch 740, rolling-avg-loss (window=10)= 0.0038442459248472006
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:23,901 INFO epoch # 741 - for optimizer <class 'torch.optim.adam.Adam'> lr : 4.092204584526539e-06-> 4.092204584526539e-06 - loss = 0.002808909397572279
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:24,073 INFO epoch # 742 - for optimizer <class 'torch.optim.adam.Adam'> lr : 4.092204584526539e-06-> 3.2737636676212312e-06 - loss = 0.002649624482728541
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:24,247 INFO epoch # 743 - for optimizer <class 'torch.optim.adam.Adam'> lr : 3.2737636676212312e-06-> 3.2737636676212312e-06 - loss = 0.004415131581481546
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:24,419 INFO epoch # 744 - for optimizer <class 'torch.optim.adam.Adam'> lr : 3.2737636676212312e-06-> 3.2737636676212312e-06 - loss = 0.0028015783173032105
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:24,593 INFO epoch # 745 - for optimizer <class 'torch.optim.adam.Adam'> lr : 3.2737636676212312e-06-> 3.2737636676212312e-06 - loss = 0.002302283886820078
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:24,765 INFO epoch # 746 - for optimizer <class 'torch.optim.adam.Adam'> lr : 3.2737636676212312e-06-> 3.2737636676212312e-06 - loss = 0.0033958248677663505
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:24,944 INFO epoch # 747 - for optimizer <class 'torch.optim.adam.Adam'> lr : 3.2737636676212312e-06-> 3.2737636676212312e-06 - loss = 0.003891663160175085
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:25,117 INFO epoch # 748 - for optimizer <class 'torch.optim.adam.Adam'> lr : 3.2737636676212312e-06-> 3.2737636676212312e-06 - loss = 0.005394284147769213
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:25,297 INFO epoch # 749 - for optimizer <class 'torch.optim.adam.Adam'> lr : 3.2737636676212312e-06-> 3.2737636676212312e-06 - loss = 0.003219391219317913
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:25,469 INFO epoch # 750 - for optimizer <class 'torch.optim.adam.Adam'> lr : 3.2737636676212312e-06-> 3.2737636676212312e-06 - loss = 0.0028895667928736657
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:45:25,469 INFO *** epoch 750, rolling-avg-loss (window=10)= 0.003376825785380788
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:25,643 INFO epoch # 751 - for optimizer <class 'torch.optim.adam.Adam'> lr : 3.2737636676212312e-06-> 3.2737636676212312e-06 - loss = 0.003728673153091222
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:25,815 INFO epoch # 752 - for optimizer <class 'torch.optim.adam.Adam'> lr : 3.2737636676212312e-06-> 3.2737636676212312e-06 - loss = 0.0031610578880645335
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:25,989 INFO epoch # 753 - for optimizer <class 'torch.optim.adam.Adam'> lr : 3.2737636676212312e-06-> 2.619010934096985e-06 - loss = 0.002502802759408951
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:26,162 INFO epoch # 754 - for optimizer <class 'torch.optim.adam.Adam'> lr : 2.619010934096985e-06-> 2.619010934096985e-06 - loss = 0.0030589448288083076
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:26,335 INFO epoch # 755 - for optimizer <class 'torch.optim.adam.Adam'> lr : 2.619010934096985e-06-> 2.619010934096985e-06 - loss = 0.0033079077256843448
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:26,508 INFO epoch # 756 - for optimizer <class 'torch.optim.adam.Adam'> lr : 2.619010934096985e-06-> 2.619010934096985e-06 - loss = 0.0054036498768255115
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:26,682 INFO epoch # 757 - for optimizer <class 'torch.optim.adam.Adam'> lr : 2.619010934096985e-06-> 2.619010934096985e-06 - loss = 0.005221463681664318
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:26,855 INFO epoch # 758 - for optimizer <class 'torch.optim.adam.Adam'> lr : 2.619010934096985e-06-> 2.619010934096985e-06 - loss = 0.004490184306632727
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:27,029 INFO epoch # 759 - for optimizer <class 'torch.optim.adam.Adam'> lr : 2.619010934096985e-06-> 2.619010934096985e-06 - loss = 0.009465122420806438
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:27,202 INFO epoch # 760 - for optimizer <class 'torch.optim.adam.Adam'> lr : 2.619010934096985e-06-> 2.619010934096985e-06 - loss = 0.002630015165777877
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:45:27,202 INFO *** epoch 760, rolling-avg-loss (window=10)= 0.004296982180676423
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:27,376 INFO epoch # 761 - for optimizer <class 'torch.optim.adam.Adam'> lr : 2.619010934096985e-06-> 2.619010934096985e-06 - loss = 0.0050316741690039635
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:27,550 INFO epoch # 762 - for optimizer <class 'torch.optim.adam.Adam'> lr : 2.619010934096985e-06-> 2.619010934096985e-06 - loss = 0.0030591428803745657
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:27,724 INFO epoch # 763 - for optimizer <class 'torch.optim.adam.Adam'> lr : 2.619010934096985e-06-> 2.619010934096985e-06 - loss = 0.006902326422277838
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:27,897 INFO epoch # 764 - for optimizer <class 'torch.optim.adam.Adam'> lr : 2.619010934096985e-06-> 2.0952087472775883e-06 - loss = 0.002708705753320828
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:28,072 INFO epoch # 765 - for optimizer <class 'torch.optim.adam.Adam'> lr : 2.0952087472775883e-06-> 2.0952087472775883e-06 - loss = 0.003129208052996546
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:28,244 INFO epoch # 766 - for optimizer <class 'torch.optim.adam.Adam'> lr : 2.0952087472775883e-06-> 2.0952087472775883e-06 - loss = 0.003213522315490991
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:28,418 INFO epoch # 767 - for optimizer <class 'torch.optim.adam.Adam'> lr : 2.0952087472775883e-06-> 2.0952087472775883e-06 - loss = 0.003545793588273227
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:28,591 INFO epoch # 768 - for optimizer <class 'torch.optim.adam.Adam'> lr : 2.0952087472775883e-06-> 2.0952087472775883e-06 - loss = 0.0023876044724602252
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:28,765 INFO epoch # 769 - for optimizer <class 'torch.optim.adam.Adam'> lr : 2.0952087472775883e-06-> 2.0952087472775883e-06 - loss = 0.0025857852306216955
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:28,956 INFO epoch # 770 - for optimizer <class 'torch.optim.adam.Adam'> lr : 2.0952087472775883e-06-> 2.0952087472775883e-06 - loss = 0.004650713060982525
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:45:28,956 INFO *** epoch 770, rolling-avg-loss (window=10)= 0.0037214475945802406
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:29,131 INFO epoch # 771 - for optimizer <class 'torch.optim.adam.Adam'> lr : 2.0952087472775883e-06-> 2.0952087472775883e-06 - loss = 0.0029759463504888117
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:29,304 INFO epoch # 772 - for optimizer <class 'torch.optim.adam.Adam'> lr : 2.0952087472775883e-06-> 2.0952087472775883e-06 - loss = 0.0037969984696246684
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:29,478 INFO epoch # 773 - for optimizer <class 'torch.optim.adam.Adam'> lr : 2.0952087472775883e-06-> 2.0952087472775883e-06 - loss = 0.0027000814443454146
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:29,654 INFO epoch # 774 - for optimizer <class 'torch.optim.adam.Adam'> lr : 2.0952087472775883e-06-> 2.0952087472775883e-06 - loss = 0.00380520720500499
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:29,828 INFO epoch # 775 - for optimizer <class 'torch.optim.adam.Adam'> lr : 2.0952087472775883e-06-> 1.6761669978220706e-06 - loss = 0.002925199514720589
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:30,001 INFO epoch # 776 - for optimizer <class 'torch.optim.adam.Adam'> lr : 1.6761669978220706e-06-> 1.6761669978220706e-06 - loss = 0.00299021287355572
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:30,175 INFO epoch # 777 - for optimizer <class 'torch.optim.adam.Adam'> lr : 1.6761669978220706e-06-> 1.6761669978220706e-06 - loss = 0.002506413555238396
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:30,349 INFO epoch # 778 - for optimizer <class 'torch.optim.adam.Adam'> lr : 1.6761669978220706e-06-> 1.6761669978220706e-06 - loss = 0.0023767677776049823
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:30,524 INFO epoch # 779 - for optimizer <class 'torch.optim.adam.Adam'> lr : 1.6761669978220706e-06-> 1.6761669978220706e-06 - loss = 0.0027038604603148997
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:30,698 INFO epoch # 780 - for optimizer <class 'torch.optim.adam.Adam'> lr : 1.6761669978220706e-06-> 1.6761669978220706e-06 - loss = 0.002711974288104102
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:45:30,698 INFO *** epoch 780, rolling-avg-loss (window=10)= 0.0029492661939002573
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:30,873 INFO epoch # 781 - for optimizer <class 'torch.optim.adam.Adam'> lr : 1.6761669978220706e-06-> 1.6761669978220706e-06 - loss = 0.0051811005105264485
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:31,046 INFO epoch # 782 - for optimizer <class 'torch.optim.adam.Adam'> lr : 1.6761669978220706e-06-> 1.6761669978220706e-06 - loss = 0.002641503349877894
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:31,223 INFO epoch # 783 - for optimizer <class 'torch.optim.adam.Adam'> lr : 1.6761669978220706e-06-> 1.6761669978220706e-06 - loss = 0.002867328410502523
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:31,395 INFO epoch # 784 - for optimizer <class 'torch.optim.adam.Adam'> lr : 1.6761669978220706e-06-> 1.6761669978220706e-06 - loss = 0.00273831095546484
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:31,570 INFO epoch # 785 - for optimizer <class 'torch.optim.adam.Adam'> lr : 1.6761669978220706e-06-> 1.6761669978220706e-06 - loss = 0.0050293379463255405
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:31,743 INFO epoch # 786 - for optimizer <class 'torch.optim.adam.Adam'> lr : 1.6761669978220706e-06-> 1.3409335982576567e-06 - loss = 0.003075090586207807
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:31,920 INFO epoch # 787 - for optimizer <class 'torch.optim.adam.Adam'> lr : 1.3409335982576567e-06-> 1.3409335982576567e-06 - loss = 0.005450890370411798
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:32,092 INFO epoch # 788 - for optimizer <class 'torch.optim.adam.Adam'> lr : 1.3409335982576567e-06-> 1.3409335982576567e-06 - loss = 0.0022620201198151335
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:32,265 INFO epoch # 789 - for optimizer <class 'torch.optim.adam.Adam'> lr : 1.3409335982576567e-06-> 1.3409335982576567e-06 - loss = 0.002652115828823298
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:32,436 INFO epoch # 790 - for optimizer <class 'torch.optim.adam.Adam'> lr : 1.3409335982576567e-06-> 1.3409335982576567e-06 - loss = 0.0034791422076523304
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:45:32,437 INFO *** epoch 790, rolling-avg-loss (window=10)= 0.0035376840285607615
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:32,613 INFO epoch # 791 - for optimizer <class 'torch.optim.adam.Adam'> lr : 1.3409335982576567e-06-> 1.3409335982576567e-06 - loss = 0.0026762507623061538
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:32,792 INFO epoch # 792 - for optimizer <class 'torch.optim.adam.Adam'> lr : 1.3409335982576567e-06-> 1.3409335982576567e-06 - loss = 0.003588532446883619
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:32,965 INFO epoch # 793 - for optimizer <class 'torch.optim.adam.Adam'> lr : 1.3409335982576567e-06-> 1.3409335982576567e-06 - loss = 0.006448702071793377
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:33,137 INFO epoch # 794 - for optimizer <class 'torch.optim.adam.Adam'> lr : 1.3409335982576567e-06-> 1.3409335982576567e-06 - loss = 0.002809167723171413
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:33,311 INFO epoch # 795 - for optimizer <class 'torch.optim.adam.Adam'> lr : 1.3409335982576567e-06-> 1.3409335982576567e-06 - loss = 0.003023987024789676
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:33,483 INFO epoch # 796 - for optimizer <class 'torch.optim.adam.Adam'> lr : 1.3409335982576567e-06-> 1.3409335982576567e-06 - loss = 0.00727440626360476
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:33,657 INFO epoch # 797 - for optimizer <class 'torch.optim.adam.Adam'> lr : 1.3409335982576567e-06-> 1.0727468786061255e-06 - loss = 0.005525797663722187
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:33,830 INFO epoch # 798 - for optimizer <class 'torch.optim.adam.Adam'> lr : 1.0727468786061255e-06-> 1.0727468786061255e-06 - loss = 0.0025516436726320535
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:34,004 INFO epoch # 799 - for optimizer <class 'torch.optim.adam.Adam'> lr : 1.0727468786061255e-06-> 1.0727468786061255e-06 - loss = 0.0027928754570893943
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:34,179 INFO epoch # 800 - for optimizer <class 'torch.optim.adam.Adam'> lr : 1.0727468786061255e-06-> 1.0727468786061255e-06 - loss = 0.003030562773346901
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:45:34,179 INFO *** epoch 800, rolling-avg-loss (window=10)= 0.0039721925859339535
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:34,354 INFO epoch # 801 - for optimizer <class 'torch.optim.adam.Adam'> lr : 1.0727468786061255e-06-> 1.0727468786061255e-06 - loss = 0.003749694034922868
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:34,529 INFO epoch # 802 - for optimizer <class 'torch.optim.adam.Adam'> lr : 1.0727468786061255e-06-> 1.0727468786061255e-06 - loss = 0.002503455471014604
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:34,702 INFO epoch # 803 - for optimizer <class 'torch.optim.adam.Adam'> lr : 1.0727468786061255e-06-> 1.0727468786061255e-06 - loss = 0.002595807338366285
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:34,875 INFO epoch # 804 - for optimizer <class 'torch.optim.adam.Adam'> lr : 1.0727468786061255e-06-> 1.0727468786061255e-06 - loss = 0.0027331485762260854
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:35,050 INFO epoch # 805 - for optimizer <class 'torch.optim.adam.Adam'> lr : 1.0727468786061255e-06-> 1.0727468786061255e-06 - loss = 0.0029257270507514477
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:35,223 INFO epoch # 806 - for optimizer <class 'torch.optim.adam.Adam'> lr : 1.0727468786061255e-06-> 1.0727468786061255e-06 - loss = 0.004904627276118845
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:35,398 INFO epoch # 807 - for optimizer <class 'torch.optim.adam.Adam'> lr : 1.0727468786061255e-06-> 1.0727468786061255e-06 - loss = 0.0022949912818148732
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:35,577 INFO epoch # 808 - for optimizer <class 'torch.optim.adam.Adam'> lr : 1.0727468786061255e-06-> 8.581975028849004e-07 - loss = 0.0023705092899035662
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:35,750 INFO epoch # 809 - for optimizer <class 'torch.optim.adam.Adam'> lr : 8.581975028849004e-07-> 8.581975028849004e-07 - loss = 0.0022220895625650883
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:35,923 INFO epoch # 810 - for optimizer <class 'torch.optim.adam.Adam'> lr : 8.581975028849004e-07-> 8.581975028849004e-07 - loss = 0.0030672183784190565
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:45:35,924 INFO *** epoch 810, rolling-avg-loss (window=10)= 0.002936726826010272
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:36,098 INFO epoch # 811 - for optimizer <class 'torch.optim.adam.Adam'> lr : 8.581975028849004e-07-> 8.581975028849004e-07 - loss = 0.003041305288206786
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:36,271 INFO epoch # 812 - for optimizer <class 'torch.optim.adam.Adam'> lr : 8.581975028849004e-07-> 8.581975028849004e-07 - loss = 0.002574101119535044
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:36,445 INFO epoch # 813 - for optimizer <class 'torch.optim.adam.Adam'> lr : 8.581975028849004e-07-> 8.581975028849004e-07 - loss = 0.0026138906250707805
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:36,619 INFO epoch # 814 - for optimizer <class 'torch.optim.adam.Adam'> lr : 8.581975028849004e-07-> 8.581975028849004e-07 - loss = 0.005006309831514955
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:36,792 INFO epoch # 815 - for optimizer <class 'torch.optim.adam.Adam'> lr : 8.581975028849004e-07-> 8.581975028849004e-07 - loss = 0.0030854848446324468
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:36,965 INFO epoch # 816 - for optimizer <class 'torch.optim.adam.Adam'> lr : 8.581975028849004e-07-> 8.581975028849004e-07 - loss = 0.003654475964140147
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:37,140 INFO epoch # 817 - for optimizer <class 'torch.optim.adam.Adam'> lr : 8.581975028849004e-07-> 8.581975028849004e-07 - loss = 0.005598929594270885
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:37,313 INFO epoch # 818 - for optimizer <class 'torch.optim.adam.Adam'> lr : 8.581975028849004e-07-> 8.581975028849004e-07 - loss = 0.0025231733452528715
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:37,486 INFO epoch # 819 - for optimizer <class 'torch.optim.adam.Adam'> lr : 8.581975028849004e-07-> 6.865580023079204e-07 - loss = 0.00506923533976078
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:37,660 INFO epoch # 820 - for optimizer <class 'torch.optim.adam.Adam'> lr : 6.865580023079204e-07-> 6.865580023079204e-07 - loss = 0.0029260083101689816
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:45:37,660 INFO *** epoch 820, rolling-avg-loss (window=10)= 0.0036092914262553675
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:37,835 INFO epoch # 821 - for optimizer <class 'torch.optim.adam.Adam'> lr : 6.865580023079204e-07-> 6.865580023079204e-07 - loss = 0.002646676846779883
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:38,008 INFO epoch # 822 - for optimizer <class 'torch.optim.adam.Adam'> lr : 6.865580023079204e-07-> 6.865580023079204e-07 - loss = 0.002799684531055391
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:38,183 INFO epoch # 823 - for optimizer <class 'torch.optim.adam.Adam'> lr : 6.865580023079204e-07-> 6.865580023079204e-07 - loss = 0.0033676847233437
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:38,356 INFO epoch # 824 - for optimizer <class 'torch.optim.adam.Adam'> lr : 6.865580023079204e-07-> 6.865580023079204e-07 - loss = 0.0027113288233522326
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:38,531 INFO epoch # 825 - for optimizer <class 'torch.optim.adam.Adam'> lr : 6.865580023079204e-07-> 6.865580023079204e-07 - loss = 0.004711863002739847
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:38,704 INFO epoch # 826 - for optimizer <class 'torch.optim.adam.Adam'> lr : 6.865580023079204e-07-> 6.865580023079204e-07 - loss = 0.0024357377260457724
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:38,891 INFO epoch # 827 - for optimizer <class 'torch.optim.adam.Adam'> lr : 6.865580023079204e-07-> 6.865580023079204e-07 - loss = 0.004789020516909659
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:39,070 INFO epoch # 828 - for optimizer <class 'torch.optim.adam.Adam'> lr : 6.865580023079204e-07-> 6.865580023079204e-07 - loss = 0.0030899119446985424
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:39,244 INFO epoch # 829 - for optimizer <class 'torch.optim.adam.Adam'> lr : 6.865580023079204e-07-> 6.865580023079204e-07 - loss = 0.004486469435505569
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:39,416 INFO epoch # 830 - for optimizer <class 'torch.optim.adam.Adam'> lr : 6.865580023079204e-07-> 5.492464018463364e-07 - loss = 0.002367227745708078
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:45:39,416 INFO *** epoch 830, rolling-avg-loss (window=10)= 0.0033405605296138673
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:39,593 INFO epoch # 831 - for optimizer <class 'torch.optim.adam.Adam'> lr : 5.492464018463364e-07-> 5.492464018463364e-07 - loss = 0.0036176008288748562
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:39,769 INFO epoch # 832 - for optimizer <class 'torch.optim.adam.Adam'> lr : 5.492464018463364e-07-> 5.492464018463364e-07 - loss = 0.0025690291076898575
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:39,954 INFO epoch # 833 - for optimizer <class 'torch.optim.adam.Adam'> lr : 5.492464018463364e-07-> 5.492464018463364e-07 - loss = 0.006665018969215453
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:40,131 INFO epoch # 834 - for optimizer <class 'torch.optim.adam.Adam'> lr : 5.492464018463364e-07-> 5.492464018463364e-07 - loss = 0.0022469142568297684
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:40,305 INFO epoch # 835 - for optimizer <class 'torch.optim.adam.Adam'> lr : 5.492464018463364e-07-> 5.492464018463364e-07 - loss = 0.003225447842851281
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:40,478 INFO epoch # 836 - for optimizer <class 'torch.optim.adam.Adam'> lr : 5.492464018463364e-07-> 5.492464018463364e-07 - loss = 0.0033484502346254885
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:40,652 INFO epoch # 837 - for optimizer <class 'torch.optim.adam.Adam'> lr : 5.492464018463364e-07-> 5.492464018463364e-07 - loss = 0.002497927809599787
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:40,825 INFO epoch # 838 - for optimizer <class 'torch.optim.adam.Adam'> lr : 5.492464018463364e-07-> 5.492464018463364e-07 - loss = 0.003144875227008015
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:40,999 INFO epoch # 839 - for optimizer <class 'torch.optim.adam.Adam'> lr : 5.492464018463364e-07-> 5.492464018463364e-07 - loss = 0.003863565216306597
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:41,173 INFO epoch # 840 - for optimizer <class 'torch.optim.adam.Adam'> lr : 5.492464018463364e-07-> 5.492464018463364e-07 - loss = 0.00235331742442213
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:45:41,173 INFO *** epoch 840, rolling-avg-loss (window=10)= 0.0033532146917423233
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:41,347 INFO epoch # 841 - for optimizer <class 'torch.optim.adam.Adam'> lr : 5.492464018463364e-07-> 4.3939712147706914e-07 - loss = 0.0029934674385003746
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:41,521 INFO epoch # 842 - for optimizer <class 'torch.optim.adam.Adam'> lr : 4.3939712147706914e-07-> 4.3939712147706914e-07 - loss = 0.0033151680254377425
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:41,697 INFO epoch # 843 - for optimizer <class 'torch.optim.adam.Adam'> lr : 4.3939712147706914e-07-> 4.3939712147706914e-07 - loss = 0.003870321554131806
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:41,870 INFO epoch # 844 - for optimizer <class 'torch.optim.adam.Adam'> lr : 4.3939712147706914e-07-> 4.3939712147706914e-07 - loss = 0.002257262749481015
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:42,044 INFO epoch # 845 - for optimizer <class 'torch.optim.adam.Adam'> lr : 4.3939712147706914e-07-> 4.3939712147706914e-07 - loss = 0.002484377706423402
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:42,218 INFO epoch # 846 - for optimizer <class 'torch.optim.adam.Adam'> lr : 4.3939712147706914e-07-> 4.3939712147706914e-07 - loss = 0.002501439244952053
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:42,391 INFO epoch # 847 - for optimizer <class 'torch.optim.adam.Adam'> lr : 4.3939712147706914e-07-> 4.3939712147706914e-07 - loss = 0.003116436011623591
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:42,564 INFO epoch # 848 - for optimizer <class 'torch.optim.adam.Adam'> lr : 4.3939712147706914e-07-> 4.3939712147706914e-07 - loss = 0.0035266115446574986
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:42,738 INFO epoch # 849 - for optimizer <class 'torch.optim.adam.Adam'> lr : 4.3939712147706914e-07-> 4.3939712147706914e-07 - loss = 0.0025070240371860564
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:42,912 INFO epoch # 850 - for optimizer <class 'torch.optim.adam.Adam'> lr : 4.3939712147706914e-07-> 4.3939712147706914e-07 - loss = 0.0027303347014822066
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:45:42,912 INFO *** epoch 850, rolling-avg-loss (window=10)= 0.0029302443013875744
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:43,087 INFO epoch # 851 - for optimizer <class 'torch.optim.adam.Adam'> lr : 4.3939712147706914e-07-> 4.3939712147706914e-07 - loss = 0.0027936804690398276
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:43,260 INFO epoch # 852 - for optimizer <class 'torch.optim.adam.Adam'> lr : 4.3939712147706914e-07-> 3.5151769718165535e-07 - loss = 0.004261149908415973
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:43,434 INFO epoch # 853 - for optimizer <class 'torch.optim.adam.Adam'> lr : 3.5151769718165535e-07-> 3.5151769718165535e-07 - loss = 0.0023901817912701517
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:43,611 INFO epoch # 854 - for optimizer <class 'torch.optim.adam.Adam'> lr : 3.5151769718165535e-07-> 3.5151769718165535e-07 - loss = 0.003263490740209818
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:43,799 INFO epoch # 855 - for optimizer <class 'torch.optim.adam.Adam'> lr : 3.5151769718165535e-07-> 3.5151769718165535e-07 - loss = 0.0021736483613494784
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:43,978 INFO epoch # 856 - for optimizer <class 'torch.optim.adam.Adam'> lr : 3.5151769718165535e-07-> 3.5151769718165535e-07 - loss = 0.002207086479756981
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:44,171 INFO epoch # 857 - for optimizer <class 'torch.optim.adam.Adam'> lr : 3.5151769718165535e-07-> 3.5151769718165535e-07 - loss = 0.006187828665133566
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:44,370 INFO epoch # 858 - for optimizer <class 'torch.optim.adam.Adam'> lr : 3.5151769718165535e-07-> 3.5151769718165535e-07 - loss = 0.0026073945919051766
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:44,557 INFO epoch # 859 - for optimizer <class 'torch.optim.adam.Adam'> lr : 3.5151769718165535e-07-> 3.5151769718165535e-07 - loss = 0.0025753651570994407
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:44,736 INFO epoch # 860 - for optimizer <class 'torch.optim.adam.Adam'> lr : 3.5151769718165535e-07-> 3.5151769718165535e-07 - loss = 0.0028309450135566294
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:45:44,737 INFO *** epoch 860, rolling-avg-loss (window=10)= 0.003129077117773704
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:44,912 INFO epoch # 861 - for optimizer <class 'torch.optim.adam.Adam'> lr : 3.5151769718165535e-07-> 3.5151769718165535e-07 - loss = 0.0029334313585422933
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:45,086 INFO epoch # 862 - for optimizer <class 'torch.optim.adam.Adam'> lr : 3.5151769718165535e-07-> 3.5151769718165535e-07 - loss = 0.002453850902384147
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:45,258 INFO epoch # 863 - for optimizer <class 'torch.optim.adam.Adam'> lr : 3.5151769718165535e-07-> 2.812141577453243e-07 - loss = 0.003118084860034287
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:45,431 INFO epoch # 864 - for optimizer <class 'torch.optim.adam.Adam'> lr : 2.812141577453243e-07-> 2.812141577453243e-07 - loss = 0.003686766605824232
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:45,605 INFO epoch # 865 - for optimizer <class 'torch.optim.adam.Adam'> lr : 2.812141577453243e-07-> 2.812141577453243e-07 - loss = 0.0025568834389559925
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:45,777 INFO epoch # 866 - for optimizer <class 'torch.optim.adam.Adam'> lr : 2.812141577453243e-07-> 2.812141577453243e-07 - loss = 0.0023181315627880394
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:45,952 INFO epoch # 867 - for optimizer <class 'torch.optim.adam.Adam'> lr : 2.812141577453243e-07-> 2.812141577453243e-07 - loss = 0.002953860879642889
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:46,126 INFO epoch # 868 - for optimizer <class 'torch.optim.adam.Adam'> lr : 2.812141577453243e-07-> 2.812141577453243e-07 - loss = 0.0022134350074338727
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:46,299 INFO epoch # 869 - for optimizer <class 'torch.optim.adam.Adam'> lr : 2.812141577453243e-07-> 2.812141577453243e-07 - loss = 0.0026056994684040546
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:46,473 INFO epoch # 870 - for optimizer <class 'torch.optim.adam.Adam'> lr : 2.812141577453243e-07-> 2.812141577453243e-07 - loss = 0.004339401551987976
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:45:46,473 INFO *** epoch 870, rolling-avg-loss (window=10)= 0.0029179545635997783
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:46,646 INFO epoch # 871 - for optimizer <class 'torch.optim.adam.Adam'> lr : 2.812141577453243e-07-> 2.812141577453243e-07 - loss = 0.0026800705527421087
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:46,820 INFO epoch # 872 - for optimizer <class 'torch.optim.adam.Adam'> lr : 2.812141577453243e-07-> 2.812141577453243e-07 - loss = 0.004473704902920872
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:46,996 INFO epoch # 873 - for optimizer <class 'torch.optim.adam.Adam'> lr : 2.812141577453243e-07-> 2.812141577453243e-07 - loss = 0.00290549875353463
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:47,169 INFO epoch # 874 - for optimizer <class 'torch.optim.adam.Adam'> lr : 2.812141577453243e-07-> 2.2497132619625947e-07 - loss = 0.002728958847001195
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:47,342 INFO epoch # 875 - for optimizer <class 'torch.optim.adam.Adam'> lr : 2.2497132619625947e-07-> 2.2497132619625947e-07 - loss = 0.002554754843004048
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:47,517 INFO epoch # 876 - for optimizer <class 'torch.optim.adam.Adam'> lr : 2.2497132619625947e-07-> 2.2497132619625947e-07 - loss = 0.0025570302095729858
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:47,692 INFO epoch # 877 - for optimizer <class 'torch.optim.adam.Adam'> lr : 2.2497132619625947e-07-> 2.2497132619625947e-07 - loss = 0.0024357202055398375
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:47,865 INFO epoch # 878 - for optimizer <class 'torch.optim.adam.Adam'> lr : 2.2497132619625947e-07-> 2.2497132619625947e-07 - loss = 0.004719639895483851
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:48,039 INFO epoch # 879 - for optimizer <class 'torch.optim.adam.Adam'> lr : 2.2497132619625947e-07-> 2.2497132619625947e-07 - loss = 0.002362970990361646
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:48,215 INFO epoch # 880 - for optimizer <class 'torch.optim.adam.Adam'> lr : 2.2497132619625947e-07-> 2.2497132619625947e-07 - loss = 0.003919169656001031
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:45:48,215 INFO *** epoch 880, rolling-avg-loss (window=10)= 0.0031337518856162207
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:48,390 INFO epoch # 881 - for optimizer <class 'torch.optim.adam.Adam'> lr : 2.2497132619625947e-07-> 2.2497132619625947e-07 - loss = 0.0028270153561607003
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:48,565 INFO epoch # 882 - for optimizer <class 'torch.optim.adam.Adam'> lr : 2.2497132619625947e-07-> 2.2497132619625947e-07 - loss = 0.0035991690238006413
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:48,756 INFO epoch # 883 - for optimizer <class 'torch.optim.adam.Adam'> lr : 2.2497132619625947e-07-> 2.2497132619625947e-07 - loss = 0.0024622079508844763
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:48,932 INFO epoch # 884 - for optimizer <class 'torch.optim.adam.Adam'> lr : 2.2497132619625947e-07-> 2.2497132619625947e-07 - loss = 0.002312280412297696
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:49,107 INFO epoch # 885 - for optimizer <class 'torch.optim.adam.Adam'> lr : 2.2497132619625947e-07-> 1.7997706095700758e-07 - loss = 0.007801328902132809
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:49,288 INFO epoch # 886 - for optimizer <class 'torch.optim.adam.Adam'> lr : 1.7997706095700758e-07-> 1.7997706095700758e-07 - loss = 0.005252560542430729
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:49,464 INFO epoch # 887 - for optimizer <class 'torch.optim.adam.Adam'> lr : 1.7997706095700758e-07-> 1.7997706095700758e-07 - loss = 0.0025242717820219696
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:49,639 INFO epoch # 888 - for optimizer <class 'torch.optim.adam.Adam'> lr : 1.7997706095700758e-07-> 1.7997706095700758e-07 - loss = 0.002648538298672065
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:49,822 INFO epoch # 889 - for optimizer <class 'torch.optim.adam.Adam'> lr : 1.7997706095700758e-07-> 1.7997706095700758e-07 - loss = 0.003473746997769922
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:50,012 INFO epoch # 890 - for optimizer <class 'torch.optim.adam.Adam'> lr : 1.7997706095700758e-07-> 1.7997706095700758e-07 - loss = 0.002442299446556717
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:45:50,012 INFO *** epoch 890, rolling-avg-loss (window=10)= 0.0035343418712727726
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:50,187 INFO epoch # 891 - for optimizer <class 'torch.optim.adam.Adam'> lr : 1.7997706095700758e-07-> 1.7997706095700758e-07 - loss = 0.0029381081112660468
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:50,361 INFO epoch # 892 - for optimizer <class 'torch.optim.adam.Adam'> lr : 1.7997706095700758e-07-> 1.7997706095700758e-07 - loss = 0.0023635669494979084
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:50,537 INFO epoch # 893 - for optimizer <class 'torch.optim.adam.Adam'> lr : 1.7997706095700758e-07-> 1.7997706095700758e-07 - loss = 0.0033446760498918593
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:50,711 INFO epoch # 894 - for optimizer <class 'torch.optim.adam.Adam'> lr : 1.7997706095700758e-07-> 1.7997706095700758e-07 - loss = 0.0037642588722519577
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:50,885 INFO epoch # 895 - for optimizer <class 'torch.optim.adam.Adam'> lr : 1.7997706095700758e-07-> 1.7997706095700758e-07 - loss = 0.003477819263935089
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:51,058 INFO epoch # 896 - for optimizer <class 'torch.optim.adam.Adam'> lr : 1.7997706095700758e-07-> 1.4398164876560607e-07 - loss = 0.0033937031985260546
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:51,232 INFO epoch # 897 - for optimizer <class 'torch.optim.adam.Adam'> lr : 1.4398164876560607e-07-> 1.4398164876560607e-07 - loss = 0.002405672916211188
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:51,404 INFO epoch # 898 - for optimizer <class 'torch.optim.adam.Adam'> lr : 1.4398164876560607e-07-> 1.4398164876560607e-07 - loss = 0.0028636307106353343
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:51,578 INFO epoch # 899 - for optimizer <class 'torch.optim.adam.Adam'> lr : 1.4398164876560607e-07-> 1.4398164876560607e-07 - loss = 0.0022854065464343876
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:51,753 INFO epoch # 900 - for optimizer <class 'torch.optim.adam.Adam'> lr : 1.4398164876560607e-07-> 1.4398164876560607e-07 - loss = 0.005244394938927144
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:45:51,753 INFO *** epoch 900, rolling-avg-loss (window=10)= 0.003208123755757697
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:51,929 INFO epoch # 901 - for optimizer <class 'torch.optim.adam.Adam'> lr : 1.4398164876560607e-07-> 1.4398164876560607e-07 - loss = 0.0028791881049983203
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:52,103 INFO epoch # 902 - for optimizer <class 'torch.optim.adam.Adam'> lr : 1.4398164876560607e-07-> 1.4398164876560607e-07 - loss = 0.0023061491374392062
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:52,277 INFO epoch # 903 - for optimizer <class 'torch.optim.adam.Adam'> lr : 1.4398164876560607e-07-> 1.4398164876560607e-07 - loss = 0.002968773420434445
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:52,449 INFO epoch # 904 - for optimizer <class 'torch.optim.adam.Adam'> lr : 1.4398164876560607e-07-> 1.4398164876560607e-07 - loss = 0.0027041733264923096
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:52,623 INFO epoch # 905 - for optimizer <class 'torch.optim.adam.Adam'> lr : 1.4398164876560607e-07-> 1.4398164876560607e-07 - loss = 0.00339507864555344
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:52,796 INFO epoch # 906 - for optimizer <class 'torch.optim.adam.Adam'> lr : 1.4398164876560607e-07-> 1.4398164876560607e-07 - loss = 0.006778520764783025
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:52,970 INFO epoch # 907 - for optimizer <class 'torch.optim.adam.Adam'> lr : 1.4398164876560607e-07-> 1.1518531901248487e-07 - loss = 0.002463504031766206
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:53,143 INFO epoch # 908 - for optimizer <class 'torch.optim.adam.Adam'> lr : 1.1518531901248487e-07-> 1.1518531901248487e-07 - loss = 0.003017322567757219
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:53,316 INFO epoch # 909 - for optimizer <class 'torch.optim.adam.Adam'> lr : 1.1518531901248487e-07-> 1.1518531901248487e-07 - loss = 0.004007451410870999
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:53,489 INFO epoch # 910 - for optimizer <class 'torch.optim.adam.Adam'> lr : 1.1518531901248487e-07-> 1.1518531901248487e-07 - loss = 0.002572118886746466
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:45:53,489 INFO *** epoch 910, rolling-avg-loss (window=10)= 0.0033092280296841635
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:53,670 INFO epoch # 911 - for optimizer <class 'torch.optim.adam.Adam'> lr : 1.1518531901248487e-07-> 1.1518531901248487e-07 - loss = 0.002543962502386421
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:53,843 INFO epoch # 912 - for optimizer <class 'torch.optim.adam.Adam'> lr : 1.1518531901248487e-07-> 1.1518531901248487e-07 - loss = 0.00406590779311955
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:54,016 INFO epoch # 913 - for optimizer <class 'torch.optim.adam.Adam'> lr : 1.1518531901248487e-07-> 1.1518531901248487e-07 - loss = 0.0032411363208666444
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:54,189 INFO epoch # 914 - for optimizer <class 'torch.optim.adam.Adam'> lr : 1.1518531901248487e-07-> 1.1518531901248487e-07 - loss = 0.0033044404699467123
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:54,363 INFO epoch # 915 - for optimizer <class 'torch.optim.adam.Adam'> lr : 1.1518531901248487e-07-> 1.1518531901248487e-07 - loss = 0.003790979040786624
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:54,536 INFO epoch # 916 - for optimizer <class 'torch.optim.adam.Adam'> lr : 1.1518531901248487e-07-> 1.1518531901248487e-07 - loss = 0.006795460300054401
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:54,711 INFO epoch # 917 - for optimizer <class 'torch.optim.adam.Adam'> lr : 1.1518531901248487e-07-> 1.1518531901248487e-07 - loss = 0.006550501275341958
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:54,883 INFO epoch # 918 - for optimizer <class 'torch.optim.adam.Adam'> lr : 1.1518531901248487e-07-> 9.21482552099879e-08 - loss = 0.002785295422654599
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:55,057 INFO epoch # 919 - for optimizer <class 'torch.optim.adam.Adam'> lr : 9.21482552099879e-08-> 9.21482552099879e-08 - loss = 0.0027728002751246095
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:55,229 INFO epoch # 920 - for optimizer <class 'torch.optim.adam.Adam'> lr : 9.21482552099879e-08-> 9.21482552099879e-08 - loss = 0.004059616185259074
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:45:55,229 INFO *** epoch 920, rolling-avg-loss (window=10)= 0.003991009958554059
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:55,404 INFO epoch # 921 - for optimizer <class 'torch.optim.adam.Adam'> lr : 9.21482552099879e-08-> 9.21482552099879e-08 - loss = 0.0036282327491790056
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:55,576 INFO epoch # 922 - for optimizer <class 'torch.optim.adam.Adam'> lr : 9.21482552099879e-08-> 9.21482552099879e-08 - loss = 0.0030167849035933614
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:55,749 INFO epoch # 923 - for optimizer <class 'torch.optim.adam.Adam'> lr : 9.21482552099879e-08-> 9.21482552099879e-08 - loss = 0.0023785012017469853
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:55,921 INFO epoch # 924 - for optimizer <class 'torch.optim.adam.Adam'> lr : 9.21482552099879e-08-> 9.21482552099879e-08 - loss = 0.0024820765829645097
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:56,095 INFO epoch # 925 - for optimizer <class 'torch.optim.adam.Adam'> lr : 9.21482552099879e-08-> 9.21482552099879e-08 - loss = 0.002567340328823775
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:56,267 INFO epoch # 926 - for optimizer <class 'torch.optim.adam.Adam'> lr : 9.21482552099879e-08-> 9.21482552099879e-08 - loss = 0.003106342162936926
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:56,441 INFO epoch # 927 - for optimizer <class 'torch.optim.adam.Adam'> lr : 9.21482552099879e-08-> 9.21482552099879e-08 - loss = 0.00225942864199169
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:56,627 INFO epoch # 928 - for optimizer <class 'torch.optim.adam.Adam'> lr : 9.21482552099879e-08-> 9.21482552099879e-08 - loss = 0.0037475481803994626
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:56,801 INFO epoch # 929 - for optimizer <class 'torch.optim.adam.Adam'> lr : 9.21482552099879e-08-> 7.371860416799032e-08 - loss = 0.003281661687651649
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:56,974 INFO epoch # 930 - for optimizer <class 'torch.optim.adam.Adam'> lr : 7.371860416799032e-08-> 7.371860416799032e-08 - loss = 0.002888373681344092
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:45:56,974 INFO *** epoch 930, rolling-avg-loss (window=10)= 0.0029356290120631456
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:57,148 INFO epoch # 931 - for optimizer <class 'torch.optim.adam.Adam'> lr : 7.371860416799032e-08-> 7.371860416799032e-08 - loss = 0.002365261985687539
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:57,321 INFO epoch # 932 - for optimizer <class 'torch.optim.adam.Adam'> lr : 7.371860416799032e-08-> 7.371860416799032e-08 - loss = 0.0026180033455602825
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:57,493 INFO epoch # 933 - for optimizer <class 'torch.optim.adam.Adam'> lr : 7.371860416799032e-08-> 7.371860416799032e-08 - loss = 0.002378384175244719
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:57,667 INFO epoch # 934 - for optimizer <class 'torch.optim.adam.Adam'> lr : 7.371860416799032e-08-> 7.371860416799032e-08 - loss = 0.0026428177661728114
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:57,844 INFO epoch # 935 - for optimizer <class 'torch.optim.adam.Adam'> lr : 7.371860416799032e-08-> 7.371860416799032e-08 - loss = 0.0035385839291848242
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:58,016 INFO epoch # 936 - for optimizer <class 'torch.optim.adam.Adam'> lr : 7.371860416799032e-08-> 7.371860416799032e-08 - loss = 0.003889811399858445
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:58,189 INFO epoch # 937 - for optimizer <class 'torch.optim.adam.Adam'> lr : 7.371860416799032e-08-> 7.371860416799032e-08 - loss = 0.0024573648115620017
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:58,361 INFO epoch # 938 - for optimizer <class 'torch.optim.adam.Adam'> lr : 7.371860416799032e-08-> 7.371860416799032e-08 - loss = 0.002670333196874708
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:58,535 INFO epoch # 939 - for optimizer <class 'torch.optim.adam.Adam'> lr : 7.371860416799032e-08-> 7.371860416799032e-08 - loss = 0.0033170614042319357
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:58,707 INFO epoch # 940 - for optimizer <class 'torch.optim.adam.Adam'> lr : 7.371860416799032e-08-> 5.897488333439226e-08 - loss = 0.0022143536480143666
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:45:58,707 INFO *** epoch 940, rolling-avg-loss (window=10)= 0.0028091975662391635
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:58,882 INFO epoch # 941 - for optimizer <class 'torch.optim.adam.Adam'> lr : 5.897488333439226e-08-> 5.897488333439226e-08 - loss = 0.002540696004871279
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:59,055 INFO epoch # 942 - for optimizer <class 'torch.optim.adam.Adam'> lr : 5.897488333439226e-08-> 5.897488333439226e-08 - loss = 0.0028559037600643933
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:59,228 INFO epoch # 943 - for optimizer <class 'torch.optim.adam.Adam'> lr : 5.897488333439226e-08-> 5.897488333439226e-08 - loss = 0.003335334244184196
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:59,401 INFO epoch # 944 - for optimizer <class 'torch.optim.adam.Adam'> lr : 5.897488333439226e-08-> 5.897488333439226e-08 - loss = 0.0028329174092505127
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:59,575 INFO epoch # 945 - for optimizer <class 'torch.optim.adam.Adam'> lr : 5.897488333439226e-08-> 5.897488333439226e-08 - loss = 0.004266405128873885
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:59,749 INFO epoch # 946 - for optimizer <class 'torch.optim.adam.Adam'> lr : 5.897488333439226e-08-> 5.897488333439226e-08 - loss = 0.002868211187887937
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:45:59,923 INFO epoch # 947 - for optimizer <class 'torch.optim.adam.Adam'> lr : 5.897488333439226e-08-> 5.897488333439226e-08 - loss = 0.002830494020599872
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:46:00,096 INFO epoch # 948 - for optimizer <class 'torch.optim.adam.Adam'> lr : 5.897488333439226e-08-> 5.897488333439226e-08 - loss = 0.0031178720528259873
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:46:00,270 INFO epoch # 949 - for optimizer <class 'torch.optim.adam.Adam'> lr : 5.897488333439226e-08-> 5.897488333439226e-08 - loss = 0.0077429162338376045
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:46:00,443 INFO epoch # 950 - for optimizer <class 'torch.optim.adam.Adam'> lr : 5.897488333439226e-08-> 5.897488333439226e-08 - loss = 0.00248295342316851
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:46:00,443 INFO *** epoch 950, rolling-avg-loss (window=10)= 0.0034873703465564177
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:46:00,616 INFO epoch # 951 - for optimizer <class 'torch.optim.adam.Adam'> lr : 5.897488333439226e-08-> 4.717990666751381e-08 - loss = 0.0027766642160713673
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:46:00,796 INFO epoch # 952 - for optimizer <class 'torch.optim.adam.Adam'> lr : 4.717990666751381e-08-> 4.717990666751381e-08 - loss = 0.0025210307503584772
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:46:00,980 INFO epoch # 953 - for optimizer <class 'torch.optim.adam.Adam'> lr : 4.717990666751381e-08-> 4.717990666751381e-08 - loss = 0.0029986209119670093
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:46:01,153 INFO epoch # 954 - for optimizer <class 'torch.optim.adam.Adam'> lr : 4.717990666751381e-08-> 4.717990666751381e-08 - loss = 0.004728001833427697
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:46:01,328 INFO epoch # 955 - for optimizer <class 'torch.optim.adam.Adam'> lr : 4.717990666751381e-08-> 4.717990666751381e-08 - loss = 0.0025957213947549462
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:46:01,500 INFO epoch # 956 - for optimizer <class 'torch.optim.adam.Adam'> lr : 4.717990666751381e-08-> 4.717990666751381e-08 - loss = 0.002465520636178553
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:46:01,674 INFO epoch # 957 - for optimizer <class 'torch.optim.adam.Adam'> lr : 4.717990666751381e-08-> 4.717990666751381e-08 - loss = 0.003145186579786241
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:46:01,852 INFO epoch # 958 - for optimizer <class 'torch.optim.adam.Adam'> lr : 4.717990666751381e-08-> 4.717990666751381e-08 - loss = 0.002991767367348075
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:46:02,026 INFO epoch # 959 - for optimizer <class 'torch.optim.adam.Adam'> lr : 4.717990666751381e-08-> 4.717990666751381e-08 - loss = 0.003482200554572046
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:46:02,199 INFO epoch # 960 - for optimizer <class 'torch.optim.adam.Adam'> lr : 4.717990666751381e-08-> 4.717990666751381e-08 - loss = 0.002313285556738265
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:46:02,199 INFO *** epoch 960, rolling-avg-loss (window=10)= 0.003001799980120268
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:46:02,373 INFO epoch # 961 - for optimizer <class 'torch.optim.adam.Adam'> lr : 4.717990666751381e-08-> 4.717990666751381e-08 - loss = 0.002749816980212927
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:46:02,547 INFO epoch # 962 - for optimizer <class 'torch.optim.adam.Adam'> lr : 4.717990666751381e-08-> 4.717990666751381e-08 - loss = 0.0027191456756554544
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:46:02,723 INFO epoch # 963 - for optimizer <class 'torch.optim.adam.Adam'> lr : 4.717990666751381e-08-> 4.717990666751381e-08 - loss = 0.002314881276106462
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:46:02,896 INFO epoch # 964 - for optimizer <class 'torch.optim.adam.Adam'> lr : 4.717990666751381e-08-> 4.717990666751381e-08 - loss = 0.0026825798267964274
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:46:03,071 INFO epoch # 965 - for optimizer <class 'torch.optim.adam.Adam'> lr : 4.717990666751381e-08-> 4.717990666751381e-08 - loss = 0.004107415210455656
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:46:03,244 INFO epoch # 966 - for optimizer <class 'torch.optim.adam.Adam'> lr : 4.717990666751381e-08-> 4.717990666751381e-08 - loss = 0.002952839306090027
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:46:03,418 INFO epoch # 967 - for optimizer <class 'torch.optim.adam.Adam'> lr : 4.717990666751381e-08-> 4.717990666751381e-08 - loss = 0.003236983495298773
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:46:03,591 INFO epoch # 968 - for optimizer <class 'torch.optim.adam.Adam'> lr : 4.717990666751381e-08-> 4.717990666751381e-08 - loss = 0.0021432946232380345
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:46:03,769 INFO epoch # 969 - for optimizer <class 'torch.optim.adam.Adam'> lr : 4.717990666751381e-08-> 4.717990666751381e-08 - loss = 0.004348618007497862
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:46:03,942 INFO epoch # 970 - for optimizer <class 'torch.optim.adam.Adam'> lr : 4.717990666751381e-08-> 4.717990666751381e-08 - loss = 0.002507137192878872
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:46:03,942 INFO *** epoch 970, rolling-avg-loss (window=10)= 0.0029762711594230494
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:46:04,117 INFO epoch # 971 - for optimizer <class 'torch.optim.adam.Adam'> lr : 4.717990666751381e-08-> 4.717990666751381e-08 - loss = 0.0033855786314234138
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:46:04,289 INFO epoch # 972 - for optimizer <class 'torch.optim.adam.Adam'> lr : 4.717990666751381e-08-> 4.717990666751381e-08 - loss = 0.0029263815958984196
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:46:04,463 INFO epoch # 973 - for optimizer <class 'torch.optim.adam.Adam'> lr : 4.717990666751381e-08-> 4.717990666751381e-08 - loss = 0.0025464658247074112
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:46:04,636 INFO epoch # 974 - for optimizer <class 'torch.optim.adam.Adam'> lr : 4.717990666751381e-08-> 4.717990666751381e-08 - loss = 0.003074315085541457
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:46:04,811 INFO epoch # 975 - for optimizer <class 'torch.optim.adam.Adam'> lr : 4.717990666751381e-08-> 4.717990666751381e-08 - loss = 0.0026602629804983735
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:46:04,983 INFO epoch # 976 - for optimizer <class 'torch.optim.adam.Adam'> lr : 4.717990666751381e-08-> 4.717990666751381e-08 - loss = 0.003462776367086917
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:46:05,157 INFO epoch # 977 - for optimizer <class 'torch.optim.adam.Adam'> lr : 4.717990666751381e-08-> 4.717990666751381e-08 - loss = 0.004835543688386679
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:46:05,329 INFO epoch # 978 - for optimizer <class 'torch.optim.adam.Adam'> lr : 4.717990666751381e-08-> 4.717990666751381e-08 - loss = 0.0068054680014029145
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:46:05,503 INFO epoch # 979 - for optimizer <class 'torch.optim.adam.Adam'> lr : 4.717990666751381e-08-> 4.717990666751381e-08 - loss = 0.006303039554040879
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:46:05,679 INFO epoch # 980 - for optimizer <class 'torch.optim.adam.Adam'> lr : 4.717990666751381e-08-> 4.717990666751381e-08 - loss = 0.002521583897760138
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:46:05,679 INFO *** epoch 980, rolling-avg-loss (window=10)= 0.0038521415626746602
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:46:05,854 INFO epoch # 981 - for optimizer <class 'torch.optim.adam.Adam'> lr : 4.717990666751381e-08-> 4.717990666751381e-08 - loss = 0.0034740639675874263
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:46:06,027 INFO epoch # 982 - for optimizer <class 'torch.optim.adam.Adam'> lr : 4.717990666751381e-08-> 4.717990666751381e-08 - loss = 0.0034049776731990278
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:46:06,201 INFO epoch # 983 - for optimizer <class 'torch.optim.adam.Adam'> lr : 4.717990666751381e-08-> 4.717990666751381e-08 - loss = 0.0025581500667613
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:46:06,373 INFO epoch # 984 - for optimizer <class 'torch.optim.adam.Adam'> lr : 4.717990666751381e-08-> 4.717990666751381e-08 - loss = 0.00270958652254194
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:46:06,547 INFO epoch # 985 - for optimizer <class 'torch.optim.adam.Adam'> lr : 4.717990666751381e-08-> 4.717990666751381e-08 - loss = 0.003989247663412243
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:46:06,720 INFO epoch # 986 - for optimizer <class 'torch.optim.adam.Adam'> lr : 4.717990666751381e-08-> 4.717990666751381e-08 - loss = 0.002942737308330834
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:46:06,898 INFO epoch # 987 - for optimizer <class 'torch.optim.adam.Adam'> lr : 4.717990666751381e-08-> 4.717990666751381e-08 - loss = 0.002587516908533871
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:46:07,070 INFO epoch # 988 - for optimizer <class 'torch.optim.adam.Adam'> lr : 4.717990666751381e-08-> 4.717990666751381e-08 - loss = 0.0024237886536866426
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:46:07,244 INFO epoch # 989 - for optimizer <class 'torch.optim.adam.Adam'> lr : 4.717990666751381e-08-> 4.717990666751381e-08 - loss = 0.004341835912782699
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:46:07,415 INFO epoch # 990 - for optimizer <class 'torch.optim.adam.Adam'> lr : 4.717990666751381e-08-> 4.717990666751381e-08 - loss = 0.0027660655905492604
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:46:07,416 INFO *** epoch 990, rolling-avg-loss (window=10)= 0.0031197970267385243
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:46:07,590 INFO epoch # 991 - for optimizer <class 'torch.optim.adam.Adam'> lr : 4.717990666751381e-08-> 4.717990666751381e-08 - loss = 0.0039032862696330994
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:46:07,764 INFO epoch # 992 - for optimizer <class 'torch.optim.adam.Adam'> lr : 4.717990666751381e-08-> 4.717990666751381e-08 - loss = 0.00371241697575897
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:46:07,938 INFO epoch # 993 - for optimizer <class 'torch.optim.adam.Adam'> lr : 4.717990666751381e-08-> 4.717990666751381e-08 - loss = 0.004515368607826531
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:46:08,112 INFO epoch # 994 - for optimizer <class 'torch.optim.adam.Adam'> lr : 4.717990666751381e-08-> 4.717990666751381e-08 - loss = 0.004198884300421923
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:46:08,285 INFO epoch # 995 - for optimizer <class 'torch.optim.adam.Adam'> lr : 4.717990666751381e-08-> 4.717990666751381e-08 - loss = 0.0022537442855536938
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:46:08,457 INFO epoch # 996 - for optimizer <class 'torch.optim.adam.Adam'> lr : 4.717990666751381e-08-> 4.717990666751381e-08 - loss = 0.003433021978707984
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:46:08,632 INFO epoch # 997 - for optimizer <class 'torch.optim.adam.Adam'> lr : 4.717990666751381e-08-> 4.717990666751381e-08 - loss = 0.002965323510579765
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:46:08,805 INFO epoch # 998 - for optimizer <class 'torch.optim.adam.Adam'> lr : 4.717990666751381e-08-> 4.717990666751381e-08 - loss = 0.002331339186639525
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:46:08,980 INFO epoch # 999 - for optimizer <class 'torch.optim.adam.Adam'> lr : 4.717990666751381e-08-> 4.717990666751381e-08 - loss = 0.0049584327498450875
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:46:09,154 INFO epoch # 1000 - for optimizer <class 'torch.optim.adam.Adam'> lr : 4.717990666751381e-08-> 4.717990666751381e-08 - loss = 0.0027883757720701396
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:46:09,154 INFO *** epoch 1000, rolling-avg-loss (window=10)= 0.0035060193637036718
[experiments_sandbox.py:572 -   <module>()] 2023-04-22 02:46:09,154 INFO training time in seconds = 176
[experiments_sandbox.py:576 -   <module>()] 2023-04-22 02:46:09,155 INFO epochs-loss curve df :
[experiments_sandbox.py:577 -   <module>()] 2023-04-22 02:46:09,159 INFO 
    epochs  rolling-avg-loss
0       10          0.227395
1       20          0.011042
2       30          0.008587
3       40          0.006604
4       50          0.008459
5       60          0.006739
6       70          0.007513
7       80          0.007615
8       90          0.007101
9      100          0.006524
10     110          0.008413
11     120          0.007257
12     130          0.005600
13     140          0.004883
14     150          0.006459
15     160          0.004333
16     170          0.005401
17     180          0.004466
18     190          0.004051
19     200          0.004944
20     210          0.003688
21     220          0.003047
22     230          0.003201
23     240          0.004065
24     250          0.005028
25     260          0.003793
26     270          0.004225
27     280          0.003108
28     290          0.003413
29     300          0.003909
30     310          0.004224
31     320          0.003993
32     330          0.003037
33     340          0.003304
34     350          0.003382
35     360          0.004538
36     370          0.003357
37     380          0.003297
38     390          0.003244
39     400          0.004132
40     410          0.003594
41     420          0.002888
42     430          0.003277
43     440          0.003133
44     450          0.002996
45     460          0.003201
46     470          0.003102
47     480          0.003622
48     490          0.002878
49     500          0.003599
50     510          0.003636
51     520          0.003993
52     530          0.003502
53     540          0.003741
54     550          0.004578
55     560          0.003354
56     570          0.003172
57     580          0.003030
58     590          0.002981
59     600          0.003159
60     610          0.003390
61     620          0.003732
62     630          0.003691
63     640          0.002904
64     650          0.003623
65     660          0.002997
66     670          0.003444
67     680          0.003198
68     690          0.003197
69     700          0.003581
70     710          0.003009
71     720          0.002848
72     730          0.003500
73     740          0.003844
74     750          0.003377
75     760          0.004297
76     770          0.003721
77     780          0.002949
78     790          0.003538
79     800          0.003972
80     810          0.002937
81     820          0.003609
82     830          0.003341
83     840          0.003353
84     850          0.002930
85     860          0.003129
86     870          0.002918
87     880          0.003134
88     890          0.003534
89     900          0.003208
90     910          0.003309
91     920          0.003991
92     930          0.002936
93     940          0.002809
94     950          0.003487
95     960          0.003002
96     970          0.002976
97     980          0.003852
98     990          0.003120
99    1000          0.003506
