[experiments_sandbox.py:440 -   <module>()] 2023-04-22 02:53:14,470 INFO SEED = 42
[experiments_sandbox.py:492 -   <module>()] 2023-04-22 02:53:14,471 INFO model = 
*** NNmodel 
 Sequential(
  (0): Linear(in_features=4, out_features=50, bias=True)
  (1): Tanh()
  (2): Linear(in_features=50, out_features=1, bias=True)
)
numel_learnable = 301
***
[experiments_sandbox.py:493 -   <module>()] 2023-04-22 02:53:14,471 INFO optimizer  = Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: False
    lr: 0.3
    maximize: False
    weight_decay: 0
)
[experiments_sandbox.py:500 -   <module>()] 2023-04-22 02:53:14,471 INFO lr_scheduler = <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7fbacc97cdc0>
[experiments_sandbox.py:509 -   <module>()] 2023-04-22 02:53:14,472 INFO data = <__main__.ToyData1 object at 0x7fbacc97cdf0>
[experiments_sandbox.py:510 -   <module>()] 2023-04-22 02:53:14,472 INFO epochs = 1000
[experiments_sandbox.py:514 -   <module>()] 2023-04-22 02:53:14,472 INFO epochs_losses_window = 10
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:16,153 INFO epoch # 0 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.3-> 0.3 - loss = 97.22991025447845
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:16,286 INFO epoch # 1 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.3-> 0.3 - loss = 36.31740555167198
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:16,428 INFO epoch # 2 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.3-> 0.3 - loss = 16.47326308488846
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:16,579 INFO epoch # 3 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.3-> 0.3 - loss = 10.637034181505442
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:16,732 INFO epoch # 4 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.3-> 0.3 - loss = 8.065403789281845
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:16,872 INFO epoch # 5 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.3-> 0.3 - loss = 6.046777993440628
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:17,011 INFO epoch # 6 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.3-> 0.3 - loss = 2.674897212535143
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:17,150 INFO epoch # 7 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.3-> 0.3 - loss = 1.341912243515253
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:17,288 INFO epoch # 8 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.3-> 0.3 - loss = 1.2302780076861382
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:17,424 INFO epoch # 9 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.3-> 0.3 - loss = 0.9444091394543648
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:17,551 INFO epoch # 10 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.3-> 0.3 - loss = 0.5717928484082222
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:53:17,551 INFO *** epoch 10, rolling-avg-loss (window=10)= 8.430317405238748
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:17,679 INFO epoch # 11 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.3-> 0.3 - loss = 0.6566975563764572
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:17,802 INFO epoch # 12 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.3-> 0.3 - loss = 0.5286352187395096
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:17,925 INFO epoch # 13 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.3-> 0.3 - loss = 0.4647785658016801
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:18,048 INFO epoch # 14 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.3-> 0.3 - loss = 0.2610759735107422
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:18,170 INFO epoch # 15 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.3-> 0.3 - loss = 0.24692162685096264
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:18,292 INFO epoch # 16 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.3-> 0.3 - loss = 0.1652086852118373
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:18,414 INFO epoch # 17 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.3-> 0.3 - loss = 0.18124481290578842
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:18,539 INFO epoch # 18 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.3-> 0.3 - loss = 0.12856856174767017
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:18,664 INFO epoch # 19 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.3-> 0.3 - loss = 0.13350437209010124
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:18,791 INFO epoch # 20 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.3-> 0.3 - loss = 0.07707859389483929
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:53:18,791 INFO *** epoch 20, rolling-avg-loss (window=10)= 0.2843713967129588
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:18,920 INFO epoch # 21 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.3-> 0.3 - loss = 0.0646289810538292
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:19,044 INFO epoch # 22 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.3-> 0.3 - loss = 0.07236243598163128
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:19,171 INFO epoch # 23 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.3-> 0.3 - loss = 0.06148333754390478
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:19,297 INFO epoch # 24 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.3-> 0.3 - loss = 0.1938707698136568
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:19,423 INFO epoch # 25 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.3-> 0.3 - loss = 0.04801235906779766
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:19,551 INFO epoch # 26 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.3-> 0.3 - loss = 0.035543207079172134
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:19,679 INFO epoch # 27 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.3-> 0.3 - loss = 0.07426244392991066
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:19,804 INFO epoch # 28 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.3-> 0.3 - loss = 0.1597719807177782
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:19,927 INFO epoch # 29 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.3-> 0.3 - loss = 0.09869743976742029
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:20,051 INFO epoch # 30 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.3-> 0.3 - loss = 0.20258909836411476
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:53:20,052 INFO *** epoch 30, rolling-avg-loss (window=10)= 0.10112220533192158
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:20,175 INFO epoch # 31 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.3-> 0.3 - loss = 0.1504865400493145
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:20,298 INFO epoch # 32 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.3-> 0.3 - loss = 0.15801816433668137
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:20,421 INFO epoch # 33 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.3-> 0.3 - loss = 0.15651792101562023
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:20,544 INFO epoch # 34 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.3-> 0.3 - loss = 0.08561055734753609
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:20,670 INFO epoch # 35 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.3-> 0.3 - loss = 0.03946735803037882
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:20,796 INFO epoch # 36 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.3-> 0.3 - loss = 0.054021865129470825
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:20,926 INFO epoch # 37 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.3-> 0.27 - loss = 0.06802722252905369
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:21,067 INFO epoch # 38 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.27-> 0.27 - loss = 0.09028016217052937
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:21,201 INFO epoch # 39 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.27-> 0.27 - loss = 0.050247383769601583
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:21,324 INFO epoch # 40 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.27-> 0.27 - loss = 0.07383732730522752
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:53:21,324 INFO *** epoch 40, rolling-avg-loss (window=10)= 0.09265145016834139
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:21,446 INFO epoch # 41 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.27-> 0.27 - loss = 0.20121617056429386
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:21,569 INFO epoch # 42 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.27-> 0.27 - loss = 0.12158130295574665
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:21,692 INFO epoch # 43 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.27-> 0.27 - loss = 0.10189981292933226
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:21,816 INFO epoch # 44 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.27-> 0.27 - loss = 0.14547680597752333
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:21,947 INFO epoch # 45 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.27-> 0.27 - loss = 0.09731459151953459
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:22,071 INFO epoch # 46 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.27-> 0.27 - loss = 0.06547370180487633
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:22,194 INFO epoch # 47 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.27-> 0.27 - loss = 0.0678148721344769
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:22,316 INFO epoch # 48 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.27-> 0.24300000000000002 - loss = 0.07981690671294928
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:22,438 INFO epoch # 49 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.24300000000000002-> 0.24300000000000002 - loss = 0.044589437544345856
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:22,571 INFO epoch # 50 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.24300000000000002-> 0.24300000000000002 - loss = 0.04326921887695789
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:53:22,571 INFO *** epoch 50, rolling-avg-loss (window=10)= 0.09684528210200369
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:22,693 INFO epoch # 51 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.24300000000000002-> 0.24300000000000002 - loss = 0.052539557218551636
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:22,817 INFO epoch # 52 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.24300000000000002-> 0.24300000000000002 - loss = 0.05106811132282019
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:22,943 INFO epoch # 53 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.24300000000000002-> 0.24300000000000002 - loss = 0.05582069139927626
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:23,076 INFO epoch # 54 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.24300000000000002-> 0.24300000000000002 - loss = 0.07958115637302399
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:23,202 INFO epoch # 55 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.24300000000000002-> 0.24300000000000002 - loss = 0.0667813466861844
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:23,327 INFO epoch # 56 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.24300000000000002-> 0.24300000000000002 - loss = 0.08198922500014305
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:23,449 INFO epoch # 57 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.24300000000000002-> 0.24300000000000002 - loss = 0.15732721402309835
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:23,572 INFO epoch # 58 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.24300000000000002-> 0.24300000000000002 - loss = 0.2393128890544176
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:23,694 INFO epoch # 59 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.24300000000000002-> 0.21870000000000003 - loss = 0.16318999789655209
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:23,831 INFO epoch # 60 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.21870000000000003-> 0.21870000000000003 - loss = 0.10552705044392496
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:53:23,831 INFO *** epoch 60, rolling-avg-loss (window=10)= 0.10531372394179925
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:23,970 INFO epoch # 61 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.21870000000000003-> 0.21870000000000003 - loss = 0.08490368211641908
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:24,110 INFO epoch # 62 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.21870000000000003-> 0.21870000000000003 - loss = 0.04920032434165478
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:24,246 INFO epoch # 63 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.21870000000000003-> 0.21870000000000003 - loss = 0.14502127468585968
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:24,370 INFO epoch # 64 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.21870000000000003-> 0.21870000000000003 - loss = 0.06805486604571342
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:24,496 INFO epoch # 65 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.21870000000000003-> 0.21870000000000003 - loss = 0.06750717666000128
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:24,619 INFO epoch # 66 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.21870000000000003-> 0.21870000000000003 - loss = 0.1336256405338645
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:24,745 INFO epoch # 67 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.21870000000000003-> 0.21870000000000003 - loss = 0.24808389972895384
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:24,872 INFO epoch # 68 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.21870000000000003-> 0.21870000000000003 - loss = 0.14185922080650926
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:24,998 INFO epoch # 69 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.21870000000000003-> 0.21870000000000003 - loss = 0.19160322658717632
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:25,122 INFO epoch # 70 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.21870000000000003-> 0.19683000000000003 - loss = 0.40362906735390425
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:53:25,122 INFO *** epoch 70, rolling-avg-loss (window=10)= 0.15334883788600565
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:25,250 INFO epoch # 71 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.19683000000000003-> 0.19683000000000003 - loss = 0.25549066346138716
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:25,376 INFO epoch # 72 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.19683000000000003-> 0.19683000000000003 - loss = 0.3062051050364971
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:25,502 INFO epoch # 73 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.19683000000000003-> 0.19683000000000003 - loss = 0.1880180537700653
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:25,624 INFO epoch # 74 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.19683000000000003-> 0.19683000000000003 - loss = 0.12213645782321692
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:25,751 INFO epoch # 75 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.19683000000000003-> 0.19683000000000003 - loss = 0.17624236084520817
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:25,876 INFO epoch # 76 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.19683000000000003-> 0.19683000000000003 - loss = 0.190877637360245
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:26,013 INFO epoch # 77 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.19683000000000003-> 0.19683000000000003 - loss = 0.18703078152611852
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:26,148 INFO epoch # 78 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.19683000000000003-> 0.19683000000000003 - loss = 0.16527706943452358
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:26,277 INFO epoch # 79 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.19683000000000003-> 0.19683000000000003 - loss = 0.1851244354620576
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:26,402 INFO epoch # 80 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.19683000000000003-> 0.19683000000000003 - loss = 0.15072844922542572
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:53:26,402 INFO *** epoch 80, rolling-avg-loss (window=10)= 0.1927131013944745
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:26,529 INFO epoch # 81 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.19683000000000003-> 0.17714700000000003 - loss = 0.15150029910728335
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:26,656 INFO epoch # 82 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.17714700000000003-> 0.17714700000000003 - loss = 0.24099577777087688
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:26,782 INFO epoch # 83 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.17714700000000003-> 0.17714700000000003 - loss = 0.12844843603670597
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:26,906 INFO epoch # 84 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.17714700000000003-> 0.17714700000000003 - loss = 0.06963536702096462
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:27,035 INFO epoch # 85 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.17714700000000003-> 0.17714700000000003 - loss = 0.05632888153195381
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:27,163 INFO epoch # 86 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.17714700000000003-> 0.17714700000000003 - loss = 0.1662234654650092
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:27,288 INFO epoch # 87 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.17714700000000003-> 0.17714700000000003 - loss = 0.05059598293155432
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:27,410 INFO epoch # 88 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.17714700000000003-> 0.17714700000000003 - loss = 0.09696832578629255
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:27,532 INFO epoch # 89 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.17714700000000003-> 0.17714700000000003 - loss = 0.0550741208717227
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:27,655 INFO epoch # 90 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.17714700000000003-> 0.17714700000000003 - loss = 0.051066222600638866
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:53:27,655 INFO *** epoch 90, rolling-avg-loss (window=10)= 0.10668368791230023
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:27,790 INFO epoch # 91 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.17714700000000003-> 0.17714700000000003 - loss = 0.03452032571658492
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:27,917 INFO epoch # 92 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.17714700000000003-> 0.17714700000000003 - loss = 0.06049235910177231
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:28,042 INFO epoch # 93 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.17714700000000003-> 0.17714700000000003 - loss = 0.08630658267065883
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:28,166 INFO epoch # 94 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.17714700000000003-> 0.17714700000000003 - loss = 0.08040845207870007
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:28,295 INFO epoch # 95 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.17714700000000003-> 0.17714700000000003 - loss = 0.08205268811434507
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:28,422 INFO epoch # 96 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.17714700000000003-> 0.17714700000000003 - loss = 0.07348848367109895
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:28,553 INFO epoch # 97 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.17714700000000003-> 0.17714700000000003 - loss = 0.04273669421672821
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:28,680 INFO epoch # 98 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.17714700000000003-> 0.17714700000000003 - loss = 0.08349594660103321
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:28,807 INFO epoch # 99 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.17714700000000003-> 0.17714700000000003 - loss = 0.3392391372472048
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:28,930 INFO epoch # 100 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.17714700000000003-> 0.17714700000000003 - loss = 0.16266766097396612
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:53:28,930 INFO *** epoch 100, rolling-avg-loss (window=10)= 0.10454083303920925
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:29,057 INFO epoch # 101 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.17714700000000003-> 0.17714700000000003 - loss = 0.30232133343815804
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:29,181 INFO epoch # 102 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.17714700000000003-> 0.15943230000000003 - loss = 0.08011925779283047
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:29,307 INFO epoch # 103 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.15943230000000003-> 0.15943230000000003 - loss = 0.0431838845834136
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:29,456 INFO epoch # 104 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.15943230000000003-> 0.15943230000000003 - loss = 0.06780645251274109
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:29,607 INFO epoch # 105 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.15943230000000003-> 0.15943230000000003 - loss = 0.05662756785750389
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:29,730 INFO epoch # 106 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.15943230000000003-> 0.15943230000000003 - loss = 0.11539913900196552
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:29,854 INFO epoch # 107 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.15943230000000003-> 0.15943230000000003 - loss = 0.07468775752931833
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:29,985 INFO epoch # 108 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.15943230000000003-> 0.15943230000000003 - loss = 0.09364202106371522
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:30,125 INFO epoch # 109 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.15943230000000003-> 0.15943230000000003 - loss = 0.09306611027568579
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:30,259 INFO epoch # 110 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.15943230000000003-> 0.15943230000000003 - loss = 0.0747179863974452
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:53:30,259 INFO *** epoch 110, rolling-avg-loss (window=10)= 0.10015715104527771
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:30,384 INFO epoch # 111 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.15943230000000003-> 0.15943230000000003 - loss = 0.12413406232371926
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:30,509 INFO epoch # 112 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.15943230000000003-> 0.15943230000000003 - loss = 0.05233537219464779
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:30,634 INFO epoch # 113 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.15943230000000003-> 0.14348907000000002 - loss = 0.06799956131726503
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:30,771 INFO epoch # 114 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.14348907000000002-> 0.14348907000000002 - loss = 0.17003336921334267
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:30,897 INFO epoch # 115 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.14348907000000002-> 0.14348907000000002 - loss = 0.09797211922705173
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:31,023 INFO epoch # 116 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.14348907000000002-> 0.14348907000000002 - loss = 0.039779543643817306
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:31,150 INFO epoch # 117 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.14348907000000002-> 0.14348907000000002 - loss = 0.07404341967776418
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:31,283 INFO epoch # 118 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.14348907000000002-> 0.14348907000000002 - loss = 0.08242730936035514
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:31,410 INFO epoch # 119 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.14348907000000002-> 0.14348907000000002 - loss = 0.049366559367626905
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:31,538 INFO epoch # 120 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.14348907000000002-> 0.14348907000000002 - loss = 0.026643746648915112
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:53:31,538 INFO *** epoch 120, rolling-avg-loss (window=10)= 0.07847350629745051
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:31,662 INFO epoch # 121 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.14348907000000002-> 0.14348907000000002 - loss = 0.03453313512727618
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:31,789 INFO epoch # 122 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.14348907000000002-> 0.14348907000000002 - loss = 0.07285694312304258
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:31,913 INFO epoch # 123 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.14348907000000002-> 0.14348907000000002 - loss = 0.06884047202765942
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:32,036 INFO epoch # 124 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.14348907000000002-> 0.14348907000000002 - loss = 0.04077101731672883
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:32,168 INFO epoch # 125 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.14348907000000002-> 0.14348907000000002 - loss = 0.09602079633623362
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:32,297 INFO epoch # 126 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.14348907000000002-> 0.14348907000000002 - loss = 0.04564132820814848
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:32,423 INFO epoch # 127 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.14348907000000002-> 0.14348907000000002 - loss = 0.0687447264790535
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:32,544 INFO epoch # 128 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.14348907000000002-> 0.14348907000000002 - loss = 0.09220860991626978
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:32,671 INFO epoch # 129 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.14348907000000002-> 0.14348907000000002 - loss = 0.10876743495464325
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:32,795 INFO epoch # 130 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.14348907000000002-> 0.14348907000000002 - loss = 0.14911907818168402
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:53:32,796 INFO *** epoch 130, rolling-avg-loss (window=10)= 0.07775035416707396
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:32,918 INFO epoch # 131 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.14348907000000002-> 0.12914016300000003 - loss = 0.07568363845348358
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:33,041 INFO epoch # 132 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.12914016300000003-> 0.12914016300000003 - loss = 0.1784909889101982
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:33,165 INFO epoch # 133 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.12914016300000003-> 0.12914016300000003 - loss = 0.46298492467030883
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:33,291 INFO epoch # 134 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.12914016300000003-> 0.12914016300000003 - loss = 0.13076405134052038
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:33,417 INFO epoch # 135 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.12914016300000003-> 0.12914016300000003 - loss = 0.20505989179946482
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:33,540 INFO epoch # 136 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.12914016300000003-> 0.12914016300000003 - loss = 0.12108520604670048
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:33,663 INFO epoch # 137 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.12914016300000003-> 0.12914016300000003 - loss = 0.13699498306959867
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:33,787 INFO epoch # 138 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.12914016300000003-> 0.12914016300000003 - loss = 0.07990956120193005
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:33,926 INFO epoch # 139 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.12914016300000003-> 0.12914016300000003 - loss = 0.0802892348729074
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:34,056 INFO epoch # 140 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.12914016300000003-> 0.12914016300000003 - loss = 0.28308316599577665
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:53:34,056 INFO *** epoch 140, rolling-avg-loss (window=10)= 0.17543456463608892
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:34,181 INFO epoch # 141 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.12914016300000003-> 0.12914016300000003 - loss = 0.07726774457842112
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:34,309 INFO epoch # 142 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.12914016300000003-> 0.11622614670000003 - loss = 0.06551615335047245
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:34,433 INFO epoch # 143 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.11622614670000003-> 0.11622614670000003 - loss = 0.055487838573753834
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:34,557 INFO epoch # 144 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.11622614670000003-> 0.11622614670000003 - loss = 0.06888518901541829
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:34,685 INFO epoch # 145 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.11622614670000003-> 0.11622614670000003 - loss = 0.18680062890052795
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:34,817 INFO epoch # 146 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.11622614670000003-> 0.11622614670000003 - loss = 0.0363852153532207
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:34,941 INFO epoch # 147 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.11622614670000003-> 0.11622614670000003 - loss = 0.03219108050689101
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:35,067 INFO epoch # 148 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.11622614670000003-> 0.11622614670000003 - loss = 0.03866104735061526
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:35,206 INFO epoch # 149 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.11622614670000003-> 0.11622614670000003 - loss = 0.12152679450809956
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:35,341 INFO epoch # 150 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.11622614670000003-> 0.11622614670000003 - loss = 0.14483123645186424
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:53:35,341 INFO *** epoch 150, rolling-avg-loss (window=10)= 0.08275529285892844
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:35,465 INFO epoch # 151 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.11622614670000003-> 0.11622614670000003 - loss = 0.1868977937847376
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:35,593 INFO epoch # 152 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.11622614670000003-> 0.11622614670000003 - loss = 0.1750357300043106
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:35,732 INFO epoch # 153 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.11622614670000003-> 0.10460353203000003 - loss = 0.10220375517383218
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:35,873 INFO epoch # 154 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.10460353203000003-> 0.10460353203000003 - loss = 0.06704548560082912
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:36,013 INFO epoch # 155 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.10460353203000003-> 0.10460353203000003 - loss = 0.05769710801541805
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:36,153 INFO epoch # 156 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.10460353203000003-> 0.10460353203000003 - loss = 0.1500402158126235
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:36,291 INFO epoch # 157 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.10460353203000003-> 0.10460353203000003 - loss = 0.07456850819289684
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:36,426 INFO epoch # 158 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.10460353203000003-> 0.10460353203000003 - loss = 0.036744541488587856
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:36,550 INFO epoch # 159 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.10460353203000003-> 0.10460353203000003 - loss = 0.06466579483821988
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:36,673 INFO epoch # 160 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.10460353203000003-> 0.10460353203000003 - loss = 0.06554989889264107
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:53:36,673 INFO *** epoch 160, rolling-avg-loss (window=10)= 0.09804488318040967
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:36,795 INFO epoch # 161 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.10460353203000003-> 0.10460353203000003 - loss = 0.1157354167662561
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:36,927 INFO epoch # 162 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.10460353203000003-> 0.10460353203000003 - loss = 0.03195248870179057
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:37,066 INFO epoch # 163 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.10460353203000003-> 0.10460353203000003 - loss = 0.03307277802377939
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:37,206 INFO epoch # 164 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.10460353203000003-> 0.09414317882700003 - loss = 0.02977650100365281
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:37,350 INFO epoch # 165 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.09414317882700003-> 0.09414317882700003 - loss = 0.029215032933279872
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:37,490 INFO epoch # 166 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.09414317882700003-> 0.09414317882700003 - loss = 0.03301882930099964
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:37,629 INFO epoch # 167 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.09414317882700003-> 0.09414317882700003 - loss = 0.04657132038846612
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:37,769 INFO epoch # 168 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.09414317882700003-> 0.09414317882700003 - loss = 0.05690074455924332
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:37,908 INFO epoch # 169 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.09414317882700003-> 0.09414317882700003 - loss = 0.10252994485199451
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:38,047 INFO epoch # 170 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.09414317882700003-> 0.09414317882700003 - loss = 0.0964001533575356
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:53:38,047 INFO *** epoch 170, rolling-avg-loss (window=10)= 0.05751732098869979
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:38,185 INFO epoch # 171 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.09414317882700003-> 0.09414317882700003 - loss = 0.08677558228373528
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:38,317 INFO epoch # 172 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.09414317882700003-> 0.09414317882700003 - loss = 0.1066022552549839
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:38,440 INFO epoch # 173 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.09414317882700003-> 0.09414317882700003 - loss = 0.1445288099348545
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:38,562 INFO epoch # 174 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.09414317882700003-> 0.09414317882700003 - loss = 0.055435646791011095
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:38,684 INFO epoch # 175 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.09414317882700003-> 0.08472886094430003 - loss = 0.05535591673105955
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:38,810 INFO epoch # 176 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.08472886094430003-> 0.08472886094430003 - loss = 0.05232483800500631
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:38,958 INFO epoch # 177 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.08472886094430003-> 0.08472886094430003 - loss = 0.07608731463551521
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:39,110 INFO epoch # 178 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.08472886094430003-> 0.08472886094430003 - loss = 0.06621711701154709
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:39,253 INFO epoch # 179 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.08472886094430003-> 0.08472886094430003 - loss = 0.06253147823736072
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:39,381 INFO epoch # 180 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.08472886094430003-> 0.08472886094430003 - loss = 0.08984915167093277
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:53:39,381 INFO *** epoch 180, rolling-avg-loss (window=10)= 0.07957081105560064
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:39,504 INFO epoch # 181 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.08472886094430003-> 0.08472886094430003 - loss = 0.16345354728400707
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:39,627 INFO epoch # 182 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.08472886094430003-> 0.08472886094430003 - loss = 0.16713961400091648
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:39,751 INFO epoch # 183 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.08472886094430003-> 0.08472886094430003 - loss = 0.15228236000984907
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:39,874 INFO epoch # 184 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.08472886094430003-> 0.08472886094430003 - loss = 0.09573831292800605
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:39,997 INFO epoch # 185 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.08472886094430003-> 0.08472886094430003 - loss = 0.06995044415816665
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:40,119 INFO epoch # 186 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.08472886094430003-> 0.07625597484987003 - loss = 0.05474564293399453
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:40,242 INFO epoch # 187 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.07625597484987003-> 0.07625597484987003 - loss = 0.05276552028954029
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:40,370 INFO epoch # 188 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.07625597484987003-> 0.07625597484987003 - loss = 0.06626055017113686
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:40,492 INFO epoch # 189 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.07625597484987003-> 0.07625597484987003 - loss = 0.021922003477811813
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:40,614 INFO epoch # 190 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.07625597484987003-> 0.07625597484987003 - loss = 0.07085782010108232
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:53:40,614 INFO *** epoch 190, rolling-avg-loss (window=10)= 0.09151158153545111
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:40,736 INFO epoch # 191 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.07625597484987003-> 0.07625597484987003 - loss = 0.08728496497496963
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:40,860 INFO epoch # 192 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.07625597484987003-> 0.07625597484987003 - loss = 0.03753678989596665
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:40,982 INFO epoch # 193 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.07625597484987003-> 0.07625597484987003 - loss = 0.04689639853313565
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:41,105 INFO epoch # 194 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.07625597484987003-> 0.07625597484987003 - loss = 0.05656334292143583
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:41,228 INFO epoch # 195 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.07625597484987003-> 0.07625597484987003 - loss = 0.08528559398837388
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:41,350 INFO epoch # 196 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.07625597484987003-> 0.07625597484987003 - loss = 0.056497666984796524
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:41,473 INFO epoch # 197 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.07625597484987003-> 0.07625597484987003 - loss = 0.060895828530192375
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:41,595 INFO epoch # 198 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.07625597484987003-> 0.07625597484987003 - loss = 0.11870741378515959
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:41,717 INFO epoch # 199 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.07625597484987003-> 0.07625597484987003 - loss = 0.18900485709309578
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:41,841 INFO epoch # 200 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.07625597484987003-> 0.06863037736488302 - loss = 0.244527667760849
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:53:41,841 INFO *** epoch 200, rolling-avg-loss (window=10)= 0.09832005244679749
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:41,964 INFO epoch # 201 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.06863037736488302-> 0.06863037736488302 - loss = 0.19163770973682404
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:42,087 INFO epoch # 202 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.06863037736488302-> 0.06863037736488302 - loss = 0.17924050893634558
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:42,211 INFO epoch # 203 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.06863037736488302-> 0.06863037736488302 - loss = 0.10894373618066311
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:42,336 INFO epoch # 204 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.06863037736488302-> 0.06863037736488302 - loss = 0.07232949044555426
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:42,458 INFO epoch # 205 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.06863037736488302-> 0.06863037736488302 - loss = 0.08052779478020966
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:42,582 INFO epoch # 206 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.06863037736488302-> 0.06863037736488302 - loss = 0.04498865734785795
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:42,707 INFO epoch # 207 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.06863037736488302-> 0.06863037736488302 - loss = 0.0609826510772109
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:42,831 INFO epoch # 208 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.06863037736488302-> 0.06863037736488302 - loss = 0.10084703378379345
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:42,954 INFO epoch # 209 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.06863037736488302-> 0.06863037736488302 - loss = 0.0716166514903307
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:43,076 INFO epoch # 210 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.06863037736488302-> 0.06863037736488302 - loss = 0.07874704990535975
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:53:43,076 INFO *** epoch 210, rolling-avg-loss (window=10)= 0.09898612836841494
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:43,199 INFO epoch # 211 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.06863037736488302-> 0.061767339628394716 - loss = 0.05285356380045414
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:43,323 INFO epoch # 212 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.061767339628394716-> 0.061767339628394716 - loss = 0.04211641475558281
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:43,445 INFO epoch # 213 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.061767339628394716-> 0.061767339628394716 - loss = 0.08129954477772117
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:43,569 INFO epoch # 214 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.061767339628394716-> 0.061767339628394716 - loss = 0.11852866504341364
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:43,691 INFO epoch # 215 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.061767339628394716-> 0.061767339628394716 - loss = 0.07850795099511743
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:43,816 INFO epoch # 216 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.061767339628394716-> 0.061767339628394716 - loss = 0.045578975579701364
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:43,939 INFO epoch # 217 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.061767339628394716-> 0.061767339628394716 - loss = 0.044961290434002876
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:44,061 INFO epoch # 218 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.061767339628394716-> 0.061767339628394716 - loss = 0.0516197644174099
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:44,182 INFO epoch # 219 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.061767339628394716-> 0.061767339628394716 - loss = 0.07262076530605555
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:44,304 INFO epoch # 220 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.061767339628394716-> 0.061767339628394716 - loss = 0.031425317749381065
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:53:44,304 INFO *** epoch 220, rolling-avg-loss (window=10)= 0.061951225285883996
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:44,431 INFO epoch # 221 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.061767339628394716-> 0.061767339628394716 - loss = 0.026784697314724326
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:44,554 INFO epoch # 222 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.061767339628394716-> 0.055590605665555244 - loss = 0.03301479248329997
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:44,677 INFO epoch # 223 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.055590605665555244-> 0.055590605665555244 - loss = 0.028310720343142748
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:44,800 INFO epoch # 224 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.055590605665555244-> 0.055590605665555244 - loss = 0.05151735292747617
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:44,923 INFO epoch # 225 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.055590605665555244-> 0.055590605665555244 - loss = 0.025665571098215878
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:45,046 INFO epoch # 226 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.055590605665555244-> 0.055590605665555244 - loss = 0.033550930209457874
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:45,183 INFO epoch # 227 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.055590605665555244-> 0.055590605665555244 - loss = 0.03204765263944864
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:45,327 INFO epoch # 228 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.055590605665555244-> 0.055590605665555244 - loss = 0.11103327479213476
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:45,468 INFO epoch # 229 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.055590605665555244-> 0.055590605665555244 - loss = 0.09906537551432848
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:45,609 INFO epoch # 230 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.055590605665555244-> 0.055590605665555244 - loss = 0.08171843364834785
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:53:45,609 INFO *** epoch 230, rolling-avg-loss (window=10)= 0.05227088009705767
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:45,749 INFO epoch # 231 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.055590605665555244-> 0.055590605665555244 - loss = 0.06833434337750077
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:45,884 INFO epoch # 232 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.055590605665555244-> 0.055590605665555244 - loss = 0.04960133880376816
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:46,031 INFO epoch # 233 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.055590605665555244-> 0.05003154509899972 - loss = 0.05811252444982529
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:46,153 INFO epoch # 234 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.05003154509899972-> 0.05003154509899972 - loss = 0.05355591373518109
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:46,279 INFO epoch # 235 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.05003154509899972-> 0.05003154509899972 - loss = 0.04284243658185005
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:46,406 INFO epoch # 236 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.05003154509899972-> 0.05003154509899972 - loss = 0.038331618532538414
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:46,529 INFO epoch # 237 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.05003154509899972-> 0.05003154509899972 - loss = 0.08659543003886938
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:46,651 INFO epoch # 238 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.05003154509899972-> 0.05003154509899972 - loss = 0.07998330798000097
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:46,775 INFO epoch # 239 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.05003154509899972-> 0.05003154509899972 - loss = 0.11556324595585465
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:46,916 INFO epoch # 240 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.05003154509899972-> 0.05003154509899972 - loss = 0.05765105364844203
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:53:46,917 INFO *** epoch 240, rolling-avg-loss (window=10)= 0.06505712131038308
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:47,051 INFO epoch # 241 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.05003154509899972-> 0.05003154509899972 - loss = 0.08054328709840775
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:47,178 INFO epoch # 242 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.05003154509899972-> 0.05003154509899972 - loss = 0.03661090834066272
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:47,303 INFO epoch # 243 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.05003154509899972-> 0.05003154509899972 - loss = 0.07512108120135963
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:47,428 INFO epoch # 244 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.05003154509899972-> 0.04502839058909975 - loss = 0.06965785101056099
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:47,550 INFO epoch # 245 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.04502839058909975-> 0.04502839058909975 - loss = 0.0430413915310055
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:47,672 INFO epoch # 246 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.04502839058909975-> 0.04502839058909975 - loss = 0.05603928258642554
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:47,794 INFO epoch # 247 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.04502839058909975-> 0.04502839058909975 - loss = 0.05778518412262201
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:47,919 INFO epoch # 248 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.04502839058909975-> 0.04502839058909975 - loss = 0.04159567132592201
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:48,042 INFO epoch # 249 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.04502839058909975-> 0.04502839058909975 - loss = 0.03962432639673352
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:48,165 INFO epoch # 250 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.04502839058909975-> 0.04502839058909975 - loss = 0.09044133918359876
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:53:48,165 INFO *** epoch 250, rolling-avg-loss (window=10)= 0.05904603227972984
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:48,287 INFO epoch # 251 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.04502839058909975-> 0.04502839058909975 - loss = 0.14320998825132847
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:48,411 INFO epoch # 252 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.04502839058909975-> 0.04502839058909975 - loss = 0.09199813846498728
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:48,537 INFO epoch # 253 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.04502839058909975-> 0.04502839058909975 - loss = 0.06719812378287315
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:48,659 INFO epoch # 254 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.04502839058909975-> 0.04502839058909975 - loss = 0.07479107193648815
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:48,782 INFO epoch # 255 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.04502839058909975-> 0.040525551530189774 - loss = 0.08071429468691349
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:48,906 INFO epoch # 256 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.040525551530189774-> 0.040525551530189774 - loss = 0.05891459947451949
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:49,041 INFO epoch # 257 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.040525551530189774-> 0.040525551530189774 - loss = 0.07241967646405101
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:49,162 INFO epoch # 258 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.040525551530189774-> 0.040525551530189774 - loss = 0.11380439577624202
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:49,284 INFO epoch # 259 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.040525551530189774-> 0.040525551530189774 - loss = 0.056850818218663335
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:49,421 INFO epoch # 260 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.040525551530189774-> 0.040525551530189774 - loss = 0.030257762409746647
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:53:49,421 INFO *** epoch 260, rolling-avg-loss (window=10)= 0.0790158869465813
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:49,552 INFO epoch # 261 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.040525551530189774-> 0.040525551530189774 - loss = 0.04026075825095177
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:49,675 INFO epoch # 262 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.040525551530189774-> 0.040525551530189774 - loss = 0.0312672215513885
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:49,797 INFO epoch # 263 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.040525551530189774-> 0.040525551530189774 - loss = 0.05534682655707002
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:49,922 INFO epoch # 264 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.040525551530189774-> 0.040525551530189774 - loss = 0.06027410039678216
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:50,044 INFO epoch # 265 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.040525551530189774-> 0.040525551530189774 - loss = 0.02746903896331787
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:50,166 INFO epoch # 266 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.040525551530189774-> 0.036472996377170795 - loss = 0.04433159250766039
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:50,288 INFO epoch # 267 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.036472996377170795-> 0.036472996377170795 - loss = 0.02602454327279702
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:50,412 INFO epoch # 268 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.036472996377170795-> 0.036472996377170795 - loss = 0.028197847306728363
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:50,539 INFO epoch # 269 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.036472996377170795-> 0.036472996377170795 - loss = 0.02803260600194335
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:50,661 INFO epoch # 270 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.036472996377170795-> 0.036472996377170795 - loss = 0.02510921098291874
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:53:50,661 INFO *** epoch 270, rolling-avg-loss (window=10)= 0.036631374579155815
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:50,785 INFO epoch # 271 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.036472996377170795-> 0.036472996377170795 - loss = 0.06510412273928523
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:50,909 INFO epoch # 272 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.036472996377170795-> 0.036472996377170795 - loss = 0.04320044303312898
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:51,040 INFO epoch # 273 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.036472996377170795-> 0.036472996377170795 - loss = 0.03289947216399014
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:51,162 INFO epoch # 274 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.036472996377170795-> 0.036472996377170795 - loss = 0.10216354392468929
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:51,284 INFO epoch # 275 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.036472996377170795-> 0.036472996377170795 - loss = 0.02186048123985529
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:51,408 INFO epoch # 276 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.036472996377170795-> 0.036472996377170795 - loss = 0.0278420802205801
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:51,531 INFO epoch # 277 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.036472996377170795-> 0.036472996377170795 - loss = 0.052577964728698134
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:51,653 INFO epoch # 278 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.036472996377170795-> 0.036472996377170795 - loss = 0.03880688943900168
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:51,775 INFO epoch # 279 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.036472996377170795-> 0.036472996377170795 - loss = 0.04693968174979091
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:51,922 INFO epoch # 280 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.036472996377170795-> 0.036472996377170795 - loss = 0.0483601363375783
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:53:51,922 INFO *** epoch 280, rolling-avg-loss (window=10)= 0.04797548155765981
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:52,051 INFO epoch # 281 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.036472996377170795-> 0.036472996377170795 - loss = 0.03377977851778269
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:52,173 INFO epoch # 282 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.036472996377170795-> 0.036472996377170795 - loss = 0.18697470985352993
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:52,295 INFO epoch # 283 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.036472996377170795-> 0.036472996377170795 - loss = 0.035841054283082485
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:52,423 INFO epoch # 284 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.036472996377170795-> 0.036472996377170795 - loss = 0.04412973183207214
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:52,559 INFO epoch # 285 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.036472996377170795-> 0.036472996377170795 - loss = 0.061596139799803495
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:52,686 INFO epoch # 286 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.036472996377170795-> 0.032825696739453715 - loss = 0.07749117305502295
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:52,808 INFO epoch # 287 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.032825696739453715-> 0.032825696739453715 - loss = 0.07439266564324498
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:52,935 INFO epoch # 288 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.032825696739453715-> 0.032825696739453715 - loss = 0.060808963142335415
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:53,057 INFO epoch # 289 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.032825696739453715-> 0.032825696739453715 - loss = 0.054759769700467587
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:53,179 INFO epoch # 290 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.032825696739453715-> 0.032825696739453715 - loss = 0.05026412778533995
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:53:53,180 INFO *** epoch 290, rolling-avg-loss (window=10)= 0.06800381136126817
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:53,301 INFO epoch # 291 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.032825696739453715-> 0.032825696739453715 - loss = 0.11132827680557966
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:53,433 INFO epoch # 292 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.032825696739453715-> 0.032825696739453715 - loss = 0.08940667053684592
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:53,559 INFO epoch # 293 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.032825696739453715-> 0.032825696739453715 - loss = 0.03765078168362379
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:53,681 INFO epoch # 294 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.032825696739453715-> 0.032825696739453715 - loss = 0.10423980467021465
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:53,805 INFO epoch # 295 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.032825696739453715-> 0.032825696739453715 - loss = 0.09840613324195147
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:53,941 INFO epoch # 296 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.032825696739453715-> 0.032825696739453715 - loss = 0.08505275286734104
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:54,084 INFO epoch # 297 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.032825696739453715-> 0.029543127065508344 - loss = 0.12205315567553043
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:54,226 INFO epoch # 298 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.029543127065508344-> 0.029543127065508344 - loss = 0.0421613403595984
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:54,350 INFO epoch # 299 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.029543127065508344-> 0.029543127065508344 - loss = 0.04696372803300619
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:54,490 INFO epoch # 300 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.029543127065508344-> 0.029543127065508344 - loss = 0.058375663589686155
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:53:54,490 INFO *** epoch 300, rolling-avg-loss (window=10)= 0.07956383074633777
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:54,622 INFO epoch # 301 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.029543127065508344-> 0.029543127065508344 - loss = 0.03488211706280708
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:54,749 INFO epoch # 302 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.029543127065508344-> 0.029543127065508344 - loss = 0.051837130915373564
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:54,873 INFO epoch # 303 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.029543127065508344-> 0.029543127065508344 - loss = 0.07045761356130242
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:55,000 INFO epoch # 304 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.029543127065508344-> 0.029543127065508344 - loss = 0.0660805085208267
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:55,123 INFO epoch # 305 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.029543127065508344-> 0.029543127065508344 - loss = 0.04215373191982508
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:55,245 INFO epoch # 306 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.029543127065508344-> 0.029543127065508344 - loss = 0.0544478353112936
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:55,369 INFO epoch # 307 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.029543127065508344-> 0.029543127065508344 - loss = 0.03319477499462664
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:55,509 INFO epoch # 308 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.029543127065508344-> 0.026588814358957512 - loss = 0.046320279128849506
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:55,635 INFO epoch # 309 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.026588814358957512-> 0.026588814358957512 - loss = 0.036701994482427835
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:55,757 INFO epoch # 310 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.026588814358957512-> 0.026588814358957512 - loss = 0.056998114101588726
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:53:55,757 INFO *** epoch 310, rolling-avg-loss (window=10)= 0.04930740999989212
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:55,881 INFO epoch # 311 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.026588814358957512-> 0.026588814358957512 - loss = 0.060956163331866264
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:56,005 INFO epoch # 312 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.026588814358957512-> 0.026588814358957512 - loss = 0.03444451396353543
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:56,128 INFO epoch # 313 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.026588814358957512-> 0.026588814358957512 - loss = 0.019678546581417322
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:56,250 INFO epoch # 314 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.026588814358957512-> 0.026588814358957512 - loss = 0.025447694119066
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:56,382 INFO epoch # 315 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.026588814358957512-> 0.026588814358957512 - loss = 0.02617880003526807
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:56,519 INFO epoch # 316 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.026588814358957512-> 0.026588814358957512 - loss = 0.037260612938553095
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:56,646 INFO epoch # 317 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.026588814358957512-> 0.026588814358957512 - loss = 0.031056649051606655
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:56,769 INFO epoch # 318 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.026588814358957512-> 0.026588814358957512 - loss = 0.025528258411213756
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:56,897 INFO epoch # 319 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.026588814358957512-> 0.026588814358957512 - loss = 0.04879702674224973
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:57,036 INFO epoch # 320 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.026588814358957512-> 0.026588814358957512 - loss = 0.050299408845603466
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:53:57,036 INFO *** epoch 320, rolling-avg-loss (window=10)= 0.03596476740203798
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:57,162 INFO epoch # 321 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.026588814358957512-> 0.026588814358957512 - loss = 0.0381234516389668
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:57,284 INFO epoch # 322 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.026588814358957512-> 0.026588814358957512 - loss = 0.03535111993551254
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:57,409 INFO epoch # 323 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.026588814358957512-> 0.026588814358957512 - loss = 0.02401239168830216
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:57,531 INFO epoch # 324 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.026588814358957512-> 0.02392993292306176 - loss = 0.036065224558115005
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:57,653 INFO epoch # 325 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.02392993292306176-> 0.02392993292306176 - loss = 0.021348408423364162
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:57,781 INFO epoch # 326 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.02392993292306176-> 0.02392993292306176 - loss = 0.035785443149507046
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:57,922 INFO epoch # 327 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.02392993292306176-> 0.02392993292306176 - loss = 0.04250000510364771
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:58,052 INFO epoch # 328 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.02392993292306176-> 0.02392993292306176 - loss = 0.030514289624989033
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:58,174 INFO epoch # 329 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.02392993292306176-> 0.02392993292306176 - loss = 0.04291338473558426
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:58,296 INFO epoch # 330 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.02392993292306176-> 0.02392993292306176 - loss = 0.04925613943487406
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:53:58,296 INFO *** epoch 330, rolling-avg-loss (window=10)= 0.03558698582928628
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:58,420 INFO epoch # 331 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.02392993292306176-> 0.02392993292306176 - loss = 0.026343942154198885
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:58,543 INFO epoch # 332 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.02392993292306176-> 0.02392993292306176 - loss = 0.07508611958473921
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:58,664 INFO epoch # 333 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.02392993292306176-> 0.02392993292306176 - loss = 0.05240231053903699
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:58,786 INFO epoch # 334 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.02392993292306176-> 0.02392993292306176 - loss = 0.10760910250246525
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:58,919 INFO epoch # 335 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.02392993292306176-> 0.021536939630755585 - loss = 0.04564358666539192
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:59,051 INFO epoch # 336 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.021536939630755585-> 0.021536939630755585 - loss = 0.09962792880833149
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:59,173 INFO epoch # 337 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.021536939630755585-> 0.021536939630755585 - loss = 0.09441458736546338
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:59,296 INFO epoch # 338 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.021536939630755585-> 0.021536939630755585 - loss = 0.028877435252070427
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:59,421 INFO epoch # 339 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.021536939630755585-> 0.021536939630755585 - loss = 0.02673069853335619
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:59,544 INFO epoch # 340 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.021536939630755585-> 0.021536939630755585 - loss = 0.03360186156351119
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:53:59,544 INFO *** epoch 340, rolling-avg-loss (window=10)= 0.05903375729685649
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:59,665 INFO epoch # 341 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.021536939630755585-> 0.021536939630755585 - loss = 0.03657253971323371
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:59,788 INFO epoch # 342 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.021536939630755585-> 0.021536939630755585 - loss = 0.032834338722750545
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:53:59,912 INFO epoch # 343 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.021536939630755585-> 0.021536939630755585 - loss = 0.03374860854819417
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:00,036 INFO epoch # 344 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.021536939630755585-> 0.021536939630755585 - loss = 0.046407400630414486
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:00,157 INFO epoch # 345 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.021536939630755585-> 0.021536939630755585 - loss = 0.035412042401731014
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:00,279 INFO epoch # 346 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.021536939630755585-> 0.019383245667680026 - loss = 0.02432342362590134
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:00,403 INFO epoch # 347 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.019383245667680026-> 0.019383245667680026 - loss = 0.020502511644735932
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:00,540 INFO epoch # 348 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.019383245667680026-> 0.019383245667680026 - loss = 0.08253250876441598
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:00,666 INFO epoch # 349 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.019383245667680026-> 0.019383245667680026 - loss = 0.029536108719184995
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:00,789 INFO epoch # 350 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.019383245667680026-> 0.019383245667680026 - loss = 0.04641683422960341
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:54:00,790 INFO *** epoch 350, rolling-avg-loss (window=10)= 0.03882863170001656
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:00,917 INFO epoch # 351 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.019383245667680026-> 0.019383245667680026 - loss = 0.08911041496321559
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:01,039 INFO epoch # 352 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.019383245667680026-> 0.019383245667680026 - loss = 0.0302224715705961
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:01,161 INFO epoch # 353 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.019383245667680026-> 0.019383245667680026 - loss = 0.040987045504152775
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:01,282 INFO epoch # 354 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.019383245667680026-> 0.019383245667680026 - loss = 0.03389322245493531
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:01,407 INFO epoch # 355 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.019383245667680026-> 0.019383245667680026 - loss = 0.06628112401813269
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:01,534 INFO epoch # 356 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.019383245667680026-> 0.019383245667680026 - loss = 0.06792986765503883
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:01,661 INFO epoch # 357 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.019383245667680026-> 0.017444921100912024 - loss = 0.04202492069453001
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:01,783 INFO epoch # 358 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.017444921100912024-> 0.017444921100912024 - loss = 0.06875168718397617
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:01,910 INFO epoch # 359 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.017444921100912024-> 0.017444921100912024 - loss = 0.042185620637610555
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:02,033 INFO epoch # 360 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.017444921100912024-> 0.017444921100912024 - loss = 0.01982273382600397
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:54:02,033 INFO *** epoch 360, rolling-avg-loss (window=10)= 0.0501209108508192
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:02,156 INFO epoch # 361 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.017444921100912024-> 0.017444921100912024 - loss = 0.029188664630055428
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:02,277 INFO epoch # 362 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.017444921100912024-> 0.017444921100912024 - loss = 0.08404690911993384
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:02,406 INFO epoch # 363 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.017444921100912024-> 0.017444921100912024 - loss = 0.060629194835200906
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:02,545 INFO epoch # 364 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.017444921100912024-> 0.017444921100912024 - loss = 0.06548159383237362
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:02,686 INFO epoch # 365 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.017444921100912024-> 0.017444921100912024 - loss = 0.11520626302808523
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:02,813 INFO epoch # 366 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.017444921100912024-> 0.017444921100912024 - loss = 0.04785933718085289
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:02,940 INFO epoch # 367 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.017444921100912024-> 0.017444921100912024 - loss = 0.08879995252937078
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:03,079 INFO epoch # 368 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.017444921100912024-> 0.015700428990820824 - loss = 0.022438366431742907
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:03,213 INFO epoch # 369 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.015700428990820824-> 0.015700428990820824 - loss = 0.041451369877904654
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:03,335 INFO epoch # 370 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.015700428990820824-> 0.015700428990820824 - loss = 0.05619268398731947
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:54:03,335 INFO *** epoch 370, rolling-avg-loss (window=10)= 0.061129433545283975
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:03,458 INFO epoch # 371 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.015700428990820824-> 0.015700428990820824 - loss = 0.020522829610854387
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:03,580 INFO epoch # 372 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.015700428990820824-> 0.015700428990820824 - loss = 0.03244123142212629
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:03,702 INFO epoch # 373 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.015700428990820824-> 0.015700428990820824 - loss = 0.03297260403633118
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:03,825 INFO epoch # 374 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.015700428990820824-> 0.015700428990820824 - loss = 0.10495581850409508
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:03,964 INFO epoch # 375 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.015700428990820824-> 0.015700428990820824 - loss = 0.1319357743486762
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:04,088 INFO epoch # 376 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.015700428990820824-> 0.015700428990820824 - loss = 0.04740030947141349
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:04,210 INFO epoch # 377 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.015700428990820824-> 0.015700428990820824 - loss = 0.08739336021244526
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:04,337 INFO epoch # 378 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.015700428990820824-> 0.015700428990820824 - loss = 0.07774411141872406
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:04,481 INFO epoch # 379 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.015700428990820824-> 0.014130386091738742 - loss = 0.09093890897929668
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:04,619 INFO epoch # 380 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.014130386091738742-> 0.014130386091738742 - loss = 0.02802220545709133
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:54:04,619 INFO *** epoch 380, rolling-avg-loss (window=10)= 0.0654327153461054
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:04,743 INFO epoch # 381 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.014130386091738742-> 0.014130386091738742 - loss = 0.029786262661218643
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:04,867 INFO epoch # 382 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.014130386091738742-> 0.014130386091738742 - loss = 0.03336299769580364
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:04,990 INFO epoch # 383 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.014130386091738742-> 0.014130386091738742 - loss = 0.0331788519397378
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:05,113 INFO epoch # 384 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.014130386091738742-> 0.014130386091738742 - loss = 0.02514645643532276
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:05,235 INFO epoch # 385 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.014130386091738742-> 0.014130386091738742 - loss = 0.04065452050417662
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:05,358 INFO epoch # 386 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.014130386091738742-> 0.014130386091738742 - loss = 0.028997041285037994
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:05,496 INFO epoch # 387 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.014130386091738742-> 0.014130386091738742 - loss = 0.024961276212707162
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:05,625 INFO epoch # 388 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.014130386091738742-> 0.014130386091738742 - loss = 0.036507639568299055
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:05,748 INFO epoch # 389 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.014130386091738742-> 0.014130386091738742 - loss = 0.02725450089201331
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:05,878 INFO epoch # 390 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.014130386091738742-> 0.012717347482564867 - loss = 0.04735661344602704
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:54:05,878 INFO *** epoch 390, rolling-avg-loss (window=10)= 0.032720616064034404
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:06,019 INFO epoch # 391 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.012717347482564867-> 0.012717347482564867 - loss = 0.05005582282319665
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:06,145 INFO epoch # 392 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.012717347482564867-> 0.012717347482564867 - loss = 0.03458878048695624
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:06,267 INFO epoch # 393 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.012717347482564867-> 0.012717347482564867 - loss = 0.02652123663574457
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:06,392 INFO epoch # 394 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.012717347482564867-> 0.012717347482564867 - loss = 0.021995676681399345
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:06,514 INFO epoch # 395 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.012717347482564867-> 0.012717347482564867 - loss = 0.017687813378870487
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:06,637 INFO epoch # 396 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.012717347482564867-> 0.012717347482564867 - loss = 0.040535048581659794
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:06,758 INFO epoch # 397 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.012717347482564867-> 0.012717347482564867 - loss = 0.022328163031488657
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:06,886 INFO epoch # 398 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.012717347482564867-> 0.012717347482564867 - loss = 0.0302206976339221
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:07,020 INFO epoch # 399 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.012717347482564867-> 0.012717347482564867 - loss = 0.028694602893665433
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:07,143 INFO epoch # 400 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.012717347482564867-> 0.012717347482564867 - loss = 0.031014952342957258
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:54:07,143 INFO *** epoch 400, rolling-avg-loss (window=10)= 0.030364279448986054
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:07,265 INFO epoch # 401 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.012717347482564867-> 0.012717347482564867 - loss = 0.020005887374281883
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:07,389 INFO epoch # 402 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.012717347482564867-> 0.012717347482564867 - loss = 0.023693942930549383
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:07,528 INFO epoch # 403 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.012717347482564867-> 0.012717347482564867 - loss = 0.0344762927852571
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:07,658 INFO epoch # 404 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.012717347482564867-> 0.012717347482564867 - loss = 0.02494179457426071
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:07,783 INFO epoch # 405 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.012717347482564867-> 0.012717347482564867 - loss = 0.05581651581451297
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:07,919 INFO epoch # 406 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.012717347482564867-> 0.01144561273430838 - loss = 0.03689516708254814
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:08,055 INFO epoch # 407 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.01144561273430838-> 0.01144561273430838 - loss = 0.019921252271160483
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:08,181 INFO epoch # 408 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.01144561273430838-> 0.01144561273430838 - loss = 0.03516536112874746
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:08,303 INFO epoch # 409 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.01144561273430838-> 0.01144561273430838 - loss = 0.12014722288586199
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:08,427 INFO epoch # 410 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.01144561273430838-> 0.01144561273430838 - loss = 0.0745879728347063
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:54:08,428 INFO *** epoch 410, rolling-avg-loss (window=10)= 0.04456514096818864
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:08,550 INFO epoch # 411 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.01144561273430838-> 0.01144561273430838 - loss = 0.049147685058414936
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:08,672 INFO epoch # 412 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.01144561273430838-> 0.01144561273430838 - loss = 0.04473789781332016
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:08,806 INFO epoch # 413 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.01144561273430838-> 0.01144561273430838 - loss = 0.04310042934957892
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:08,947 INFO epoch # 414 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.01144561273430838-> 0.01144561273430838 - loss = 0.03724643029272556
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:09,070 INFO epoch # 415 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.01144561273430838-> 0.01144561273430838 - loss = 0.044076228979974985
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:09,192 INFO epoch # 416 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.01144561273430838-> 0.01144561273430838 - loss = 0.03454089513979852
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:09,314 INFO epoch # 417 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.01144561273430838-> 0.010301051460877543 - loss = 0.04561127396300435
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:09,442 INFO epoch # 418 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.010301051460877543-> 0.010301051460877543 - loss = 0.05110662104561925
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:09,572 INFO epoch # 419 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.010301051460877543-> 0.010301051460877543 - loss = 0.05312979221343994
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:09,698 INFO epoch # 420 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.010301051460877543-> 0.010301051460877543 - loss = 0.06149749318137765
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:54:09,698 INFO *** epoch 420, rolling-avg-loss (window=10)= 0.04641947470372543
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:09,821 INFO epoch # 421 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.010301051460877543-> 0.010301051460877543 - loss = 0.019344418309628963
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:09,946 INFO epoch # 422 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.010301051460877543-> 0.010301051460877543 - loss = 0.045775933656841516
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:10,067 INFO epoch # 423 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.010301051460877543-> 0.010301051460877543 - loss = 0.043812337797135115
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:10,193 INFO epoch # 424 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.010301051460877543-> 0.010301051460877543 - loss = 0.05450670514255762
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:10,316 INFO epoch # 425 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.010301051460877543-> 0.010301051460877543 - loss = 0.06131902802735567
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:10,454 INFO epoch # 426 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.010301051460877543-> 0.010301051460877543 - loss = 0.026708164485171437
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:10,590 INFO epoch # 427 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.010301051460877543-> 0.010301051460877543 - loss = 0.026401030831038952
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:10,715 INFO epoch # 428 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.010301051460877543-> 0.009270946314789788 - loss = 0.0304214539937675
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:10,843 INFO epoch # 429 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.009270946314789788-> 0.009270946314789788 - loss = 0.03007000032812357
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:10,985 INFO epoch # 430 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.009270946314789788-> 0.009270946314789788 - loss = 0.06034650234505534
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:54:10,985 INFO *** epoch 430, rolling-avg-loss (window=10)= 0.03987055749166757
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:11,122 INFO epoch # 431 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.009270946314789788-> 0.009270946314789788 - loss = 0.09605336654931307
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:11,246 INFO epoch # 432 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.009270946314789788-> 0.009270946314789788 - loss = 0.024761212524026632
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:11,375 INFO epoch # 433 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.009270946314789788-> 0.009270946314789788 - loss = 0.0222677665296942
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:11,515 INFO epoch # 434 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.009270946314789788-> 0.009270946314789788 - loss = 0.02759026223793626
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:11,650 INFO epoch # 435 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.009270946314789788-> 0.009270946314789788 - loss = 0.028223522705957294
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:11,777 INFO epoch # 436 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.009270946314789788-> 0.009270946314789788 - loss = 0.03530325973406434
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:11,909 INFO epoch # 437 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.009270946314789788-> 0.009270946314789788 - loss = 0.032524562906473875
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:12,047 INFO epoch # 438 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.009270946314789788-> 0.009270946314789788 - loss = 0.030149896861985326
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:12,172 INFO epoch # 439 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.009270946314789788-> 0.00834385168331081 - loss = 0.02610616758465767
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:12,295 INFO epoch # 440 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00834385168331081-> 0.00834385168331081 - loss = 0.022300796816125512
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:54:12,295 INFO *** epoch 440, rolling-avg-loss (window=10)= 0.034528081445023416
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:12,421 INFO epoch # 441 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00834385168331081-> 0.00834385168331081 - loss = 0.021749532083049417
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:12,545 INFO epoch # 442 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00834385168331081-> 0.00834385168331081 - loss = 0.03696180693805218
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:12,667 INFO epoch # 443 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00834385168331081-> 0.00834385168331081 - loss = 0.046760057331994176
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:12,792 INFO epoch # 444 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00834385168331081-> 0.00834385168331081 - loss = 0.025540126021951437
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:12,918 INFO epoch # 445 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00834385168331081-> 0.00834385168331081 - loss = 0.023134344024583697
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:13,042 INFO epoch # 446 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00834385168331081-> 0.00834385168331081 - loss = 0.02253404725342989
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:13,165 INFO epoch # 447 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00834385168331081-> 0.00834385168331081 - loss = 0.051465896889567375
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:13,287 INFO epoch # 448 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00834385168331081-> 0.00834385168331081 - loss = 0.025241568684577942
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:13,423 INFO epoch # 449 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00834385168331081-> 0.00834385168331081 - loss = 0.02038621506653726
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:13,564 INFO epoch # 450 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00834385168331081-> 0.007509466514979729 - loss = 0.02825157716870308
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:54:13,564 INFO *** epoch 450, rolling-avg-loss (window=10)= 0.030202517146244647
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:13,689 INFO epoch # 451 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.007509466514979729-> 0.007509466514979729 - loss = 0.03370830719359219
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:13,824 INFO epoch # 452 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.007509466514979729-> 0.007509466514979729 - loss = 0.029182296013459563
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:13,947 INFO epoch # 453 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.007509466514979729-> 0.007509466514979729 - loss = 0.0244967769831419
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:14,126 INFO epoch # 454 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.007509466514979729-> 0.007509466514979729 - loss = 0.06895748595707119
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:14,335 INFO epoch # 455 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.007509466514979729-> 0.007509466514979729 - loss = 0.028824131470173597
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:14,460 INFO epoch # 456 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.007509466514979729-> 0.007509466514979729 - loss = 0.02156543778255582
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:14,583 INFO epoch # 457 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.007509466514979729-> 0.007509466514979729 - loss = 0.019244620576500893
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:14,706 INFO epoch # 458 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.007509466514979729-> 0.007509466514979729 - loss = 0.02407617773860693
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:14,829 INFO epoch # 459 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.007509466514979729-> 0.007509466514979729 - loss = 0.018348849145695567
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:14,953 INFO epoch # 460 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.007509466514979729-> 0.007509466514979729 - loss = 0.030684194061905146
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:54:14,953 INFO *** epoch 460, rolling-avg-loss (window=10)= 0.029908827692270278
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:15,076 INFO epoch # 461 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.007509466514979729-> 0.006758519863481757 - loss = 0.08894846122711897
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:15,198 INFO epoch # 462 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.006758519863481757-> 0.006758519863481757 - loss = 0.027812342392280698
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:15,322 INFO epoch # 463 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.006758519863481757-> 0.006758519863481757 - loss = 0.023167481645941734
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:15,447 INFO epoch # 464 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.006758519863481757-> 0.006758519863481757 - loss = 0.03474426083266735
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:15,571 INFO epoch # 465 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.006758519863481757-> 0.006758519863481757 - loss = 0.049824092304334044
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:15,693 INFO epoch # 466 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.006758519863481757-> 0.006758519863481757 - loss = 0.027763228630647063
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:15,816 INFO epoch # 467 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.006758519863481757-> 0.006758519863481757 - loss = 0.025118115358054638
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:15,941 INFO epoch # 468 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.006758519863481757-> 0.006758519863481757 - loss = 0.012477555486839265
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:16,065 INFO epoch # 469 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.006758519863481757-> 0.006758519863481757 - loss = 0.04734205827116966
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:16,189 INFO epoch # 470 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.006758519863481757-> 0.006758519863481757 - loss = 0.0887153772637248
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:54:16,189 INFO *** epoch 470, rolling-avg-loss (window=10)= 0.042591297341277826
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:16,312 INFO epoch # 471 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.006758519863481757-> 0.006758519863481757 - loss = 0.029252109117805958
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:16,434 INFO epoch # 472 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.006758519863481757-> 0.006758519863481757 - loss = 0.027600493747740984
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:16,557 INFO epoch # 473 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.006758519863481757-> 0.006758519863481757 - loss = 0.02376357722096145
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:16,679 INFO epoch # 474 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.006758519863481757-> 0.006758519863481757 - loss = 0.014499904587864876
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:16,802 INFO epoch # 475 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.006758519863481757-> 0.006758519863481757 - loss = 0.058736955747008324
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:16,925 INFO epoch # 476 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.006758519863481757-> 0.006758519863481757 - loss = 0.11628095409832895
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:17,048 INFO epoch # 477 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.006758519863481757-> 0.006758519863481757 - loss = 0.05148684931918979
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:17,170 INFO epoch # 478 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.006758519863481757-> 0.006758519863481757 - loss = 0.05235598562285304
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:17,292 INFO epoch # 479 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.006758519863481757-> 0.006082667877133581 - loss = 0.01992013305425644
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:17,414 INFO epoch # 480 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.006082667877133581-> 0.006082667877133581 - loss = 0.0679896678775549
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:54:17,414 INFO *** epoch 480, rolling-avg-loss (window=10)= 0.04618866303935647
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:17,536 INFO epoch # 481 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.006082667877133581-> 0.006082667877133581 - loss = 0.10663646552711725
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:17,659 INFO epoch # 482 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.006082667877133581-> 0.006082667877133581 - loss = 0.03281646454706788
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:17,781 INFO epoch # 483 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.006082667877133581-> 0.006082667877133581 - loss = 0.036564555019140244
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:17,903 INFO epoch # 484 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.006082667877133581-> 0.006082667877133581 - loss = 0.02518189325928688
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:18,026 INFO epoch # 485 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.006082667877133581-> 0.006082667877133581 - loss = 0.05768857733346522
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:18,148 INFO epoch # 486 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.006082667877133581-> 0.006082667877133581 - loss = 0.03488357178866863
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:18,271 INFO epoch # 487 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.006082667877133581-> 0.006082667877133581 - loss = 0.03528321022167802
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:18,393 INFO epoch # 488 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.006082667877133581-> 0.006082667877133581 - loss = 0.0952774528414011
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:18,516 INFO epoch # 489 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.006082667877133581-> 0.006082667877133581 - loss = 0.02316116774454713
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:18,638 INFO epoch # 490 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.006082667877133581-> 0.005474401089420223 - loss = 0.038961331360042095
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:54:18,638 INFO *** epoch 490, rolling-avg-loss (window=10)= 0.04864546896424145
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:18,760 INFO epoch # 491 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.005474401089420223-> 0.005474401089420223 - loss = 0.038952987641096115
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:18,883 INFO epoch # 492 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.005474401089420223-> 0.005474401089420223 - loss = 0.05192250059917569
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:19,006 INFO epoch # 493 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.005474401089420223-> 0.005474401089420223 - loss = 0.1307177951093763
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:19,129 INFO epoch # 494 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.005474401089420223-> 0.005474401089420223 - loss = 0.022673966828733683
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:19,253 INFO epoch # 495 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.005474401089420223-> 0.005474401089420223 - loss = 0.045871937181800604
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:19,380 INFO epoch # 496 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.005474401089420223-> 0.005474401089420223 - loss = 0.035631555831059813
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:19,503 INFO epoch # 497 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.005474401089420223-> 0.005474401089420223 - loss = 0.035540427546948195
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:19,627 INFO epoch # 498 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.005474401089420223-> 0.005474401089420223 - loss = 0.029592373874038458
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:19,750 INFO epoch # 499 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.005474401089420223-> 0.005474401089420223 - loss = 0.08460792852565646
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:19,890 INFO epoch # 500 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.005474401089420223-> 0.005474401089420223 - loss = 0.0346872266381979
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:54:19,890 INFO *** epoch 500, rolling-avg-loss (window=10)= 0.05101986997760832
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:20,030 INFO epoch # 501 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.005474401089420223-> 0.004926960980478201 - loss = 0.054346068762242794
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:20,170 INFO epoch # 502 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.004926960980478201-> 0.004926960980478201 - loss = 0.03625985258258879
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:20,312 INFO epoch # 503 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.004926960980478201-> 0.004926960980478201 - loss = 0.01799905952066183
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:20,453 INFO epoch # 504 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.004926960980478201-> 0.004926960980478201 - loss = 0.04290749877691269
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:20,596 INFO epoch # 505 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.004926960980478201-> 0.004926960980478201 - loss = 0.022264210041612387
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:20,738 INFO epoch # 506 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.004926960980478201-> 0.004926960980478201 - loss = 0.04633893957361579
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:20,882 INFO epoch # 507 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.004926960980478201-> 0.004926960980478201 - loss = 0.02338020270690322
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:21,047 INFO epoch # 508 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.004926960980478201-> 0.004926960980478201 - loss = 0.02857461152598262
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:21,188 INFO epoch # 509 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.004926960980478201-> 0.004926960980478201 - loss = 0.028720256173983216
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:21,317 INFO epoch # 510 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.004926960980478201-> 0.004926960980478201 - loss = 0.055074206087738276
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:54:21,317 INFO *** epoch 510, rolling-avg-loss (window=10)= 0.03558649057522416
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:21,448 INFO epoch # 511 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.004926960980478201-> 0.004926960980478201 - loss = 0.030043430160731077
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:21,590 INFO epoch # 512 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.004926960980478201-> 0.004434264882430382 - loss = 0.03361589601263404
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:21,728 INFO epoch # 513 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.004434264882430382-> 0.004434264882430382 - loss = 0.04264142271131277
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:21,878 INFO epoch # 514 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.004434264882430382-> 0.004434264882430382 - loss = 0.026039546355605125
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:22,020 INFO epoch # 515 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.004434264882430382-> 0.004434264882430382 - loss = 0.029532174579799175
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:22,162 INFO epoch # 516 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.004434264882430382-> 0.004434264882430382 - loss = 0.0594637063331902
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:22,306 INFO epoch # 517 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.004434264882430382-> 0.004434264882430382 - loss = 0.022763464134186506
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:22,448 INFO epoch # 518 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.004434264882430382-> 0.004434264882430382 - loss = 0.03988943342119455
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:22,580 INFO epoch # 519 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.004434264882430382-> 0.004434264882430382 - loss = 0.052636450389400125
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:22,729 INFO epoch # 520 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.004434264882430382-> 0.004434264882430382 - loss = 0.04019290581345558
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:54:22,729 INFO *** epoch 520, rolling-avg-loss (window=10)= 0.03768184299115092
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:22,864 INFO epoch # 521 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.004434264882430382-> 0.004434264882430382 - loss = 0.02175125782378018
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:22,990 INFO epoch # 522 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.004434264882430382-> 0.004434264882430382 - loss = 0.036148675717413425
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:23,122 INFO epoch # 523 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.004434264882430382-> 0.003990838394187343 - loss = 0.02301435498520732
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:23,265 INFO epoch # 524 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.003990838394187343-> 0.003990838394187343 - loss = 0.05447795847430825
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:23,391 INFO epoch # 525 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.003990838394187343-> 0.003990838394187343 - loss = 0.03243412030860782
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:23,523 INFO epoch # 526 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.003990838394187343-> 0.003990838394187343 - loss = 0.03335172729566693
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:23,663 INFO epoch # 527 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.003990838394187343-> 0.003990838394187343 - loss = 0.021712052170187235
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:23,808 INFO epoch # 528 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.003990838394187343-> 0.003990838394187343 - loss = 0.01447021251078695
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:23,967 INFO epoch # 529 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.003990838394187343-> 0.003990838394187343 - loss = 0.02592538599856198
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:24,102 INFO epoch # 530 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.003990838394187343-> 0.003990838394187343 - loss = 0.01905205042567104
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:54:24,102 INFO *** epoch 530, rolling-avg-loss (window=10)= 0.028233779571019114
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:24,247 INFO epoch # 531 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.003990838394187343-> 0.003990838394187343 - loss = 0.02180650783702731
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:24,379 INFO epoch # 532 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.003990838394187343-> 0.003990838394187343 - loss = 0.04124754713848233
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:24,519 INFO epoch # 533 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.003990838394187343-> 0.003990838394187343 - loss = 0.013900016667321324
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:24,663 INFO epoch # 534 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.003990838394187343-> 0.003591754554768609 - loss = 0.019930903101339936
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:24,808 INFO epoch # 535 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.003591754554768609-> 0.003591754554768609 - loss = 0.03166652284562588
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:24,950 INFO epoch # 536 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.003591754554768609-> 0.003591754554768609 - loss = 0.015538016334176064
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:25,081 INFO epoch # 537 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.003591754554768609-> 0.003591754554768609 - loss = 0.02858969522640109
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:25,206 INFO epoch # 538 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.003591754554768609-> 0.003591754554768609 - loss = 0.01639609911944717
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:25,336 INFO epoch # 539 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.003591754554768609-> 0.003591754554768609 - loss = 0.037527193780988455
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:25,478 INFO epoch # 540 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.003591754554768609-> 0.003591754554768609 - loss = 0.02596249943599105
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:54:25,478 INFO *** epoch 540, rolling-avg-loss (window=10)= 0.025256500148680062
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:25,620 INFO epoch # 541 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.003591754554768609-> 0.003591754554768609 - loss = 0.036260498221963644
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:25,762 INFO epoch # 542 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.003591754554768609-> 0.003591754554768609 - loss = 0.03347241319715977
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:25,894 INFO epoch # 543 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.003591754554768609-> 0.003591754554768609 - loss = 0.02717330167070031
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:26,024 INFO epoch # 544 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.003591754554768609-> 0.003591754554768609 - loss = 0.02946602739393711
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:26,169 INFO epoch # 545 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.003591754554768609-> 0.003232579099291748 - loss = 0.040880360174924135
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:26,314 INFO epoch # 546 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.003232579099291748-> 0.003232579099291748 - loss = 0.020890912041068077
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:26,451 INFO epoch # 547 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.003232579099291748-> 0.003232579099291748 - loss = 0.05822595348581672
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:26,595 INFO epoch # 548 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.003232579099291748-> 0.003232579099291748 - loss = 0.032044705003499985
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:26,746 INFO epoch # 549 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.003232579099291748-> 0.003232579099291748 - loss = 0.045595749747008085
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:26,889 INFO epoch # 550 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.003232579099291748-> 0.003232579099291748 - loss = 0.02804124215617776
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:54:26,889 INFO *** epoch 550, rolling-avg-loss (window=10)= 0.035205116309225556
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:27,031 INFO epoch # 551 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.003232579099291748-> 0.003232579099291748 - loss = 0.056740736588835716
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:27,170 INFO epoch # 552 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.003232579099291748-> 0.003232579099291748 - loss = 0.027903492096811533
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:27,303 INFO epoch # 553 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.003232579099291748-> 0.003232579099291748 - loss = 0.057857867097482085
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:27,440 INFO epoch # 554 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.003232579099291748-> 0.003232579099291748 - loss = 0.04130830243229866
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:27,582 INFO epoch # 555 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.003232579099291748-> 0.003232579099291748 - loss = 0.05822047730907798
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:27,729 INFO epoch # 556 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.003232579099291748-> 0.0029093211893625732 - loss = 0.07101401826366782
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:27,875 INFO epoch # 557 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0029093211893625732-> 0.0029093211893625732 - loss = 0.05149705056101084
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:28,016 INFO epoch # 558 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0029093211893625732-> 0.0029093211893625732 - loss = 0.039221548940986395
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:28,158 INFO epoch # 559 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0029093211893625732-> 0.0029093211893625732 - loss = 0.01652277377434075
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:28,305 INFO epoch # 560 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0029093211893625732-> 0.0029093211893625732 - loss = 0.0183465622831136
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:54:28,305 INFO *** epoch 560, rolling-avg-loss (window=10)= 0.043863282934762535
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:28,435 INFO epoch # 561 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0029093211893625732-> 0.0029093211893625732 - loss = 0.02253689616918564
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:28,578 INFO epoch # 562 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0029093211893625732-> 0.0029093211893625732 - loss = 0.018811195623129606
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:28,707 INFO epoch # 563 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0029093211893625732-> 0.0029093211893625732 - loss = 0.029170148307457566
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:28,832 INFO epoch # 564 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0029093211893625732-> 0.0029093211893625732 - loss = 0.015702393371611834
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:28,978 INFO epoch # 565 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0029093211893625732-> 0.0029093211893625732 - loss = 0.04023091564886272
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:29,123 INFO epoch # 566 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0029093211893625732-> 0.0029093211893625732 - loss = 0.02156665362417698
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:29,265 INFO epoch # 567 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0029093211893625732-> 0.002618389070426316 - loss = 0.0489266028162092
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:29,408 INFO epoch # 568 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.002618389070426316-> 0.002618389070426316 - loss = 0.032820874359458685
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:29,536 INFO epoch # 569 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.002618389070426316-> 0.002618389070426316 - loss = 0.03738480596803129
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:29,662 INFO epoch # 570 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.002618389070426316-> 0.002618389070426316 - loss = 0.02165387012064457
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:54:29,662 INFO *** epoch 570, rolling-avg-loss (window=10)= 0.02888043560087681
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:29,793 INFO epoch # 571 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.002618389070426316-> 0.002618389070426316 - loss = 0.061049374053254724
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:29,927 INFO epoch # 572 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.002618389070426316-> 0.002618389070426316 - loss = 0.06806819350458682
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:30,072 INFO epoch # 573 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.002618389070426316-> 0.002618389070426316 - loss = 0.04477825155481696
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:30,214 INFO epoch # 574 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.002618389070426316-> 0.002618389070426316 - loss = 0.11086944164708257
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:30,356 INFO epoch # 575 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.002618389070426316-> 0.002618389070426316 - loss = 0.03127026744186878
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:30,495 INFO epoch # 576 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.002618389070426316-> 0.002618389070426316 - loss = 0.016141931992024183
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:30,638 INFO epoch # 577 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.002618389070426316-> 0.002618389070426316 - loss = 0.020378774497658014
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:30,781 INFO epoch # 578 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.002618389070426316-> 0.0023565501633836844 - loss = 0.03041933523491025
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:30,924 INFO epoch # 579 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0023565501633836844-> 0.0023565501633836844 - loss = 0.025055709993466735
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:31,053 INFO epoch # 580 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0023565501633836844-> 0.0023565501633836844 - loss = 0.09689164301380515
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:54:31,054 INFO *** epoch 580, rolling-avg-loss (window=10)= 0.05049229229334742
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:31,188 INFO epoch # 581 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0023565501633836844-> 0.0023565501633836844 - loss = 0.0434279409237206
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:31,326 INFO epoch # 582 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0023565501633836844-> 0.0023565501633836844 - loss = 0.02577005699276924
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:31,467 INFO epoch # 583 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0023565501633836844-> 0.0023565501633836844 - loss = 0.034290850162506104
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:31,597 INFO epoch # 584 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0023565501633836844-> 0.0023565501633836844 - loss = 0.034840398002415895
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:31,729 INFO epoch # 585 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0023565501633836844-> 0.0023565501633836844 - loss = 0.016592561965808272
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:31,871 INFO epoch # 586 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0023565501633836844-> 0.0023565501633836844 - loss = 0.03959829732775688
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:32,014 INFO epoch # 587 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0023565501633836844-> 0.0023565501633836844 - loss = 0.05280483467504382
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:32,150 INFO epoch # 588 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0023565501633836844-> 0.0023565501633836844 - loss = 0.04914098186418414
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:32,290 INFO epoch # 589 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0023565501633836844-> 0.002120895147045316 - loss = 0.018199805170297623
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:32,431 INFO epoch # 590 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.002120895147045316-> 0.002120895147045316 - loss = 0.02130757737904787
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:54:32,431 INFO *** epoch 590, rolling-avg-loss (window=10)= 0.033597330446355045
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:32,556 INFO epoch # 591 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.002120895147045316-> 0.002120895147045316 - loss = 0.01956400671042502
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:32,688 INFO epoch # 592 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.002120895147045316-> 0.002120895147045316 - loss = 0.018687630305066705
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:32,832 INFO epoch # 593 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.002120895147045316-> 0.002120895147045316 - loss = 0.04571881820447743
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:32,974 INFO epoch # 594 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.002120895147045316-> 0.002120895147045316 - loss = 0.027725042775273323
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:33,116 INFO epoch # 595 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.002120895147045316-> 0.002120895147045316 - loss = 0.02999376179650426
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:33,261 INFO epoch # 596 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.002120895147045316-> 0.002120895147045316 - loss = 0.038178178016096354
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:33,398 INFO epoch # 597 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.002120895147045316-> 0.002120895147045316 - loss = 0.018385418923571706
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:33,538 INFO epoch # 598 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.002120895147045316-> 0.002120895147045316 - loss = 0.0344259450212121
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:33,666 INFO epoch # 599 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.002120895147045316-> 0.002120895147045316 - loss = 0.04514301614835858
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:33,809 INFO epoch # 600 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.002120895147045316-> 0.0019088056323407843 - loss = 0.030043671373277903
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:54:33,809 INFO *** epoch 600, rolling-avg-loss (window=10)= 0.030786548927426338
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:33,951 INFO epoch # 601 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0019088056323407843-> 0.0019088056323407843 - loss = 0.03385955421254039
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:34,092 INFO epoch # 602 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0019088056323407843-> 0.0019088056323407843 - loss = 0.03053659899160266
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:34,233 INFO epoch # 603 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0019088056323407843-> 0.0019088056323407843 - loss = 0.0306016793474555
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:34,361 INFO epoch # 604 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0019088056323407843-> 0.0019088056323407843 - loss = 0.032751585356891155
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:34,487 INFO epoch # 605 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0019088056323407843-> 0.0019088056323407843 - loss = 0.0482306182384491
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:34,611 INFO epoch # 606 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0019088056323407843-> 0.0019088056323407843 - loss = 0.04066574294120073
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:34,737 INFO epoch # 607 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0019088056323407843-> 0.0019088056323407843 - loss = 0.017697335919365287
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:34,863 INFO epoch # 608 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0019088056323407843-> 0.0019088056323407843 - loss = 0.04029330355115235
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:34,987 INFO epoch # 609 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0019088056323407843-> 0.0019088056323407843 - loss = 0.07487806933932006
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:35,112 INFO epoch # 610 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0019088056323407843-> 0.0019088056323407843 - loss = 0.021012504817917943
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:54:35,112 INFO *** epoch 610, rolling-avg-loss (window=10)= 0.037052699271589516
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:35,236 INFO epoch # 611 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0019088056323407843-> 0.001717925069106706 - loss = 0.030238340608775616
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:35,362 INFO epoch # 612 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.001717925069106706-> 0.001717925069106706 - loss = 0.02760400017723441
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:35,498 INFO epoch # 613 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.001717925069106706-> 0.001717925069106706 - loss = 0.07225612993352115
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:35,643 INFO epoch # 614 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.001717925069106706-> 0.001717925069106706 - loss = 0.017304451554082334
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:35,785 INFO epoch # 615 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.001717925069106706-> 0.001717925069106706 - loss = 0.07557022012770176
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:35,926 INFO epoch # 616 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.001717925069106706-> 0.001717925069106706 - loss = 0.02862200583331287
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:36,052 INFO epoch # 617 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.001717925069106706-> 0.001717925069106706 - loss = 0.030399123206734657
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:36,177 INFO epoch # 618 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.001717925069106706-> 0.001717925069106706 - loss = 0.013782227120827883
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:36,307 INFO epoch # 619 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.001717925069106706-> 0.001717925069106706 - loss = 0.035264371894299984
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:36,435 INFO epoch # 620 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.001717925069106706-> 0.001717925069106706 - loss = 0.024394951527938247
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:54:36,435 INFO *** epoch 620, rolling-avg-loss (window=10)= 0.03554358219844289
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:36,576 INFO epoch # 621 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.001717925069106706-> 0.001717925069106706 - loss = 0.02220603497698903
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:36,714 INFO epoch # 622 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.001717925069106706-> 0.0015461325621960354 - loss = 0.03369556833058596
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:36,843 INFO epoch # 623 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0015461325621960354-> 0.0015461325621960354 - loss = 0.07965489756315947
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:36,984 INFO epoch # 624 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0015461325621960354-> 0.0015461325621960354 - loss = 0.031184373423457146
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:37,113 INFO epoch # 625 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0015461325621960354-> 0.0015461325621960354 - loss = 0.02903551096096635
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:37,258 INFO epoch # 626 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0015461325621960354-> 0.0015461325621960354 - loss = 0.03569485805928707
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:37,406 INFO epoch # 627 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0015461325621960354-> 0.0015461325621960354 - loss = 0.03509764722548425
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:37,549 INFO epoch # 628 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0015461325621960354-> 0.0015461325621960354 - loss = 0.018610060506034642
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:37,683 INFO epoch # 629 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0015461325621960354-> 0.0015461325621960354 - loss = 0.019483498763293028
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:37,827 INFO epoch # 630 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0015461325621960354-> 0.0015461325621960354 - loss = 0.039041721960529685
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:54:37,827 INFO *** epoch 630, rolling-avg-loss (window=10)= 0.03437041717697866
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:37,970 INFO epoch # 631 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0015461325621960354-> 0.0015461325621960354 - loss = 0.019590265583246946
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:38,106 INFO epoch # 632 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0015461325621960354-> 0.0015461325621960354 - loss = 0.05527148628607392
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:38,243 INFO epoch # 633 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0015461325621960354-> 0.0013915193059764318 - loss = 0.06263007526285946
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:38,385 INFO epoch # 634 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0013915193059764318-> 0.0013915193059764318 - loss = 0.043767877388745546
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:38,518 INFO epoch # 635 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0013915193059764318-> 0.0013915193059764318 - loss = 0.033230887260288
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:38,651 INFO epoch # 636 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0013915193059764318-> 0.0013915193059764318 - loss = 0.01965420530177653
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:38,787 INFO epoch # 637 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0013915193059764318-> 0.0013915193059764318 - loss = 0.02852980513125658
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:38,937 INFO epoch # 638 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0013915193059764318-> 0.0013915193059764318 - loss = 0.02556122513487935
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:39,086 INFO epoch # 639 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0013915193059764318-> 0.0013915193059764318 - loss = 0.021758250193670392
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:39,230 INFO epoch # 640 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0013915193059764318-> 0.0013915193059764318 - loss = 0.03676835121586919
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:54:39,230 INFO *** epoch 640, rolling-avg-loss (window=10)= 0.03467624287586659
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:39,381 INFO epoch # 641 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0013915193059764318-> 0.0013915193059764318 - loss = 0.03312102169729769
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:39,531 INFO epoch # 642 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0013915193059764318-> 0.0013915193059764318 - loss = 0.03645769413560629
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:39,675 INFO epoch # 643 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0013915193059764318-> 0.0013915193059764318 - loss = 0.04363939864560962
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:39,819 INFO epoch # 644 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0013915193059764318-> 0.0012523673753787887 - loss = 0.02512327115982771
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:39,973 INFO epoch # 645 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0012523673753787887-> 0.0012523673753787887 - loss = 0.039144461741670966
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:40,107 INFO epoch # 646 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0012523673753787887-> 0.0012523673753787887 - loss = 0.054537125397473574
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:40,258 INFO epoch # 647 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0012523673753787887-> 0.0012523673753787887 - loss = 0.027555378037504852
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:40,404 INFO epoch # 648 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0012523673753787887-> 0.0012523673753787887 - loss = 0.04330327338539064
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:40,533 INFO epoch # 649 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0012523673753787887-> 0.0012523673753787887 - loss = 0.0956425832118839
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:40,676 INFO epoch # 650 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0012523673753787887-> 0.0012523673753787887 - loss = 0.02338726306334138
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:54:40,677 INFO *** epoch 650, rolling-avg-loss (window=10)= 0.04219114704756066
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:40,820 INFO epoch # 651 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0012523673753787887-> 0.0012523673753787887 - loss = 0.13161184918135405
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:40,960 INFO epoch # 652 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0012523673753787887-> 0.0012523673753787887 - loss = 0.02909531770274043
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:41,102 INFO epoch # 653 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0012523673753787887-> 0.0012523673753787887 - loss = 0.021358885685913265
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:41,237 INFO epoch # 654 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0012523673753787887-> 0.0012523673753787887 - loss = 0.02724684844724834
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:41,374 INFO epoch # 655 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0012523673753787887-> 0.00112713063784091 - loss = 0.02721768314950168
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:41,505 INFO epoch # 656 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00112713063784091-> 0.00112713063784091 - loss = 0.03374174144119024
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:41,649 INFO epoch # 657 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00112713063784091-> 0.00112713063784091 - loss = 0.02791699394583702
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:41,782 INFO epoch # 658 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00112713063784091-> 0.00112713063784091 - loss = 0.01782169286161661
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:41,908 INFO epoch # 659 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00112713063784091-> 0.00112713063784091 - loss = 0.08805717807263136
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:42,039 INFO epoch # 660 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00112713063784091-> 0.00112713063784091 - loss = 0.04403049545362592
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:54:42,039 INFO *** epoch 660, rolling-avg-loss (window=10)= 0.04480986859416589
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:42,185 INFO epoch # 661 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00112713063784091-> 0.00112713063784091 - loss = 0.029151203576475382
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:42,335 INFO epoch # 662 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00112713063784091-> 0.00112713063784091 - loss = 0.031235529109835625
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:42,476 INFO epoch # 663 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00112713063784091-> 0.00112713063784091 - loss = 0.019024690613150597
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:42,602 INFO epoch # 664 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00112713063784091-> 0.00112713063784091 - loss = 0.039659618865698576
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:42,737 INFO epoch # 665 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00112713063784091-> 0.00112713063784091 - loss = 0.028098626527935266
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:42,873 INFO epoch # 666 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00112713063784091-> 0.0010144175740568189 - loss = 0.021546806674450636
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:43,000 INFO epoch # 667 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0010144175740568189-> 0.0010144175740568189 - loss = 0.021140240132808685
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:43,124 INFO epoch # 668 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0010144175740568189-> 0.0010144175740568189 - loss = 0.02999198855832219
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:43,254 INFO epoch # 669 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0010144175740568189-> 0.0010144175740568189 - loss = 0.019342553336173296
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:43,390 INFO epoch # 670 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0010144175740568189-> 0.0010144175740568189 - loss = 0.0291973315179348
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:54:43,391 INFO *** epoch 670, rolling-avg-loss (window=10)= 0.026838858891278506
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:43,535 INFO epoch # 671 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0010144175740568189-> 0.0010144175740568189 - loss = 0.07170553738251328
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:43,685 INFO epoch # 672 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0010144175740568189-> 0.0010144175740568189 - loss = 0.026353648398071527
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:43,813 INFO epoch # 673 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0010144175740568189-> 0.0010144175740568189 - loss = 0.022037215530872345
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:43,937 INFO epoch # 674 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0010144175740568189-> 0.0010144175740568189 - loss = 0.02316446788609028
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:44,063 INFO epoch # 675 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0010144175740568189-> 0.0010144175740568189 - loss = 0.031234244350343943
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:44,189 INFO epoch # 676 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0010144175740568189-> 0.0010144175740568189 - loss = 0.015679147094488144
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:44,331 INFO epoch # 677 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0010144175740568189-> 0.000912975816651137 - loss = 0.03505749790929258
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:44,458 INFO epoch # 678 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.000912975816651137-> 0.000912975816651137 - loss = 0.016525292536243796
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:44,584 INFO epoch # 679 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.000912975816651137-> 0.000912975816651137 - loss = 0.019416293129324913
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:44,709 INFO epoch # 680 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.000912975816651137-> 0.000912975816651137 - loss = 0.0318355958443135
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:54:44,709 INFO *** epoch 680, rolling-avg-loss (window=10)= 0.02930089400615543
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:44,834 INFO epoch # 681 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.000912975816651137-> 0.000912975816651137 - loss = 0.03817441547289491
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:44,972 INFO epoch # 682 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.000912975816651137-> 0.000912975816651137 - loss = 0.029122128151357174
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:45,101 INFO epoch # 683 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.000912975816651137-> 0.000912975816651137 - loss = 0.023327310103923082
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:45,227 INFO epoch # 684 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.000912975816651137-> 0.000912975816651137 - loss = 0.019943662686273456
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:45,352 INFO epoch # 685 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.000912975816651137-> 0.000912975816651137 - loss = 0.050509825348854065
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:45,480 INFO epoch # 686 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.000912975816651137-> 0.000912975816651137 - loss = 0.09314054041169584
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:45,610 INFO epoch # 687 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.000912975816651137-> 0.000912975816651137 - loss = 0.0487277377396822
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:45,736 INFO epoch # 688 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.000912975816651137-> 0.0008216782349860233 - loss = 0.02619241550564766
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:45,863 INFO epoch # 689 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0008216782349860233-> 0.0008216782349860233 - loss = 0.02194301877170801
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:45,987 INFO epoch # 690 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0008216782349860233-> 0.0008216782349860233 - loss = 0.04065703600645065
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:54:45,987 INFO *** epoch 690, rolling-avg-loss (window=10)= 0.0391738090198487
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:46,124 INFO epoch # 691 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0008216782349860233-> 0.0008216782349860233 - loss = 0.023191040148958564
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:46,268 INFO epoch # 692 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0008216782349860233-> 0.0008216782349860233 - loss = 0.043457897612825036
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:46,412 INFO epoch # 693 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0008216782349860233-> 0.0008216782349860233 - loss = 0.01940015982836485
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:46,556 INFO epoch # 694 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0008216782349860233-> 0.0008216782349860233 - loss = 0.01632994576357305
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:46,698 INFO epoch # 695 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0008216782349860233-> 0.0008216782349860233 - loss = 0.021190527826547623
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:46,835 INFO epoch # 696 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0008216782349860233-> 0.0008216782349860233 - loss = 0.028665521182119846
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:46,986 INFO epoch # 697 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0008216782349860233-> 0.0008216782349860233 - loss = 0.038560185581445694
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:47,128 INFO epoch # 698 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0008216782349860233-> 0.0008216782349860233 - loss = 0.05513768224045634
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:47,272 INFO epoch # 699 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0008216782349860233-> 0.000739510411487421 - loss = 0.04069960583001375
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:47,417 INFO epoch # 700 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.000739510411487421-> 0.000739510411487421 - loss = 0.02597595821134746
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:54:47,417 INFO *** epoch 700, rolling-avg-loss (window=10)= 0.031260852422565225
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:47,561 INFO epoch # 701 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.000739510411487421-> 0.000739510411487421 - loss = 0.03116689040325582
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:47,697 INFO epoch # 702 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.000739510411487421-> 0.000739510411487421 - loss = 0.08247687807306647
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:47,836 INFO epoch # 703 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.000739510411487421-> 0.000739510411487421 - loss = 0.027608080534264445
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:47,968 INFO epoch # 704 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.000739510411487421-> 0.000739510411487421 - loss = 0.028332773596048355
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:48,101 INFO epoch # 705 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.000739510411487421-> 0.000739510411487421 - loss = 0.07273828564211726
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:48,227 INFO epoch # 706 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.000739510411487421-> 0.000739510411487421 - loss = 0.021966058760881424
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:48,358 INFO epoch # 707 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.000739510411487421-> 0.000739510411487421 - loss = 0.040932771284133196
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:48,488 INFO epoch # 708 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.000739510411487421-> 0.000739510411487421 - loss = 0.026372371707111597
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:48,614 INFO epoch # 709 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.000739510411487421-> 0.000739510411487421 - loss = 0.08427745453082025
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:48,738 INFO epoch # 710 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.000739510411487421-> 0.0006655593703386789 - loss = 0.01873891009017825
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:54:48,738 INFO *** epoch 710, rolling-avg-loss (window=10)= 0.04346104746218771
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:48,864 INFO epoch # 711 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0006655593703386789-> 0.0006655593703386789 - loss = 0.03898039739578962
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:48,991 INFO epoch # 712 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0006655593703386789-> 0.0006655593703386789 - loss = 0.018521679798141122
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:49,114 INFO epoch # 713 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0006655593703386789-> 0.0006655593703386789 - loss = 0.029913743026554585
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:49,238 INFO epoch # 714 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0006655593703386789-> 0.0006655593703386789 - loss = 0.019606540445238352
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:49,364 INFO epoch # 715 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0006655593703386789-> 0.0006655593703386789 - loss = 0.026449717115610838
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:49,490 INFO epoch # 716 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0006655593703386789-> 0.0006655593703386789 - loss = 0.022300831973552704
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:49,615 INFO epoch # 717 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0006655593703386789-> 0.0006655593703386789 - loss = 0.0356005160138011
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:49,739 INFO epoch # 718 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0006655593703386789-> 0.0006655593703386789 - loss = 0.018601095769554377
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:49,879 INFO epoch # 719 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0006655593703386789-> 0.0006655593703386789 - loss = 0.061386458575725555
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:50,011 INFO epoch # 720 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0006655593703386789-> 0.0006655593703386789 - loss = 0.04256395110860467
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:54:50,011 INFO *** epoch 720, rolling-avg-loss (window=10)= 0.031392493122257295
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:50,135 INFO epoch # 721 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0006655593703386789-> 0.0005990034333048111 - loss = 0.02118455048184842
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:50,278 INFO epoch # 722 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0005990034333048111-> 0.0005990034333048111 - loss = 0.02003343217074871
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:50,410 INFO epoch # 723 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0005990034333048111-> 0.0005990034333048111 - loss = 0.018595946487039328
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:50,534 INFO epoch # 724 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0005990034333048111-> 0.0005990034333048111 - loss = 0.02944214944727719
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:50,658 INFO epoch # 725 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0005990034333048111-> 0.0005990034333048111 - loss = 0.03984722832683474
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:50,784 INFO epoch # 726 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0005990034333048111-> 0.0005990034333048111 - loss = 0.14376777270808816
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:50,906 INFO epoch # 727 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0005990034333048111-> 0.0005990034333048111 - loss = 0.05975564639084041
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:51,031 INFO epoch # 728 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0005990034333048111-> 0.0005990034333048111 - loss = 0.02170994644984603
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:51,155 INFO epoch # 729 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0005990034333048111-> 0.0005990034333048111 - loss = 0.028928928775712848
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:51,277 INFO epoch # 730 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0005990034333048111-> 0.0005990034333048111 - loss = 0.06957781594246626
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:54:51,277 INFO *** epoch 730, rolling-avg-loss (window=10)= 0.045284341718070206
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:51,400 INFO epoch # 731 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0005990034333048111-> 0.0005990034333048111 - loss = 0.051840373780578375
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:51,523 INFO epoch # 732 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0005990034333048111-> 0.0005391030899743299 - loss = 0.026290546637028456
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:51,646 INFO epoch # 733 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0005391030899743299-> 0.0005391030899743299 - loss = 0.020262714941054583
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:51,769 INFO epoch # 734 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0005391030899743299-> 0.0005391030899743299 - loss = 0.10448764474131167
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:51,893 INFO epoch # 735 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0005391030899743299-> 0.0005391030899743299 - loss = 0.05312059330753982
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:52,016 INFO epoch # 736 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0005391030899743299-> 0.0005391030899743299 - loss = 0.01913191401399672
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:52,141 INFO epoch # 737 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0005391030899743299-> 0.0005391030899743299 - loss = 0.03678217902779579
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:52,275 INFO epoch # 738 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0005391030899743299-> 0.0005391030899743299 - loss = 0.04748415504582226
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:52,417 INFO epoch # 739 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0005391030899743299-> 0.0005391030899743299 - loss = 0.059100598096847534
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:52,544 INFO epoch # 740 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0005391030899743299-> 0.0005391030899743299 - loss = 0.019247265299782157
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:54:52,545 INFO *** epoch 740, rolling-avg-loss (window=10)= 0.04377479848917574
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:52,668 INFO epoch # 741 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0005391030899743299-> 0.0005391030899743299 - loss = 0.037156354170292616
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:52,791 INFO epoch # 742 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0005391030899743299-> 0.0005391030899743299 - loss = 0.03557301638647914
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:52,914 INFO epoch # 743 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0005391030899743299-> 0.00048519278097689693 - loss = 0.03383035655133426
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:53,046 INFO epoch # 744 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00048519278097689693-> 0.00048519278097689693 - loss = 0.022922247415408492
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:53,183 INFO epoch # 745 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00048519278097689693-> 0.00048519278097689693 - loss = 0.023562456015497446
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:53,318 INFO epoch # 746 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00048519278097689693-> 0.00048519278097689693 - loss = 0.041201363783329725
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:53,440 INFO epoch # 747 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00048519278097689693-> 0.00048519278097689693 - loss = 0.014753007213585079
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:53,562 INFO epoch # 748 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00048519278097689693-> 0.00048519278097689693 - loss = 0.01661834307014942
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:53,695 INFO epoch # 749 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00048519278097689693-> 0.00048519278097689693 - loss = 0.026123495772480965
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:53,831 INFO epoch # 750 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00048519278097689693-> 0.00048519278097689693 - loss = 0.03080569440498948
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:54:53,831 INFO *** epoch 750, rolling-avg-loss (window=10)= 0.028254633478354663
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:53,955 INFO epoch # 751 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00048519278097689693-> 0.00048519278097689693 - loss = 0.019163277931511402
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:54,097 INFO epoch # 752 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00048519278097689693-> 0.00048519278097689693 - loss = 0.03363386821001768
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:54,240 INFO epoch # 753 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00048519278097689693-> 0.00048519278097689693 - loss = 0.01727324817329645
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:54,368 INFO epoch # 754 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00048519278097689693-> 0.00043667350287920724 - loss = 0.020681698340922594
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:54,510 INFO epoch # 755 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00043667350287920724-> 0.00043667350287920724 - loss = 0.0255277743563056
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:54,651 INFO epoch # 756 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00043667350287920724-> 0.00043667350287920724 - loss = 0.023411328438669443
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:54,796 INFO epoch # 757 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00043667350287920724-> 0.00043667350287920724 - loss = 0.027091593947261572
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:54,940 INFO epoch # 758 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00043667350287920724-> 0.00043667350287920724 - loss = 0.08627037447877228
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:55,083 INFO epoch # 759 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00043667350287920724-> 0.00043667350287920724 - loss = 0.021578327752649784
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:55,227 INFO epoch # 760 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00043667350287920724-> 0.00043667350287920724 - loss = 0.04079463519155979
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:54:55,227 INFO *** epoch 760, rolling-avg-loss (window=10)= 0.03154261268209666
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:55,369 INFO epoch # 761 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00043667350287920724-> 0.00043667350287920724 - loss = 0.025221217889338732
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:55,495 INFO epoch # 762 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00043667350287920724-> 0.00043667350287920724 - loss = 0.04346243804320693
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:55,619 INFO epoch # 763 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00043667350287920724-> 0.00043667350287920724 - loss = 0.018167099682614207
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:55,744 INFO epoch # 764 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00043667350287920724-> 0.00043667350287920724 - loss = 0.04517193045467138
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:55,870 INFO epoch # 765 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00043667350287920724-> 0.0003930061525912865 - loss = 0.026010545436292887
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:55,993 INFO epoch # 766 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0003930061525912865-> 0.0003930061525912865 - loss = 0.024686605902388692
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:56,116 INFO epoch # 767 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0003930061525912865-> 0.0003930061525912865 - loss = 0.04265719698742032
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:56,239 INFO epoch # 768 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0003930061525912865-> 0.0003930061525912865 - loss = 0.032367527950555086
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:56,362 INFO epoch # 769 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0003930061525912865-> 0.0003930061525912865 - loss = 0.022609528619796038
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:56,486 INFO epoch # 770 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0003930061525912865-> 0.0003930061525912865 - loss = 0.032540926709771156
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:54:56,486 INFO *** epoch 770, rolling-avg-loss (window=10)= 0.031289501767605546
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:56,615 INFO epoch # 771 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0003930061525912865-> 0.0003930061525912865 - loss = 0.015416151378303766
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:56,755 INFO epoch # 772 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0003930061525912865-> 0.0003930061525912865 - loss = 0.032084029633551836
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:56,897 INFO epoch # 773 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0003930061525912865-> 0.0003930061525912865 - loss = 0.0338018829934299
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:57,052 INFO epoch # 774 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0003930061525912865-> 0.0003930061525912865 - loss = 0.0324324700050056
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:57,197 INFO epoch # 775 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0003930061525912865-> 0.0003930061525912865 - loss = 0.0846908618696034
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:57,340 INFO epoch # 776 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0003930061525912865-> 0.0003537055373321579 - loss = 0.04838570673018694
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:57,483 INFO epoch # 777 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0003537055373321579-> 0.0003537055373321579 - loss = 0.04065258102491498
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:57,628 INFO epoch # 778 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0003537055373321579-> 0.0003537055373321579 - loss = 0.04956217645667493
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:57,770 INFO epoch # 779 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0003537055373321579-> 0.0003537055373321579 - loss = 0.02264576405286789
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:57,913 INFO epoch # 780 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0003537055373321579-> 0.0003537055373321579 - loss = 0.04011877626180649
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:54:57,913 INFO *** epoch 780, rolling-avg-loss (window=10)= 0.03997904004063457
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:58,058 INFO epoch # 781 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0003537055373321579-> 0.0003537055373321579 - loss = 0.028361228993162513
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:58,191 INFO epoch # 782 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0003537055373321579-> 0.0003537055373321579 - loss = 0.05910427821800113
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:58,326 INFO epoch # 783 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0003537055373321579-> 0.0003537055373321579 - loss = 0.017140959855169058
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:58,463 INFO epoch # 784 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0003537055373321579-> 0.0003537055373321579 - loss = 0.02953446190804243
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:58,591 INFO epoch # 785 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0003537055373321579-> 0.0003537055373321579 - loss = 0.043756692204624414
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:58,716 INFO epoch # 786 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0003537055373321579-> 0.0003537055373321579 - loss = 0.025127704720944166
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:58,838 INFO epoch # 787 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0003537055373321579-> 0.00031833498359894213 - loss = 0.02739856392145157
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:58,961 INFO epoch # 788 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00031833498359894213-> 0.00031833498359894213 - loss = 0.02672275109216571
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:59,083 INFO epoch # 789 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00031833498359894213-> 0.00031833498359894213 - loss = 0.023297627922147512
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:59,207 INFO epoch # 790 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00031833498359894213-> 0.00031833498359894213 - loss = 0.02563335548620671
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:54:59,207 INFO *** epoch 790, rolling-avg-loss (window=10)= 0.030607762432191522
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:59,330 INFO epoch # 791 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00031833498359894213-> 0.00031833498359894213 - loss = 0.04655360127799213
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:59,454 INFO epoch # 792 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00031833498359894213-> 0.00031833498359894213 - loss = 0.04307899950072169
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:59,578 INFO epoch # 793 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00031833498359894213-> 0.00031833498359894213 - loss = 0.024525738786906004
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:59,701 INFO epoch # 794 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00031833498359894213-> 0.00031833498359894213 - loss = 0.05127035011537373
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:59,833 INFO epoch # 795 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00031833498359894213-> 0.00031833498359894213 - loss = 0.025151236448436975
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:54:59,962 INFO epoch # 796 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00031833498359894213-> 0.00031833498359894213 - loss = 0.025131186936050653
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:00,098 INFO epoch # 797 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00031833498359894213-> 0.00031833498359894213 - loss = 0.04306518565863371
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:00,225 INFO epoch # 798 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00031833498359894213-> 0.00028650148523904793 - loss = 0.04294362827204168
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:00,373 INFO epoch # 799 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00028650148523904793-> 0.00028650148523904793 - loss = 0.027518995571881533
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:00,499 INFO epoch # 800 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00028650148523904793-> 0.00028650148523904793 - loss = 0.018854463240131736
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:55:00,499 INFO *** epoch 800, rolling-avg-loss (window=10)= 0.03480933858081699
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:00,623 INFO epoch # 801 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00028650148523904793-> 0.00028650148523904793 - loss = 0.02273444994352758
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:00,749 INFO epoch # 802 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00028650148523904793-> 0.00028650148523904793 - loss = 0.031314578372985125
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:00,890 INFO epoch # 803 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00028650148523904793-> 0.00028650148523904793 - loss = 0.023368437075987458
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:01,018 INFO epoch # 804 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00028650148523904793-> 0.00028650148523904793 - loss = 0.01676607341505587
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:01,150 INFO epoch # 805 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00028650148523904793-> 0.00028650148523904793 - loss = 0.02990331663750112
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:01,295 INFO epoch # 806 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00028650148523904793-> 0.00028650148523904793 - loss = 0.03209430677816272
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:01,430 INFO epoch # 807 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00028650148523904793-> 0.00028650148523904793 - loss = 0.02114218659698963
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:01,554 INFO epoch # 808 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00028650148523904793-> 0.00028650148523904793 - loss = 0.034968772903084755
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:01,679 INFO epoch # 809 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00028650148523904793-> 0.00025785133671514315 - loss = 0.048485659528523684
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:01,806 INFO epoch # 810 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00025785133671514315-> 0.00025785133671514315 - loss = 0.0372229740023613
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:55:01,806 INFO *** epoch 810, rolling-avg-loss (window=10)= 0.029800075525417923
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:01,931 INFO epoch # 811 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00025785133671514315-> 0.00025785133671514315 - loss = 0.043785585090518
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:02,068 INFO epoch # 812 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00025785133671514315-> 0.00025785133671514315 - loss = 0.025405116379261017
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:02,202 INFO epoch # 813 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00025785133671514315-> 0.00025785133671514315 - loss = 0.020069795195013285
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:02,336 INFO epoch # 814 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00025785133671514315-> 0.00025785133671514315 - loss = 0.10249041998758912
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:02,462 INFO epoch # 815 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00025785133671514315-> 0.00025785133671514315 - loss = 0.04063249612227082
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:02,586 INFO epoch # 816 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00025785133671514315-> 0.00025785133671514315 - loss = 0.01947089098393917
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:02,709 INFO epoch # 817 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00025785133671514315-> 0.00025785133671514315 - loss = 0.019645768217742443
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:02,895 INFO epoch # 818 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00025785133671514315-> 0.00025785133671514315 - loss = 0.025254360865801573
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:03,080 INFO epoch # 819 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00025785133671514315-> 0.00025785133671514315 - loss = 0.024274643044918776
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:03,207 INFO epoch # 820 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00025785133671514315-> 0.00023206620304362885 - loss = 0.050382710760459304
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:55:03,207 INFO *** epoch 820, rolling-avg-loss (window=10)= 0.03714117866475135
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:03,333 INFO epoch # 821 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00023206620304362885-> 0.00023206620304362885 - loss = 0.023341465275734663
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:03,457 INFO epoch # 822 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00023206620304362885-> 0.00023206620304362885 - loss = 0.02657519467175007
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:03,579 INFO epoch # 823 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00023206620304362885-> 0.00023206620304362885 - loss = 0.04990715952590108
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:03,702 INFO epoch # 824 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00023206620304362885-> 0.00023206620304362885 - loss = 0.06138581037521362
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:03,825 INFO epoch # 825 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00023206620304362885-> 0.00023206620304362885 - loss = 0.023056614911183715
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:03,948 INFO epoch # 826 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00023206620304362885-> 0.00023206620304362885 - loss = 0.0378231224603951
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:04,070 INFO epoch # 827 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00023206620304362885-> 0.00023206620304362885 - loss = 0.02654860494658351
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:04,197 INFO epoch # 828 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00023206620304362885-> 0.00023206620304362885 - loss = 0.01925847213715315
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:04,325 INFO epoch # 829 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00023206620304362885-> 0.00023206620304362885 - loss = 0.08859346085228026
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:04,448 INFO epoch # 830 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00023206620304362885-> 0.00023206620304362885 - loss = 0.040537730790674686
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:55:04,448 INFO *** epoch 830, rolling-avg-loss (window=10)= 0.03970276359468698
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:04,571 INFO epoch # 831 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00023206620304362885-> 0.00020885958273926598 - loss = 0.036331105045974255
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:04,694 INFO epoch # 832 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00020885958273926598-> 0.00020885958273926598 - loss = 0.057498014997690916
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:04,817 INFO epoch # 833 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00020885958273926598-> 0.00020885958273926598 - loss = 0.030430414248257875
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:04,940 INFO epoch # 834 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00020885958273926598-> 0.00020885958273926598 - loss = 0.03673572116531432
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:05,062 INFO epoch # 835 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00020885958273926598-> 0.00020885958273926598 - loss = 0.03172454284504056
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:05,198 INFO epoch # 836 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00020885958273926598-> 0.00020885958273926598 - loss = 0.023346089525148273
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:05,326 INFO epoch # 837 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00020885958273926598-> 0.00020885958273926598 - loss = 0.09246895788237453
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:05,447 INFO epoch # 838 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00020885958273926598-> 0.00020885958273926598 - loss = 0.040481018368154764
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:05,569 INFO epoch # 839 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00020885958273926598-> 0.00020885958273926598 - loss = 0.05746685713529587
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:05,692 INFO epoch # 840 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00020885958273926598-> 0.00020885958273926598 - loss = 0.030697002075612545
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:55:05,692 INFO *** epoch 840, rolling-avg-loss (window=10)= 0.04371797232888639
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:05,828 INFO epoch # 841 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00020885958273926598-> 0.00020885958273926598 - loss = 0.04986369842663407
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:05,968 INFO epoch # 842 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00020885958273926598-> 0.00018797362446533938 - loss = 0.03021987108513713
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:06,090 INFO epoch # 843 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00018797362446533938-> 0.00018797362446533938 - loss = 0.036001973785459995
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:06,212 INFO epoch # 844 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00018797362446533938-> 0.00018797362446533938 - loss = 0.018132843542844057
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:06,336 INFO epoch # 845 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00018797362446533938-> 0.00018797362446533938 - loss = 0.03376354766078293
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:06,468 INFO epoch # 846 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00018797362446533938-> 0.00018797362446533938 - loss = 0.04606367414817214
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:06,598 INFO epoch # 847 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00018797362446533938-> 0.00018797362446533938 - loss = 0.01855636341497302
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:06,723 INFO epoch # 848 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00018797362446533938-> 0.00018797362446533938 - loss = 0.042864910792559385
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:06,846 INFO epoch # 849 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00018797362446533938-> 0.00018797362446533938 - loss = 0.04279255005531013
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:06,969 INFO epoch # 850 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00018797362446533938-> 0.00018797362446533938 - loss = 0.019434866961091757
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:55:06,969 INFO *** epoch 850, rolling-avg-loss (window=10)= 0.03376942998729646
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:07,091 INFO epoch # 851 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00018797362446533938-> 0.00018797362446533938 - loss = 0.027085734996944666
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:07,213 INFO epoch # 852 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00018797362446533938-> 0.00018797362446533938 - loss = 0.04042592039331794
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:07,334 INFO epoch # 853 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00018797362446533938-> 0.00016917626201880544 - loss = 0.0658436631783843
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:07,475 INFO epoch # 854 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00016917626201880544-> 0.00016917626201880544 - loss = 0.021117015276104212
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:07,611 INFO epoch # 855 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00016917626201880544-> 0.00016917626201880544 - loss = 0.025514956563711166
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:07,739 INFO epoch # 856 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00016917626201880544-> 0.00016917626201880544 - loss = 0.01658640056848526
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:07,868 INFO epoch # 857 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00016917626201880544-> 0.00016917626201880544 - loss = 0.0383846377953887
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:08,013 INFO epoch # 858 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00016917626201880544-> 0.00016917626201880544 - loss = 0.051017478806898
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:08,137 INFO epoch # 859 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00016917626201880544-> 0.00016917626201880544 - loss = 0.028389909537509084
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:08,261 INFO epoch # 860 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00016917626201880544-> 0.00016917626201880544 - loss = 0.03586522466503084
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:55:08,261 INFO *** epoch 860, rolling-avg-loss (window=10)= 0.035023094178177415
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:08,382 INFO epoch # 861 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00016917626201880544-> 0.00016917626201880544 - loss = 0.03242567041888833
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:08,504 INFO epoch # 862 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00016917626201880544-> 0.00016917626201880544 - loss = 0.03794684028252959
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:08,626 INFO epoch # 863 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00016917626201880544-> 0.00016917626201880544 - loss = 0.048759145895019174
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:08,747 INFO epoch # 864 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00016917626201880544-> 0.00015225863581692489 - loss = 0.033586230129003525
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:08,874 INFO epoch # 865 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00015225863581692489-> 0.00015225863581692489 - loss = 0.053832946345210075
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:09,013 INFO epoch # 866 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00015225863581692489-> 0.00015225863581692489 - loss = 0.0357233309186995
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:09,149 INFO epoch # 867 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00015225863581692489-> 0.00015225863581692489 - loss = 0.04053770238533616
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:09,273 INFO epoch # 868 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00015225863581692489-> 0.00015225863581692489 - loss = 0.020253776106983423
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:09,399 INFO epoch # 869 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00015225863581692489-> 0.00015225863581692489 - loss = 0.013915507355704904
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:09,521 INFO epoch # 870 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00015225863581692489-> 0.00015225863581692489 - loss = 0.01799205271527171
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:55:09,521 INFO *** epoch 870, rolling-avg-loss (window=10)= 0.03349732025526464
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:09,643 INFO epoch # 871 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00015225863581692489-> 0.00015225863581692489 - loss = 0.01973246969282627
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:09,766 INFO epoch # 872 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00015225863581692489-> 0.00015225863581692489 - loss = 0.03227134421467781
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:09,888 INFO epoch # 873 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00015225863581692489-> 0.00015225863581692489 - loss = 0.017246168339625
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:10,011 INFO epoch # 874 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00015225863581692489-> 0.00015225863581692489 - loss = 0.02875903807580471
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:10,133 INFO epoch # 875 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00015225863581692489-> 0.0001370327722352324 - loss = 0.02294163592159748
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:10,257 INFO epoch # 876 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0001370327722352324-> 0.0001370327722352324 - loss = 0.040212720865383744
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:10,380 INFO epoch # 877 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0001370327722352324-> 0.0001370327722352324 - loss = 0.032364089507609606
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:10,502 INFO epoch # 878 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0001370327722352324-> 0.0001370327722352324 - loss = 0.045467083575204015
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:10,625 INFO epoch # 879 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0001370327722352324-> 0.0001370327722352324 - loss = 0.034536973340436816
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:10,747 INFO epoch # 880 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0001370327722352324-> 0.0001370327722352324 - loss = 0.03820320824161172
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:55:10,747 INFO *** epoch 880, rolling-avg-loss (window=10)= 0.031173473177477717
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:10,891 INFO epoch # 881 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0001370327722352324-> 0.0001370327722352324 - loss = 0.04856248293071985
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:11,034 INFO epoch # 882 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0001370327722352324-> 0.0001370327722352324 - loss = 0.01881651789881289
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:11,164 INFO epoch # 883 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0001370327722352324-> 0.0001370327722352324 - loss = 0.045423035975545645
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:11,297 INFO epoch # 884 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0001370327722352324-> 0.0001370327722352324 - loss = 0.04632407543249428
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:11,423 INFO epoch # 885 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0001370327722352324-> 0.0001370327722352324 - loss = 0.05235959030687809
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:11,546 INFO epoch # 886 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0001370327722352324-> 0.00012332949501170915 - loss = 0.05301602091640234
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:11,671 INFO epoch # 887 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00012332949501170915-> 0.00012332949501170915 - loss = 0.027539280941709876
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:11,794 INFO epoch # 888 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00012332949501170915-> 0.00012332949501170915 - loss = 0.02048321207985282
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:11,932 INFO epoch # 889 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00012332949501170915-> 0.00012332949501170915 - loss = 0.053073600865900517
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:12,068 INFO epoch # 890 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00012332949501170915-> 0.00012332949501170915 - loss = 0.05845401110127568
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:55:12,068 INFO *** epoch 890, rolling-avg-loss (window=10)= 0.0424051828449592
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:12,198 INFO epoch # 891 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00012332949501170915-> 0.00012332949501170915 - loss = 0.05767057719640434
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:12,327 INFO epoch # 892 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00012332949501170915-> 0.00012332949501170915 - loss = 0.021856694133020937
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:12,450 INFO epoch # 893 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00012332949501170915-> 0.00012332949501170915 - loss = 0.03307407023385167
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:12,572 INFO epoch # 894 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00012332949501170915-> 0.00012332949501170915 - loss = 0.028162346221506596
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:12,694 INFO epoch # 895 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00012332949501170915-> 0.00012332949501170915 - loss = 0.029284637654200196
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:12,817 INFO epoch # 896 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00012332949501170915-> 0.00012332949501170915 - loss = 0.05171420832630247
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:12,940 INFO epoch # 897 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00012332949501170915-> 0.00011099654551053824 - loss = 0.01608721073716879
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:13,062 INFO epoch # 898 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00011099654551053824-> 0.00011099654551053824 - loss = 0.050665233284235
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:13,185 INFO epoch # 899 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00011099654551053824-> 0.00011099654551053824 - loss = 0.016883169068023562
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:13,324 INFO epoch # 900 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00011099654551053824-> 0.00011099654551053824 - loss = 0.036925120279192924
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:55:13,324 INFO *** epoch 900, rolling-avg-loss (window=10)= 0.034232326713390646
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:13,461 INFO epoch # 901 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00011099654551053824-> 0.00011099654551053824 - loss = 0.031394824385643005
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:13,599 INFO epoch # 902 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00011099654551053824-> 0.00011099654551053824 - loss = 0.041905582416802645
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:13,725 INFO epoch # 903 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00011099654551053824-> 0.00011099654551053824 - loss = 0.02230872819200158
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:13,847 INFO epoch # 904 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00011099654551053824-> 0.00011099654551053824 - loss = 0.03662866586819291
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:13,969 INFO epoch # 905 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00011099654551053824-> 0.00011099654551053824 - loss = 0.04545530630275607
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:14,092 INFO epoch # 906 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00011099654551053824-> 0.00011099654551053824 - loss = 0.016676688799634576
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:14,218 INFO epoch # 907 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00011099654551053824-> 0.00011099654551053824 - loss = 0.05177256837487221
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:14,350 INFO epoch # 908 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00011099654551053824-> 9.989689095948442e-05 - loss = 0.027038504369556904
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:14,473 INFO epoch # 909 - for optimizer <class 'torch.optim.adam.Adam'> lr : 9.989689095948442e-05-> 9.989689095948442e-05 - loss = 0.025612293276935816
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:14,594 INFO epoch # 910 - for optimizer <class 'torch.optim.adam.Adam'> lr : 9.989689095948442e-05-> 9.989689095948442e-05 - loss = 0.032621690072119236
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:55:14,594 INFO *** epoch 910, rolling-avg-loss (window=10)= 0.033141485205851494
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:14,716 INFO epoch # 911 - for optimizer <class 'torch.optim.adam.Adam'> lr : 9.989689095948442e-05-> 9.989689095948442e-05 - loss = 0.02108016237616539
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:14,839 INFO epoch # 912 - for optimizer <class 'torch.optim.adam.Adam'> lr : 9.989689095948442e-05-> 9.989689095948442e-05 - loss = 0.024431883357465267
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:14,961 INFO epoch # 913 - for optimizer <class 'torch.optim.adam.Adam'> lr : 9.989689095948442e-05-> 9.989689095948442e-05 - loss = 0.0158569379709661
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:15,083 INFO epoch # 914 - for optimizer <class 'torch.optim.adam.Adam'> lr : 9.989689095948442e-05-> 9.989689095948442e-05 - loss = 0.025962447049096227
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:15,209 INFO epoch # 915 - for optimizer <class 'torch.optim.adam.Adam'> lr : 9.989689095948442e-05-> 9.989689095948442e-05 - loss = 0.10529632261022925
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:15,348 INFO epoch # 916 - for optimizer <class 'torch.optim.adam.Adam'> lr : 9.989689095948442e-05-> 9.989689095948442e-05 - loss = 0.02624054392799735
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:15,475 INFO epoch # 917 - for optimizer <class 'torch.optim.adam.Adam'> lr : 9.989689095948442e-05-> 9.989689095948442e-05 - loss = 0.04102686932310462
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:15,605 INFO epoch # 918 - for optimizer <class 'torch.optim.adam.Adam'> lr : 9.989689095948442e-05-> 9.989689095948442e-05 - loss = 0.023136897245422006
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:15,745 INFO epoch # 919 - for optimizer <class 'torch.optim.adam.Adam'> lr : 9.989689095948442e-05-> 8.990720186353598e-05 - loss = 0.04978410806506872
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:15,877 INFO epoch # 920 - for optimizer <class 'torch.optim.adam.Adam'> lr : 8.990720186353598e-05-> 8.990720186353598e-05 - loss = 0.02926498814485967
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:55:15,877 INFO *** epoch 920, rolling-avg-loss (window=10)= 0.03620811600703746
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:16,016 INFO epoch # 921 - for optimizer <class 'torch.optim.adam.Adam'> lr : 8.990720186353598e-05-> 8.990720186353598e-05 - loss = 0.02138363104313612
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:16,155 INFO epoch # 922 - for optimizer <class 'torch.optim.adam.Adam'> lr : 8.990720186353598e-05-> 8.990720186353598e-05 - loss = 0.01621016301214695
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:16,282 INFO epoch # 923 - for optimizer <class 'torch.optim.adam.Adam'> lr : 8.990720186353598e-05-> 8.990720186353598e-05 - loss = 0.01600770209915936
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:16,417 INFO epoch # 924 - for optimizer <class 'torch.optim.adam.Adam'> lr : 8.990720186353598e-05-> 8.990720186353598e-05 - loss = 0.013772551785223186
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:16,540 INFO epoch # 925 - for optimizer <class 'torch.optim.adam.Adam'> lr : 8.990720186353598e-05-> 8.990720186353598e-05 - loss = 0.026215512305498123
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:16,663 INFO epoch # 926 - for optimizer <class 'torch.optim.adam.Adam'> lr : 8.990720186353598e-05-> 8.990720186353598e-05 - loss = 0.01792641496285796
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:16,786 INFO epoch # 927 - for optimizer <class 'torch.optim.adam.Adam'> lr : 8.990720186353598e-05-> 8.990720186353598e-05 - loss = 0.02422729041427374
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:16,909 INFO epoch # 928 - for optimizer <class 'torch.optim.adam.Adam'> lr : 8.990720186353598e-05-> 8.990720186353598e-05 - loss = 0.08763179578818381
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:17,032 INFO epoch # 929 - for optimizer <class 'torch.optim.adam.Adam'> lr : 8.990720186353598e-05-> 8.990720186353598e-05 - loss = 0.027707867324352264
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:17,154 INFO epoch # 930 - for optimizer <class 'torch.optim.adam.Adam'> lr : 8.990720186353598e-05-> 8.091648167718239e-05 - loss = 0.027066972106695175
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:55:17,154 INFO *** epoch 930, rolling-avg-loss (window=10)= 0.02781499008415267
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:17,278 INFO epoch # 931 - for optimizer <class 'torch.optim.adam.Adam'> lr : 8.091648167718239e-05-> 8.091648167718239e-05 - loss = 0.02913088514469564
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:17,409 INFO epoch # 932 - for optimizer <class 'torch.optim.adam.Adam'> lr : 8.091648167718239e-05-> 8.091648167718239e-05 - loss = 0.012398816179484129
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:17,538 INFO epoch # 933 - for optimizer <class 'torch.optim.adam.Adam'> lr : 8.091648167718239e-05-> 8.091648167718239e-05 - loss = 0.021414837799966335
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:17,660 INFO epoch # 934 - for optimizer <class 'torch.optim.adam.Adam'> lr : 8.091648167718239e-05-> 8.091648167718239e-05 - loss = 0.01818980905227363
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:17,784 INFO epoch # 935 - for optimizer <class 'torch.optim.adam.Adam'> lr : 8.091648167718239e-05-> 8.091648167718239e-05 - loss = 0.031746407272294164
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:17,906 INFO epoch # 936 - for optimizer <class 'torch.optim.adam.Adam'> lr : 8.091648167718239e-05-> 8.091648167718239e-05 - loss = 0.13780351425521076
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:18,029 INFO epoch # 937 - for optimizer <class 'torch.optim.adam.Adam'> lr : 8.091648167718239e-05-> 8.091648167718239e-05 - loss = 0.015246430411934853
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:18,168 INFO epoch # 938 - for optimizer <class 'torch.optim.adam.Adam'> lr : 8.091648167718239e-05-> 8.091648167718239e-05 - loss = 0.07286045257933438
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:18,294 INFO epoch # 939 - for optimizer <class 'torch.optim.adam.Adam'> lr : 8.091648167718239e-05-> 8.091648167718239e-05 - loss = 0.024971904465928674
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:18,430 INFO epoch # 940 - for optimizer <class 'torch.optim.adam.Adam'> lr : 8.091648167718239e-05-> 8.091648167718239e-05 - loss = 0.07435518386773765
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:55:18,430 INFO *** epoch 940, rolling-avg-loss (window=10)= 0.04381182410288602
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:18,552 INFO epoch # 941 - for optimizer <class 'torch.optim.adam.Adam'> lr : 8.091648167718239e-05-> 8.091648167718239e-05 - loss = 0.04168370272964239
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:18,675 INFO epoch # 942 - for optimizer <class 'torch.optim.adam.Adam'> lr : 8.091648167718239e-05-> 8.091648167718239e-05 - loss = 0.03473768453113735
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:18,806 INFO epoch # 943 - for optimizer <class 'torch.optim.adam.Adam'> lr : 8.091648167718239e-05-> 7.282483350946415e-05 - loss = 0.02452929876744747
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:18,940 INFO epoch # 944 - for optimizer <class 'torch.optim.adam.Adam'> lr : 7.282483350946415e-05-> 7.282483350946415e-05 - loss = 0.04699182976037264
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:19,063 INFO epoch # 945 - for optimizer <class 'torch.optim.adam.Adam'> lr : 7.282483350946415e-05-> 7.282483350946415e-05 - loss = 0.031655756291002035
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:19,185 INFO epoch # 946 - for optimizer <class 'torch.optim.adam.Adam'> lr : 7.282483350946415e-05-> 7.282483350946415e-05 - loss = 0.05506518529728055
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:19,307 INFO epoch # 947 - for optimizer <class 'torch.optim.adam.Adam'> lr : 7.282483350946415e-05-> 7.282483350946415e-05 - loss = 0.042190339881926775
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:19,431 INFO epoch # 948 - for optimizer <class 'torch.optim.adam.Adam'> lr : 7.282483350946415e-05-> 7.282483350946415e-05 - loss = 0.01784121128730476
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:19,553 INFO epoch # 949 - for optimizer <class 'torch.optim.adam.Adam'> lr : 7.282483350946415e-05-> 7.282483350946415e-05 - loss = 0.02004822692833841
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:19,675 INFO epoch # 950 - for optimizer <class 'torch.optim.adam.Adam'> lr : 7.282483350946415e-05-> 7.282483350946415e-05 - loss = 0.03256542608141899
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:55:19,675 INFO *** epoch 950, rolling-avg-loss (window=10)= 0.03473086615558714
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:19,802 INFO epoch # 951 - for optimizer <class 'torch.optim.adam.Adam'> lr : 7.282483350946415e-05-> 7.282483350946415e-05 - loss = 0.02546977950260043
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:19,937 INFO epoch # 952 - for optimizer <class 'torch.optim.adam.Adam'> lr : 7.282483350946415e-05-> 7.282483350946415e-05 - loss = 0.02966420422308147
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:20,059 INFO epoch # 953 - for optimizer <class 'torch.optim.adam.Adam'> lr : 7.282483350946415e-05-> 7.282483350946415e-05 - loss = 0.01983003248460591
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:20,180 INFO epoch # 954 - for optimizer <class 'torch.optim.adam.Adam'> lr : 7.282483350946415e-05-> 6.554235015851773e-05 - loss = 0.03613895992748439
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:20,303 INFO epoch # 955 - for optimizer <class 'torch.optim.adam.Adam'> lr : 6.554235015851773e-05-> 6.554235015851773e-05 - loss = 0.0316042467020452
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:20,425 INFO epoch # 956 - for optimizer <class 'torch.optim.adam.Adam'> lr : 6.554235015851773e-05-> 6.554235015851773e-05 - loss = 0.024257979821413755
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:20,548 INFO epoch # 957 - for optimizer <class 'torch.optim.adam.Adam'> lr : 6.554235015851773e-05-> 6.554235015851773e-05 - loss = 0.032825051341205835
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:20,670 INFO epoch # 958 - for optimizer <class 'torch.optim.adam.Adam'> lr : 6.554235015851773e-05-> 6.554235015851773e-05 - loss = 0.03237617947161198
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:20,797 INFO epoch # 959 - for optimizer <class 'torch.optim.adam.Adam'> lr : 6.554235015851773e-05-> 6.554235015851773e-05 - loss = 0.024452148471027613
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:20,945 INFO epoch # 960 - for optimizer <class 'torch.optim.adam.Adam'> lr : 6.554235015851773e-05-> 6.554235015851773e-05 - loss = 0.054137111408635974
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:55:20,945 INFO *** epoch 960, rolling-avg-loss (window=10)= 0.031075569335371256
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:21,081 INFO epoch # 961 - for optimizer <class 'torch.optim.adam.Adam'> lr : 6.554235015851773e-05-> 6.554235015851773e-05 - loss = 0.05197002599015832
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:21,212 INFO epoch # 962 - for optimizer <class 'torch.optim.adam.Adam'> lr : 6.554235015851773e-05-> 6.554235015851773e-05 - loss = 0.05075729568488896
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:21,335 INFO epoch # 963 - for optimizer <class 'torch.optim.adam.Adam'> lr : 6.554235015851773e-05-> 6.554235015851773e-05 - loss = 0.021204680670052767
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:21,458 INFO epoch # 964 - for optimizer <class 'torch.optim.adam.Adam'> lr : 6.554235015851773e-05-> 6.554235015851773e-05 - loss = 0.05264888261444867
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:21,580 INFO epoch # 965 - for optimizer <class 'torch.optim.adam.Adam'> lr : 6.554235015851773e-05-> 5.898811514266596e-05 - loss = 0.04078141716308892
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:21,703 INFO epoch # 966 - for optimizer <class 'torch.optim.adam.Adam'> lr : 5.898811514266596e-05-> 5.898811514266596e-05 - loss = 0.07052566693164408
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:21,825 INFO epoch # 967 - for optimizer <class 'torch.optim.adam.Adam'> lr : 5.898811514266596e-05-> 5.898811514266596e-05 - loss = 0.0386503292247653
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:21,947 INFO epoch # 968 - for optimizer <class 'torch.optim.adam.Adam'> lr : 5.898811514266596e-05-> 5.898811514266596e-05 - loss = 0.015729082049801946
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:22,069 INFO epoch # 969 - for optimizer <class 'torch.optim.adam.Adam'> lr : 5.898811514266596e-05-> 5.898811514266596e-05 - loss = 0.01645763940177858
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:22,191 INFO epoch # 970 - for optimizer <class 'torch.optim.adam.Adam'> lr : 5.898811514266596e-05-> 5.898811514266596e-05 - loss = 0.04130038246512413
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:55:22,191 INFO *** epoch 970, rolling-avg-loss (window=10)= 0.04000254021957517
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:22,315 INFO epoch # 971 - for optimizer <class 'torch.optim.adam.Adam'> lr : 5.898811514266596e-05-> 5.898811514266596e-05 - loss = 0.023769403574988246
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:22,439 INFO epoch # 972 - for optimizer <class 'torch.optim.adam.Adam'> lr : 5.898811514266596e-05-> 5.898811514266596e-05 - loss = 0.024591451976448298
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:22,563 INFO epoch # 973 - for optimizer <class 'torch.optim.adam.Adam'> lr : 5.898811514266596e-05-> 5.898811514266596e-05 - loss = 0.018545647617429495
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:22,690 INFO epoch # 974 - for optimizer <class 'torch.optim.adam.Adam'> lr : 5.898811514266596e-05-> 5.898811514266596e-05 - loss = 0.029858459485694766
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:22,819 INFO epoch # 975 - for optimizer <class 'torch.optim.adam.Adam'> lr : 5.898811514266596e-05-> 5.898811514266596e-05 - loss = 0.021921697538346052
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:22,959 INFO epoch # 976 - for optimizer <class 'torch.optim.adam.Adam'> lr : 5.898811514266596e-05-> 5.3089303628399366e-05 - loss = 0.05341267865151167
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:23,087 INFO epoch # 977 - for optimizer <class 'torch.optim.adam.Adam'> lr : 5.3089303628399366e-05-> 5.3089303628399366e-05 - loss = 0.022972052451223135
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:23,212 INFO epoch # 978 - for optimizer <class 'torch.optim.adam.Adam'> lr : 5.3089303628399366e-05-> 5.3089303628399366e-05 - loss = 0.05468140193261206
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:23,335 INFO epoch # 979 - for optimizer <class 'torch.optim.adam.Adam'> lr : 5.3089303628399366e-05-> 5.3089303628399366e-05 - loss = 0.04634263180196285
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:23,456 INFO epoch # 980 - for optimizer <class 'torch.optim.adam.Adam'> lr : 5.3089303628399366e-05-> 5.3089303628399366e-05 - loss = 0.03497817902825773
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:55:23,456 INFO *** epoch 980, rolling-avg-loss (window=10)= 0.03310736040584743
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:23,582 INFO epoch # 981 - for optimizer <class 'torch.optim.adam.Adam'> lr : 5.3089303628399366e-05-> 5.3089303628399366e-05 - loss = 0.013428935839328915
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:23,722 INFO epoch # 982 - for optimizer <class 'torch.optim.adam.Adam'> lr : 5.3089303628399366e-05-> 5.3089303628399366e-05 - loss = 0.017216258798725903
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:23,845 INFO epoch # 983 - for optimizer <class 'torch.optim.adam.Adam'> lr : 5.3089303628399366e-05-> 5.3089303628399366e-05 - loss = 0.03530379896983504
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:23,983 INFO epoch # 984 - for optimizer <class 'torch.optim.adam.Adam'> lr : 5.3089303628399366e-05-> 5.3089303628399366e-05 - loss = 0.029019213747233152
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:24,119 INFO epoch # 985 - for optimizer <class 'torch.optim.adam.Adam'> lr : 5.3089303628399366e-05-> 5.3089303628399366e-05 - loss = 0.048765672370791435
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:24,241 INFO epoch # 986 - for optimizer <class 'torch.optim.adam.Adam'> lr : 5.3089303628399366e-05-> 5.3089303628399366e-05 - loss = 0.0373007208108902
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:24,364 INFO epoch # 987 - for optimizer <class 'torch.optim.adam.Adam'> lr : 5.3089303628399366e-05-> 4.778037326555943e-05 - loss = 0.05495328223332763
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:24,486 INFO epoch # 988 - for optimizer <class 'torch.optim.adam.Adam'> lr : 4.778037326555943e-05-> 4.778037326555943e-05 - loss = 0.013892210787162185
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:24,608 INFO epoch # 989 - for optimizer <class 'torch.optim.adam.Adam'> lr : 4.778037326555943e-05-> 4.778037326555943e-05 - loss = 0.0287809947039932
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:24,731 INFO epoch # 990 - for optimizer <class 'torch.optim.adam.Adam'> lr : 4.778037326555943e-05-> 4.778037326555943e-05 - loss = 0.05825472599826753
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:55:24,731 INFO *** epoch 990, rolling-avg-loss (window=10)= 0.03369158142595552
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:24,857 INFO epoch # 991 - for optimizer <class 'torch.optim.adam.Adam'> lr : 4.778037326555943e-05-> 4.778037326555943e-05 - loss = 0.10540125612169504
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:25,001 INFO epoch # 992 - for optimizer <class 'torch.optim.adam.Adam'> lr : 4.778037326555943e-05-> 4.778037326555943e-05 - loss = 0.07068483857437968
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:25,127 INFO epoch # 993 - for optimizer <class 'torch.optim.adam.Adam'> lr : 4.778037326555943e-05-> 4.778037326555943e-05 - loss = 0.04097406892105937
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:25,251 INFO epoch # 994 - for optimizer <class 'torch.optim.adam.Adam'> lr : 4.778037326555943e-05-> 4.778037326555943e-05 - loss = 0.03805238287895918
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:25,376 INFO epoch # 995 - for optimizer <class 'torch.optim.adam.Adam'> lr : 4.778037326555943e-05-> 4.778037326555943e-05 - loss = 0.07235011085867882
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:25,498 INFO epoch # 996 - for optimizer <class 'torch.optim.adam.Adam'> lr : 4.778037326555943e-05-> 4.778037326555943e-05 - loss = 0.025203031487762928
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:25,620 INFO epoch # 997 - for optimizer <class 'torch.optim.adam.Adam'> lr : 4.778037326555943e-05-> 4.778037326555943e-05 - loss = 0.015773978549987078
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:25,752 INFO epoch # 998 - for optimizer <class 'torch.optim.adam.Adam'> lr : 4.778037326555943e-05-> 4.300233593900349e-05 - loss = 0.016241638688370585
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:25,879 INFO epoch # 999 - for optimizer <class 'torch.optim.adam.Adam'> lr : 4.300233593900349e-05-> 4.300233593900349e-05 - loss = 0.01711255731061101
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:55:26,002 INFO epoch # 1000 - for optimizer <class 'torch.optim.adam.Adam'> lr : 4.300233593900349e-05-> 4.300233593900349e-05 - loss = 0.015190457925200462
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:55:26,002 INFO *** epoch 1000, rolling-avg-loss (window=10)= 0.04169843213167042
[experiments_sandbox.py:572 -   <module>()] 2023-04-22 02:55:26,002 INFO training time in seconds = 131
[experiments_sandbox.py:576 -   <module>()] 2023-04-22 02:55:26,002 INFO epochs-loss curve df :
[experiments_sandbox.py:577 -   <module>()] 2023-04-22 02:55:26,007 INFO 
    epochs  rolling-avg-loss
0       10          8.430317
1       20          0.284371
2       30          0.101122
3       40          0.092651
4       50          0.096845
5       60          0.105314
6       70          0.153349
7       80          0.192713
8       90          0.106684
9      100          0.104541
10     110          0.100157
11     120          0.078474
12     130          0.077750
13     140          0.175435
14     150          0.082755
15     160          0.098045
16     170          0.057517
17     180          0.079571
18     190          0.091512
19     200          0.098320
20     210          0.098986
21     220          0.061951
22     230          0.052271
23     240          0.065057
24     250          0.059046
25     260          0.079016
26     270          0.036631
27     280          0.047975
28     290          0.068004
29     300          0.079564
30     310          0.049307
31     320          0.035965
32     330          0.035587
33     340          0.059034
34     350          0.038829
35     360          0.050121
36     370          0.061129
37     380          0.065433
38     390          0.032721
39     400          0.030364
40     410          0.044565
41     420          0.046419
42     430          0.039871
43     440          0.034528
44     450          0.030203
45     460          0.029909
46     470          0.042591
47     480          0.046189
48     490          0.048645
49     500          0.051020
50     510          0.035586
51     520          0.037682
52     530          0.028234
53     540          0.025257
54     550          0.035205
55     560          0.043863
56     570          0.028880
57     580          0.050492
58     590          0.033597
59     600          0.030787
60     610          0.037053
61     620          0.035544
62     630          0.034370
63     640          0.034676
64     650          0.042191
65     660          0.044810
66     670          0.026839
67     680          0.029301
68     690          0.039174
69     700          0.031261
70     710          0.043461
71     720          0.031392
72     730          0.045284
73     740          0.043775
74     750          0.028255
75     760          0.031543
76     770          0.031290
77     780          0.039979
78     790          0.030608
79     800          0.034809
80     810          0.029800
81     820          0.037141
82     830          0.039703
83     840          0.043718
84     850          0.033769
85     860          0.035023
86     870          0.033497
87     880          0.031173
88     890          0.042405
89     900          0.034232
90     910          0.033141
91     920          0.036208
92     930          0.027815
93     940          0.043812
94     950          0.034731
95     960          0.031076
96     970          0.040003
97     980          0.033107
98     990          0.033692
99    1000          0.041698
