train:
  log-level: "debug"
  seed: 42
  N: 1024
  loss: "mse" # FIXME add implementation to code
  device: "cpu"
  epochs: 10000
  batch_size: 64
  lr: 0.1
  dataset: "boston-housing"
  ratio: 0.8
  shuffle: True
  regularization:
    method: "lp"
    p: 2
  dtype: "torch.float32"
  epochs_block: 10
  models_dir : "/home/mbaddar/phd/augmented-neural-odes/phd_experiments/hybrid_node_tt/ode_func_models"

init:
  method: "uniform"
  uniform:
    low: -0.5
    high: 0.5
  normal:
    mean: 0.0
    std: 0.1

container:
  latent-dim: 13 # 13 for boston, 2 for toy-relu, 2 for toy-ode


projection:
  learnable: False
  activation: "identity"

output:
  activation: "identity"
  learnable: False
  full: 0.1 # if learnable is false, this is the synthetic value used to
  #  fill the weight matrix for linear-module part

ode:
  solver:
    t-span: [ 0,1.0 ]
    method: "rk45"
    euler:
      step-size: 0.1
    rk45:
      rtol: 0.001
  #--
  model: "nn"
  tt:
    activation: "sigmoid"
    rank: "3" # string , if numeric then fixed else the string = "adaptive"
    basis:
      model: "poly"
      poly:
        deg: 4
      rbf:
        window: 1.0
  nn:
    hidden-dim: 100
    tt_emulation: True # if True, use nn-trajectory to train A_TT.phi([z,t]) model
    loss_threshold: 0.01 # loss-threshold for nn-ode-func model to start tt-emulation call
