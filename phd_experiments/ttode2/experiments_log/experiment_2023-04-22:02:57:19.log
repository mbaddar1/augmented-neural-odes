[experiments_sandbox.py:440 -   <module>()] 2023-04-22 02:57:19,093 INFO SEED = 42
[experiments_sandbox.py:492 -   <module>()] 2023-04-22 02:57:19,094 INFO model = 
***
RBF
in_dim=4
n_centres=20
out_dim=1
basis_fn=gaussian
numel_learnable=121
***

[experiments_sandbox.py:493 -   <module>()] 2023-04-22 02:57:19,094 INFO optimizer  = Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: False
    lr: 0.3
    maximize: False
    weight_decay: 0
)
[experiments_sandbox.py:500 -   <module>()] 2023-04-22 02:57:19,094 INFO lr_scheduler = <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7f60fcf6cdf0>
[experiments_sandbox.py:509 -   <module>()] 2023-04-22 02:57:19,095 INFO data = <__main__.ToyData1 object at 0x7f60fcf6cd90>
[experiments_sandbox.py:510 -   <module>()] 2023-04-22 02:57:19,095 INFO epochs = 1000
[experiments_sandbox.py:514 -   <module>()] 2023-04-22 02:57:19,095 INFO epochs_losses_window = 10
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:20,811 INFO epoch # 0 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.3-> 0.3 - loss = 0.29688140377402306
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:20,961 INFO epoch # 1 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.3-> 0.3 - loss = 0.09997049905359745
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:21,112 INFO epoch # 2 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.3-> 0.3 - loss = 0.12490729615092278
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:21,263 INFO epoch # 3 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.3-> 0.3 - loss = 0.13865600898861885
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:21,415 INFO epoch # 4 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.3-> 0.3 - loss = 0.13308453559875488
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:21,565 INFO epoch # 5 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.3-> 0.3 - loss = 0.10507490113377571
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:21,716 INFO epoch # 6 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.3-> 0.3 - loss = 0.13500124961137772
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:21,867 INFO epoch # 7 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.3-> 0.3 - loss = 0.14746946841478348
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:22,017 INFO epoch # 8 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.3-> 0.3 - loss = 0.13561446964740753
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:22,169 INFO epoch # 9 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.3-> 0.3 - loss = 0.09221801115199924
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:22,319 INFO epoch # 10 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.3-> 0.3 - loss = 0.08568310551345348
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:57:22,319 INFO *** epoch 10, rolling-avg-loss (window=10)= 0.11976795452646911
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:22,470 INFO epoch # 11 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.3-> 0.3 - loss = 0.08897748216986656
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:22,621 INFO epoch # 12 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.3-> 0.3 - loss = 0.07481455011293292
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:22,770 INFO epoch # 13 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.3-> 0.3 - loss = 0.056574656162410975
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:22,922 INFO epoch # 14 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.3-> 0.3 - loss = 0.10282694874331355
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:23,074 INFO epoch # 15 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.3-> 0.3 - loss = 0.12378038465976715
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:23,225 INFO epoch # 16 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.3-> 0.3 - loss = 0.08987513557076454
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:23,376 INFO epoch # 17 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.3-> 0.3 - loss = 0.053235932253301144
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:23,528 INFO epoch # 18 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.3-> 0.3 - loss = 0.072055758908391
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:23,679 INFO epoch # 19 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.3-> 0.3 - loss = 0.057126957923173904
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:23,830 INFO epoch # 20 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.3-> 0.3 - loss = 0.12167741265147924
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:57:23,830 INFO *** epoch 20, rolling-avg-loss (window=10)= 0.0840945219155401
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:23,982 INFO epoch # 21 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.3-> 0.3 - loss = 0.11875724699348211
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:24,134 INFO epoch # 22 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.3-> 0.3 - loss = 0.11522393673658371
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:24,284 INFO epoch # 23 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.3-> 0.3 - loss = 0.18453122675418854
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:24,436 INFO epoch # 24 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.3-> 0.3 - loss = 0.11376452073454857
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:24,587 INFO epoch # 25 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.3-> 0.3 - loss = 0.10665214248001575
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:24,738 INFO epoch # 26 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.3-> 0.3 - loss = 0.07138379383832216
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:24,890 INFO epoch # 27 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.3-> 0.3 - loss = 0.07029454968869686
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:25,042 INFO epoch # 28 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.3-> 0.27 - loss = 0.10418262518942356
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:25,194 INFO epoch # 29 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.27-> 0.27 - loss = 0.05768717732280493
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:25,344 INFO epoch # 30 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.27-> 0.27 - loss = 0.09103687666356564
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:57:25,344 INFO *** epoch 30, rolling-avg-loss (window=10)= 0.10335140964016318
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:25,494 INFO epoch # 31 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.27-> 0.27 - loss = 0.07118240324780345
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:25,644 INFO epoch # 32 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.27-> 0.27 - loss = 0.07088083773851395
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:25,794 INFO epoch # 33 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.27-> 0.27 - loss = 0.08294903486967087
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:25,947 INFO epoch # 34 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.27-> 0.27 - loss = 0.061331829987466335
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:26,101 INFO epoch # 35 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.27-> 0.27 - loss = 0.052805634681135416
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:26,252 INFO epoch # 36 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.27-> 0.27 - loss = 0.04562391107901931
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:26,404 INFO epoch # 37 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.27-> 0.27 - loss = 0.0735096768476069
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:26,554 INFO epoch # 38 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.27-> 0.27 - loss = 0.15866965195164084
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:26,705 INFO epoch # 39 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.27-> 0.27 - loss = 0.07922405004501343
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:26,857 INFO epoch # 40 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.27-> 0.27 - loss = 0.058542714454233646
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:57:26,857 INFO *** epoch 40, rolling-avg-loss (window=10)= 0.07547197449021041
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:27,008 INFO epoch # 41 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.27-> 0.27 - loss = 0.09095225390046835
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:27,162 INFO epoch # 42 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.27-> 0.27 - loss = 0.07582743745297194
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:27,313 INFO epoch # 43 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.27-> 0.27 - loss = 0.05582660110667348
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:27,463 INFO epoch # 44 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.27-> 0.27 - loss = 0.06375905871391296
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:27,614 INFO epoch # 45 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.27-> 0.27 - loss = 0.05839355383068323
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:27,765 INFO epoch # 46 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.27-> 0.27 - loss = 0.04928902513347566
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:27,916 INFO epoch # 47 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.27-> 0.24300000000000002 - loss = 0.047209690790623426
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:28,069 INFO epoch # 48 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.24300000000000002-> 0.24300000000000002 - loss = 0.10224531404674053
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:28,220 INFO epoch # 49 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.24300000000000002-> 0.24300000000000002 - loss = 0.05692638177424669
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:28,372 INFO epoch # 50 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.24300000000000002-> 0.24300000000000002 - loss = 0.04140454903244972
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:57:28,372 INFO *** epoch 50, rolling-avg-loss (window=10)= 0.0641833865782246
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:28,524 INFO epoch # 51 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.24300000000000002-> 0.24300000000000002 - loss = 0.0694666737690568
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:28,676 INFO epoch # 52 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.24300000000000002-> 0.24300000000000002 - loss = 0.11388015933334827
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:28,827 INFO epoch # 53 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.24300000000000002-> 0.24300000000000002 - loss = 0.05132294166833162
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:28,978 INFO epoch # 54 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.24300000000000002-> 0.24300000000000002 - loss = 0.08555247075855732
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:29,133 INFO epoch # 55 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.24300000000000002-> 0.24300000000000002 - loss = 0.12401666305959225
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:29,284 INFO epoch # 56 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.24300000000000002-> 0.24300000000000002 - loss = 0.1562255471944809
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:29,436 INFO epoch # 57 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.24300000000000002-> 0.24300000000000002 - loss = 0.11014106683433056
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:29,586 INFO epoch # 58 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.24300000000000002-> 0.24300000000000002 - loss = 0.18432283774018288
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:29,737 INFO epoch # 59 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.24300000000000002-> 0.24300000000000002 - loss = 0.10688977036625147
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:29,908 INFO epoch # 60 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.24300000000000002-> 0.24300000000000002 - loss = 0.11684726574458182
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:57:29,908 INFO *** epoch 60, rolling-avg-loss (window=10)= 0.11186653964687139
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:30,068 INFO epoch # 61 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.24300000000000002-> 0.21870000000000003 - loss = 0.10931829456239939
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:30,225 INFO epoch # 62 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.21870000000000003-> 0.21870000000000003 - loss = 0.13478185795247555
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:30,376 INFO epoch # 63 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.21870000000000003-> 0.21870000000000003 - loss = 0.12207486666738987
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:30,528 INFO epoch # 64 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.21870000000000003-> 0.21870000000000003 - loss = 0.12603950314223766
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:30,679 INFO epoch # 65 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.21870000000000003-> 0.21870000000000003 - loss = 0.18534366972744465
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:30,830 INFO epoch # 66 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.21870000000000003-> 0.21870000000000003 - loss = 0.14417591597884893
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:30,982 INFO epoch # 67 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.21870000000000003-> 0.21870000000000003 - loss = 0.1166233392432332
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:31,133 INFO epoch # 68 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.21870000000000003-> 0.21870000000000003 - loss = 0.07215121388435364
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:31,284 INFO epoch # 69 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.21870000000000003-> 0.21870000000000003 - loss = 0.13215693272650242
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:31,436 INFO epoch # 70 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.21870000000000003-> 0.21870000000000003 - loss = 0.07611328735947609
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:57:31,436 INFO *** epoch 70, rolling-avg-loss (window=10)= 0.12187788812443615
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:31,587 INFO epoch # 71 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.21870000000000003-> 0.21870000000000003 - loss = 0.1017121896147728
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:31,740 INFO epoch # 72 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.21870000000000003-> 0.19683000000000003 - loss = 0.08920701593160629
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:31,892 INFO epoch # 73 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.19683000000000003-> 0.19683000000000003 - loss = 0.10700350254774094
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:32,043 INFO epoch # 74 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.19683000000000003-> 0.19683000000000003 - loss = 0.06515373475849628
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:32,194 INFO epoch # 75 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.19683000000000003-> 0.19683000000000003 - loss = 0.1228530379012227
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:32,346 INFO epoch # 76 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.19683000000000003-> 0.19683000000000003 - loss = 0.059733584988862276
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:32,497 INFO epoch # 77 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.19683000000000003-> 0.19683000000000003 - loss = 0.06137766130268574
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:32,647 INFO epoch # 78 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.19683000000000003-> 0.19683000000000003 - loss = 0.05993496626615524
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:32,799 INFO epoch # 79 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.19683000000000003-> 0.19683000000000003 - loss = 0.04201074317097664
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:32,950 INFO epoch # 80 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.19683000000000003-> 0.19683000000000003 - loss = 0.05209479480981827
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:57:32,950 INFO *** epoch 80, rolling-avg-loss (window=10)= 0.07610812312923372
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:33,101 INFO epoch # 81 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.19683000000000003-> 0.19683000000000003 - loss = 0.05920911766588688
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:33,253 INFO epoch # 82 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.19683000000000003-> 0.19683000000000003 - loss = 0.04721988970413804
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:33,404 INFO epoch # 83 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.19683000000000003-> 0.17714700000000003 - loss = 0.05206779995933175
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:33,555 INFO epoch # 84 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.17714700000000003-> 0.17714700000000003 - loss = 0.05180402286350727
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:33,707 INFO epoch # 85 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.17714700000000003-> 0.17714700000000003 - loss = 0.08167594484984875
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:33,859 INFO epoch # 86 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.17714700000000003-> 0.17714700000000003 - loss = 0.06407902669161558
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:34,016 INFO epoch # 87 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.17714700000000003-> 0.17714700000000003 - loss = 0.06110819149762392
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:34,167 INFO epoch # 88 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.17714700000000003-> 0.17714700000000003 - loss = 0.036936196498572826
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:34,319 INFO epoch # 89 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.17714700000000003-> 0.17714700000000003 - loss = 0.052580032497644424
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:34,472 INFO epoch # 90 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.17714700000000003-> 0.17714700000000003 - loss = 0.055367049761116505
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:57:34,472 INFO *** epoch 90, rolling-avg-loss (window=10)= 0.05620472719892859
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:34,622 INFO epoch # 91 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.17714700000000003-> 0.17714700000000003 - loss = 0.04633048642426729
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:34,773 INFO epoch # 92 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.17714700000000003-> 0.17714700000000003 - loss = 0.17234987020492554
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:34,924 INFO epoch # 93 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.17714700000000003-> 0.17714700000000003 - loss = 0.27142631635069847
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:35,073 INFO epoch # 94 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.17714700000000003-> 0.17714700000000003 - loss = 0.11308355070650578
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:35,229 INFO epoch # 95 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.17714700000000003-> 0.17714700000000003 - loss = 0.14735770039260387
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:35,382 INFO epoch # 96 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.17714700000000003-> 0.17714700000000003 - loss = 0.08790790848433971
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:35,539 INFO epoch # 97 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.17714700000000003-> 0.17714700000000003 - loss = 0.10390136670321226
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:35,691 INFO epoch # 98 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.17714700000000003-> 0.17714700000000003 - loss = 0.08269504923373461
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:35,842 INFO epoch # 99 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.17714700000000003-> 0.15943230000000003 - loss = 0.08347851783037186
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:36,007 INFO epoch # 100 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.15943230000000003-> 0.15943230000000003 - loss = 0.057575189508497715
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:57:36,007 INFO *** epoch 100, rolling-avg-loss (window=10)= 0.1166105955839157
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:36,174 INFO epoch # 101 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.15943230000000003-> 0.15943230000000003 - loss = 0.061259565874934196
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:36,327 INFO epoch # 102 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.15943230000000003-> 0.15943230000000003 - loss = 0.04469599900767207
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:36,482 INFO epoch # 103 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.15943230000000003-> 0.15943230000000003 - loss = 0.04468175210058689
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:36,632 INFO epoch # 104 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.15943230000000003-> 0.15943230000000003 - loss = 0.11085019912570715
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:36,784 INFO epoch # 105 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.15943230000000003-> 0.15943230000000003 - loss = 0.0712185325101018
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:36,937 INFO epoch # 106 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.15943230000000003-> 0.15943230000000003 - loss = 0.03999212570488453
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:37,088 INFO epoch # 107 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.15943230000000003-> 0.15943230000000003 - loss = 0.09003685880452394
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:37,240 INFO epoch # 108 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.15943230000000003-> 0.15943230000000003 - loss = 0.12983842846006155
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:37,393 INFO epoch # 109 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.15943230000000003-> 0.15943230000000003 - loss = 0.07045277394354343
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:37,543 INFO epoch # 110 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.15943230000000003-> 0.14348907000000002 - loss = 0.06115455739200115
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:57:37,543 INFO *** epoch 110, rolling-avg-loss (window=10)= 0.07241807929240167
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:37,693 INFO epoch # 111 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.14348907000000002-> 0.14348907000000002 - loss = 0.11239273939281702
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:37,845 INFO epoch # 112 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.14348907000000002-> 0.14348907000000002 - loss = 0.059146796353161335
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:37,997 INFO epoch # 113 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.14348907000000002-> 0.14348907000000002 - loss = 0.05009154649451375
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:38,149 INFO epoch # 114 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.14348907000000002-> 0.14348907000000002 - loss = 0.07420322485268116
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:38,301 INFO epoch # 115 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.14348907000000002-> 0.14348907000000002 - loss = 0.04931785073131323
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:38,452 INFO epoch # 116 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.14348907000000002-> 0.14348907000000002 - loss = 0.039654361084103584
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:38,602 INFO epoch # 117 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.14348907000000002-> 0.14348907000000002 - loss = 0.049366048304364085
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:38,753 INFO epoch # 118 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.14348907000000002-> 0.14348907000000002 - loss = 0.04315496329218149
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:38,908 INFO epoch # 119 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.14348907000000002-> 0.14348907000000002 - loss = 0.04452848061919212
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:39,060 INFO epoch # 120 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.14348907000000002-> 0.14348907000000002 - loss = 0.04829535214230418
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:57:39,060 INFO *** epoch 120, rolling-avg-loss (window=10)= 0.0570151363266632
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:39,213 INFO epoch # 121 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.14348907000000002-> 0.12914016300000003 - loss = 0.05922034848481417
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:39,369 INFO epoch # 122 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.12914016300000003-> 0.12914016300000003 - loss = 0.049874003045260906
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:39,520 INFO epoch # 123 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.12914016300000003-> 0.12914016300000003 - loss = 0.042853718623518944
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:39,672 INFO epoch # 124 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.12914016300000003-> 0.12914016300000003 - loss = 0.039317162707448006
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:39,834 INFO epoch # 125 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.12914016300000003-> 0.12914016300000003 - loss = 0.05370859615504742
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:39,995 INFO epoch # 126 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.12914016300000003-> 0.12914016300000003 - loss = 0.052751701325178146
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:40,154 INFO epoch # 127 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.12914016300000003-> 0.12914016300000003 - loss = 0.06110994890332222
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:40,319 INFO epoch # 128 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.12914016300000003-> 0.12914016300000003 - loss = 0.06112330220639706
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:40,474 INFO epoch # 129 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.12914016300000003-> 0.12914016300000003 - loss = 0.08564860094338655
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:40,627 INFO epoch # 130 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.12914016300000003-> 0.12914016300000003 - loss = 0.09951150231063366
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:57:40,627 INFO *** epoch 130, rolling-avg-loss (window=10)= 0.06051188847050071
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:40,777 INFO epoch # 131 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.12914016300000003-> 0.12914016300000003 - loss = 0.14161004219204187
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:40,929 INFO epoch # 132 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.12914016300000003-> 0.11622614670000003 - loss = 0.06557574309408665
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:41,080 INFO epoch # 133 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.11622614670000003-> 0.11622614670000003 - loss = 0.06973098963499069
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:41,234 INFO epoch # 134 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.11622614670000003-> 0.11622614670000003 - loss = 0.050279539078474045
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:41,386 INFO epoch # 135 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.11622614670000003-> 0.11622614670000003 - loss = 0.07249009516090155
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:41,539 INFO epoch # 136 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.11622614670000003-> 0.11622614670000003 - loss = 0.0495436554774642
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:41,692 INFO epoch # 137 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.11622614670000003-> 0.11622614670000003 - loss = 0.10172017477452755
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:41,845 INFO epoch # 138 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.11622614670000003-> 0.11622614670000003 - loss = 0.1462875548750162
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:41,998 INFO epoch # 139 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.11622614670000003-> 0.11622614670000003 - loss = 0.13951547257602215
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:42,162 INFO epoch # 140 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.11622614670000003-> 0.11622614670000003 - loss = 0.06698352750390768
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:57:42,162 INFO *** epoch 140, rolling-avg-loss (window=10)= 0.09037367943674326
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:42,324 INFO epoch # 141 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.11622614670000003-> 0.11622614670000003 - loss = 0.07319292332977057
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:42,480 INFO epoch # 142 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.11622614670000003-> 0.11622614670000003 - loss = 0.08105213288217783
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:42,637 INFO epoch # 143 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.11622614670000003-> 0.10460353203000003 - loss = 0.06482029799371958
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:42,822 INFO epoch # 144 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.10460353203000003-> 0.10460353203000003 - loss = 0.05699393060058355
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:42,974 INFO epoch # 145 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.10460353203000003-> 0.10460353203000003 - loss = 0.06993003003299236
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:43,127 INFO epoch # 146 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.10460353203000003-> 0.10460353203000003 - loss = 0.09131910372525454
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:43,283 INFO epoch # 147 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.10460353203000003-> 0.10460353203000003 - loss = 0.058585233287885785
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:43,436 INFO epoch # 148 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.10460353203000003-> 0.10460353203000003 - loss = 0.06850823201239109
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:43,588 INFO epoch # 149 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.10460353203000003-> 0.10460353203000003 - loss = 0.08788532670587301
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:43,745 INFO epoch # 150 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.10460353203000003-> 0.10460353203000003 - loss = 0.120618786662817
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:57:43,746 INFO *** epoch 150, rolling-avg-loss (window=10)= 0.07729059972334654
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:43,901 INFO epoch # 151 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.10460353203000003-> 0.10460353203000003 - loss = 0.04609890282154083
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:44,058 INFO epoch # 152 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.10460353203000003-> 0.10460353203000003 - loss = 0.1134680425748229
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:44,219 INFO epoch # 153 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.10460353203000003-> 0.10460353203000003 - loss = 0.08005352690815926
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:44,390 INFO epoch # 154 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.10460353203000003-> 0.09414317882700003 - loss = 0.1049242690205574
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:44,554 INFO epoch # 155 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.09414317882700003-> 0.09414317882700003 - loss = 0.08501513488590717
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:44,731 INFO epoch # 156 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.09414317882700003-> 0.09414317882700003 - loss = 0.07086189556866884
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:44,893 INFO epoch # 157 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.09414317882700003-> 0.09414317882700003 - loss = 0.06301880534738302
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:45,069 INFO epoch # 158 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.09414317882700003-> 0.09414317882700003 - loss = 0.04746473266277462
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:45,224 INFO epoch # 159 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.09414317882700003-> 0.09414317882700003 - loss = 0.06276555359363556
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:45,381 INFO epoch # 160 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.09414317882700003-> 0.09414317882700003 - loss = 0.059628913179039955
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:57:45,381 INFO *** epoch 160, rolling-avg-loss (window=10)= 0.07332997765624896
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:45,535 INFO epoch # 161 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.09414317882700003-> 0.09414317882700003 - loss = 0.06689425930380821
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:45,688 INFO epoch # 162 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.09414317882700003-> 0.09414317882700003 - loss = 0.037022287491708994
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:45,839 INFO epoch # 163 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.09414317882700003-> 0.09414317882700003 - loss = 0.08752021007239819
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:45,991 INFO epoch # 164 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.09414317882700003-> 0.09414317882700003 - loss = 0.08048131875693798
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:46,146 INFO epoch # 165 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.09414317882700003-> 0.08472886094430003 - loss = 0.055131024681031704
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:46,297 INFO epoch # 166 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.08472886094430003-> 0.08472886094430003 - loss = 0.04847142891958356
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:46,448 INFO epoch # 167 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.08472886094430003-> 0.08472886094430003 - loss = 0.044885427225381136
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:46,598 INFO epoch # 168 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.08472886094430003-> 0.08472886094430003 - loss = 0.04864728730171919
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:46,749 INFO epoch # 169 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.08472886094430003-> 0.08472886094430003 - loss = 0.045248656533658504
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:46,901 INFO epoch # 170 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.08472886094430003-> 0.08472886094430003 - loss = 0.038199362345039845
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:57:46,901 INFO *** epoch 170, rolling-avg-loss (window=10)= 0.05525012626312673
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:47,053 INFO epoch # 171 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.08472886094430003-> 0.08472886094430003 - loss = 0.09751771437004209
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:47,204 INFO epoch # 172 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.08472886094430003-> 0.08472886094430003 - loss = 0.04981119278818369
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:47,357 INFO epoch # 173 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.08472886094430003-> 0.08472886094430003 - loss = 0.03277422348037362
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:47,510 INFO epoch # 174 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.08472886094430003-> 0.08472886094430003 - loss = 0.06103214528411627
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:47,662 INFO epoch # 175 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.08472886094430003-> 0.08472886094430003 - loss = 0.03203909192234278
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:47,816 INFO epoch # 176 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.08472886094430003-> 0.08472886094430003 - loss = 0.030766614130698144
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:47,969 INFO epoch # 177 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.08472886094430003-> 0.08472886094430003 - loss = 0.03656970430165529
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:48,124 INFO epoch # 178 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.08472886094430003-> 0.08472886094430003 - loss = 0.03731753583997488
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:48,279 INFO epoch # 179 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.08472886094430003-> 0.08472886094430003 - loss = 0.06030749063938856
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:48,432 INFO epoch # 180 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.08472886094430003-> 0.08472886094430003 - loss = 0.043381112394854426
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:57:48,432 INFO *** epoch 180, rolling-avg-loss (window=10)= 0.048151682515162976
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:48,583 INFO epoch # 181 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.08472886094430003-> 0.08472886094430003 - loss = 0.03271457692608237
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:48,734 INFO epoch # 182 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.08472886094430003-> 0.08472886094430003 - loss = 0.045222187880426645
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:48,886 INFO epoch # 183 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.08472886094430003-> 0.08472886094430003 - loss = 0.07996526313945651
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:49,037 INFO epoch # 184 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.08472886094430003-> 0.08472886094430003 - loss = 0.03802125062793493
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:49,188 INFO epoch # 185 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.08472886094430003-> 0.08472886094430003 - loss = 0.05597011838108301
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:49,338 INFO epoch # 186 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.08472886094430003-> 0.08472886094430003 - loss = 0.03293564636260271
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:49,488 INFO epoch # 187 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.08472886094430003-> 0.07625597484987003 - loss = 0.038920828606933355
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:49,639 INFO epoch # 188 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.07625597484987003-> 0.07625597484987003 - loss = 0.038572012446820736
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:49,795 INFO epoch # 189 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.07625597484987003-> 0.07625597484987003 - loss = 0.04571797652170062
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:49,956 INFO epoch # 190 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.07625597484987003-> 0.07625597484987003 - loss = 0.03317111358046532
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:57:49,956 INFO *** epoch 190, rolling-avg-loss (window=10)= 0.04412109744735062
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:50,107 INFO epoch # 191 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.07625597484987003-> 0.07625597484987003 - loss = 0.04152391105890274
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:50,259 INFO epoch # 192 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.07625597484987003-> 0.07625597484987003 - loss = 0.04674962256103754
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:50,410 INFO epoch # 193 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.07625597484987003-> 0.07625597484987003 - loss = 0.040731018874794245
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:50,561 INFO epoch # 194 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.07625597484987003-> 0.07625597484987003 - loss = 0.029103313805535436
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:50,712 INFO epoch # 195 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.07625597484987003-> 0.07625597484987003 - loss = 0.034002030501142144
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:50,863 INFO epoch # 196 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.07625597484987003-> 0.07625597484987003 - loss = 0.029641980305314064
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:51,014 INFO epoch # 197 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.07625597484987003-> 0.07625597484987003 - loss = 0.06522853532806039
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:51,165 INFO epoch # 198 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.07625597484987003-> 0.07625597484987003 - loss = 0.06191417668014765
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:51,314 INFO epoch # 199 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.07625597484987003-> 0.07625597484987003 - loss = 0.04136387724429369
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:51,465 INFO epoch # 200 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.07625597484987003-> 0.07625597484987003 - loss = 0.06911719869822264
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:57:51,465 INFO *** epoch 200, rolling-avg-loss (window=10)= 0.045937566505745056
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:51,617 INFO epoch # 201 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.07625597484987003-> 0.07625597484987003 - loss = 0.09222036134451628
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:51,767 INFO epoch # 202 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.07625597484987003-> 0.07625597484987003 - loss = 0.0698642279021442
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:51,918 INFO epoch # 203 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.07625597484987003-> 0.07625597484987003 - loss = 0.05192337930202484
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:52,069 INFO epoch # 204 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.07625597484987003-> 0.07625597484987003 - loss = 0.15038535743951797
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:52,218 INFO epoch # 205 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.07625597484987003-> 0.06863037736488302 - loss = 0.07055410835891962
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:52,369 INFO epoch # 206 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.06863037736488302-> 0.06863037736488302 - loss = 0.06479643750935793
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:52,519 INFO epoch # 207 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.06863037736488302-> 0.06863037736488302 - loss = 0.03828691225498915
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:52,670 INFO epoch # 208 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.06863037736488302-> 0.06863037736488302 - loss = 0.04031662689521909
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:52,820 INFO epoch # 209 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.06863037736488302-> 0.06863037736488302 - loss = 0.0411751177161932
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:52,971 INFO epoch # 210 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.06863037736488302-> 0.06863037736488302 - loss = 0.04975653626024723
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:57:52,971 INFO *** epoch 210, rolling-avg-loss (window=10)= 0.06692790649831296
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:53,121 INFO epoch # 211 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.06863037736488302-> 0.06863037736488302 - loss = 0.04067090153694153
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:53,272 INFO epoch # 212 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.06863037736488302-> 0.06863037736488302 - loss = 0.09927037451416254
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:53,423 INFO epoch # 213 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.06863037736488302-> 0.06863037736488302 - loss = 0.02982138399966061
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:53,573 INFO epoch # 214 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.06863037736488302-> 0.06863037736488302 - loss = 0.051239047199487686
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:53,723 INFO epoch # 215 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.06863037736488302-> 0.06863037736488302 - loss = 0.05281338561326265
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:53,874 INFO epoch # 216 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.06863037736488302-> 0.061767339628394716 - loss = 0.039223081432282925
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:54,024 INFO epoch # 217 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.061767339628394716-> 0.061767339628394716 - loss = 0.04044512566179037
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:54,180 INFO epoch # 218 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.061767339628394716-> 0.061767339628394716 - loss = 0.02669700072146952
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:54,330 INFO epoch # 219 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.061767339628394716-> 0.061767339628394716 - loss = 0.039400009671226144
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:54,483 INFO epoch # 220 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.061767339628394716-> 0.061767339628394716 - loss = 0.058742052875459194
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:57:54,483 INFO *** epoch 220, rolling-avg-loss (window=10)= 0.047832236322574315
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:54,633 INFO epoch # 221 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.061767339628394716-> 0.061767339628394716 - loss = 0.07619042415171862
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:54,784 INFO epoch # 222 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.061767339628394716-> 0.061767339628394716 - loss = 0.06597803207114339
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:54,935 INFO epoch # 223 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.061767339628394716-> 0.061767339628394716 - loss = 0.08511458523571491
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:55,091 INFO epoch # 224 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.061767339628394716-> 0.061767339628394716 - loss = 0.0432609599083662
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:55,241 INFO epoch # 225 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.061767339628394716-> 0.061767339628394716 - loss = 0.04804838728159666
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:55,391 INFO epoch # 226 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.061767339628394716-> 0.061767339628394716 - loss = 0.04629040972213261
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:55,544 INFO epoch # 227 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.061767339628394716-> 0.061767339628394716 - loss = 0.03273933217860758
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:55,693 INFO epoch # 228 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.061767339628394716-> 0.061767339628394716 - loss = 0.035440919920802116
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:55,845 INFO epoch # 229 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.061767339628394716-> 0.055590605665555244 - loss = 0.049418439622968435
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:55,994 INFO epoch # 230 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.055590605665555244-> 0.055590605665555244 - loss = 0.06154665257781744
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:57:55,994 INFO *** epoch 230, rolling-avg-loss (window=10)= 0.0544028142670868
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:56,144 INFO epoch # 231 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.055590605665555244-> 0.055590605665555244 - loss = 0.03436393663287163
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:56,296 INFO epoch # 232 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.055590605665555244-> 0.055590605665555244 - loss = 0.04503737576305866
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:56,447 INFO epoch # 233 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.055590605665555244-> 0.055590605665555244 - loss = 0.055974917486310005
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:56,598 INFO epoch # 234 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.055590605665555244-> 0.055590605665555244 - loss = 0.05954760126769543
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:56,748 INFO epoch # 235 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.055590605665555244-> 0.055590605665555244 - loss = 0.04324272694066167
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:56,897 INFO epoch # 236 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.055590605665555244-> 0.055590605665555244 - loss = 0.061864604242146015
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:57,048 INFO epoch # 237 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.055590605665555244-> 0.055590605665555244 - loss = 0.037232748698443174
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:57,198 INFO epoch # 238 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.055590605665555244-> 0.055590605665555244 - loss = 0.0660325912758708
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:57,349 INFO epoch # 239 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.055590605665555244-> 0.055590605665555244 - loss = 0.03920895792543888
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:57,503 INFO epoch # 240 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.055590605665555244-> 0.05003154509899972 - loss = 0.0655084764584899
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:57:57,503 INFO *** epoch 240, rolling-avg-loss (window=10)= 0.05080139366909862
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:57,655 INFO epoch # 241 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.05003154509899972-> 0.05003154509899972 - loss = 0.03116951882839203
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:57,805 INFO epoch # 242 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.05003154509899972-> 0.05003154509899972 - loss = 0.033428143709897995
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:57,956 INFO epoch # 243 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.05003154509899972-> 0.05003154509899972 - loss = 0.039287394378334284
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:58,106 INFO epoch # 244 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.05003154509899972-> 0.05003154509899972 - loss = 0.03730953414924443
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:58,256 INFO epoch # 245 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.05003154509899972-> 0.05003154509899972 - loss = 0.03352841641753912
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:58,407 INFO epoch # 246 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.05003154509899972-> 0.05003154509899972 - loss = 0.02363509382121265
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:58,558 INFO epoch # 247 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.05003154509899972-> 0.05003154509899972 - loss = 0.02501850971020758
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:58,709 INFO epoch # 248 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.05003154509899972-> 0.05003154509899972 - loss = 0.030646896455436945
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:58,859 INFO epoch # 249 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.05003154509899972-> 0.05003154509899972 - loss = 0.03417259780690074
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:59,010 INFO epoch # 250 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.05003154509899972-> 0.05003154509899972 - loss = 0.031570745166391134
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:57:59,010 INFO *** epoch 250, rolling-avg-loss (window=10)= 0.03197668504435569
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:59,160 INFO epoch # 251 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.05003154509899972-> 0.05003154509899972 - loss = 0.038805588614195585
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:59,310 INFO epoch # 252 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.05003154509899972-> 0.05003154509899972 - loss = 0.04390022298321128
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:59,461 INFO epoch # 253 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.05003154509899972-> 0.05003154509899972 - loss = 0.03757566213607788
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:59,615 INFO epoch # 254 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.05003154509899972-> 0.05003154509899972 - loss = 0.043484343215823174
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:59,775 INFO epoch # 255 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.05003154509899972-> 0.05003154509899972 - loss = 0.05798247526399791
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:57:59,935 INFO epoch # 256 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.05003154509899972-> 0.05003154509899972 - loss = 0.04220834281295538
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:00,087 INFO epoch # 257 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.05003154509899972-> 0.04502839058909975 - loss = 0.0275380602106452
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:00,238 INFO epoch # 258 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.04502839058909975-> 0.04502839058909975 - loss = 0.05201018135994673
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:00,387 INFO epoch # 259 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.04502839058909975-> 0.04502839058909975 - loss = 0.0652684411033988
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:00,537 INFO epoch # 260 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.04502839058909975-> 0.04502839058909975 - loss = 0.03416063520126045
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:58:00,537 INFO *** epoch 260, rolling-avg-loss (window=10)= 0.044293395290151236
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:00,687 INFO epoch # 261 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.04502839058909975-> 0.04502839058909975 - loss = 0.04005048517137766
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:00,837 INFO epoch # 262 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.04502839058909975-> 0.04502839058909975 - loss = 0.05019073933362961
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:00,987 INFO epoch # 263 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.04502839058909975-> 0.04502839058909975 - loss = 0.02992666931822896
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:01,138 INFO epoch # 264 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.04502839058909975-> 0.04502839058909975 - loss = 0.04274146165698767
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:01,288 INFO epoch # 265 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.04502839058909975-> 0.04502839058909975 - loss = 0.04334442317485809
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:01,438 INFO epoch # 266 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.04502839058909975-> 0.04502839058909975 - loss = 0.06395530514419079
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:01,590 INFO epoch # 267 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.04502839058909975-> 0.04502839058909975 - loss = 0.03006142587400973
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:01,740 INFO epoch # 268 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.04502839058909975-> 0.040525551530189774 - loss = 0.063212966080755
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:01,890 INFO epoch # 269 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.040525551530189774-> 0.040525551530189774 - loss = 0.03760435665026307
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:02,040 INFO epoch # 270 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.040525551530189774-> 0.040525551530189774 - loss = 0.040556153282523155
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:58:02,040 INFO *** epoch 270, rolling-avg-loss (window=10)= 0.04416439856868237
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:02,190 INFO epoch # 271 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.040525551530189774-> 0.040525551530189774 - loss = 0.0891178548336029
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:02,345 INFO epoch # 272 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.040525551530189774-> 0.040525551530189774 - loss = 0.04166918992996216
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:02,496 INFO epoch # 273 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.040525551530189774-> 0.040525551530189774 - loss = 0.03141511091962457
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:02,646 INFO epoch # 274 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.040525551530189774-> 0.040525551530189774 - loss = 0.03667348576709628
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:02,796 INFO epoch # 275 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.040525551530189774-> 0.040525551530189774 - loss = 0.03682466130703688
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:02,949 INFO epoch # 276 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.040525551530189774-> 0.040525551530189774 - loss = 0.04889907734468579
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:03,101 INFO epoch # 277 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.040525551530189774-> 0.040525551530189774 - loss = 0.08531242050230503
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:03,252 INFO epoch # 278 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.040525551530189774-> 0.040525551530189774 - loss = 0.030752386897802353
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:03,402 INFO epoch # 279 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.040525551530189774-> 0.036472996377170795 - loss = 0.030485503375530243
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:03,551 INFO epoch # 280 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.036472996377170795-> 0.036472996377170795 - loss = 0.05909298174083233
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:58:03,551 INFO *** epoch 280, rolling-avg-loss (window=10)= 0.04902426726184785
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:03,701 INFO epoch # 281 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.036472996377170795-> 0.036472996377170795 - loss = 0.032404291443526745
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:03,851 INFO epoch # 282 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.036472996377170795-> 0.036472996377170795 - loss = 0.028361182718072087
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:04,001 INFO epoch # 283 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.036472996377170795-> 0.036472996377170795 - loss = 0.06334711471572518
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:04,150 INFO epoch # 284 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.036472996377170795-> 0.036472996377170795 - loss = 0.06156299216672778
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:04,302 INFO epoch # 285 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.036472996377170795-> 0.036472996377170795 - loss = 0.03900489769876003
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:04,452 INFO epoch # 286 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.036472996377170795-> 0.036472996377170795 - loss = 0.03728337585926056
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:04,602 INFO epoch # 287 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.036472996377170795-> 0.036472996377170795 - loss = 0.04788145888596773
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:04,752 INFO epoch # 288 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.036472996377170795-> 0.036472996377170795 - loss = 0.034961432218551636
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:04,902 INFO epoch # 289 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.036472996377170795-> 0.036472996377170795 - loss = 0.08059875667095184
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:05,053 INFO epoch # 290 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.036472996377170795-> 0.032825696739453715 - loss = 0.030639859149232507
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:58:05,053 INFO *** epoch 290, rolling-avg-loss (window=10)= 0.04560453615267761
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:05,204 INFO epoch # 291 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.032825696739453715-> 0.032825696739453715 - loss = 0.03951779566705227
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:05,355 INFO epoch # 292 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.032825696739453715-> 0.032825696739453715 - loss = 0.03915253933519125
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:05,507 INFO epoch # 293 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.032825696739453715-> 0.032825696739453715 - loss = 0.046929062344133854
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:05,663 INFO epoch # 294 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.032825696739453715-> 0.032825696739453715 - loss = 0.03225556202232838
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:05,823 INFO epoch # 295 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.032825696739453715-> 0.032825696739453715 - loss = 0.022009917185641825
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:05,975 INFO epoch # 296 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.032825696739453715-> 0.032825696739453715 - loss = 0.07531178975477815
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:06,128 INFO epoch # 297 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.032825696739453715-> 0.032825696739453715 - loss = 0.040968939661979675
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:06,280 INFO epoch # 298 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.032825696739453715-> 0.032825696739453715 - loss = 0.08633911702781916
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:06,431 INFO epoch # 299 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.032825696739453715-> 0.032825696739453715 - loss = 0.033434093464165926
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:06,582 INFO epoch # 300 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.032825696739453715-> 0.032825696739453715 - loss = 0.03133158478885889
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:58:06,583 INFO *** epoch 300, rolling-avg-loss (window=10)= 0.04472504012519494
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:06,734 INFO epoch # 301 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.032825696739453715-> 0.032825696739453715 - loss = 0.03887179121375084
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:06,884 INFO epoch # 302 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.032825696739453715-> 0.032825696739453715 - loss = 0.06037097983062267
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:07,035 INFO epoch # 303 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.032825696739453715-> 0.032825696739453715 - loss = 0.0619055712595582
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:07,185 INFO epoch # 304 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.032825696739453715-> 0.032825696739453715 - loss = 0.04377479199320078
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:07,336 INFO epoch # 305 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.032825696739453715-> 0.032825696739453715 - loss = 0.09468229301273823
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:07,487 INFO epoch # 306 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.032825696739453715-> 0.029543127065508344 - loss = 0.047857122495770454
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:07,637 INFO epoch # 307 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.029543127065508344-> 0.029543127065508344 - loss = 0.06038072519004345
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:07,789 INFO epoch # 308 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.029543127065508344-> 0.029543127065508344 - loss = 0.051952813751995564
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:07,944 INFO epoch # 309 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.029543127065508344-> 0.029543127065508344 - loss = 0.04508479172363877
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:08,094 INFO epoch # 310 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.029543127065508344-> 0.029543127065508344 - loss = 0.03262361837550998
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:58:08,094 INFO *** epoch 310, rolling-avg-loss (window=10)= 0.053750449884682895
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:08,244 INFO epoch # 311 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.029543127065508344-> 0.029543127065508344 - loss = 0.037593550980091095
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:08,394 INFO epoch # 312 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.029543127065508344-> 0.029543127065508344 - loss = 0.09342595050111413
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:08,545 INFO epoch # 313 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.029543127065508344-> 0.029543127065508344 - loss = 0.0812147376127541
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:08,696 INFO epoch # 314 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.029543127065508344-> 0.029543127065508344 - loss = 0.063389852643013
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:08,846 INFO epoch # 315 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.029543127065508344-> 0.029543127065508344 - loss = 0.03737269761040807
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:08,996 INFO epoch # 316 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.029543127065508344-> 0.029543127065508344 - loss = 0.039493172662332654
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:09,147 INFO epoch # 317 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.029543127065508344-> 0.026588814358957512 - loss = 0.051321936305612326
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:09,298 INFO epoch # 318 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.026588814358957512-> 0.026588814358957512 - loss = 0.03638901049271226
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:09,449 INFO epoch # 319 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.026588814358957512-> 0.026588814358957512 - loss = 0.052210747729986906
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:09,600 INFO epoch # 320 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.026588814358957512-> 0.026588814358957512 - loss = 0.037300306372344494
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:58:09,600 INFO *** epoch 320, rolling-avg-loss (window=10)= 0.0529711962910369
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:09,751 INFO epoch # 321 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.026588814358957512-> 0.026588814358957512 - loss = 0.08914907556027174
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:09,901 INFO epoch # 322 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.026588814358957512-> 0.026588814358957512 - loss = 0.042224785313010216
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:10,051 INFO epoch # 323 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.026588814358957512-> 0.026588814358957512 - loss = 0.127075192052871
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:10,202 INFO epoch # 324 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.026588814358957512-> 0.026588814358957512 - loss = 0.04145011072978377
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:10,352 INFO epoch # 325 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.026588814358957512-> 0.026588814358957512 - loss = 0.03788366308435798
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:10,502 INFO epoch # 326 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.026588814358957512-> 0.026588814358957512 - loss = 0.038823891431093216
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:10,654 INFO epoch # 327 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.026588814358957512-> 0.026588814358957512 - loss = 0.048629438038915396
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:10,811 INFO epoch # 328 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.026588814358957512-> 0.02392993292306176 - loss = 0.04107668763026595
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:10,966 INFO epoch # 329 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.02392993292306176-> 0.02392993292306176 - loss = 0.04886464960873127
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:11,118 INFO epoch # 330 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.02392993292306176-> 0.02392993292306176 - loss = 0.04872997757047415
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:58:11,118 INFO *** epoch 330, rolling-avg-loss (window=10)= 0.056390747101977466
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:11,269 INFO epoch # 331 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.02392993292306176-> 0.02392993292306176 - loss = 0.04833638668060303
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:11,421 INFO epoch # 332 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.02392993292306176-> 0.02392993292306176 - loss = 0.06412603985518217
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:11,572 INFO epoch # 333 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.02392993292306176-> 0.02392993292306176 - loss = 0.02976268669590354
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:11,724 INFO epoch # 334 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.02392993292306176-> 0.02392993292306176 - loss = 0.02988542104139924
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:11,875 INFO epoch # 335 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.02392993292306176-> 0.02392993292306176 - loss = 0.06348616303876042
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:12,027 INFO epoch # 336 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.02392993292306176-> 0.02392993292306176 - loss = 0.028902099700644612
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:12,177 INFO epoch # 337 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.02392993292306176-> 0.02392993292306176 - loss = 0.03681385237723589
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:12,328 INFO epoch # 338 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.02392993292306176-> 0.02392993292306176 - loss = 0.029840230708941817
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:12,479 INFO epoch # 339 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.02392993292306176-> 0.021536939630755585 - loss = 0.03144958196207881
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:12,630 INFO epoch # 340 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.021536939630755585-> 0.021536939630755585 - loss = 0.03535077162086964
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:58:12,630 INFO *** epoch 340, rolling-avg-loss (window=10)= 0.03979532336816192
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:12,779 INFO epoch # 341 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.021536939630755585-> 0.021536939630755585 - loss = 0.055650258203968406
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:12,931 INFO epoch # 342 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.021536939630755585-> 0.021536939630755585 - loss = 0.040472020860761404
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:13,080 INFO epoch # 343 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.021536939630755585-> 0.021536939630755585 - loss = 0.02899003936909139
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:13,231 INFO epoch # 344 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.021536939630755585-> 0.021536939630755585 - loss = 0.04025436099618673
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:13,380 INFO epoch # 345 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.021536939630755585-> 0.021536939630755585 - loss = 0.03512942558154464
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:13,530 INFO epoch # 346 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.021536939630755585-> 0.021536939630755585 - loss = 0.04443378373980522
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:13,680 INFO epoch # 347 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.021536939630755585-> 0.021536939630755585 - loss = 0.03214734932407737
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:13,831 INFO epoch # 348 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.021536939630755585-> 0.021536939630755585 - loss = 0.05947243981063366
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:13,983 INFO epoch # 349 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.021536939630755585-> 0.021536939630755585 - loss = 0.04782127728685737
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:14,136 INFO epoch # 350 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.021536939630755585-> 0.019383245667680026 - loss = 0.06311574531719089
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:58:14,136 INFO *** epoch 350, rolling-avg-loss (window=10)= 0.04474867004901171
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:14,286 INFO epoch # 351 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.019383245667680026-> 0.019383245667680026 - loss = 0.03446566732600331
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:14,436 INFO epoch # 352 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.019383245667680026-> 0.019383245667680026 - loss = 0.03561060596257448
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:14,587 INFO epoch # 353 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.019383245667680026-> 0.019383245667680026 - loss = 0.03236220218241215
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:14,738 INFO epoch # 354 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.019383245667680026-> 0.019383245667680026 - loss = 0.030283923260867596
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:14,887 INFO epoch # 355 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.019383245667680026-> 0.019383245667680026 - loss = 0.023224594071507454
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:15,037 INFO epoch # 356 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.019383245667680026-> 0.019383245667680026 - loss = 0.031704981811344624
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:15,187 INFO epoch # 357 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.019383245667680026-> 0.019383245667680026 - loss = 0.04090259736403823
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:15,339 INFO epoch # 358 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.019383245667680026-> 0.019383245667680026 - loss = 0.03214725572615862
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:15,489 INFO epoch # 359 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.019383245667680026-> 0.019383245667680026 - loss = 0.054059629794210196
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:15,640 INFO epoch # 360 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.019383245667680026-> 0.019383245667680026 - loss = 0.0442523704841733
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:58:15,641 INFO *** epoch 360, rolling-avg-loss (window=10)= 0.035901382798328996
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:15,792 INFO epoch # 361 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.019383245667680026-> 0.017444921100912024 - loss = 0.0443069851025939
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:15,943 INFO epoch # 362 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.017444921100912024-> 0.017444921100912024 - loss = 0.06303311651572585
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:16,094 INFO epoch # 363 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.017444921100912024-> 0.017444921100912024 - loss = 0.03148753149434924
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:16,244 INFO epoch # 364 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.017444921100912024-> 0.017444921100912024 - loss = 0.03245816379785538
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:16,395 INFO epoch # 365 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.017444921100912024-> 0.017444921100912024 - loss = 0.04406909365206957
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:16,556 INFO epoch # 366 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.017444921100912024-> 0.017444921100912024 - loss = 0.10232102079316974
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:16,709 INFO epoch # 367 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.017444921100912024-> 0.017444921100912024 - loss = 0.04424066282808781
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:16,860 INFO epoch # 368 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.017444921100912024-> 0.017444921100912024 - loss = 0.05107697797939181
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:17,010 INFO epoch # 369 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.017444921100912024-> 0.017444921100912024 - loss = 0.037818366661667824
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:17,160 INFO epoch # 370 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.017444921100912024-> 0.017444921100912024 - loss = 0.047830207739025354
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:58:17,160 INFO *** epoch 370, rolling-avg-loss (window=10)= 0.049864212656393646
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:17,310 INFO epoch # 371 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.017444921100912024-> 0.017444921100912024 - loss = 0.06220655515789986
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:17,462 INFO epoch # 372 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.017444921100912024-> 0.015700428990820824 - loss = 0.02913077874109149
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:17,613 INFO epoch # 373 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.015700428990820824-> 0.015700428990820824 - loss = 0.1027813395485282
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:17,763 INFO epoch # 374 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.015700428990820824-> 0.015700428990820824 - loss = 0.03126610303297639
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:17,914 INFO epoch # 375 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.015700428990820824-> 0.015700428990820824 - loss = 0.04898401349782944
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:18,066 INFO epoch # 376 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.015700428990820824-> 0.015700428990820824 - loss = 0.03846873762086034
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:18,216 INFO epoch # 377 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.015700428990820824-> 0.015700428990820824 - loss = 0.05456494353711605
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:18,368 INFO epoch # 378 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.015700428990820824-> 0.015700428990820824 - loss = 0.03343087527900934
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:18,518 INFO epoch # 379 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.015700428990820824-> 0.015700428990820824 - loss = 0.0296561224386096
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:18,670 INFO epoch # 380 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.015700428990820824-> 0.015700428990820824 - loss = 0.027857954613864422
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:58:18,670 INFO *** epoch 380, rolling-avg-loss (window=10)= 0.04583474234677851
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:18,820 INFO epoch # 381 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.015700428990820824-> 0.015700428990820824 - loss = 0.039421995636075735
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:18,971 INFO epoch # 382 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.015700428990820824-> 0.015700428990820824 - loss = 0.027013559360057116
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:19,120 INFO epoch # 383 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.015700428990820824-> 0.014130386091738742 - loss = 0.035734760109335184
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:19,270 INFO epoch # 384 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.014130386091738742-> 0.014130386091738742 - loss = 0.041026562452316284
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:19,419 INFO epoch # 385 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.014130386091738742-> 0.014130386091738742 - loss = 0.04726194869726896
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:19,569 INFO epoch # 386 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.014130386091738742-> 0.014130386091738742 - loss = 0.02784076624084264
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:19,719 INFO epoch # 387 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.014130386091738742-> 0.014130386091738742 - loss = 0.03134007006883621
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:19,869 INFO epoch # 388 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.014130386091738742-> 0.014130386091738742 - loss = 0.05639446061104536
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:20,018 INFO epoch # 389 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.014130386091738742-> 0.014130386091738742 - loss = 0.04813596187159419
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:20,168 INFO epoch # 390 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.014130386091738742-> 0.014130386091738742 - loss = 0.024544872576370835
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:58:20,168 INFO *** epoch 390, rolling-avg-loss (window=10)= 0.03787149576237425
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:20,317 INFO epoch # 391 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.014130386091738742-> 0.014130386091738742 - loss = 0.033625527285039425
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:20,466 INFO epoch # 392 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.014130386091738742-> 0.014130386091738742 - loss = 0.04932698095217347
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:20,615 INFO epoch # 393 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.014130386091738742-> 0.014130386091738742 - loss = 0.034744965843856335
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:20,767 INFO epoch # 394 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.014130386091738742-> 0.012717347482564867 - loss = 0.03918156074360013
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:20,916 INFO epoch # 395 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.012717347482564867-> 0.012717347482564867 - loss = 0.0253694960847497
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:21,066 INFO epoch # 396 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.012717347482564867-> 0.012717347482564867 - loss = 0.045513277873396873
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:21,215 INFO epoch # 397 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.012717347482564867-> 0.012717347482564867 - loss = 0.027560252463445067
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:21,364 INFO epoch # 398 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.012717347482564867-> 0.012717347482564867 - loss = 0.032171607948839664
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:21,513 INFO epoch # 399 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.012717347482564867-> 0.012717347482564867 - loss = 0.04439378250390291
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:21,664 INFO epoch # 400 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.012717347482564867-> 0.012717347482564867 - loss = 0.04793380666524172
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:58:21,664 INFO *** epoch 400, rolling-avg-loss (window=10)= 0.03798212583642453
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:21,821 INFO epoch # 401 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.012717347482564867-> 0.012717347482564867 - loss = 0.049238042905926704
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:21,976 INFO epoch # 402 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.012717347482564867-> 0.012717347482564867 - loss = 0.03329700790345669
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:22,126 INFO epoch # 403 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.012717347482564867-> 0.012717347482564867 - loss = 0.04362754104658961
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:22,276 INFO epoch # 404 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.012717347482564867-> 0.012717347482564867 - loss = 0.042378455866128206
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:22,427 INFO epoch # 405 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.012717347482564867-> 0.01144561273430838 - loss = 0.04715764755383134
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:22,578 INFO epoch # 406 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.01144561273430838-> 0.01144561273430838 - loss = 0.031227126251906157
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:22,728 INFO epoch # 407 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.01144561273430838-> 0.01144561273430838 - loss = 0.049744253512471914
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:22,879 INFO epoch # 408 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.01144561273430838-> 0.01144561273430838 - loss = 0.030895109055563807
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:23,031 INFO epoch # 409 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.01144561273430838-> 0.01144561273430838 - loss = 0.11246104445308447
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:23,182 INFO epoch # 410 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.01144561273430838-> 0.01144561273430838 - loss = 0.049612581729888916
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:58:23,182 INFO *** epoch 410, rolling-avg-loss (window=10)= 0.04896388102788478
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:23,332 INFO epoch # 411 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.01144561273430838-> 0.01144561273430838 - loss = 0.05203695967793465
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:23,483 INFO epoch # 412 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.01144561273430838-> 0.01144561273430838 - loss = 0.043142369482666254
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:23,633 INFO epoch # 413 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.01144561273430838-> 0.01144561273430838 - loss = 0.06730285007506609
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:23,784 INFO epoch # 414 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.01144561273430838-> 0.01144561273430838 - loss = 0.07926659286022186
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:23,934 INFO epoch # 415 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.01144561273430838-> 0.01144561273430838 - loss = 0.041664708871394396
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:24,084 INFO epoch # 416 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.01144561273430838-> 0.010301051460877543 - loss = 0.028291331487707794
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:24,235 INFO epoch # 417 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.010301051460877543-> 0.010301051460877543 - loss = 0.032177557004615664
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:24,386 INFO epoch # 418 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.010301051460877543-> 0.010301051460877543 - loss = 0.030000197235494852
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:24,538 INFO epoch # 419 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.010301051460877543-> 0.010301051460877543 - loss = 0.0811469154432416
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:24,689 INFO epoch # 420 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.010301051460877543-> 0.010301051460877543 - loss = 0.08061587484553456
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:58:24,689 INFO *** epoch 420, rolling-avg-loss (window=10)= 0.053564535698387775
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:24,840 INFO epoch # 421 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.010301051460877543-> 0.010301051460877543 - loss = 0.05180208804085851
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:24,990 INFO epoch # 422 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.010301051460877543-> 0.010301051460877543 - loss = 0.032268673880025744
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:25,140 INFO epoch # 423 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.010301051460877543-> 0.010301051460877543 - loss = 0.03289570566266775
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:25,291 INFO epoch # 424 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.010301051460877543-> 0.010301051460877543 - loss = 0.024804494809359312
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:25,442 INFO epoch # 425 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.010301051460877543-> 0.010301051460877543 - loss = 0.030668013263493776
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:25,593 INFO epoch # 426 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.010301051460877543-> 0.010301051460877543 - loss = 0.03093713941052556
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:25,743 INFO epoch # 427 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.010301051460877543-> 0.009270946314789788 - loss = 0.03235868364572525
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:25,893 INFO epoch # 428 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.009270946314789788-> 0.009270946314789788 - loss = 0.04363249847665429
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:26,044 INFO epoch # 429 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.009270946314789788-> 0.009270946314789788 - loss = 0.026588978711515665
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:26,195 INFO epoch # 430 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.009270946314789788-> 0.009270946314789788 - loss = 0.029388726223260164
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:58:26,195 INFO *** epoch 430, rolling-avg-loss (window=10)= 0.0335345002124086
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:26,346 INFO epoch # 431 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.009270946314789788-> 0.009270946314789788 - loss = 0.030019402503967285
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:26,497 INFO epoch # 432 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.009270946314789788-> 0.009270946314789788 - loss = 0.08737453306093812
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:26,647 INFO epoch # 433 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.009270946314789788-> 0.009270946314789788 - loss = 0.042056864127516747
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:26,798 INFO epoch # 434 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.009270946314789788-> 0.009270946314789788 - loss = 0.04789921175688505
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:26,948 INFO epoch # 435 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.009270946314789788-> 0.009270946314789788 - loss = 0.04916567821055651
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:27,099 INFO epoch # 436 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.009270946314789788-> 0.009270946314789788 - loss = 0.06737277703359723
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:27,249 INFO epoch # 437 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.009270946314789788-> 0.009270946314789788 - loss = 0.03101085964590311
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:27,400 INFO epoch # 438 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.009270946314789788-> 0.00834385168331081 - loss = 0.045973087660968304
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:27,551 INFO epoch # 439 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00834385168331081-> 0.00834385168331081 - loss = 0.040177250280976295
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:27,701 INFO epoch # 440 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00834385168331081-> 0.00834385168331081 - loss = 0.03362660855054855
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:58:27,701 INFO *** epoch 440, rolling-avg-loss (window=10)= 0.04746762728318572
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:27,852 INFO epoch # 441 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00834385168331081-> 0.00834385168331081 - loss = 0.03247399441897869
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:28,003 INFO epoch # 442 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00834385168331081-> 0.00834385168331081 - loss = 0.03300190786831081
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:28,152 INFO epoch # 443 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00834385168331081-> 0.00834385168331081 - loss = 0.034885547356680036
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:28,303 INFO epoch # 444 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00834385168331081-> 0.00834385168331081 - loss = 0.10574965411797166
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:28,453 INFO epoch # 445 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00834385168331081-> 0.00834385168331081 - loss = 0.032020943239331245
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:28,604 INFO epoch # 446 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00834385168331081-> 0.00834385168331081 - loss = 0.03828867617994547
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:28,754 INFO epoch # 447 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00834385168331081-> 0.00834385168331081 - loss = 0.038177359849214554
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:28,905 INFO epoch # 448 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00834385168331081-> 0.00834385168331081 - loss = 0.04133082483895123
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:29,055 INFO epoch # 449 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00834385168331081-> 0.007509466514979729 - loss = 0.04371046647429466
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:29,206 INFO epoch # 450 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.007509466514979729-> 0.007509466514979729 - loss = 0.02334420703118667
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:58:29,206 INFO *** epoch 450, rolling-avg-loss (window=10)= 0.0422983581374865
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:29,356 INFO epoch # 451 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.007509466514979729-> 0.007509466514979729 - loss = 0.025757765979506075
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:29,506 INFO epoch # 452 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.007509466514979729-> 0.007509466514979729 - loss = 0.03841263521462679
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:29,657 INFO epoch # 453 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.007509466514979729-> 0.007509466514979729 - loss = 0.05401922692544758
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:29,808 INFO epoch # 454 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.007509466514979729-> 0.007509466514979729 - loss = 0.031382405664771795
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:29,959 INFO epoch # 455 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.007509466514979729-> 0.007509466514979729 - loss = 0.041019583120942116
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:30,109 INFO epoch # 456 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.007509466514979729-> 0.007509466514979729 - loss = 0.034381650388240814
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:30,260 INFO epoch # 457 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.007509466514979729-> 0.007509466514979729 - loss = 0.04638785123825073
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:30,410 INFO epoch # 458 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.007509466514979729-> 0.007509466514979729 - loss = 0.03864579414948821
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:30,561 INFO epoch # 459 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.007509466514979729-> 0.007509466514979729 - loss = 0.031220980919897556
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:30,712 INFO epoch # 460 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.007509466514979729-> 0.006758519863481757 - loss = 0.030307345557957888
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:58:30,713 INFO *** epoch 460, rolling-avg-loss (window=10)= 0.03715352391591296
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:30,863 INFO epoch # 461 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.006758519863481757-> 0.006758519863481757 - loss = 0.03188723465427756
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:31,014 INFO epoch # 462 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.006758519863481757-> 0.006758519863481757 - loss = 0.04708658158779144
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:31,164 INFO epoch # 463 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.006758519863481757-> 0.006758519863481757 - loss = 0.03235736768692732
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:31,314 INFO epoch # 464 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.006758519863481757-> 0.006758519863481757 - loss = 0.05425038328394294
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:31,463 INFO epoch # 465 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.006758519863481757-> 0.006758519863481757 - loss = 0.03838981967419386
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:31,615 INFO epoch # 466 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.006758519863481757-> 0.006758519863481757 - loss = 0.03727630153298378
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:31,766 INFO epoch # 467 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.006758519863481757-> 0.006758519863481757 - loss = 0.04992828983813524
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:31,934 INFO epoch # 468 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.006758519863481757-> 0.006758519863481757 - loss = 0.030842785723507404
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:32,085 INFO epoch # 469 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.006758519863481757-> 0.006758519863481757 - loss = 0.03391263959929347
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:32,236 INFO epoch # 470 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.006758519863481757-> 0.006758519863481757 - loss = 0.02793967816978693
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:58:32,236 INFO *** epoch 470, rolling-avg-loss (window=10)= 0.03838710817508399
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:32,387 INFO epoch # 471 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.006758519863481757-> 0.006082667877133581 - loss = 0.03556577255949378
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:32,538 INFO epoch # 472 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.006082667877133581-> 0.006082667877133581 - loss = 0.03019237332046032
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:32,689 INFO epoch # 473 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.006082667877133581-> 0.006082667877133581 - loss = 0.06027293996885419
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:32,840 INFO epoch # 474 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.006082667877133581-> 0.006082667877133581 - loss = 0.029444776941090822
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:32,990 INFO epoch # 475 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.006082667877133581-> 0.006082667877133581 - loss = 0.023492817766964436
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:33,142 INFO epoch # 476 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.006082667877133581-> 0.006082667877133581 - loss = 0.05159714026376605
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:33,292 INFO epoch # 477 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.006082667877133581-> 0.006082667877133581 - loss = 0.06487761624157429
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:33,441 INFO epoch # 478 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.006082667877133581-> 0.006082667877133581 - loss = 0.028248637914657593
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:33,591 INFO epoch # 479 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.006082667877133581-> 0.006082667877133581 - loss = 0.026406338496599346
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:33,742 INFO epoch # 480 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.006082667877133581-> 0.006082667877133581 - loss = 0.022126611787825823
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:58:33,742 INFO *** epoch 480, rolling-avg-loss (window=10)= 0.037222502526128666
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:33,897 INFO epoch # 481 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.006082667877133581-> 0.006082667877133581 - loss = 0.026293013710528612
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:34,049 INFO epoch # 482 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.006082667877133581-> 0.005474401089420223 - loss = 0.051008958369493484
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:34,199 INFO epoch # 483 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.005474401089420223-> 0.005474401089420223 - loss = 0.06167361792176962
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:34,350 INFO epoch # 484 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.005474401089420223-> 0.005474401089420223 - loss = 0.034120989264920354
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:34,501 INFO epoch # 485 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.005474401089420223-> 0.005474401089420223 - loss = 0.059327407740056515
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:34,658 INFO epoch # 486 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.005474401089420223-> 0.005474401089420223 - loss = 0.046641829423606396
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:34,812 INFO epoch # 487 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.005474401089420223-> 0.005474401089420223 - loss = 0.04091179254464805
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:34,962 INFO epoch # 488 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.005474401089420223-> 0.005474401089420223 - loss = 0.03789198026061058
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:35,112 INFO epoch # 489 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.005474401089420223-> 0.005474401089420223 - loss = 0.026936895214021206
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:35,263 INFO epoch # 490 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.005474401089420223-> 0.005474401089420223 - loss = 0.024576411582529545
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:58:35,263 INFO *** epoch 490, rolling-avg-loss (window=10)= 0.040938289603218436
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:35,413 INFO epoch # 491 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.005474401089420223-> 0.005474401089420223 - loss = 0.029612074606120586
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:35,564 INFO epoch # 492 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.005474401089420223-> 0.005474401089420223 - loss = 0.04523365758359432
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:35,715 INFO epoch # 493 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.005474401089420223-> 0.004926960980478201 - loss = 0.035108188167214394
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:35,867 INFO epoch # 494 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.004926960980478201-> 0.004926960980478201 - loss = 0.05176572501659393
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:36,017 INFO epoch # 495 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.004926960980478201-> 0.004926960980478201 - loss = 0.0696714473888278
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:36,169 INFO epoch # 496 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.004926960980478201-> 0.004926960980478201 - loss = 0.05828731646761298
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:36,320 INFO epoch # 497 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.004926960980478201-> 0.004926960980478201 - loss = 0.032834951765835285
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:36,471 INFO epoch # 498 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.004926960980478201-> 0.004926960980478201 - loss = 0.03546163160353899
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:36,623 INFO epoch # 499 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.004926960980478201-> 0.004926960980478201 - loss = 0.043090407736599445
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:36,773 INFO epoch # 500 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.004926960980478201-> 0.004926960980478201 - loss = 0.07066500280052423
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:58:36,774 INFO *** epoch 500, rolling-avg-loss (window=10)= 0.0471730403136462
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:36,924 INFO epoch # 501 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.004926960980478201-> 0.004926960980478201 - loss = 0.024244353524409235
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:37,074 INFO epoch # 502 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.004926960980478201-> 0.004926960980478201 - loss = 0.02713026129640639
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:37,222 INFO epoch # 503 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.004926960980478201-> 0.004926960980478201 - loss = 0.06422581686638296
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:37,373 INFO epoch # 504 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.004926960980478201-> 0.004434264882430382 - loss = 0.024487545248121023
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:37,523 INFO epoch # 505 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.004434264882430382-> 0.004434264882430382 - loss = 0.02426514122635126
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:37,674 INFO epoch # 506 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.004434264882430382-> 0.004434264882430382 - loss = 0.030294138006865978
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:37,823 INFO epoch # 507 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.004434264882430382-> 0.004434264882430382 - loss = 0.039974628016352654
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:37,973 INFO epoch # 508 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.004434264882430382-> 0.004434264882430382 - loss = 0.028156030923128128
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:38,123 INFO epoch # 509 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.004434264882430382-> 0.004434264882430382 - loss = 0.04830865701660514
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:38,274 INFO epoch # 510 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.004434264882430382-> 0.004434264882430382 - loss = 0.03530081268399954
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:58:38,274 INFO *** epoch 510, rolling-avg-loss (window=10)= 0.03463873848086223
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:38,424 INFO epoch # 511 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.004434264882430382-> 0.004434264882430382 - loss = 0.11306059500202537
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:38,574 INFO epoch # 512 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.004434264882430382-> 0.004434264882430382 - loss = 0.08869898598641157
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:38,724 INFO epoch # 513 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.004434264882430382-> 0.004434264882430382 - loss = 0.050394556019455194
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:38,888 INFO epoch # 514 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.004434264882430382-> 0.004434264882430382 - loss = 0.05531342327594757
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:39,044 INFO epoch # 515 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.004434264882430382-> 0.003990838394187343 - loss = 0.03658910933881998
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:39,197 INFO epoch # 516 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.003990838394187343-> 0.003990838394187343 - loss = 0.033352623926475644
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:39,349 INFO epoch # 517 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.003990838394187343-> 0.003990838394187343 - loss = 0.030435954686254263
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:39,503 INFO epoch # 518 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.003990838394187343-> 0.003990838394187343 - loss = 0.033805654384195805
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:39,655 INFO epoch # 519 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.003990838394187343-> 0.003990838394187343 - loss = 0.057473883498460054
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:39,805 INFO epoch # 520 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.003990838394187343-> 0.003990838394187343 - loss = 0.06522061815485358
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:58:39,805 INFO *** epoch 520, rolling-avg-loss (window=10)= 0.0564345404272899
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:39,956 INFO epoch # 521 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.003990838394187343-> 0.003990838394187343 - loss = 0.031445319997146726
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:40,108 INFO epoch # 522 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.003990838394187343-> 0.003990838394187343 - loss = 0.034650054294615984
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:40,258 INFO epoch # 523 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.003990838394187343-> 0.003990838394187343 - loss = 0.0357966274023056
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:40,409 INFO epoch # 524 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.003990838394187343-> 0.003990838394187343 - loss = 0.05937739135697484
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:40,559 INFO epoch # 525 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.003990838394187343-> 0.003990838394187343 - loss = 0.03681978955864906
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:40,709 INFO epoch # 526 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.003990838394187343-> 0.003591754554768609 - loss = 0.031191744143143296
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:40,859 INFO epoch # 527 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.003591754554768609-> 0.003591754554768609 - loss = 0.10654145525768399
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:41,016 INFO epoch # 528 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.003591754554768609-> 0.003591754554768609 - loss = 0.030897631775587797
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:41,167 INFO epoch # 529 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.003591754554768609-> 0.003591754554768609 - loss = 0.03565931785851717
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:41,317 INFO epoch # 530 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.003591754554768609-> 0.003591754554768609 - loss = 0.040734846610575914
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:58:41,317 INFO *** epoch 530, rolling-avg-loss (window=10)= 0.04431141782552004
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:41,467 INFO epoch # 531 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.003591754554768609-> 0.003591754554768609 - loss = 0.03371548745781183
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:41,617 INFO epoch # 532 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.003591754554768609-> 0.003591754554768609 - loss = 0.07932777656242251
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:41,769 INFO epoch # 533 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.003591754554768609-> 0.003591754554768609 - loss = 0.03546624770388007
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:41,919 INFO epoch # 534 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.003591754554768609-> 0.003591754554768609 - loss = 0.03014705702662468
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:42,070 INFO epoch # 535 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.003591754554768609-> 0.003591754554768609 - loss = 0.034868571907281876
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:42,220 INFO epoch # 536 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.003591754554768609-> 0.003591754554768609 - loss = 0.0663568009622395
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:42,371 INFO epoch # 537 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.003591754554768609-> 0.003232579099291748 - loss = 0.04517717706039548
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:42,521 INFO epoch # 538 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.003232579099291748-> 0.003232579099291748 - loss = 0.07262498326599598
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:42,671 INFO epoch # 539 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.003232579099291748-> 0.003232579099291748 - loss = 0.023987339809536934
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:42,831 INFO epoch # 540 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.003232579099291748-> 0.003232579099291748 - loss = 0.05043535400182009
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:58:42,831 INFO *** epoch 540, rolling-avg-loss (window=10)= 0.0472106795758009
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:42,984 INFO epoch # 541 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.003232579099291748-> 0.003232579099291748 - loss = 0.03944134572520852
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:43,136 INFO epoch # 542 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.003232579099291748-> 0.003232579099291748 - loss = 0.036735924892127514
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:43,285 INFO epoch # 543 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.003232579099291748-> 0.003232579099291748 - loss = 0.02635966381058097
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:43,436 INFO epoch # 544 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.003232579099291748-> 0.003232579099291748 - loss = 0.027094645891338587
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:43,586 INFO epoch # 545 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.003232579099291748-> 0.003232579099291748 - loss = 0.03173953830264509
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:43,737 INFO epoch # 546 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.003232579099291748-> 0.003232579099291748 - loss = 0.028390056919306517
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:43,887 INFO epoch # 547 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.003232579099291748-> 0.003232579099291748 - loss = 0.027841884992085397
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:44,038 INFO epoch # 548 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.003232579099291748-> 0.0029093211893625732 - loss = 0.030970464926213026
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:44,188 INFO epoch # 549 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0029093211893625732-> 0.0029093211893625732 - loss = 0.028154322877526283
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:44,339 INFO epoch # 550 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0029093211893625732-> 0.0029093211893625732 - loss = 0.0674740350805223
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:58:44,339 INFO *** epoch 550, rolling-avg-loss (window=10)= 0.03442018834175542
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:44,489 INFO epoch # 551 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0029093211893625732-> 0.0029093211893625732 - loss = 0.029708224930800498
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:44,640 INFO epoch # 552 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0029093211893625732-> 0.0029093211893625732 - loss = 0.03899622522294521
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:44,790 INFO epoch # 553 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0029093211893625732-> 0.0029093211893625732 - loss = 0.03370065474882722
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:44,941 INFO epoch # 554 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0029093211893625732-> 0.0029093211893625732 - loss = 0.06910554761998355
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:45,092 INFO epoch # 555 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0029093211893625732-> 0.0029093211893625732 - loss = 0.025573834078386426
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:45,242 INFO epoch # 556 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0029093211893625732-> 0.0029093211893625732 - loss = 0.03459902526810765
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:45,393 INFO epoch # 557 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0029093211893625732-> 0.0029093211893625732 - loss = 0.04315448645502329
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:45,544 INFO epoch # 558 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0029093211893625732-> 0.0029093211893625732 - loss = 0.042690010741353035
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:45,695 INFO epoch # 559 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0029093211893625732-> 0.002618389070426316 - loss = 0.040220081340521574
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:45,845 INFO epoch # 560 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.002618389070426316-> 0.002618389070426316 - loss = 0.040229199919849634
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:58:45,846 INFO *** epoch 560, rolling-avg-loss (window=10)= 0.03979772903257981
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:45,997 INFO epoch # 561 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.002618389070426316-> 0.002618389070426316 - loss = 0.0811955165117979
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:46,148 INFO epoch # 562 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.002618389070426316-> 0.002618389070426316 - loss = 0.030296301003545523
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:46,299 INFO epoch # 563 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.002618389070426316-> 0.002618389070426316 - loss = 0.03072553174570203
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:46,450 INFO epoch # 564 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.002618389070426316-> 0.002618389070426316 - loss = 0.024178833235055208
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:46,602 INFO epoch # 565 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.002618389070426316-> 0.002618389070426316 - loss = 0.02753747603856027
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:46,753 INFO epoch # 566 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.002618389070426316-> 0.002618389070426316 - loss = 0.0442495783790946
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:46,904 INFO epoch # 567 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.002618389070426316-> 0.002618389070426316 - loss = 0.03197497222572565
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:47,057 INFO epoch # 568 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.002618389070426316-> 0.002618389070426316 - loss = 0.037839422933757305
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:47,208 INFO epoch # 569 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.002618389070426316-> 0.002618389070426316 - loss = 0.023127422435209155
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:47,359 INFO epoch # 570 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.002618389070426316-> 0.0023565501633836844 - loss = 0.039341806434094906
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:58:47,360 INFO *** epoch 570, rolling-avg-loss (window=10)= 0.03704668609425425
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:47,510 INFO epoch # 571 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0023565501633836844-> 0.0023565501633836844 - loss = 0.03566657565534115
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:47,661 INFO epoch # 572 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0023565501633836844-> 0.0023565501633836844 - loss = 0.03369299927726388
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:47,811 INFO epoch # 573 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0023565501633836844-> 0.0023565501633836844 - loss = 0.03555846866220236
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:47,962 INFO epoch # 574 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0023565501633836844-> 0.0023565501633836844 - loss = 0.03107889974489808
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:48,112 INFO epoch # 575 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0023565501633836844-> 0.0023565501633836844 - loss = 0.026959343580529094
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:48,263 INFO epoch # 576 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0023565501633836844-> 0.0023565501633836844 - loss = 0.03999660746194422
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:48,414 INFO epoch # 577 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0023565501633836844-> 0.0023565501633836844 - loss = 0.06705379509367049
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:48,565 INFO epoch # 578 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0023565501633836844-> 0.0023565501633836844 - loss = 0.053667329251766205
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:48,715 INFO epoch # 579 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0023565501633836844-> 0.0023565501633836844 - loss = 0.0326296326238662
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:48,868 INFO epoch # 580 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0023565501633836844-> 0.0023565501633836844 - loss = 0.052026581950485706
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:58:48,868 INFO *** epoch 580, rolling-avg-loss (window=10)= 0.04083302333019674
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:49,018 INFO epoch # 581 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0023565501633836844-> 0.002120895147045316 - loss = 0.04733338346704841
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:49,168 INFO epoch # 582 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.002120895147045316-> 0.002120895147045316 - loss = 0.07552714832127094
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:49,318 INFO epoch # 583 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.002120895147045316-> 0.002120895147045316 - loss = 0.04506291355937719
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:49,469 INFO epoch # 584 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.002120895147045316-> 0.002120895147045316 - loss = 0.03785583935678005
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:49,621 INFO epoch # 585 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.002120895147045316-> 0.002120895147045316 - loss = 0.05006846925243735
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:49,771 INFO epoch # 586 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.002120895147045316-> 0.002120895147045316 - loss = 0.05955703160725534
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:49,921 INFO epoch # 587 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.002120895147045316-> 0.002120895147045316 - loss = 0.03098633512854576
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:50,073 INFO epoch # 588 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.002120895147045316-> 0.002120895147045316 - loss = 0.043331582099199295
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:50,223 INFO epoch # 589 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.002120895147045316-> 0.002120895147045316 - loss = 0.05177898146212101
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:50,373 INFO epoch # 590 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.002120895147045316-> 0.002120895147045316 - loss = 0.03698757430538535
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:58:50,373 INFO *** epoch 590, rolling-avg-loss (window=10)= 0.04784892585594207
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:50,525 INFO epoch # 591 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.002120895147045316-> 0.002120895147045316 - loss = 0.03934499341994524
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:50,675 INFO epoch # 592 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.002120895147045316-> 0.0019088056323407843 - loss = 0.02877869480289519
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:50,824 INFO epoch # 593 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0019088056323407843-> 0.0019088056323407843 - loss = 0.026329065847676247
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:50,975 INFO epoch # 594 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0019088056323407843-> 0.0019088056323407843 - loss = 0.027906935196369886
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:51,126 INFO epoch # 595 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0019088056323407843-> 0.0019088056323407843 - loss = 0.028869237285107374
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:51,277 INFO epoch # 596 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0019088056323407843-> 0.0019088056323407843 - loss = 0.03774527879431844
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:51,427 INFO epoch # 597 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0019088056323407843-> 0.0019088056323407843 - loss = 0.07460844097658992
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:51,578 INFO epoch # 598 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0019088056323407843-> 0.0019088056323407843 - loss = 0.03340155212208629
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:51,728 INFO epoch # 599 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0019088056323407843-> 0.0019088056323407843 - loss = 0.035498755518347025
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:51,896 INFO epoch # 600 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0019088056323407843-> 0.0019088056323407843 - loss = 0.054025824181735516
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:58:51,896 INFO *** epoch 600, rolling-avg-loss (window=10)= 0.038650877814507115
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:52,050 INFO epoch # 601 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0019088056323407843-> 0.0019088056323407843 - loss = 0.021406072191894054
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:52,200 INFO epoch # 602 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0019088056323407843-> 0.0019088056323407843 - loss = 0.024194807978346944
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:52,364 INFO epoch # 603 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0019088056323407843-> 0.0019088056323407843 - loss = 0.062326096929609776
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:52,516 INFO epoch # 604 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0019088056323407843-> 0.0019088056323407843 - loss = 0.04110533045604825
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:52,666 INFO epoch # 605 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0019088056323407843-> 0.0019088056323407843 - loss = 0.040194894187152386
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:52,819 INFO epoch # 606 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0019088056323407843-> 0.0019088056323407843 - loss = 0.06576201831921935
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:52,968 INFO epoch # 607 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0019088056323407843-> 0.0019088056323407843 - loss = 0.033586643636226654
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:53,119 INFO epoch # 608 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0019088056323407843-> 0.0019088056323407843 - loss = 0.03304609074257314
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:53,269 INFO epoch # 609 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0019088056323407843-> 0.0019088056323407843 - loss = 0.03281129337847233
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:53,419 INFO epoch # 610 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0019088056323407843-> 0.0019088056323407843 - loss = 0.03482781071215868
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:58:53,419 INFO *** epoch 610, rolling-avg-loss (window=10)= 0.038926105853170155
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:53,569 INFO epoch # 611 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0019088056323407843-> 0.0019088056323407843 - loss = 0.02617215900681913
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:53,719 INFO epoch # 612 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0019088056323407843-> 0.001717925069106706 - loss = 0.040415427181869745
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:53,870 INFO epoch # 613 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.001717925069106706-> 0.001717925069106706 - loss = 0.0647744401358068
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:54,021 INFO epoch # 614 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.001717925069106706-> 0.001717925069106706 - loss = 0.033857461996376514
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:54,171 INFO epoch # 615 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.001717925069106706-> 0.001717925069106706 - loss = 0.0754046174697578
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:54,320 INFO epoch # 616 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.001717925069106706-> 0.001717925069106706 - loss = 0.03003772906959057
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:54,470 INFO epoch # 617 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.001717925069106706-> 0.001717925069106706 - loss = 0.03752476302906871
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:54,621 INFO epoch # 618 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.001717925069106706-> 0.001717925069106706 - loss = 0.029871306847780943
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:54,769 INFO epoch # 619 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.001717925069106706-> 0.001717925069106706 - loss = 0.038610102608799934
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:54,920 INFO epoch # 620 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.001717925069106706-> 0.001717925069106706 - loss = 0.02384239062666893
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:58:54,920 INFO *** epoch 620, rolling-avg-loss (window=10)= 0.040051039797253905
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:55,071 INFO epoch # 621 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.001717925069106706-> 0.001717925069106706 - loss = 0.0386084858328104
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:55,221 INFO epoch # 622 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.001717925069106706-> 0.001717925069106706 - loss = 0.047784220427274704
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:55,371 INFO epoch # 623 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.001717925069106706-> 0.0015461325621960354 - loss = 0.03773794136941433
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:55,530 INFO epoch # 624 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0015461325621960354-> 0.0015461325621960354 - loss = 0.054854159243404865
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:55,690 INFO epoch # 625 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0015461325621960354-> 0.0015461325621960354 - loss = 0.037730101961642504
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:55,841 INFO epoch # 626 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0015461325621960354-> 0.0015461325621960354 - loss = 0.033216041047126055
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:55,991 INFO epoch # 627 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0015461325621960354-> 0.0015461325621960354 - loss = 0.02786991884931922
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:56,142 INFO epoch # 628 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0015461325621960354-> 0.0015461325621960354 - loss = 0.07535750698298216
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:56,293 INFO epoch # 629 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0015461325621960354-> 0.0015461325621960354 - loss = 0.05386429047212005
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:56,443 INFO epoch # 630 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0015461325621960354-> 0.0015461325621960354 - loss = 0.02635265444405377
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:58:56,443 INFO *** epoch 630, rolling-avg-loss (window=10)= 0.04333753206301481
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:56,593 INFO epoch # 631 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0015461325621960354-> 0.0015461325621960354 - loss = 0.041866234969347715
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:56,743 INFO epoch # 632 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0015461325621960354-> 0.0015461325621960354 - loss = 0.04195313714444637
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:56,894 INFO epoch # 633 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0015461325621960354-> 0.0015461325621960354 - loss = 0.03597367648035288
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:57,045 INFO epoch # 634 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0015461325621960354-> 0.0013915193059764318 - loss = 0.029630268458276987
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:57,197 INFO epoch # 635 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0013915193059764318-> 0.0013915193059764318 - loss = 0.05285857152193785
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:57,349 INFO epoch # 636 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0013915193059764318-> 0.0013915193059764318 - loss = 0.024614134337753057
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:57,499 INFO epoch # 637 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0013915193059764318-> 0.0013915193059764318 - loss = 0.02893371880054474
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:57,650 INFO epoch # 638 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0013915193059764318-> 0.0013915193059764318 - loss = 0.03325699595734477
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:57,799 INFO epoch # 639 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0013915193059764318-> 0.0013915193059764318 - loss = 0.046402265317738056
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:57,949 INFO epoch # 640 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0013915193059764318-> 0.0013915193059764318 - loss = 0.03133785258978605
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:58:57,949 INFO *** epoch 640, rolling-avg-loss (window=10)= 0.03668268555775285
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:58,099 INFO epoch # 641 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0013915193059764318-> 0.0013915193059764318 - loss = 0.050500921439379454
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:58,250 INFO epoch # 642 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0013915193059764318-> 0.0013915193059764318 - loss = 0.03806314151734114
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:58,400 INFO epoch # 643 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0013915193059764318-> 0.0013915193059764318 - loss = 0.030460288748145103
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:58,550 INFO epoch # 644 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0013915193059764318-> 0.0013915193059764318 - loss = 0.08253448409959674
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:58,703 INFO epoch # 645 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0013915193059764318-> 0.0012523673753787887 - loss = 0.03991100797429681
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:58,853 INFO epoch # 646 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0012523673753787887-> 0.0012523673753787887 - loss = 0.025617547100409865
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:59,004 INFO epoch # 647 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0012523673753787887-> 0.0012523673753787887 - loss = 0.02700235997326672
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:59,157 INFO epoch # 648 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0012523673753787887-> 0.0012523673753787887 - loss = 0.042354307603091
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:59,307 INFO epoch # 649 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0012523673753787887-> 0.0012523673753787887 - loss = 0.05712326942011714
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:59,457 INFO epoch # 650 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0012523673753787887-> 0.0012523673753787887 - loss = 0.0527552692219615
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:58:59,457 INFO *** epoch 650, rolling-avg-loss (window=10)= 0.04463225970976055
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:59,606 INFO epoch # 651 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0012523673753787887-> 0.0012523673753787887 - loss = 0.04457847075536847
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:59,759 INFO epoch # 652 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0012523673753787887-> 0.0012523673753787887 - loss = 0.03995125973597169
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:58:59,912 INFO epoch # 653 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0012523673753787887-> 0.0012523673753787887 - loss = 0.04130835924297571
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:00,069 INFO epoch # 654 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0012523673753787887-> 0.0012523673753787887 - loss = 0.03465460613369942
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:00,233 INFO epoch # 655 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0012523673753787887-> 0.0012523673753787887 - loss = 0.04477865109220147
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:00,390 INFO epoch # 656 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0012523673753787887-> 0.00112713063784091 - loss = 0.030881595332175493
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:00,541 INFO epoch # 657 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00112713063784091-> 0.00112713063784091 - loss = 0.02502763131633401
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:00,691 INFO epoch # 658 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00112713063784091-> 0.00112713063784091 - loss = 0.025604217080399394
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:00,841 INFO epoch # 659 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00112713063784091-> 0.00112713063784091 - loss = 0.028054721653461456
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:00,992 INFO epoch # 660 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00112713063784091-> 0.00112713063784091 - loss = 0.02774734888225794
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:59:00,992 INFO *** epoch 660, rolling-avg-loss (window=10)= 0.034258686122484505
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:01,143 INFO epoch # 661 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00112713063784091-> 0.00112713063784091 - loss = 0.05132788605988026
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:01,292 INFO epoch # 662 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00112713063784091-> 0.00112713063784091 - loss = 0.0732807326130569
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:01,442 INFO epoch # 663 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00112713063784091-> 0.00112713063784091 - loss = 0.03593768225982785
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:01,592 INFO epoch # 664 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00112713063784091-> 0.00112713063784091 - loss = 0.05329193314537406
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:01,743 INFO epoch # 665 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00112713063784091-> 0.00112713063784091 - loss = 0.03851938480511308
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:01,894 INFO epoch # 666 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00112713063784091-> 0.00112713063784091 - loss = 0.030709417071193457
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:02,045 INFO epoch # 667 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00112713063784091-> 0.0010144175740568189 - loss = 0.06261718459427357
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:02,195 INFO epoch # 668 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0010144175740568189-> 0.0010144175740568189 - loss = 0.07134091854095459
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:02,347 INFO epoch # 669 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0010144175740568189-> 0.0010144175740568189 - loss = 0.029124346561729908
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:02,499 INFO epoch # 670 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0010144175740568189-> 0.0010144175740568189 - loss = 0.062107575591653585
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:59:02,499 INFO *** epoch 670, rolling-avg-loss (window=10)= 0.050825706124305724
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:02,650 INFO epoch # 671 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0010144175740568189-> 0.0010144175740568189 - loss = 0.03307397570461035
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:02,811 INFO epoch # 672 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0010144175740568189-> 0.0010144175740568189 - loss = 0.03401093650609255
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:02,972 INFO epoch # 673 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0010144175740568189-> 0.0010144175740568189 - loss = 0.16266991989687085
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:03,123 INFO epoch # 674 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0010144175740568189-> 0.0010144175740568189 - loss = 0.05014785332605243
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:03,273 INFO epoch # 675 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0010144175740568189-> 0.0010144175740568189 - loss = 0.027773995883762836
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:03,423 INFO epoch # 676 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0010144175740568189-> 0.0010144175740568189 - loss = 0.039604405872523785
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:03,575 INFO epoch # 677 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0010144175740568189-> 0.0010144175740568189 - loss = 0.039101981557905674
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:03,725 INFO epoch # 678 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0010144175740568189-> 0.000912975816651137 - loss = 0.031200267374515533
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:03,876 INFO epoch # 679 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.000912975816651137-> 0.000912975816651137 - loss = 0.046884593553841114
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:04,025 INFO epoch # 680 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.000912975816651137-> 0.000912975816651137 - loss = 0.023295743390917778
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:59:04,025 INFO *** epoch 680, rolling-avg-loss (window=10)= 0.04877636730670929
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:04,176 INFO epoch # 681 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.000912975816651137-> 0.000912975816651137 - loss = 0.029300665337359533
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:04,326 INFO epoch # 682 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.000912975816651137-> 0.000912975816651137 - loss = 0.04784555616788566
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:04,475 INFO epoch # 683 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.000912975816651137-> 0.000912975816651137 - loss = 0.03524081641808152
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:04,624 INFO epoch # 684 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.000912975816651137-> 0.000912975816651137 - loss = 0.04691197024658322
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:04,774 INFO epoch # 685 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.000912975816651137-> 0.000912975816651137 - loss = 0.021314401063136756
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:04,925 INFO epoch # 686 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.000912975816651137-> 0.000912975816651137 - loss = 0.0382243525236845
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:05,074 INFO epoch # 687 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.000912975816651137-> 0.000912975816651137 - loss = 0.1395116038620472
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:05,224 INFO epoch # 688 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.000912975816651137-> 0.000912975816651137 - loss = 0.03437259211204946
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:05,374 INFO epoch # 689 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.000912975816651137-> 0.000912975816651137 - loss = 0.052190974820405245
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:05,524 INFO epoch # 690 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.000912975816651137-> 0.000912975816651137 - loss = 0.04618084290996194
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:59:05,524 INFO *** epoch 690, rolling-avg-loss (window=10)= 0.049109377546119506
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:05,676 INFO epoch # 691 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.000912975816651137-> 0.000912975816651137 - loss = 0.02937992289662361
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:05,827 INFO epoch # 692 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.000912975816651137-> 0.000912975816651137 - loss = 0.04651604779064655
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:05,978 INFO epoch # 693 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.000912975816651137-> 0.000912975816651137 - loss = 0.047049048356711864
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:06,129 INFO epoch # 694 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.000912975816651137-> 0.000912975816651137 - loss = 0.02837505633942783
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:06,280 INFO epoch # 695 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.000912975816651137-> 0.000912975816651137 - loss = 0.04480602312833071
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:06,431 INFO epoch # 696 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.000912975816651137-> 0.0008216782349860233 - loss = 0.058609397150576115
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:06,584 INFO epoch # 697 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0008216782349860233-> 0.0008216782349860233 - loss = 0.032337062526494265
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:06,733 INFO epoch # 698 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0008216782349860233-> 0.0008216782349860233 - loss = 0.057882816065102816
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:06,884 INFO epoch # 699 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0008216782349860233-> 0.0008216782349860233 - loss = 0.044015195686370134
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:07,034 INFO epoch # 700 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0008216782349860233-> 0.0008216782349860233 - loss = 0.04334717383608222
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:59:07,035 INFO *** epoch 700, rolling-avg-loss (window=10)= 0.04323177437763661
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:07,185 INFO epoch # 701 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0008216782349860233-> 0.0008216782349860233 - loss = 0.04282182268798351
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:07,337 INFO epoch # 702 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0008216782349860233-> 0.0008216782349860233 - loss = 0.03497403394430876
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:07,487 INFO epoch # 703 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0008216782349860233-> 0.0008216782349860233 - loss = 0.03494045231491327
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:07,639 INFO epoch # 704 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0008216782349860233-> 0.0008216782349860233 - loss = 0.030757613480091095
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:07,788 INFO epoch # 705 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0008216782349860233-> 0.0008216782349860233 - loss = 0.0363492276519537
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:07,938 INFO epoch # 706 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0008216782349860233-> 0.0008216782349860233 - loss = 0.07255172659642994
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:08,087 INFO epoch # 707 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0008216782349860233-> 0.000739510411487421 - loss = 0.03725603548809886
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:08,238 INFO epoch # 708 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.000739510411487421-> 0.000739510411487421 - loss = 0.02790013561025262
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:08,387 INFO epoch # 709 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.000739510411487421-> 0.000739510411487421 - loss = 0.0574969700537622
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:08,538 INFO epoch # 710 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.000739510411487421-> 0.000739510411487421 - loss = 0.036822529044002295
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:59:08,538 INFO *** epoch 710, rolling-avg-loss (window=10)= 0.041187054687179626
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:08,688 INFO epoch # 711 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.000739510411487421-> 0.000739510411487421 - loss = 0.044732532231137156
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:08,841 INFO epoch # 712 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.000739510411487421-> 0.000739510411487421 - loss = 0.03805972309783101
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:08,992 INFO epoch # 713 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.000739510411487421-> 0.000739510411487421 - loss = 0.03704491909593344
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:09,143 INFO epoch # 714 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.000739510411487421-> 0.000739510411487421 - loss = 0.046097153797745705
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:09,293 INFO epoch # 715 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.000739510411487421-> 0.000739510411487421 - loss = 0.03447638335637748
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:09,443 INFO epoch # 716 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.000739510411487421-> 0.000739510411487421 - loss = 0.061780334915965796
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:09,594 INFO epoch # 717 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.000739510411487421-> 0.000739510411487421 - loss = 0.0439273901283741
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:09,744 INFO epoch # 718 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.000739510411487421-> 0.0006655593703386789 - loss = 0.033897032495588064
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:09,894 INFO epoch # 719 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0006655593703386789-> 0.0006655593703386789 - loss = 0.025949558010324836
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:10,047 INFO epoch # 720 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0006655593703386789-> 0.0006655593703386789 - loss = 0.08681814651936293
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:59:10,047 INFO *** epoch 720, rolling-avg-loss (window=10)= 0.045278317364864054
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:10,203 INFO epoch # 721 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0006655593703386789-> 0.0006655593703386789 - loss = 0.03734267735853791
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:10,355 INFO epoch # 722 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0006655593703386789-> 0.0006655593703386789 - loss = 0.03549518063664436
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:10,505 INFO epoch # 723 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0006655593703386789-> 0.0006655593703386789 - loss = 0.07960331346839666
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:10,656 INFO epoch # 724 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0006655593703386789-> 0.0006655593703386789 - loss = 0.05179980304092169
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:10,807 INFO epoch # 725 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0006655593703386789-> 0.0006655593703386789 - loss = 0.0237555259373039
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:10,959 INFO epoch # 726 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0006655593703386789-> 0.0006655593703386789 - loss = 0.04440766340121627
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:11,109 INFO epoch # 727 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0006655593703386789-> 0.0006655593703386789 - loss = 0.033058207016438246
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:11,259 INFO epoch # 728 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0006655593703386789-> 0.0006655593703386789 - loss = 0.023348862305283546
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:11,409 INFO epoch # 729 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0006655593703386789-> 0.0005990034333048111 - loss = 0.02944225911051035
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:11,560 INFO epoch # 730 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0005990034333048111-> 0.0005990034333048111 - loss = 0.028414825443178415
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:59:11,560 INFO *** epoch 730, rolling-avg-loss (window=10)= 0.03866683177184314
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:11,709 INFO epoch # 731 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0005990034333048111-> 0.0005990034333048111 - loss = 0.03612975915893912
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:11,862 INFO epoch # 732 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0005990034333048111-> 0.0005990034333048111 - loss = 0.027346659335307777
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:12,011 INFO epoch # 733 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0005990034333048111-> 0.0005990034333048111 - loss = 0.03271370241418481
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:12,162 INFO epoch # 734 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0005990034333048111-> 0.0005990034333048111 - loss = 0.03000278677791357
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:12,313 INFO epoch # 735 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0005990034333048111-> 0.0005990034333048111 - loss = 0.04894484905526042
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:12,464 INFO epoch # 736 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0005990034333048111-> 0.0005990034333048111 - loss = 0.04731030436232686
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:12,615 INFO epoch # 737 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0005990034333048111-> 0.0005990034333048111 - loss = 0.022964142728596926
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:12,766 INFO epoch # 738 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0005990034333048111-> 0.0005990034333048111 - loss = 0.025017077336087823
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:12,930 INFO epoch # 739 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0005990034333048111-> 0.0005990034333048111 - loss = 0.04463424952700734
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:13,085 INFO epoch # 740 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0005990034333048111-> 0.0005391030899743299 - loss = 0.03458816162310541
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:59:13,085 INFO *** epoch 740, rolling-avg-loss (window=10)= 0.034965169231873004
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:13,243 INFO epoch # 741 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0005391030899743299-> 0.0005391030899743299 - loss = 0.04196055606007576
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:13,401 INFO epoch # 742 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0005391030899743299-> 0.0005391030899743299 - loss = 0.03730141092091799
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:13,558 INFO epoch # 743 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0005391030899743299-> 0.0005391030899743299 - loss = 0.04886107938364148
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:13,712 INFO epoch # 744 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0005391030899743299-> 0.0005391030899743299 - loss = 0.02128705196082592
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:13,866 INFO epoch # 745 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0005391030899743299-> 0.0005391030899743299 - loss = 0.048808942548930645
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:14,020 INFO epoch # 746 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0005391030899743299-> 0.0005391030899743299 - loss = 0.030776252038776875
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:14,169 INFO epoch # 747 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0005391030899743299-> 0.0005391030899743299 - loss = 0.03149343142285943
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:14,322 INFO epoch # 748 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0005391030899743299-> 0.0005391030899743299 - loss = 0.05294426693581045
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:14,472 INFO epoch # 749 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0005391030899743299-> 0.0005391030899743299 - loss = 0.05360313877463341
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:14,623 INFO epoch # 750 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0005391030899743299-> 0.0005391030899743299 - loss = 0.021743020974099636
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:59:14,624 INFO *** epoch 750, rolling-avg-loss (window=10)= 0.03887791510205716
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:14,774 INFO epoch # 751 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0005391030899743299-> 0.0005391030899743299 - loss = 0.03109282162040472
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:14,924 INFO epoch # 752 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0005391030899743299-> 0.0005391030899743299 - loss = 0.032970319502055645
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:15,074 INFO epoch # 753 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0005391030899743299-> 0.0005391030899743299 - loss = 0.04183950927108526
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:15,224 INFO epoch # 754 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0005391030899743299-> 0.0005391030899743299 - loss = 0.04392929608002305
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:15,376 INFO epoch # 755 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0005391030899743299-> 0.00048519278097689693 - loss = 0.04031685320660472
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:15,527 INFO epoch # 756 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00048519278097689693-> 0.00048519278097689693 - loss = 0.07834762008860707
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:15,678 INFO epoch # 757 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00048519278097689693-> 0.00048519278097689693 - loss = 0.039371675346046686
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:15,828 INFO epoch # 758 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00048519278097689693-> 0.00048519278097689693 - loss = 0.04740450903773308
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:15,978 INFO epoch # 759 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00048519278097689693-> 0.00048519278097689693 - loss = 0.03139540133997798
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:16,128 INFO epoch # 760 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00048519278097689693-> 0.00048519278097689693 - loss = 0.04052753373980522
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:59:16,128 INFO *** epoch 760, rolling-avg-loss (window=10)= 0.042719553923234344
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:16,279 INFO epoch # 761 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00048519278097689693-> 0.00048519278097689693 - loss = 0.03603195957839489
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:16,429 INFO epoch # 762 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00048519278097689693-> 0.00048519278097689693 - loss = 0.03755710832774639
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:16,579 INFO epoch # 763 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00048519278097689693-> 0.00048519278097689693 - loss = 0.038008956238627434
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:16,730 INFO epoch # 764 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00048519278097689693-> 0.00048519278097689693 - loss = 0.03885366627946496
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:16,880 INFO epoch # 765 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00048519278097689693-> 0.00048519278097689693 - loss = 0.03572485409677029
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:17,031 INFO epoch # 766 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00048519278097689693-> 0.00043667350287920724 - loss = 0.03017171286046505
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:17,181 INFO epoch # 767 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00043667350287920724-> 0.00043667350287920724 - loss = 0.05087165138684213
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:17,331 INFO epoch # 768 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00043667350287920724-> 0.00043667350287920724 - loss = 0.09621710190549493
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:17,481 INFO epoch # 769 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00043667350287920724-> 0.00043667350287920724 - loss = 0.04861353896558285
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:17,632 INFO epoch # 770 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00043667350287920724-> 0.00043667350287920724 - loss = 0.03850667690858245
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:59:17,632 INFO *** epoch 770, rolling-avg-loss (window=10)= 0.04505572265479714
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:17,782 INFO epoch # 771 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00043667350287920724-> 0.00043667350287920724 - loss = 0.06444133445620537
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:17,932 INFO epoch # 772 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00043667350287920724-> 0.00043667350287920724 - loss = 0.045854947064071894
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:18,083 INFO epoch # 773 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00043667350287920724-> 0.00043667350287920724 - loss = 0.0365960281342268
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:18,234 INFO epoch # 774 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00043667350287920724-> 0.00043667350287920724 - loss = 0.07386190677061677
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:18,384 INFO epoch # 775 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00043667350287920724-> 0.00043667350287920724 - loss = 0.03746959334239364
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:18,534 INFO epoch # 776 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00043667350287920724-> 0.00043667350287920724 - loss = 0.03159586526453495
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:18,684 INFO epoch # 777 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00043667350287920724-> 0.0003930061525912865 - loss = 0.0362405008636415
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:18,834 INFO epoch # 778 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0003930061525912865-> 0.0003930061525912865 - loss = 0.05399540904909372
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:18,984 INFO epoch # 779 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0003930061525912865-> 0.0003930061525912865 - loss = 0.026756544830277562
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:19,135 INFO epoch # 780 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0003930061525912865-> 0.0003930061525912865 - loss = 0.02581058331998065
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:59:19,135 INFO *** epoch 780, rolling-avg-loss (window=10)= 0.04326227130950429
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:19,286 INFO epoch # 781 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0003930061525912865-> 0.0003930061525912865 - loss = 0.05057530803605914
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:19,435 INFO epoch # 782 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0003930061525912865-> 0.0003930061525912865 - loss = 0.04590151319280267
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:19,586 INFO epoch # 783 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0003930061525912865-> 0.0003930061525912865 - loss = 0.04992624185979366
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:19,736 INFO epoch # 784 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0003930061525912865-> 0.0003930061525912865 - loss = 0.037126467446796596
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:19,887 INFO epoch # 785 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0003930061525912865-> 0.0003930061525912865 - loss = 0.04145338316448033
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:20,042 INFO epoch # 786 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0003930061525912865-> 0.0003930061525912865 - loss = 0.0404033325612545
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:20,192 INFO epoch # 787 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0003930061525912865-> 0.0003930061525912865 - loss = 0.04548099637031555
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:20,342 INFO epoch # 788 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0003930061525912865-> 0.0003537055373321579 - loss = 0.032675135880708694
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:20,493 INFO epoch # 789 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0003537055373321579-> 0.0003537055373321579 - loss = 0.08742902148514986
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:20,644 INFO epoch # 790 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0003537055373321579-> 0.0003537055373321579 - loss = 0.025715985451824963
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:59:20,644 INFO *** epoch 790, rolling-avg-loss (window=10)= 0.0456687385449186
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:20,793 INFO epoch # 791 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0003537055373321579-> 0.0003537055373321579 - loss = 0.028671263717114925
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:20,942 INFO epoch # 792 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0003537055373321579-> 0.0003537055373321579 - loss = 0.037853635381907225
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:21,092 INFO epoch # 793 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0003537055373321579-> 0.0003537055373321579 - loss = 0.07819794118404388
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:21,241 INFO epoch # 794 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0003537055373321579-> 0.0003537055373321579 - loss = 0.03048470849171281
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:21,391 INFO epoch # 795 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0003537055373321579-> 0.0003537055373321579 - loss = 0.053976074792444706
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:21,540 INFO epoch # 796 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0003537055373321579-> 0.0003537055373321579 - loss = 0.08773858333006501
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:21,691 INFO epoch # 797 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0003537055373321579-> 0.0003537055373321579 - loss = 0.05185191077180207
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:21,841 INFO epoch # 798 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0003537055373321579-> 0.0003537055373321579 - loss = 0.05273063667118549
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:21,991 INFO epoch # 799 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0003537055373321579-> 0.00031833498359894213 - loss = 0.04381069540977478
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:22,140 INFO epoch # 800 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00031833498359894213-> 0.00031833498359894213 - loss = 0.06322392215952277
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:59:22,140 INFO *** epoch 800, rolling-avg-loss (window=10)= 0.052853937190957365
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:22,291 INFO epoch # 801 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00031833498359894213-> 0.00031833498359894213 - loss = 0.05623584985733032
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:22,445 INFO epoch # 802 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00031833498359894213-> 0.00031833498359894213 - loss = 0.03789970465004444
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:22,595 INFO epoch # 803 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00031833498359894213-> 0.00031833498359894213 - loss = 0.03913345979526639
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:22,745 INFO epoch # 804 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00031833498359894213-> 0.00031833498359894213 - loss = 0.028107004705816507
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:22,911 INFO epoch # 805 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00031833498359894213-> 0.00031833498359894213 - loss = 0.048705254681408405
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:23,063 INFO epoch # 806 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00031833498359894213-> 0.00031833498359894213 - loss = 0.027340494329109788
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:23,213 INFO epoch # 807 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00031833498359894213-> 0.00031833498359894213 - loss = 0.02488877112045884
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:23,363 INFO epoch # 808 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00031833498359894213-> 0.00031833498359894213 - loss = 0.0257772677578032
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:23,515 INFO epoch # 809 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00031833498359894213-> 0.00031833498359894213 - loss = 0.034085663966834545
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:23,666 INFO epoch # 810 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00031833498359894213-> 0.00028650148523904793 - loss = 0.035835869144648314
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:59:23,666 INFO *** epoch 810, rolling-avg-loss (window=10)= 0.03580093400087207
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:23,816 INFO epoch # 811 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00028650148523904793-> 0.00028650148523904793 - loss = 0.048960212618112564
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:23,967 INFO epoch # 812 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00028650148523904793-> 0.00028650148523904793 - loss = 0.025604636408388615
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:24,117 INFO epoch # 813 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00028650148523904793-> 0.00028650148523904793 - loss = 0.059644979890435934
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:24,270 INFO epoch # 814 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00028650148523904793-> 0.00028650148523904793 - loss = 0.02566249785013497
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:24,423 INFO epoch # 815 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00028650148523904793-> 0.00028650148523904793 - loss = 0.025108554866164923
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:24,573 INFO epoch # 816 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00028650148523904793-> 0.00028650148523904793 - loss = 0.039724310860037804
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:24,723 INFO epoch # 817 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00028650148523904793-> 0.00028650148523904793 - loss = 0.05043322127312422
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:24,873 INFO epoch # 818 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00028650148523904793-> 0.00028650148523904793 - loss = 0.021416713658254594
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:25,022 INFO epoch # 819 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00028650148523904793-> 0.00028650148523904793 - loss = 0.08897857554256916
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:25,173 INFO epoch # 820 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00028650148523904793-> 0.00028650148523904793 - loss = 0.026142842136323452
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:59:25,173 INFO *** epoch 820, rolling-avg-loss (window=10)= 0.041167654510354625
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:25,324 INFO epoch # 821 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00028650148523904793-> 0.00025785133671514315 - loss = 0.024606421124190092
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:25,478 INFO epoch # 822 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00025785133671514315-> 0.00025785133671514315 - loss = 0.039029999636113644
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:25,629 INFO epoch # 823 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00025785133671514315-> 0.00025785133671514315 - loss = 0.03699262230657041
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:25,785 INFO epoch # 824 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00025785133671514315-> 0.00025785133671514315 - loss = 0.02661472698673606
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:25,935 INFO epoch # 825 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00025785133671514315-> 0.00025785133671514315 - loss = 0.03249839507043362
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:26,085 INFO epoch # 826 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00025785133671514315-> 0.00025785133671514315 - loss = 0.02309408679138869
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:26,236 INFO epoch # 827 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00025785133671514315-> 0.00025785133671514315 - loss = 0.03175470419228077
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:26,387 INFO epoch # 828 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00025785133671514315-> 0.00025785133671514315 - loss = 0.1285907868295908
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:26,537 INFO epoch # 829 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00025785133671514315-> 0.00025785133671514315 - loss = 0.03579483274370432
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:26,688 INFO epoch # 830 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00025785133671514315-> 0.00025785133671514315 - loss = 0.037848121486604214
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:59:26,688 INFO *** epoch 830, rolling-avg-loss (window=10)= 0.04168246971676126
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:26,839 INFO epoch # 831 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00025785133671514315-> 0.00025785133671514315 - loss = 0.027630356955341995
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:27,004 INFO epoch # 832 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00025785133671514315-> 0.00023206620304362885 - loss = 0.04279167461208999
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:27,172 INFO epoch # 833 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00023206620304362885-> 0.00023206620304362885 - loss = 0.05236318311654031
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:27,323 INFO epoch # 834 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00023206620304362885-> 0.00023206620304362885 - loss = 0.04925607028417289
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:27,475 INFO epoch # 835 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00023206620304362885-> 0.00023206620304362885 - loss = 0.05522632738575339
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:27,626 INFO epoch # 836 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00023206620304362885-> 0.00023206620304362885 - loss = 0.04010486649349332
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:27,776 INFO epoch # 837 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00023206620304362885-> 0.00023206620304362885 - loss = 0.03099799097981304
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:27,927 INFO epoch # 838 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00023206620304362885-> 0.00023206620304362885 - loss = 0.048079365864396095
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:28,078 INFO epoch # 839 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00023206620304362885-> 0.00023206620304362885 - loss = 0.028690728824585676
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:28,229 INFO epoch # 840 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00023206620304362885-> 0.00023206620304362885 - loss = 0.03279209556058049
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:59:28,229 INFO *** epoch 840, rolling-avg-loss (window=10)= 0.04079326600767672
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:28,381 INFO epoch # 841 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00023206620304362885-> 0.00023206620304362885 - loss = 0.03903432423248887
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:28,531 INFO epoch # 842 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00023206620304362885-> 0.00023206620304362885 - loss = 0.08223634213209152
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:28,682 INFO epoch # 843 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00023206620304362885-> 0.00020885958273926598 - loss = 0.029738154960796237
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:28,833 INFO epoch # 844 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00020885958273926598-> 0.00020885958273926598 - loss = 0.030706726014614105
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:28,984 INFO epoch # 845 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00020885958273926598-> 0.00020885958273926598 - loss = 0.03780295234173536
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:29,135 INFO epoch # 846 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00020885958273926598-> 0.00020885958273926598 - loss = 0.0379251129925251
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:29,284 INFO epoch # 847 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00020885958273926598-> 0.00020885958273926598 - loss = 0.06001271028071642
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:29,435 INFO epoch # 848 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00020885958273926598-> 0.00020885958273926598 - loss = 0.027380996849387884
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:29,585 INFO epoch # 849 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00020885958273926598-> 0.00020885958273926598 - loss = 0.03736187983304262
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:29,736 INFO epoch # 850 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00020885958273926598-> 0.00020885958273926598 - loss = 0.04587583523243666
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:59:29,736 INFO *** epoch 850, rolling-avg-loss (window=10)= 0.04280750348698348
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:29,888 INFO epoch # 851 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00020885958273926598-> 0.00020885958273926598 - loss = 0.05080097168684006
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:30,038 INFO epoch # 852 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00020885958273926598-> 0.00020885958273926598 - loss = 0.048002449329942465
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:30,189 INFO epoch # 853 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00020885958273926598-> 0.00020885958273926598 - loss = 0.025518161477521062
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:30,340 INFO epoch # 854 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00020885958273926598-> 0.00018797362446533938 - loss = 0.042561931535601616
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:30,489 INFO epoch # 855 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00018797362446533938-> 0.00018797362446533938 - loss = 0.03134152898564935
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:30,640 INFO epoch # 856 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00018797362446533938-> 0.00018797362446533938 - loss = 0.02325098612345755
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:30,790 INFO epoch # 857 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00018797362446533938-> 0.00018797362446533938 - loss = 0.025276130065321922
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:30,940 INFO epoch # 858 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00018797362446533938-> 0.00018797362446533938 - loss = 0.03618706809356809
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:31,091 INFO epoch # 859 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00018797362446533938-> 0.00018797362446533938 - loss = 0.02808548044413328
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:31,241 INFO epoch # 860 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00018797362446533938-> 0.00018797362446533938 - loss = 0.0471352469176054
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:59:31,241 INFO *** epoch 860, rolling-avg-loss (window=10)= 0.035815995465964076
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:31,392 INFO epoch # 861 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00018797362446533938-> 0.00018797362446533938 - loss = 0.02695436868816614
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:31,543 INFO epoch # 862 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00018797362446533938-> 0.00018797362446533938 - loss = 0.026782242581248283
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:31,693 INFO epoch # 863 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00018797362446533938-> 0.00018797362446533938 - loss = 0.025799565482884645
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:31,843 INFO epoch # 864 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00018797362446533938-> 0.00018797362446533938 - loss = 0.0319338443223387
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:31,995 INFO epoch # 865 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00018797362446533938-> 0.00016917626201880544 - loss = 0.055960772559046745
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:32,149 INFO epoch # 866 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00016917626201880544-> 0.00016917626201880544 - loss = 0.048337253741919994
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:32,303 INFO epoch # 867 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00016917626201880544-> 0.00016917626201880544 - loss = 0.05238382797688246
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:32,455 INFO epoch # 868 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00016917626201880544-> 0.00016917626201880544 - loss = 0.03199975332245231
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:32,610 INFO epoch # 869 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00016917626201880544-> 0.00016917626201880544 - loss = 0.025675687473267317
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:32,765 INFO epoch # 870 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00016917626201880544-> 0.00016917626201880544 - loss = 0.03942871792241931
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:59:32,765 INFO *** epoch 870, rolling-avg-loss (window=10)= 0.03652560340706259
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:32,914 INFO epoch # 871 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00016917626201880544-> 0.00016917626201880544 - loss = 0.034129969077184796
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:33,064 INFO epoch # 872 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00016917626201880544-> 0.00016917626201880544 - loss = 0.029788727639243007
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:33,214 INFO epoch # 873 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00016917626201880544-> 0.00016917626201880544 - loss = 0.028823272790759802
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:33,365 INFO epoch # 874 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00016917626201880544-> 0.00016917626201880544 - loss = 0.04511637729592621
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:33,520 INFO epoch # 875 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00016917626201880544-> 0.00016917626201880544 - loss = 0.030399351380765438
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:33,670 INFO epoch # 876 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00016917626201880544-> 0.00015225863581692489 - loss = 0.028649299405515194
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:33,830 INFO epoch # 877 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00015225863581692489-> 0.00015225863581692489 - loss = 0.029722829815000296
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:33,986 INFO epoch # 878 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00015225863581692489-> 0.00015225863581692489 - loss = 0.034267236944288015
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:34,135 INFO epoch # 879 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00015225863581692489-> 0.00015225863581692489 - loss = 0.028078013216145337
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:34,284 INFO epoch # 880 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00015225863581692489-> 0.00015225863581692489 - loss = 0.03301713429391384
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:59:34,284 INFO *** epoch 880, rolling-avg-loss (window=10)= 0.03219922118587419
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:34,435 INFO epoch # 881 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00015225863581692489-> 0.00015225863581692489 - loss = 0.03166112257167697
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:34,585 INFO epoch # 882 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00015225863581692489-> 0.00015225863581692489 - loss = 0.043441761285066605
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:34,735 INFO epoch # 883 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00015225863581692489-> 0.00015225863581692489 - loss = 0.05984620563685894
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:34,885 INFO epoch # 884 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00015225863581692489-> 0.00015225863581692489 - loss = 0.03544530272483826
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:35,035 INFO epoch # 885 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00015225863581692489-> 0.00015225863581692489 - loss = 0.027397651225328445
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:35,185 INFO epoch # 886 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00015225863581692489-> 0.00015225863581692489 - loss = 0.03254333604127169
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:35,334 INFO epoch # 887 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00015225863581692489-> 0.0001370327722352324 - loss = 0.04471493512392044
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:35,484 INFO epoch # 888 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0001370327722352324-> 0.0001370327722352324 - loss = 0.059747799299657345
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:35,634 INFO epoch # 889 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0001370327722352324-> 0.0001370327722352324 - loss = 0.028437124099582434
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:35,785 INFO epoch # 890 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0001370327722352324-> 0.0001370327722352324 - loss = 0.07138395891524851
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:59:35,785 INFO *** epoch 890, rolling-avg-loss (window=10)= 0.04346191969234496
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:35,935 INFO epoch # 891 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0001370327722352324-> 0.0001370327722352324 - loss = 0.026924410136416554
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:36,085 INFO epoch # 892 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0001370327722352324-> 0.0001370327722352324 - loss = 0.04381360067054629
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:36,236 INFO epoch # 893 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0001370327722352324-> 0.0001370327722352324 - loss = 0.05218251654878259
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:36,387 INFO epoch # 894 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0001370327722352324-> 0.0001370327722352324 - loss = 0.040266182739287615
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:36,539 INFO epoch # 895 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0001370327722352324-> 0.0001370327722352324 - loss = 0.030037969816476107
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:36,689 INFO epoch # 896 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0001370327722352324-> 0.0001370327722352324 - loss = 0.035283982986584306
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:36,839 INFO epoch # 897 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0001370327722352324-> 0.0001370327722352324 - loss = 0.029149954672902822
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:36,990 INFO epoch # 898 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0001370327722352324-> 0.00012332949501170915 - loss = 0.041571032255887985
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:37,141 INFO epoch # 899 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00012332949501170915-> 0.00012332949501170915 - loss = 0.03249299805611372
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:37,291 INFO epoch # 900 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00012332949501170915-> 0.00012332949501170915 - loss = 0.03448110376484692
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:59:37,291 INFO *** epoch 900, rolling-avg-loss (window=10)= 0.03662037516478449
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:37,442 INFO epoch # 901 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00012332949501170915-> 0.00012332949501170915 - loss = 0.03884500544518232
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:37,594 INFO epoch # 902 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00012332949501170915-> 0.00012332949501170915 - loss = 0.05751257250085473
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:37,744 INFO epoch # 903 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00012332949501170915-> 0.00012332949501170915 - loss = 0.02282647881656885
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:37,894 INFO epoch # 904 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00012332949501170915-> 0.00012332949501170915 - loss = 0.03028112812899053
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:38,046 INFO epoch # 905 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00012332949501170915-> 0.00012332949501170915 - loss = 0.025508380495011806
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:38,200 INFO epoch # 906 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00012332949501170915-> 0.00012332949501170915 - loss = 0.0373395555652678
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:38,354 INFO epoch # 907 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00012332949501170915-> 0.00012332949501170915 - loss = 0.02823504013940692
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:38,509 INFO epoch # 908 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00012332949501170915-> 0.00012332949501170915 - loss = 0.031943079782649875
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:38,659 INFO epoch # 909 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00012332949501170915-> 0.00011099654551053824 - loss = 0.06457189843058586
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:38,811 INFO epoch # 910 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00011099654551053824-> 0.00011099654551053824 - loss = 0.06671930151060224
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:59:38,812 INFO *** epoch 910, rolling-avg-loss (window=10)= 0.040378244081512096
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:38,973 INFO epoch # 911 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00011099654551053824-> 0.00011099654551053824 - loss = 0.02949523227289319
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:39,124 INFO epoch # 912 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00011099654551053824-> 0.00011099654551053824 - loss = 0.029428815934807062
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:39,275 INFO epoch # 913 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00011099654551053824-> 0.00011099654551053824 - loss = 0.04284837003797293
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:39,427 INFO epoch # 914 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00011099654551053824-> 0.00011099654551053824 - loss = 0.0415967651642859
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:39,577 INFO epoch # 915 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00011099654551053824-> 0.00011099654551053824 - loss = 0.03527434263378382
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:39,727 INFO epoch # 916 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00011099654551053824-> 0.00011099654551053824 - loss = 0.03829057328402996
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:39,877 INFO epoch # 917 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00011099654551053824-> 0.00011099654551053824 - loss = 0.04721606196835637
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:40,027 INFO epoch # 918 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00011099654551053824-> 0.00011099654551053824 - loss = 0.026221076026558876
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:40,177 INFO epoch # 919 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00011099654551053824-> 0.00011099654551053824 - loss = 0.026523099280893803
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:40,328 INFO epoch # 920 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00011099654551053824-> 9.989689095948442e-05 - loss = 0.03197000967338681
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:59:40,328 INFO *** epoch 920, rolling-avg-loss (window=10)= 0.034886434627696875
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:40,478 INFO epoch # 921 - for optimizer <class 'torch.optim.adam.Adam'> lr : 9.989689095948442e-05-> 9.989689095948442e-05 - loss = 0.05965201137587428
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:40,629 INFO epoch # 922 - for optimizer <class 'torch.optim.adam.Adam'> lr : 9.989689095948442e-05-> 9.989689095948442e-05 - loss = 0.04274002416059375
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:40,778 INFO epoch # 923 - for optimizer <class 'torch.optim.adam.Adam'> lr : 9.989689095948442e-05-> 9.989689095948442e-05 - loss = 0.054746903479099274
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:40,928 INFO epoch # 924 - for optimizer <class 'torch.optim.adam.Adam'> lr : 9.989689095948442e-05-> 9.989689095948442e-05 - loss = 0.06358342058956623
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:41,080 INFO epoch # 925 - for optimizer <class 'torch.optim.adam.Adam'> lr : 9.989689095948442e-05-> 9.989689095948442e-05 - loss = 0.03838490089401603
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:41,230 INFO epoch # 926 - for optimizer <class 'torch.optim.adam.Adam'> lr : 9.989689095948442e-05-> 9.989689095948442e-05 - loss = 0.021140021039173007
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:41,380 INFO epoch # 927 - for optimizer <class 'torch.optim.adam.Adam'> lr : 9.989689095948442e-05-> 9.989689095948442e-05 - loss = 0.02773114526644349
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:41,530 INFO epoch # 928 - for optimizer <class 'torch.optim.adam.Adam'> lr : 9.989689095948442e-05-> 9.989689095948442e-05 - loss = 0.035815306939184666
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:41,681 INFO epoch # 929 - for optimizer <class 'torch.optim.adam.Adam'> lr : 9.989689095948442e-05-> 9.989689095948442e-05 - loss = 0.042103835847228765
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:41,831 INFO epoch # 930 - for optimizer <class 'torch.optim.adam.Adam'> lr : 9.989689095948442e-05-> 9.989689095948442e-05 - loss = 0.03402160620316863
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:59:41,831 INFO *** epoch 930, rolling-avg-loss (window=10)= 0.04199191757943481
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:41,984 INFO epoch # 931 - for optimizer <class 'torch.optim.adam.Adam'> lr : 9.989689095948442e-05-> 9.989689095948442e-05 - loss = 0.026684238575398922
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:42,140 INFO epoch # 932 - for optimizer <class 'torch.optim.adam.Adam'> lr : 9.989689095948442e-05-> 9.989689095948442e-05 - loss = 0.038304598070681095
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:42,290 INFO epoch # 933 - for optimizer <class 'torch.optim.adam.Adam'> lr : 9.989689095948442e-05-> 9.989689095948442e-05 - loss = 0.03464167262427509
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:42,440 INFO epoch # 934 - for optimizer <class 'torch.optim.adam.Adam'> lr : 9.989689095948442e-05-> 9.989689095948442e-05 - loss = 0.02964949607849121
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:42,592 INFO epoch # 935 - for optimizer <class 'torch.optim.adam.Adam'> lr : 9.989689095948442e-05-> 9.989689095948442e-05 - loss = 0.04198601562529802
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:42,742 INFO epoch # 936 - for optimizer <class 'torch.optim.adam.Adam'> lr : 9.989689095948442e-05-> 9.989689095948442e-05 - loss = 0.05253870761953294
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:42,893 INFO epoch # 937 - for optimizer <class 'torch.optim.adam.Adam'> lr : 9.989689095948442e-05-> 8.990720186353598e-05 - loss = 0.03534968919120729
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:43,043 INFO epoch # 938 - for optimizer <class 'torch.optim.adam.Adam'> lr : 8.990720186353598e-05-> 8.990720186353598e-05 - loss = 0.02750215376727283
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:43,193 INFO epoch # 939 - for optimizer <class 'torch.optim.adam.Adam'> lr : 8.990720186353598e-05-> 8.990720186353598e-05 - loss = 0.09091282309964299
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:43,342 INFO epoch # 940 - for optimizer <class 'torch.optim.adam.Adam'> lr : 8.990720186353598e-05-> 8.990720186353598e-05 - loss = 0.03530116192996502
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:59:43,343 INFO *** epoch 940, rolling-avg-loss (window=10)= 0.041287055658176544
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:43,492 INFO epoch # 941 - for optimizer <class 'torch.optim.adam.Adam'> lr : 8.990720186353598e-05-> 8.990720186353598e-05 - loss = 0.02573125623166561
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:43,642 INFO epoch # 942 - for optimizer <class 'torch.optim.adam.Adam'> lr : 8.990720186353598e-05-> 8.990720186353598e-05 - loss = 0.021899903658777475
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:43,793 INFO epoch # 943 - for optimizer <class 'torch.optim.adam.Adam'> lr : 8.990720186353598e-05-> 8.990720186353598e-05 - loss = 0.07002964802086353
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:43,944 INFO epoch # 944 - for optimizer <class 'torch.optim.adam.Adam'> lr : 8.990720186353598e-05-> 8.990720186353598e-05 - loss = 0.020023316727019846
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:44,093 INFO epoch # 945 - for optimizer <class 'torch.optim.adam.Adam'> lr : 8.990720186353598e-05-> 8.990720186353598e-05 - loss = 0.028587553650140762
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:44,244 INFO epoch # 946 - for optimizer <class 'torch.optim.adam.Adam'> lr : 8.990720186353598e-05-> 8.990720186353598e-05 - loss = 0.029362716421019286
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:44,393 INFO epoch # 947 - for optimizer <class 'torch.optim.adam.Adam'> lr : 8.990720186353598e-05-> 8.990720186353598e-05 - loss = 0.021052902564406395
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:44,544 INFO epoch # 948 - for optimizer <class 'torch.optim.adam.Adam'> lr : 8.990720186353598e-05-> 8.990720186353598e-05 - loss = 0.03856838680803776
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:44,694 INFO epoch # 949 - for optimizer <class 'torch.optim.adam.Adam'> lr : 8.990720186353598e-05-> 8.990720186353598e-05 - loss = 0.05040253233164549
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:44,854 INFO epoch # 950 - for optimizer <class 'torch.optim.adam.Adam'> lr : 8.990720186353598e-05-> 8.990720186353598e-05 - loss = 0.054919891990721226
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:59:44,854 INFO *** epoch 950, rolling-avg-loss (window=10)= 0.036057810840429735
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:45,005 INFO epoch # 951 - for optimizer <class 'torch.optim.adam.Adam'> lr : 8.990720186353598e-05-> 8.990720186353598e-05 - loss = 0.024857159238308668
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:45,158 INFO epoch # 952 - for optimizer <class 'torch.optim.adam.Adam'> lr : 8.990720186353598e-05-> 8.990720186353598e-05 - loss = 0.06288532679900527
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:45,308 INFO epoch # 953 - for optimizer <class 'torch.optim.adam.Adam'> lr : 8.990720186353598e-05-> 8.990720186353598e-05 - loss = 0.040768774691969156
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:45,462 INFO epoch # 954 - for optimizer <class 'torch.optim.adam.Adam'> lr : 8.990720186353598e-05-> 8.990720186353598e-05 - loss = 0.048439473612233996
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:45,612 INFO epoch # 955 - for optimizer <class 'torch.optim.adam.Adam'> lr : 8.990720186353598e-05-> 8.091648167718239e-05 - loss = 0.0494178868830204
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:45,762 INFO epoch # 956 - for optimizer <class 'torch.optim.adam.Adam'> lr : 8.091648167718239e-05-> 8.091648167718239e-05 - loss = 0.031585581600666046
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:45,913 INFO epoch # 957 - for optimizer <class 'torch.optim.adam.Adam'> lr : 8.091648167718239e-05-> 8.091648167718239e-05 - loss = 0.05264940299093723
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:46,064 INFO epoch # 958 - for optimizer <class 'torch.optim.adam.Adam'> lr : 8.091648167718239e-05-> 8.091648167718239e-05 - loss = 0.04142667539417744
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:46,214 INFO epoch # 959 - for optimizer <class 'torch.optim.adam.Adam'> lr : 8.091648167718239e-05-> 8.091648167718239e-05 - loss = 0.026503484696149826
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:46,365 INFO epoch # 960 - for optimizer <class 'torch.optim.adam.Adam'> lr : 8.091648167718239e-05-> 8.091648167718239e-05 - loss = 0.0244341284269467
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:59:46,365 INFO *** epoch 960, rolling-avg-loss (window=10)= 0.04029678943334147
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:46,518 INFO epoch # 961 - for optimizer <class 'torch.optim.adam.Adam'> lr : 8.091648167718239e-05-> 8.091648167718239e-05 - loss = 0.06534985406324267
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:46,668 INFO epoch # 962 - for optimizer <class 'torch.optim.adam.Adam'> lr : 8.091648167718239e-05-> 8.091648167718239e-05 - loss = 0.052892154548317194
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:46,819 INFO epoch # 963 - for optimizer <class 'torch.optim.adam.Adam'> lr : 8.091648167718239e-05-> 8.091648167718239e-05 - loss = 0.04452715814113617
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:46,970 INFO epoch # 964 - for optimizer <class 'torch.optim.adam.Adam'> lr : 8.091648167718239e-05-> 8.091648167718239e-05 - loss = 0.04210303770378232
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:47,120 INFO epoch # 965 - for optimizer <class 'torch.optim.adam.Adam'> lr : 8.091648167718239e-05-> 8.091648167718239e-05 - loss = 0.05805632332339883
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:47,271 INFO epoch # 966 - for optimizer <class 'torch.optim.adam.Adam'> lr : 8.091648167718239e-05-> 7.282483350946415e-05 - loss = 0.03285542828962207
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:47,421 INFO epoch # 967 - for optimizer <class 'torch.optim.adam.Adam'> lr : 7.282483350946415e-05-> 7.282483350946415e-05 - loss = 0.026117694680579007
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:47,574 INFO epoch # 968 - for optimizer <class 'torch.optim.adam.Adam'> lr : 7.282483350946415e-05-> 7.282483350946415e-05 - loss = 0.06323096575215459
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:47,724 INFO epoch # 969 - for optimizer <class 'torch.optim.adam.Adam'> lr : 7.282483350946415e-05-> 7.282483350946415e-05 - loss = 0.05558990244753659
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:47,877 INFO epoch # 970 - for optimizer <class 'torch.optim.adam.Adam'> lr : 7.282483350946415e-05-> 7.282483350946415e-05 - loss = 0.05574809666723013
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:59:47,877 INFO *** epoch 970, rolling-avg-loss (window=10)= 0.04964706156169996
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:48,027 INFO epoch # 971 - for optimizer <class 'torch.optim.adam.Adam'> lr : 7.282483350946415e-05-> 7.282483350946415e-05 - loss = 0.07170432014390826
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:48,177 INFO epoch # 972 - for optimizer <class 'torch.optim.adam.Adam'> lr : 7.282483350946415e-05-> 7.282483350946415e-05 - loss = 0.02649149135686457
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:48,328 INFO epoch # 973 - for optimizer <class 'torch.optim.adam.Adam'> lr : 7.282483350946415e-05-> 7.282483350946415e-05 - loss = 0.02866937592625618
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:48,479 INFO epoch # 974 - for optimizer <class 'torch.optim.adam.Adam'> lr : 7.282483350946415e-05-> 7.282483350946415e-05 - loss = 0.03075540065765381
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:48,629 INFO epoch # 975 - for optimizer <class 'torch.optim.adam.Adam'> lr : 7.282483350946415e-05-> 7.282483350946415e-05 - loss = 0.05974877160042524
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:48,782 INFO epoch # 976 - for optimizer <class 'torch.optim.adam.Adam'> lr : 7.282483350946415e-05-> 7.282483350946415e-05 - loss = 0.03111180430278182
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:48,933 INFO epoch # 977 - for optimizer <class 'torch.optim.adam.Adam'> lr : 7.282483350946415e-05-> 6.554235015851773e-05 - loss = 0.027357014478184283
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:49,084 INFO epoch # 978 - for optimizer <class 'torch.optim.adam.Adam'> lr : 6.554235015851773e-05-> 6.554235015851773e-05 - loss = 0.057321395026519895
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:49,235 INFO epoch # 979 - for optimizer <class 'torch.optim.adam.Adam'> lr : 6.554235015851773e-05-> 6.554235015851773e-05 - loss = 0.07388858404010534
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:49,385 INFO epoch # 980 - for optimizer <class 'torch.optim.adam.Adam'> lr : 6.554235015851773e-05-> 6.554235015851773e-05 - loss = 0.026532421354204416
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:59:49,386 INFO *** epoch 980, rolling-avg-loss (window=10)= 0.043358057888690384
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:49,536 INFO epoch # 981 - for optimizer <class 'torch.optim.adam.Adam'> lr : 6.554235015851773e-05-> 6.554235015851773e-05 - loss = 0.03576517850160599
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:49,687 INFO epoch # 982 - for optimizer <class 'torch.optim.adam.Adam'> lr : 6.554235015851773e-05-> 6.554235015851773e-05 - loss = 0.03867107164114714
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:49,837 INFO epoch # 983 - for optimizer <class 'torch.optim.adam.Adam'> lr : 6.554235015851773e-05-> 6.554235015851773e-05 - loss = 0.02666762680746615
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:49,987 INFO epoch # 984 - for optimizer <class 'torch.optim.adam.Adam'> lr : 6.554235015851773e-05-> 6.554235015851773e-05 - loss = 0.03989749448373914
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:50,138 INFO epoch # 985 - for optimizer <class 'torch.optim.adam.Adam'> lr : 6.554235015851773e-05-> 6.554235015851773e-05 - loss = 0.04713050089776516
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:50,289 INFO epoch # 986 - for optimizer <class 'torch.optim.adam.Adam'> lr : 6.554235015851773e-05-> 6.554235015851773e-05 - loss = 0.06343498826026917
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:50,440 INFO epoch # 987 - for optimizer <class 'torch.optim.adam.Adam'> lr : 6.554235015851773e-05-> 6.554235015851773e-05 - loss = 0.04785897536203265
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:50,590 INFO epoch # 988 - for optimizer <class 'torch.optim.adam.Adam'> lr : 6.554235015851773e-05-> 5.898811514266596e-05 - loss = 0.029023457318544388
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:50,743 INFO epoch # 989 - for optimizer <class 'torch.optim.adam.Adam'> lr : 5.898811514266596e-05-> 5.898811514266596e-05 - loss = 0.03946557501330972
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:50,898 INFO epoch # 990 - for optimizer <class 'torch.optim.adam.Adam'> lr : 5.898811514266596e-05-> 5.898811514266596e-05 - loss = 0.025744491256773472
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:59:50,898 INFO *** epoch 990, rolling-avg-loss (window=10)= 0.039365935954265296
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:51,052 INFO epoch # 991 - for optimizer <class 'torch.optim.adam.Adam'> lr : 5.898811514266596e-05-> 5.898811514266596e-05 - loss = 0.03665469121187925
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:51,209 INFO epoch # 992 - for optimizer <class 'torch.optim.adam.Adam'> lr : 5.898811514266596e-05-> 5.898811514266596e-05 - loss = 0.05407429672777653
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:51,367 INFO epoch # 993 - for optimizer <class 'torch.optim.adam.Adam'> lr : 5.898811514266596e-05-> 5.898811514266596e-05 - loss = 0.028795194812119007
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:51,523 INFO epoch # 994 - for optimizer <class 'torch.optim.adam.Adam'> lr : 5.898811514266596e-05-> 5.898811514266596e-05 - loss = 0.07238049758598208
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:51,673 INFO epoch # 995 - for optimizer <class 'torch.optim.adam.Adam'> lr : 5.898811514266596e-05-> 5.898811514266596e-05 - loss = 0.03626382164657116
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:51,823 INFO epoch # 996 - for optimizer <class 'torch.optim.adam.Adam'> lr : 5.898811514266596e-05-> 5.898811514266596e-05 - loss = 0.03671323508024216
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:51,973 INFO epoch # 997 - for optimizer <class 'torch.optim.adam.Adam'> lr : 5.898811514266596e-05-> 5.898811514266596e-05 - loss = 0.026708535384386778
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:52,124 INFO epoch # 998 - for optimizer <class 'torch.optim.adam.Adam'> lr : 5.898811514266596e-05-> 5.898811514266596e-05 - loss = 0.03435098007321358
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:52,274 INFO epoch # 999 - for optimizer <class 'torch.optim.adam.Adam'> lr : 5.898811514266596e-05-> 5.3089303628399366e-05 - loss = 0.027155850548297167
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:59:52,424 INFO epoch # 1000 - for optimizer <class 'torch.optim.adam.Adam'> lr : 5.3089303628399366e-05-> 5.3089303628399366e-05 - loss = 0.026949464343488216
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:59:52,425 INFO *** epoch 1000, rolling-avg-loss (window=10)= 0.038004656741395595
[experiments_sandbox.py:572 -   <module>()] 2023-04-22 02:59:52,425 INFO training time in seconds = 153
[experiments_sandbox.py:576 -   <module>()] 2023-04-22 02:59:52,425 INFO epochs-loss curve df :
[experiments_sandbox.py:577 -   <module>()] 2023-04-22 02:59:52,430 INFO 
    epochs  rolling-avg-loss
0       10          0.119768
1       20          0.084095
2       30          0.103351
3       40          0.075472
4       50          0.064183
5       60          0.111867
6       70          0.121878
7       80          0.076108
8       90          0.056205
9      100          0.116611
10     110          0.072418
11     120          0.057015
12     130          0.060512
13     140          0.090374
14     150          0.077291
15     160          0.073330
16     170          0.055250
17     180          0.048152
18     190          0.044121
19     200          0.045938
20     210          0.066928
21     220          0.047832
22     230          0.054403
23     240          0.050801
24     250          0.031977
25     260          0.044293
26     270          0.044164
27     280          0.049024
28     290          0.045605
29     300          0.044725
30     310          0.053750
31     320          0.052971
32     330          0.056391
33     340          0.039795
34     350          0.044749
35     360          0.035901
36     370          0.049864
37     380          0.045835
38     390          0.037871
39     400          0.037982
40     410          0.048964
41     420          0.053565
42     430          0.033535
43     440          0.047468
44     450          0.042298
45     460          0.037154
46     470          0.038387
47     480          0.037223
48     490          0.040938
49     500          0.047173
50     510          0.034639
51     520          0.056435
52     530          0.044311
53     540          0.047211
54     550          0.034420
55     560          0.039798
56     570          0.037047
57     580          0.040833
58     590          0.047849
59     600          0.038651
60     610          0.038926
61     620          0.040051
62     630          0.043338
63     640          0.036683
64     650          0.044632
65     660          0.034259
66     670          0.050826
67     680          0.048776
68     690          0.049109
69     700          0.043232
70     710          0.041187
71     720          0.045278
72     730          0.038667
73     740          0.034965
74     750          0.038878
75     760          0.042720
76     770          0.045056
77     780          0.043262
78     790          0.045669
79     800          0.052854
80     810          0.035801
81     820          0.041168
82     830          0.041682
83     840          0.040793
84     850          0.042808
85     860          0.035816
86     870          0.036526
87     880          0.032199
88     890          0.043462
89     900          0.036620
90     910          0.040378
91     920          0.034886
92     930          0.041992
93     940          0.041287
94     950          0.036058
95     960          0.040297
96     970          0.049647
97     980          0.043358
98     990          0.039366
99    1000          0.038005
