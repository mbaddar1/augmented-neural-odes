[experiments_sandbox.py:440 -   <module>()] 2023-04-22 02:19:02,763 INFO SEED = 42
[experiments_sandbox.py:492 -   <module>()] 2023-04-22 02:19:02,764 INFO model = 
*** NNmodel 
 Sequential(
  (0): Linear(in_features=2, out_features=50, bias=True)
  (1): Tanh()
  (2): Linear(in_features=50, out_features=1, bias=True)
)
numel_learnable = 201
***
[experiments_sandbox.py:493 -   <module>()] 2023-04-22 02:19:02,764 INFO optimizer  = Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: False
    lr: 0.3
    maximize: False
    weight_decay: 0
)
[experiments_sandbox.py:500 -   <module>()] 2023-04-22 02:19:02,764 INFO lr_scheduler = <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7f3505e78d00>
[experiments_sandbox.py:509 -   <module>()] 2023-04-22 02:19:02,765 INFO data = <__main__.ToyData1 object at 0x7f3505e78d30>
[experiments_sandbox.py:510 -   <module>()] 2023-04-22 02:19:02,765 INFO epochs = 1000
[experiments_sandbox.py:514 -   <module>()] 2023-04-22 02:19:02,765 INFO epochs_losses_window = 10
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:04,470 INFO epoch # 0 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.3-> 0.3 - loss = 90.8068984746933
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:04,594 INFO epoch # 1 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.3-> 0.3 - loss = 35.53418576717377
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:04,718 INFO epoch # 2 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.3-> 0.3 - loss = 19.335918068885803
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:04,842 INFO epoch # 3 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.3-> 0.3 - loss = 15.736950039863586
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:04,966 INFO epoch # 4 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.3-> 0.3 - loss = 11.289352059364319
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:05,088 INFO epoch # 5 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.3-> 0.3 - loss = 4.985940456390381
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:05,212 INFO epoch # 6 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.3-> 0.3 - loss = 3.19475756585598
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:05,339 INFO epoch # 7 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.3-> 0.3 - loss = 3.9403426945209503
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:05,462 INFO epoch # 8 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.3-> 0.3 - loss = 1.8416918143630028
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:05,586 INFO epoch # 9 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.3-> 0.3 - loss = 0.7813325542956591
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:05,711 INFO epoch # 10 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.3-> 0.3 - loss = 0.8838038705289364
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:19:05,711 INFO *** epoch 10, rolling-avg-loss (window=10)= 9.752427489124239
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:05,834 INFO epoch # 11 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.3-> 0.3 - loss = 0.6739820763468742
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:05,987 INFO epoch # 12 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.3-> 0.3 - loss = 0.2682279124855995
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:06,111 INFO epoch # 13 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.3-> 0.3 - loss = 0.18205108679831028
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:06,234 INFO epoch # 14 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.3-> 0.3 - loss = 0.17897166684269905
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:06,357 INFO epoch # 15 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.3-> 0.3 - loss = 0.15910772373899817
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:06,481 INFO epoch # 16 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.3-> 0.3 - loss = 0.06474341684952378
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:06,604 INFO epoch # 17 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.3-> 0.3 - loss = 0.026040302822366357
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:06,726 INFO epoch # 18 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.3-> 0.3 - loss = 0.03735410957597196
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:06,850 INFO epoch # 19 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.3-> 0.3 - loss = 0.044595696963369846
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:06,975 INFO epoch # 20 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.3-> 0.3 - loss = 0.05016524624079466
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:19:06,975 INFO *** epoch 20, rolling-avg-loss (window=10)= 0.1685239238664508
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:07,105 INFO epoch # 21 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.3-> 0.3 - loss = 0.03185177315026522
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:07,229 INFO epoch # 22 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.3-> 0.3 - loss = 0.014888119185343385
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:07,352 INFO epoch # 23 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.3-> 0.3 - loss = 0.017347424407489598
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:07,474 INFO epoch # 24 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.3-> 0.3 - loss = 0.011426636250689626
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:07,602 INFO epoch # 25 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.3-> 0.3 - loss = 0.020418461179360747
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:07,724 INFO epoch # 26 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.3-> 0.3 - loss = 0.00657307100482285
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:07,848 INFO epoch # 27 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.3-> 0.3 - loss = 0.007687603938393295
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:07,971 INFO epoch # 28 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.3-> 0.3 - loss = 0.009167360491119325
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:08,093 INFO epoch # 29 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.3-> 0.3 - loss = 0.010601176880300045
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:08,216 INFO epoch # 30 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.3-> 0.3 - loss = 0.0037300284020602703
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:19:08,217 INFO *** epoch 30, rolling-avg-loss (window=10)= 0.013369165488984435
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:08,338 INFO epoch # 31 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.3-> 0.3 - loss = 0.00484367337776348
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:08,461 INFO epoch # 32 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.3-> 0.3 - loss = 0.007332257810048759
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:08,589 INFO epoch # 33 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.3-> 0.3 - loss = 0.00932824402116239
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:08,712 INFO epoch # 34 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.3-> 0.3 - loss = 0.006886088929604739
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:08,846 INFO epoch # 35 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.3-> 0.3 - loss = 0.011344372935127467
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:08,984 INFO epoch # 36 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.3-> 0.3 - loss = 0.005477767961565405
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:09,123 INFO epoch # 37 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.3-> 0.3 - loss = 0.004895930644124746
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:09,263 INFO epoch # 38 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.3-> 0.3 - loss = 0.008295786450617015
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:09,384 INFO epoch # 39 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.3-> 0.3 - loss = 0.01106690865708515
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:09,508 INFO epoch # 40 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.3-> 0.3 - loss = 0.01442288316320628
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:19:09,508 INFO *** epoch 40, rolling-avg-loss (window=10)= 0.008389391395030543
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:09,630 INFO epoch # 41 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.3-> 0.27 - loss = 0.006424758466891944
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:09,754 INFO epoch # 42 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.27-> 0.27 - loss = 0.008761784643866122
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:09,878 INFO epoch # 43 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.27-> 0.27 - loss = 0.005337770679034293
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:10,003 INFO epoch # 44 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.27-> 0.27 - loss = 0.01164280972443521
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:10,126 INFO epoch # 45 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.27-> 0.27 - loss = 0.004693837050581351
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:10,250 INFO epoch # 46 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.27-> 0.27 - loss = 0.005420625908300281
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:10,372 INFO epoch # 47 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.27-> 0.27 - loss = 0.00887165660969913
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:10,494 INFO epoch # 48 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.27-> 0.27 - loss = 0.00795719027519226
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:10,616 INFO epoch # 49 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.27-> 0.27 - loss = 0.006251228041946888
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:10,739 INFO epoch # 50 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.27-> 0.27 - loss = 0.007097962079569697
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:19:10,739 INFO *** epoch 50, rolling-avg-loss (window=10)= 0.007245962347951718
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:10,862 INFO epoch # 51 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.27-> 0.27 - loss = 0.004655227705370635
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:10,984 INFO epoch # 52 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.27-> 0.24300000000000002 - loss = 0.00535087677417323
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:11,106 INFO epoch # 53 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.24300000000000002-> 0.24300000000000002 - loss = 0.004794520209543407
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:11,229 INFO epoch # 54 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.24300000000000002-> 0.24300000000000002 - loss = 0.007713635335676372
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:11,352 INFO epoch # 55 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.24300000000000002-> 0.24300000000000002 - loss = 0.005238048848696053
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:11,476 INFO epoch # 56 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.24300000000000002-> 0.24300000000000002 - loss = 0.007130174082703888
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:11,598 INFO epoch # 57 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.24300000000000002-> 0.24300000000000002 - loss = 0.003151171753415838
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:11,721 INFO epoch # 58 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.24300000000000002-> 0.24300000000000002 - loss = 0.005607781873550266
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:11,843 INFO epoch # 59 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.24300000000000002-> 0.24300000000000002 - loss = 0.003034139168448746
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:11,966 INFO epoch # 60 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.24300000000000002-> 0.24300000000000002 - loss = 0.003796472039539367
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:19:11,966 INFO *** epoch 60, rolling-avg-loss (window=10)= 0.00504720477911178
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:12,104 INFO epoch # 61 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.24300000000000002-> 0.24300000000000002 - loss = 0.002719163312576711
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:12,250 INFO epoch # 62 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.24300000000000002-> 0.24300000000000002 - loss = 0.006152142683276907
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:12,391 INFO epoch # 63 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.24300000000000002-> 0.24300000000000002 - loss = 0.0024408517383562867
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:12,514 INFO epoch # 64 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.24300000000000002-> 0.24300000000000002 - loss = 0.005788739013951272
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:12,639 INFO epoch # 65 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.24300000000000002-> 0.24300000000000002 - loss = 0.0032984415302053094
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:12,762 INFO epoch # 66 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.24300000000000002-> 0.24300000000000002 - loss = 0.003914935747161508
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:12,884 INFO epoch # 67 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.24300000000000002-> 0.24300000000000002 - loss = 0.0040306851151399314
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:13,008 INFO epoch # 68 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.24300000000000002-> 0.24300000000000002 - loss = 0.0034420525771565735
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:13,131 INFO epoch # 69 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.24300000000000002-> 0.24300000000000002 - loss = 0.006494315515737981
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:13,254 INFO epoch # 70 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.24300000000000002-> 0.24300000000000002 - loss = 0.0048720003687776625
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:19:13,254 INFO *** epoch 70, rolling-avg-loss (window=10)= 0.0043153327602340145
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:13,377 INFO epoch # 71 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.24300000000000002-> 0.24300000000000002 - loss = 0.005775058409199119
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:13,504 INFO epoch # 72 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.24300000000000002-> 0.24300000000000002 - loss = 0.0032437696354463696
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:13,631 INFO epoch # 73 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.24300000000000002-> 0.24300000000000002 - loss = 0.003090125508606434
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:13,753 INFO epoch # 74 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.24300000000000002-> 0.21870000000000003 - loss = 0.005134469422046095
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:13,878 INFO epoch # 75 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.21870000000000003-> 0.21870000000000003 - loss = 0.0047862756182439625
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:13,999 INFO epoch # 76 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.21870000000000003-> 0.21870000000000003 - loss = 0.003953265433665365
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:14,122 INFO epoch # 77 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.21870000000000003-> 0.21870000000000003 - loss = 0.003506514258333482
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:14,244 INFO epoch # 78 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.21870000000000003-> 0.21870000000000003 - loss = 0.004546320124063641
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:14,366 INFO epoch # 79 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.21870000000000003-> 0.21870000000000003 - loss = 0.006861397181637585
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:14,489 INFO epoch # 80 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.21870000000000003-> 0.21870000000000003 - loss = 0.004814352258108556
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:19:14,489 INFO *** epoch 80, rolling-avg-loss (window=10)= 0.0045711547849350605
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:14,611 INFO epoch # 81 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.21870000000000003-> 0.21870000000000003 - loss = 0.006065304740332067
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:14,734 INFO epoch # 82 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.21870000000000003-> 0.21870000000000003 - loss = 0.006129567278549075
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:14,856 INFO epoch # 83 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.21870000000000003-> 0.21870000000000003 - loss = 0.012636220431886613
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:14,979 INFO epoch # 84 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.21870000000000003-> 0.21870000000000003 - loss = 0.008206953818444163
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:15,100 INFO epoch # 85 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.21870000000000003-> 0.19683000000000003 - loss = 0.007201129978056997
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:15,223 INFO epoch # 86 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.19683000000000003-> 0.19683000000000003 - loss = 0.003358450543601066
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:15,346 INFO epoch # 87 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.19683000000000003-> 0.19683000000000003 - loss = 0.0088737670739647
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:15,467 INFO epoch # 88 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.19683000000000003-> 0.19683000000000003 - loss = 0.006362203450407833
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:15,591 INFO epoch # 89 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.19683000000000003-> 0.19683000000000003 - loss = 0.006016353610903025
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:15,716 INFO epoch # 90 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.19683000000000003-> 0.19683000000000003 - loss = 0.01358557736966759
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:19:15,717 INFO *** epoch 90, rolling-avg-loss (window=10)= 0.007843552829581314
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:15,839 INFO epoch # 91 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.19683000000000003-> 0.19683000000000003 - loss = 0.02187249413691461
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:15,962 INFO epoch # 92 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.19683000000000003-> 0.19683000000000003 - loss = 0.012582674040459096
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:16,087 INFO epoch # 93 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.19683000000000003-> 0.19683000000000003 - loss = 0.01005012565292418
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:16,211 INFO epoch # 94 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.19683000000000003-> 0.19683000000000003 - loss = 0.020108453230932355
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:16,334 INFO epoch # 95 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.19683000000000003-> 0.19683000000000003 - loss = 0.003810869646258652
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:16,457 INFO epoch # 96 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.19683000000000003-> 0.17714700000000003 - loss = 0.004319429281167686
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:16,580 INFO epoch # 97 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.17714700000000003-> 0.17714700000000003 - loss = 0.0052329739555716515
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:16,703 INFO epoch # 98 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.17714700000000003-> 0.17714700000000003 - loss = 0.0064200725755654275
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:16,827 INFO epoch # 99 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.17714700000000003-> 0.17714700000000003 - loss = 0.0035909561556763947
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:16,950 INFO epoch # 100 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.17714700000000003-> 0.17714700000000003 - loss = 0.0025696074008010328
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:19:16,950 INFO *** epoch 100, rolling-avg-loss (window=10)= 0.009055765607627109
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:17,073 INFO epoch # 101 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.17714700000000003-> 0.17714700000000003 - loss = 0.0029117768299329327
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:17,195 INFO epoch # 102 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.17714700000000003-> 0.17714700000000003 - loss = 0.003232466842746362
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:17,318 INFO epoch # 103 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.17714700000000003-> 0.17714700000000003 - loss = 0.0028768109041266143
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:17,440 INFO epoch # 104 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.17714700000000003-> 0.17714700000000003 - loss = 0.002479985181707889
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:17,561 INFO epoch # 105 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.17714700000000003-> 0.17714700000000003 - loss = 0.0025032328558154404
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:17,683 INFO epoch # 106 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.17714700000000003-> 0.17714700000000003 - loss = 0.0025521087227389216
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:17,805 INFO epoch # 107 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.17714700000000003-> 0.15943230000000003 - loss = 0.002512647130060941
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:17,927 INFO epoch # 108 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.15943230000000003-> 0.15943230000000003 - loss = 0.0024886559112928808
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:18,048 INFO epoch # 109 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.15943230000000003-> 0.15943230000000003 - loss = 0.0038677339907735586
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:18,170 INFO epoch # 110 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.15943230000000003-> 0.15943230000000003 - loss = 0.0038607958995271474
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:19:18,170 INFO *** epoch 110, rolling-avg-loss (window=10)= 0.0029286214268722686
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:18,292 INFO epoch # 111 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.15943230000000003-> 0.15943230000000003 - loss = 0.0023549964535050094
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:18,414 INFO epoch # 112 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.15943230000000003-> 0.15943230000000003 - loss = 0.0032251966767944396
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:18,537 INFO epoch # 113 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.15943230000000003-> 0.15943230000000003 - loss = 0.0050451564602553844
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:18,659 INFO epoch # 114 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.15943230000000003-> 0.15943230000000003 - loss = 0.003830399044090882
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:18,782 INFO epoch # 115 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.15943230000000003-> 0.15943230000000003 - loss = 0.009270169568480924
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:18,910 INFO epoch # 116 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.15943230000000003-> 0.15943230000000003 - loss = 0.00479410873958841
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:19,050 INFO epoch # 117 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.15943230000000003-> 0.15943230000000003 - loss = 0.0034314566291868687
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:19,179 INFO epoch # 118 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.15943230000000003-> 0.15943230000000003 - loss = 0.004344479006249458
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:19,301 INFO epoch # 119 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.15943230000000003-> 0.15943230000000003 - loss = 0.003982082358561456
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:19,424 INFO epoch # 120 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.15943230000000003-> 0.15943230000000003 - loss = 0.0029161586426198483
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:19:19,424 INFO *** epoch 120, rolling-avg-loss (window=10)= 0.004319420357933268
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:19,546 INFO epoch # 121 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.15943230000000003-> 0.15943230000000003 - loss = 0.002879021078115329
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:19,669 INFO epoch # 122 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.15943230000000003-> 0.14348907000000002 - loss = 0.003235923097236082
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:19,797 INFO epoch # 123 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.14348907000000002-> 0.14348907000000002 - loss = 0.0030296053155325353
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:19,939 INFO epoch # 124 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.14348907000000002-> 0.14348907000000002 - loss = 0.003524675645167008
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:20,077 INFO epoch # 125 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.14348907000000002-> 0.14348907000000002 - loss = 0.003027572383871302
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:20,216 INFO epoch # 126 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.14348907000000002-> 0.14348907000000002 - loss = 0.005524008942302316
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:20,355 INFO epoch # 127 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.14348907000000002-> 0.14348907000000002 - loss = 0.0062561522936448455
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:20,477 INFO epoch # 128 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.14348907000000002-> 0.14348907000000002 - loss = 0.008248300524428487
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:20,599 INFO epoch # 129 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.14348907000000002-> 0.14348907000000002 - loss = 0.012424486980307847
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:20,722 INFO epoch # 130 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.14348907000000002-> 0.14348907000000002 - loss = 0.009462444169912487
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:19:20,722 INFO *** epoch 130, rolling-avg-loss (window=10)= 0.005761219043051824
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:20,844 INFO epoch # 131 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.14348907000000002-> 0.14348907000000002 - loss = 0.004994383227312937
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:20,966 INFO epoch # 132 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.14348907000000002-> 0.14348907000000002 - loss = 0.006188077095430344
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:21,088 INFO epoch # 133 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.14348907000000002-> 0.12914016300000003 - loss = 0.006214424327481538
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:21,212 INFO epoch # 134 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.12914016300000003-> 0.12914016300000003 - loss = 0.006317673251032829
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:21,334 INFO epoch # 135 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.12914016300000003-> 0.12914016300000003 - loss = 0.0031893648847471923
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:21,457 INFO epoch # 136 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.12914016300000003-> 0.12914016300000003 - loss = 0.003203518659574911
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:21,579 INFO epoch # 137 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.12914016300000003-> 0.12914016300000003 - loss = 0.0021738539362559095
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:21,702 INFO epoch # 138 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.12914016300000003-> 0.12914016300000003 - loss = 0.0029772578418487683
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:21,826 INFO epoch # 139 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.12914016300000003-> 0.12914016300000003 - loss = 0.006599891174118966
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:21,949 INFO epoch # 140 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.12914016300000003-> 0.12914016300000003 - loss = 0.003048769780434668
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:19:21,949 INFO *** epoch 140, rolling-avg-loss (window=10)= 0.004490721417823806
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:22,072 INFO epoch # 141 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.12914016300000003-> 0.12914016300000003 - loss = 0.00814558012643829
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:22,195 INFO epoch # 142 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.12914016300000003-> 0.12914016300000003 - loss = 0.005033310793805867
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:22,317 INFO epoch # 143 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.12914016300000003-> 0.12914016300000003 - loss = 0.0047359823365695775
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:22,440 INFO epoch # 144 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.12914016300000003-> 0.12914016300000003 - loss = 0.004461303993593901
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:22,569 INFO epoch # 145 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.12914016300000003-> 0.12914016300000003 - loss = 0.0035149258183082566
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:22,697 INFO epoch # 146 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.12914016300000003-> 0.12914016300000003 - loss = 0.008898557105567306
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:22,838 INFO epoch # 147 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.12914016300000003-> 0.12914016300000003 - loss = 0.008358488325029612
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:22,979 INFO epoch # 148 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.12914016300000003-> 0.11622614670000003 - loss = 0.0041791757685132325
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:23,122 INFO epoch # 149 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.11622614670000003-> 0.11622614670000003 - loss = 0.0028680616815108806
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:23,248 INFO epoch # 150 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.11622614670000003-> 0.11622614670000003 - loss = 0.003178714687237516
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:19:23,249 INFO *** epoch 150, rolling-avg-loss (window=10)= 0.005337410063657444
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:23,371 INFO epoch # 151 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.11622614670000003-> 0.11622614670000003 - loss = 0.0021077998680993915
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:23,495 INFO epoch # 152 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.11622614670000003-> 0.11622614670000003 - loss = 0.004136431613005698
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:23,618 INFO epoch # 153 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.11622614670000003-> 0.11622614670000003 - loss = 0.001528225586298504
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:23,741 INFO epoch # 154 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.11622614670000003-> 0.11622614670000003 - loss = 0.004018220643047243
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:23,863 INFO epoch # 155 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.11622614670000003-> 0.11622614670000003 - loss = 0.0028456993168219924
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:23,985 INFO epoch # 156 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.11622614670000003-> 0.11622614670000003 - loss = 0.002407885011052713
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:24,108 INFO epoch # 157 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.11622614670000003-> 0.11622614670000003 - loss = 0.002640356164192781
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:24,231 INFO epoch # 158 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.11622614670000003-> 0.11622614670000003 - loss = 0.003294347698101774
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:24,353 INFO epoch # 159 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.11622614670000003-> 0.11622614670000003 - loss = 0.003942171315429732
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:24,476 INFO epoch # 160 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.11622614670000003-> 0.11622614670000003 - loss = 0.0028229676536284387
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:19:24,476 INFO *** epoch 160, rolling-avg-loss (window=10)= 0.0029744104869678266
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:24,598 INFO epoch # 161 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.11622614670000003-> 0.11622614670000003 - loss = 0.004010724602267146
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:24,721 INFO epoch # 162 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.11622614670000003-> 0.11622614670000003 - loss = 0.003741702559636906
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:24,843 INFO epoch # 163 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.11622614670000003-> 0.11622614670000003 - loss = 0.002990043954923749
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:24,966 INFO epoch # 164 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.11622614670000003-> 0.10460353203000003 - loss = 0.0018856947135645896
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:25,088 INFO epoch # 165 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.10460353203000003-> 0.10460353203000003 - loss = 0.0032793127465993166
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:25,211 INFO epoch # 166 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.10460353203000003-> 0.10460353203000003 - loss = 0.0035328366211615503
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:25,334 INFO epoch # 167 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.10460353203000003-> 0.10460353203000003 - loss = 0.002921563689596951
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:25,456 INFO epoch # 168 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.10460353203000003-> 0.10460353203000003 - loss = 0.0021171557309571654
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:25,579 INFO epoch # 169 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.10460353203000003-> 0.10460353203000003 - loss = 0.004440256278030574
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:25,702 INFO epoch # 170 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.10460353203000003-> 0.10460353203000003 - loss = 0.003326940961414948
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:19:25,702 INFO *** epoch 170, rolling-avg-loss (window=10)= 0.0032246231858152896
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:25,825 INFO epoch # 171 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.10460353203000003-> 0.10460353203000003 - loss = 0.0030572809046134353
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:25,948 INFO epoch # 172 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.10460353203000003-> 0.10460353203000003 - loss = 0.005298247269820422
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:26,071 INFO epoch # 173 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.10460353203000003-> 0.10460353203000003 - loss = 0.0022817105636931956
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:26,194 INFO epoch # 174 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.10460353203000003-> 0.10460353203000003 - loss = 0.0031920974142849445
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:26,316 INFO epoch # 175 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.10460353203000003-> 0.09414317882700003 - loss = 0.0020202371815685183
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:26,464 INFO epoch # 176 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.09414317882700003-> 0.09414317882700003 - loss = 0.0014302250056061894
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:26,593 INFO epoch # 177 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.09414317882700003-> 0.09414317882700003 - loss = 0.0024888326588552445
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:26,716 INFO epoch # 178 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.09414317882700003-> 0.09414317882700003 - loss = 0.002336428689886816
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:26,838 INFO epoch # 179 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.09414317882700003-> 0.09414317882700003 - loss = 0.0045273982104845345
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:26,961 INFO epoch # 180 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.09414317882700003-> 0.09414317882700003 - loss = 0.004619546700268984
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:19:26,961 INFO *** epoch 180, rolling-avg-loss (window=10)= 0.0031252004599082285
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:27,083 INFO epoch # 181 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.09414317882700003-> 0.09414317882700003 - loss = 0.004313530924264342
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:27,206 INFO epoch # 182 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.09414317882700003-> 0.09414317882700003 - loss = 0.003494625212624669
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:27,329 INFO epoch # 183 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.09414317882700003-> 0.09414317882700003 - loss = 0.002835763618350029
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:27,452 INFO epoch # 184 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.09414317882700003-> 0.09414317882700003 - loss = 0.0027858273533638567
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:27,574 INFO epoch # 185 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.09414317882700003-> 0.09414317882700003 - loss = 0.004037538601551205
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:27,696 INFO epoch # 186 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.09414317882700003-> 0.09414317882700003 - loss = 0.00420165917603299
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:27,819 INFO epoch # 187 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.09414317882700003-> 0.08472886094430003 - loss = 0.002585677691968158
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:27,942 INFO epoch # 188 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.08472886094430003-> 0.08472886094430003 - loss = 0.002837416890542954
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:28,064 INFO epoch # 189 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.08472886094430003-> 0.08472886094430003 - loss = 0.004648992791771889
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:28,187 INFO epoch # 190 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.08472886094430003-> 0.08472886094430003 - loss = 0.0026532987831160426
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:19:28,187 INFO *** epoch 190, rolling-avg-loss (window=10)= 0.0034394331043586133
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:28,309 INFO epoch # 191 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.08472886094430003-> 0.08472886094430003 - loss = 0.003214941534679383
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:28,432 INFO epoch # 192 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.08472886094430003-> 0.08472886094430003 - loss = 0.0031153562013059855
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:28,555 INFO epoch # 193 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.08472886094430003-> 0.08472886094430003 - loss = 0.002212793508078903
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:28,678 INFO epoch # 194 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.08472886094430003-> 0.08472886094430003 - loss = 0.0022889951651450247
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:28,801 INFO epoch # 195 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.08472886094430003-> 0.08472886094430003 - loss = 0.003408357239095494
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:28,923 INFO epoch # 196 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.08472886094430003-> 0.08472886094430003 - loss = 0.0044206879392731935
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:29,045 INFO epoch # 197 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.08472886094430003-> 0.08472886094430003 - loss = 0.005868589389137924
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:29,168 INFO epoch # 198 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.08472886094430003-> 0.07625597484987003 - loss = 0.001994325954001397
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:29,290 INFO epoch # 199 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.07625597484987003-> 0.07625597484987003 - loss = 0.0027183902566321194
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:29,413 INFO epoch # 200 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.07625597484987003-> 0.07625597484987003 - loss = 0.0027164932107552886
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:19:29,413 INFO *** epoch 200, rolling-avg-loss (window=10)= 0.0031958930398104713
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:29,535 INFO epoch # 201 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.07625597484987003-> 0.07625597484987003 - loss = 0.0018781059043249115
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:29,661 INFO epoch # 202 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.07625597484987003-> 0.07625597484987003 - loss = 0.002895660523790866
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:29,788 INFO epoch # 203 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.07625597484987003-> 0.07625597484987003 - loss = 0.008353301673196256
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:29,927 INFO epoch # 204 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.07625597484987003-> 0.07625597484987003 - loss = 0.002018131228396669
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:30,067 INFO epoch # 205 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.07625597484987003-> 0.07625597484987003 - loss = 0.0024767762806732208
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:30,206 INFO epoch # 206 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.07625597484987003-> 0.07625597484987003 - loss = 0.0035667363554239273
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:30,345 INFO epoch # 207 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.07625597484987003-> 0.07625597484987003 - loss = 0.006068371934816241
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:30,485 INFO epoch # 208 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.07625597484987003-> 0.07625597484987003 - loss = 0.003887827566359192
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:30,623 INFO epoch # 209 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.07625597484987003-> 0.06863037736488302 - loss = 0.004368607827927917
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:30,762 INFO epoch # 210 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.06863037736488302-> 0.06863037736488302 - loss = 0.0024257969052996486
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:19:30,762 INFO *** epoch 210, rolling-avg-loss (window=10)= 0.003793931620020885
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:30,899 INFO epoch # 211 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.06863037736488302-> 0.06863037736488302 - loss = 0.006798268062993884
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:31,039 INFO epoch # 212 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.06863037736488302-> 0.06863037736488302 - loss = 0.0018082533351844177
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:31,178 INFO epoch # 213 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.06863037736488302-> 0.06863037736488302 - loss = 0.0063094497891142964
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:31,317 INFO epoch # 214 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.06863037736488302-> 0.06863037736488302 - loss = 0.009409635997144505
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:31,456 INFO epoch # 215 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.06863037736488302-> 0.06863037736488302 - loss = 0.011011997587047517
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:31,596 INFO epoch # 216 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.06863037736488302-> 0.06863037736488302 - loss = 0.010815139627084136
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:31,735 INFO epoch # 217 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.06863037736488302-> 0.06863037736488302 - loss = 0.004912474891170859
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:31,875 INFO epoch # 218 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.06863037736488302-> 0.06863037736488302 - loss = 0.0037033105036243796
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:32,015 INFO epoch # 219 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.06863037736488302-> 0.06863037736488302 - loss = 0.004067547153681517
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:32,155 INFO epoch # 220 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.06863037736488302-> 0.061767339628394716 - loss = 0.004534664418315515
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:19:32,155 INFO *** epoch 220, rolling-avg-loss (window=10)= 0.006337074136536103
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:32,296 INFO epoch # 221 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.061767339628394716-> 0.061767339628394716 - loss = 0.003609675040934235
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:32,435 INFO epoch # 222 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.061767339628394716-> 0.061767339628394716 - loss = 0.013593954819953069
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:32,573 INFO epoch # 223 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.061767339628394716-> 0.061767339628394716 - loss = 0.004270425299182534
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:32,712 INFO epoch # 224 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.061767339628394716-> 0.061767339628394716 - loss = 0.004916393954772502
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:32,852 INFO epoch # 225 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.061767339628394716-> 0.061767339628394716 - loss = 0.003662963310489431
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:32,992 INFO epoch # 226 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.061767339628394716-> 0.061767339628394716 - loss = 0.002729952961090021
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:33,131 INFO epoch # 227 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.061767339628394716-> 0.061767339628394716 - loss = 0.0021345324348658323
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:33,271 INFO epoch # 228 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.061767339628394716-> 0.061767339628394716 - loss = 0.0012955989222973585
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:33,410 INFO epoch # 229 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.061767339628394716-> 0.061767339628394716 - loss = 0.0024395677028223872
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:33,549 INFO epoch # 230 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.061767339628394716-> 0.061767339628394716 - loss = 0.0029130798648111522
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:19:33,549 INFO *** epoch 230, rolling-avg-loss (window=10)= 0.004156614431121852
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:33,677 INFO epoch # 231 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.061767339628394716-> 0.061767339628394716 - loss = 0.0031958436011336744
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:33,800 INFO epoch # 232 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.061767339628394716-> 0.061767339628394716 - loss = 0.0028795000398531556
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:33,922 INFO epoch # 233 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.061767339628394716-> 0.061767339628394716 - loss = 0.002678052638657391
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:34,044 INFO epoch # 234 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.061767339628394716-> 0.061767339628394716 - loss = 0.0025342897861264646
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:34,166 INFO epoch # 235 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.061767339628394716-> 0.061767339628394716 - loss = 0.0036579125735443085
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:34,289 INFO epoch # 236 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.061767339628394716-> 0.061767339628394716 - loss = 0.002182449519750662
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:34,414 INFO epoch # 237 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.061767339628394716-> 0.061767339628394716 - loss = 0.0024403782736044377
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:34,536 INFO epoch # 238 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.061767339628394716-> 0.061767339628394716 - loss = 0.002609543298603967
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:34,658 INFO epoch # 239 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.061767339628394716-> 0.055590605665555244 - loss = 0.005412008264102042
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:34,781 INFO epoch # 240 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.055590605665555244-> 0.055590605665555244 - loss = 0.002270598284667358
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:19:34,781 INFO *** epoch 240, rolling-avg-loss (window=10)= 0.002986057628004346
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:34,904 INFO epoch # 241 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.055590605665555244-> 0.055590605665555244 - loss = 0.0022384970798157156
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:35,026 INFO epoch # 242 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.055590605665555244-> 0.055590605665555244 - loss = 0.001994249993003905
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:35,148 INFO epoch # 243 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.055590605665555244-> 0.055590605665555244 - loss = 0.0022914585861144587
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:35,271 INFO epoch # 244 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.055590605665555244-> 0.055590605665555244 - loss = 0.003678418986964971
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:35,394 INFO epoch # 245 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.055590605665555244-> 0.055590605665555244 - loss = 0.0069370474957395345
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:35,516 INFO epoch # 246 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.055590605665555244-> 0.055590605665555244 - loss = 0.005250356771284714
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:35,639 INFO epoch # 247 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.055590605665555244-> 0.055590605665555244 - loss = 0.007752358971629292
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:35,762 INFO epoch # 248 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.055590605665555244-> 0.055590605665555244 - loss = 0.0036779747460968792
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:35,884 INFO epoch # 249 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.055590605665555244-> 0.055590605665555244 - loss = 0.002178801514673978
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:36,005 INFO epoch # 250 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.055590605665555244-> 0.05003154509899972 - loss = 0.0029293223342392594
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:19:36,006 INFO *** epoch 250, rolling-avg-loss (window=10)= 0.0038928486479562706
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:36,128 INFO epoch # 251 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.05003154509899972-> 0.05003154509899972 - loss = 0.0021686360705643892
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:36,251 INFO epoch # 252 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.05003154509899972-> 0.05003154509899972 - loss = 0.0013250511547084898
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:36,386 INFO epoch # 253 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.05003154509899972-> 0.05003154509899972 - loss = 0.0017656076161074452
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:36,525 INFO epoch # 254 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.05003154509899972-> 0.05003154509899972 - loss = 0.0019697394454851747
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:36,665 INFO epoch # 255 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.05003154509899972-> 0.05003154509899972 - loss = 0.0032127307495102286
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:36,806 INFO epoch # 256 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.05003154509899972-> 0.05003154509899972 - loss = 0.002640462073031813
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:36,948 INFO epoch # 257 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.05003154509899972-> 0.05003154509899972 - loss = 0.001960229012183845
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:37,089 INFO epoch # 258 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.05003154509899972-> 0.05003154509899972 - loss = 0.0031229058222379535
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:37,228 INFO epoch # 259 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.05003154509899972-> 0.05003154509899972 - loss = 0.0015897112025413662
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:37,372 INFO epoch # 260 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.05003154509899972-> 0.05003154509899972 - loss = 0.001527286702184938
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:19:37,372 INFO *** epoch 260, rolling-avg-loss (window=10)= 0.0021282359848555643
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:37,512 INFO epoch # 261 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.05003154509899972-> 0.04502839058909975 - loss = 0.002067908291792264
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:37,653 INFO epoch # 262 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.04502839058909975-> 0.04502839058909975 - loss = 0.0024886348110157996
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:37,792 INFO epoch # 263 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.04502839058909975-> 0.04502839058909975 - loss = 0.00643706027767621
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:37,933 INFO epoch # 264 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.04502839058909975-> 0.04502839058909975 - loss = 0.002832900790963322
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:38,072 INFO epoch # 265 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.04502839058909975-> 0.04502839058909975 - loss = 0.002941722428658977
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:38,213 INFO epoch # 266 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.04502839058909975-> 0.04502839058909975 - loss = 0.0025250647449865937
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:38,353 INFO epoch # 267 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.04502839058909975-> 0.04502839058909975 - loss = 0.0018279751820955426
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:38,492 INFO epoch # 268 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.04502839058909975-> 0.04502839058909975 - loss = 0.002900151739595458
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:38,631 INFO epoch # 269 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.04502839058909975-> 0.04502839058909975 - loss = 0.0032880027720239013
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:38,770 INFO epoch # 270 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.04502839058909975-> 0.04502839058909975 - loss = 0.001270972061320208
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:19:38,770 INFO *** epoch 270, rolling-avg-loss (window=10)= 0.0028580393100128276
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:38,914 INFO epoch # 271 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.04502839058909975-> 0.04502839058909975 - loss = 0.0050851340929511935
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:39,057 INFO epoch # 272 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.04502839058909975-> 0.04502839058909975 - loss = 0.00437918450916186
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:39,196 INFO epoch # 273 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.04502839058909975-> 0.04502839058909975 - loss = 0.0023004253453109413
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:39,336 INFO epoch # 274 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.04502839058909975-> 0.04502839058909975 - loss = 0.006088142399676144
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:39,476 INFO epoch # 275 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.04502839058909975-> 0.04502839058909975 - loss = 0.0036065320600755513
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:39,602 INFO epoch # 276 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.04502839058909975-> 0.04502839058909975 - loss = 0.0034190347651019692
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:39,724 INFO epoch # 277 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.04502839058909975-> 0.04502839058909975 - loss = 0.003553800634108484
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:39,847 INFO epoch # 278 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.04502839058909975-> 0.04502839058909975 - loss = 0.003054256783798337
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:39,971 INFO epoch # 279 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.04502839058909975-> 0.04502839058909975 - loss = 0.004539740562904626
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:40,094 INFO epoch # 280 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.04502839058909975-> 0.04502839058909975 - loss = 0.0026413657324155793
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:19:40,094 INFO *** epoch 280, rolling-avg-loss (window=10)= 0.0038667616885504686
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:40,217 INFO epoch # 281 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.04502839058909975-> 0.040525551530189774 - loss = 0.0037277493975125253
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:40,339 INFO epoch # 282 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.040525551530189774-> 0.040525551530189774 - loss = 0.0032541865366511047
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:40,461 INFO epoch # 283 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.040525551530189774-> 0.040525551530189774 - loss = 0.004542004724498838
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:40,583 INFO epoch # 284 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.040525551530189774-> 0.040525551530189774 - loss = 0.0017880531086120754
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:40,705 INFO epoch # 285 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.040525551530189774-> 0.040525551530189774 - loss = 0.003317359572974965
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:40,837 INFO epoch # 286 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.040525551530189774-> 0.040525551530189774 - loss = 0.0038844530354253948
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:40,975 INFO epoch # 287 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.040525551530189774-> 0.040525551530189774 - loss = 0.0035391635028645396
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:41,098 INFO epoch # 288 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.040525551530189774-> 0.040525551530189774 - loss = 0.0019565070106182247
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:41,219 INFO epoch # 289 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.040525551530189774-> 0.040525551530189774 - loss = 0.0036658215103670955
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:41,342 INFO epoch # 290 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.040525551530189774-> 0.040525551530189774 - loss = 0.005361338495276868
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:19:41,342 INFO *** epoch 290, rolling-avg-loss (window=10)= 0.0035036636894801632
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:41,464 INFO epoch # 291 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.040525551530189774-> 0.040525551530189774 - loss = 0.007947126287035644
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:41,594 INFO epoch # 292 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.040525551530189774-> 0.036472996377170795 - loss = 0.0030501690634991974
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:41,740 INFO epoch # 293 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.036472996377170795-> 0.036472996377170795 - loss = 0.005243478051852435
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:41,866 INFO epoch # 294 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.036472996377170795-> 0.036472996377170795 - loss = 0.0050558652728796005
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:41,990 INFO epoch # 295 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.036472996377170795-> 0.036472996377170795 - loss = 0.003874042071402073
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:42,112 INFO epoch # 296 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.036472996377170795-> 0.036472996377170795 - loss = 0.007848226348869503
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:42,234 INFO epoch # 297 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.036472996377170795-> 0.036472996377170795 - loss = 0.005078515241621062
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:42,357 INFO epoch # 298 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.036472996377170795-> 0.036472996377170795 - loss = 0.0017844238900579512
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:42,479 INFO epoch # 299 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.036472996377170795-> 0.036472996377170795 - loss = 0.004919566854368895
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:42,603 INFO epoch # 300 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.036472996377170795-> 0.036472996377170795 - loss = 0.0029872691666241735
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:19:42,603 INFO *** epoch 300, rolling-avg-loss (window=10)= 0.004778868224821054
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:42,741 INFO epoch # 301 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.036472996377170795-> 0.036472996377170795 - loss = 0.004623822693247348
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:42,873 INFO epoch # 302 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.036472996377170795-> 0.036472996377170795 - loss = 0.0024104048497974873
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:42,996 INFO epoch # 303 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.036472996377170795-> 0.032825696739453715 - loss = 0.0026778141618706286
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:43,119 INFO epoch # 304 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.032825696739453715-> 0.032825696739453715 - loss = 0.0026304241036996245
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:43,241 INFO epoch # 305 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.032825696739453715-> 0.032825696739453715 - loss = 0.002503949624951929
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:43,364 INFO epoch # 306 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.032825696739453715-> 0.032825696739453715 - loss = 0.0022897232265677303
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:43,486 INFO epoch # 307 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.032825696739453715-> 0.032825696739453715 - loss = 0.0024517713609384373
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:43,610 INFO epoch # 308 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.032825696739453715-> 0.032825696739453715 - loss = 0.0049717416550265625
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:43,732 INFO epoch # 309 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.032825696739453715-> 0.032825696739453715 - loss = 0.0019143779354635626
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:43,855 INFO epoch # 310 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.032825696739453715-> 0.032825696739453715 - loss = 0.0018312013999093324
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:19:43,856 INFO *** epoch 310, rolling-avg-loss (window=10)= 0.0028305231011472643
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:43,978 INFO epoch # 311 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.032825696739453715-> 0.032825696739453715 - loss = 0.0024241066130343825
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:44,102 INFO epoch # 312 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.032825696739453715-> 0.032825696739453715 - loss = 0.004420836572535336
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:44,224 INFO epoch # 313 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.032825696739453715-> 0.032825696739453715 - loss = 0.003158294828608632
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:44,357 INFO epoch # 314 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.032825696739453715-> 0.029543127065508344 - loss = 0.0038872838631505147
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:44,485 INFO epoch # 315 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.029543127065508344-> 0.029543127065508344 - loss = 0.0033870890620164573
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:44,607 INFO epoch # 316 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.029543127065508344-> 0.029543127065508344 - loss = 0.002321230567758903
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:44,730 INFO epoch # 317 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.029543127065508344-> 0.029543127065508344 - loss = 0.0014700012397952378
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:44,853 INFO epoch # 318 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.029543127065508344-> 0.029543127065508344 - loss = 0.004604878602549434
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:44,975 INFO epoch # 319 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.029543127065508344-> 0.029543127065508344 - loss = 0.0017944912833627313
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:45,098 INFO epoch # 320 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.029543127065508344-> 0.029543127065508344 - loss = 0.0036308252601884305
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:19:45,098 INFO *** epoch 320, rolling-avg-loss (window=10)= 0.003109903789300006
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:45,220 INFO epoch # 321 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.029543127065508344-> 0.029543127065508344 - loss = 0.001976943574845791
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:45,344 INFO epoch # 322 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.029543127065508344-> 0.029543127065508344 - loss = 0.002357633551582694
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:45,466 INFO epoch # 323 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.029543127065508344-> 0.029543127065508344 - loss = 0.0014256226568249986
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:45,589 INFO epoch # 324 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.029543127065508344-> 0.029543127065508344 - loss = 0.002054288488579914
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:45,711 INFO epoch # 325 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.029543127065508344-> 0.026588814358957512 - loss = 0.002098148273944389
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:45,834 INFO epoch # 326 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.026588814358957512-> 0.026588814358957512 - loss = 0.003349005652125925
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:45,956 INFO epoch # 327 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.026588814358957512-> 0.026588814358957512 - loss = 0.0028522683132905513
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:46,078 INFO epoch # 328 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.026588814358957512-> 0.026588814358957512 - loss = 0.0054827737039886415
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:46,201 INFO epoch # 329 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.026588814358957512-> 0.026588814358957512 - loss = 0.0038624388398602605
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:46,323 INFO epoch # 330 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.026588814358957512-> 0.026588814358957512 - loss = 0.008761377015616745
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:19:46,323 INFO *** epoch 330, rolling-avg-loss (window=10)= 0.003422050007065991
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:46,446 INFO epoch # 331 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.026588814358957512-> 0.026588814358957512 - loss = 0.0037611367588397115
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:46,568 INFO epoch # 332 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.026588814358957512-> 0.026588814358957512 - loss = 0.006087798523367383
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:46,690 INFO epoch # 333 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.026588814358957512-> 0.026588814358957512 - loss = 0.0023880201479187235
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:46,814 INFO epoch # 334 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.026588814358957512-> 0.026588814358957512 - loss = 0.002254626975627616
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:46,936 INFO epoch # 335 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.026588814358957512-> 0.026588814358957512 - loss = 0.002372055925661698
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:47,059 INFO epoch # 336 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.026588814358957512-> 0.02392993292306176 - loss = 0.0018133072881028056
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:47,181 INFO epoch # 337 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.02392993292306176-> 0.02392993292306176 - loss = 0.0016835083661135286
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:47,303 INFO epoch # 338 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.02392993292306176-> 0.02392993292306176 - loss = 0.001606311445357278
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:47,425 INFO epoch # 339 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.02392993292306176-> 0.02392993292306176 - loss = 0.003196868725353852
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:47,549 INFO epoch # 340 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.02392993292306176-> 0.02392993292306176 - loss = 0.0015430626517627388
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:19:47,549 INFO *** epoch 340, rolling-avg-loss (window=10)= 0.0026706696808105335
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:47,670 INFO epoch # 341 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.02392993292306176-> 0.02392993292306176 - loss = 0.0026396056346129626
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:47,793 INFO epoch # 342 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.02392993292306176-> 0.02392993292306176 - loss = 0.002537565946113318
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:47,914 INFO epoch # 343 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.02392993292306176-> 0.02392993292306176 - loss = 0.0020879981748294085
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:48,036 INFO epoch # 344 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.02392993292306176-> 0.02392993292306176 - loss = 0.0029780854238197207
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:48,158 INFO epoch # 345 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.02392993292306176-> 0.02392993292306176 - loss = 0.00158586265752092
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:48,280 INFO epoch # 346 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.02392993292306176-> 0.02392993292306176 - loss = 0.0020584448357112706
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:48,402 INFO epoch # 347 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.02392993292306176-> 0.021536939630755585 - loss = 0.007974463194841519
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:48,525 INFO epoch # 348 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.021536939630755585-> 0.021536939630755585 - loss = 0.0029695147823076695
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:48,647 INFO epoch # 349 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.021536939630755585-> 0.021536939630755585 - loss = 0.005125764757394791
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:48,770 INFO epoch # 350 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.021536939630755585-> 0.021536939630755585 - loss = 0.0017820020948420279
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:19:48,770 INFO *** epoch 350, rolling-avg-loss (window=10)= 0.0031739307501993607
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:48,891 INFO epoch # 351 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.021536939630755585-> 0.021536939630755585 - loss = 0.0017085496219806373
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:49,013 INFO epoch # 352 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.021536939630755585-> 0.021536939630755585 - loss = 0.0018498222052585334
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:49,135 INFO epoch # 353 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.021536939630755585-> 0.021536939630755585 - loss = 0.009998472058214247
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:49,257 INFO epoch # 354 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.021536939630755585-> 0.021536939630755585 - loss = 0.010205744416452944
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:49,378 INFO epoch # 355 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.021536939630755585-> 0.021536939630755585 - loss = 0.010666075453627855
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:49,500 INFO epoch # 356 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.021536939630755585-> 0.021536939630755585 - loss = 0.0022603694415010978
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:49,621 INFO epoch # 357 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.021536939630755585-> 0.021536939630755585 - loss = 0.005421813577413559
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:49,743 INFO epoch # 358 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.021536939630755585-> 0.019383245667680026 - loss = 0.002944311883766204
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:49,864 INFO epoch # 359 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.019383245667680026-> 0.019383245667680026 - loss = 0.0020747825037688017
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:49,986 INFO epoch # 360 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.019383245667680026-> 0.019383245667680026 - loss = 0.0036625256470870227
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:19:49,986 INFO *** epoch 360, rolling-avg-loss (window=10)= 0.00507924668090709
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:50,109 INFO epoch # 361 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.019383245667680026-> 0.019383245667680026 - loss = 0.0057672185357660055
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:50,231 INFO epoch # 362 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.019383245667680026-> 0.019383245667680026 - loss = 0.001939995403517969
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:50,353 INFO epoch # 363 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.019383245667680026-> 0.019383245667680026 - loss = 0.0041171174379996955
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:50,475 INFO epoch # 364 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.019383245667680026-> 0.019383245667680026 - loss = 0.0021743105608038604
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:50,597 INFO epoch # 365 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.019383245667680026-> 0.019383245667680026 - loss = 0.004664592212066054
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:50,723 INFO epoch # 366 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.019383245667680026-> 0.019383245667680026 - loss = 0.0021170551772229373
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:50,858 INFO epoch # 367 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.019383245667680026-> 0.019383245667680026 - loss = 0.002493442065315321
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:50,997 INFO epoch # 368 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.019383245667680026-> 0.019383245667680026 - loss = 0.0015967533981893212
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:51,135 INFO epoch # 369 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.019383245667680026-> 0.017444921100912024 - loss = 0.003932407373213209
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:51,275 INFO epoch # 370 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.017444921100912024-> 0.017444921100912024 - loss = 0.003088266312261112
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:19:51,275 INFO *** epoch 370, rolling-avg-loss (window=10)= 0.0031891158476355487
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:51,414 INFO epoch # 371 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.017444921100912024-> 0.017444921100912024 - loss = 0.0016970968717942014
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:51,554 INFO epoch # 372 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.017444921100912024-> 0.017444921100912024 - loss = 0.005067735735792667
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:51,694 INFO epoch # 373 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.017444921100912024-> 0.017444921100912024 - loss = 0.0036924391170032322
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:51,833 INFO epoch # 374 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.017444921100912024-> 0.017444921100912024 - loss = 0.002629828406497836
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:51,972 INFO epoch # 375 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.017444921100912024-> 0.017444921100912024 - loss = 0.0036396351642906666
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:52,097 INFO epoch # 376 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.017444921100912024-> 0.017444921100912024 - loss = 0.0026064270350616425
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:52,236 INFO epoch # 377 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.017444921100912024-> 0.017444921100912024 - loss = 0.004004345566499978
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:52,363 INFO epoch # 378 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.017444921100912024-> 0.017444921100912024 - loss = 0.0017871971358545125
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:52,485 INFO epoch # 379 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.017444921100912024-> 0.017444921100912024 - loss = 0.003531742258928716
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:52,608 INFO epoch # 380 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.017444921100912024-> 0.015700428990820824 - loss = 0.0028447004297049716
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:19:52,608 INFO *** epoch 380, rolling-avg-loss (window=10)= 0.0031501147721428426
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:52,730 INFO epoch # 381 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.015700428990820824-> 0.015700428990820824 - loss = 0.0028767784242518246
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:52,853 INFO epoch # 382 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.015700428990820824-> 0.015700428990820824 - loss = 0.0017664334445726126
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:52,984 INFO epoch # 383 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.015700428990820824-> 0.015700428990820824 - loss = 0.001953963888809085
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:53,124 INFO epoch # 384 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.015700428990820824-> 0.015700428990820824 - loss = 0.003307465580292046
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:53,262 INFO epoch # 385 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.015700428990820824-> 0.015700428990820824 - loss = 0.001882221084088087
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:53,401 INFO epoch # 386 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.015700428990820824-> 0.015700428990820824 - loss = 0.0016542050143470988
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:53,540 INFO epoch # 387 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.015700428990820824-> 0.015700428990820824 - loss = 0.002049586153589189
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:53,667 INFO epoch # 388 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.015700428990820824-> 0.015700428990820824 - loss = 0.005333428387530148
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:53,789 INFO epoch # 389 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.015700428990820824-> 0.015700428990820824 - loss = 0.0025531042483635247
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:53,911 INFO epoch # 390 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.015700428990820824-> 0.015700428990820824 - loss = 0.006550276040798053
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:19:53,912 INFO *** epoch 390, rolling-avg-loss (window=10)= 0.0029927462266641667
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:54,034 INFO epoch # 391 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.015700428990820824-> 0.014130386091738742 - loss = 0.0022744766902178526
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:54,156 INFO epoch # 392 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.014130386091738742-> 0.014130386091738742 - loss = 0.0022322448348859325
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:54,279 INFO epoch # 393 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.014130386091738742-> 0.014130386091738742 - loss = 0.0024410838377662003
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:54,401 INFO epoch # 394 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.014130386091738742-> 0.014130386091738742 - loss = 0.0028783260786440223
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:54,523 INFO epoch # 395 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.014130386091738742-> 0.014130386091738742 - loss = 0.0020862782548647374
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:54,646 INFO epoch # 396 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.014130386091738742-> 0.014130386091738742 - loss = 0.0024042673176154494
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:54,768 INFO epoch # 397 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.014130386091738742-> 0.014130386091738742 - loss = 0.00209844863275066
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:54,892 INFO epoch # 398 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.014130386091738742-> 0.014130386091738742 - loss = 0.0017902491381391883
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:55,020 INFO epoch # 399 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.014130386091738742-> 0.014130386091738742 - loss = 0.002229191886726767
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:55,144 INFO epoch # 400 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.014130386091738742-> 0.014130386091738742 - loss = 0.0017209968209499493
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:19:55,144 INFO *** epoch 400, rolling-avg-loss (window=10)= 0.002215556349256076
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:55,267 INFO epoch # 401 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.014130386091738742-> 0.014130386091738742 - loss = 0.0018107921059709042
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:55,391 INFO epoch # 402 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.014130386091738742-> 0.012717347482564867 - loss = 0.001666202733758837
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:55,513 INFO epoch # 403 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.012717347482564867-> 0.012717347482564867 - loss = 0.0033355944033246487
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:55,636 INFO epoch # 404 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.012717347482564867-> 0.012717347482564867 - loss = 0.0024745179398451
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:55,758 INFO epoch # 405 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.012717347482564867-> 0.012717347482564867 - loss = 0.0031665980350226164
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:55,881 INFO epoch # 406 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.012717347482564867-> 0.012717347482564867 - loss = 0.003741002277820371
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:56,003 INFO epoch # 407 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.012717347482564867-> 0.012717347482564867 - loss = 0.001287171195144765
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:56,125 INFO epoch # 408 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.012717347482564867-> 0.012717347482564867 - loss = 0.0017426567792426795
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:56,247 INFO epoch # 409 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.012717347482564867-> 0.012717347482564867 - loss = 0.002447874197969213
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:56,369 INFO epoch # 410 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.012717347482564867-> 0.012717347482564867 - loss = 0.0024885860038921237
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:19:56,369 INFO *** epoch 410, rolling-avg-loss (window=10)= 0.002416099567199126
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:56,491 INFO epoch # 411 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.012717347482564867-> 0.012717347482564867 - loss = 0.004179785377345979
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:56,613 INFO epoch # 412 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.012717347482564867-> 0.012717347482564867 - loss = 0.0025480275216978043
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:56,735 INFO epoch # 413 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.012717347482564867-> 0.01144561273430838 - loss = 0.0018581388285383582
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:56,858 INFO epoch # 414 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.01144561273430838-> 0.01144561273430838 - loss = 0.00298449513502419
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:56,979 INFO epoch # 415 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.01144561273430838-> 0.01144561273430838 - loss = 0.0035094443010166287
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:57,102 INFO epoch # 416 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.01144561273430838-> 0.01144561273430838 - loss = 0.002212922350736335
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:57,225 INFO epoch # 417 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.01144561273430838-> 0.01144561273430838 - loss = 0.001793057657778263
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:57,347 INFO epoch # 418 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.01144561273430838-> 0.01144561273430838 - loss = 0.0036898325488436967
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:57,469 INFO epoch # 419 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.01144561273430838-> 0.01144561273430838 - loss = 0.003999350970843807
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:57,592 INFO epoch # 420 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.01144561273430838-> 0.01144561273430838 - loss = 0.0020839251519646496
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:19:57,592 INFO *** epoch 420, rolling-avg-loss (window=10)= 0.0028858979843789712
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:57,714 INFO epoch # 421 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.01144561273430838-> 0.01144561273430838 - loss = 0.0038629582850262523
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:57,836 INFO epoch # 422 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.01144561273430838-> 0.01144561273430838 - loss = 0.0028842690226156265
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:57,958 INFO epoch # 423 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.01144561273430838-> 0.01144561273430838 - loss = 0.0032330200192518532
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:58,081 INFO epoch # 424 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.01144561273430838-> 0.010301051460877543 - loss = 0.0021276145707815886
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:58,203 INFO epoch # 425 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.010301051460877543-> 0.010301051460877543 - loss = 0.0013739375863224268
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:58,325 INFO epoch # 426 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.010301051460877543-> 0.010301051460877543 - loss = 0.0029644016758538783
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:58,448 INFO epoch # 427 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.010301051460877543-> 0.010301051460877543 - loss = 0.003927146375644952
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:58,571 INFO epoch # 428 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.010301051460877543-> 0.010301051460877543 - loss = 0.004913667129585519
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:58,693 INFO epoch # 429 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.010301051460877543-> 0.010301051460877543 - loss = 0.005316885595675558
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:58,816 INFO epoch # 430 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.010301051460877543-> 0.010301051460877543 - loss = 0.002354942131205462
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:19:58,816 INFO *** epoch 430, rolling-avg-loss (window=10)= 0.003295884239196312
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:58,938 INFO epoch # 431 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.010301051460877543-> 0.010301051460877543 - loss = 0.00692774064373225
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:59,061 INFO epoch # 432 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.010301051460877543-> 0.010301051460877543 - loss = 0.0029177602846175432
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:59,184 INFO epoch # 433 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.010301051460877543-> 0.010301051460877543 - loss = 0.0029496692295651883
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:59,307 INFO epoch # 434 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.010301051460877543-> 0.010301051460877543 - loss = 0.0033450158953201026
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:59,430 INFO epoch # 435 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.010301051460877543-> 0.009270946314789788 - loss = 0.001824177845264785
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:59,554 INFO epoch # 436 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.009270946314789788-> 0.009270946314789788 - loss = 0.0024085319018922746
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:59,676 INFO epoch # 437 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.009270946314789788-> 0.009270946314789788 - loss = 0.0016208049637498334
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:59,799 INFO epoch # 438 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.009270946314789788-> 0.009270946314789788 - loss = 0.002553849626565352
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:19:59,941 INFO epoch # 439 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.009270946314789788-> 0.009270946314789788 - loss = 0.0029357937746681273
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:00,067 INFO epoch # 440 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.009270946314789788-> 0.009270946314789788 - loss = 0.0014655537233920768
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:20:00,067 INFO *** epoch 440, rolling-avg-loss (window=10)= 0.0028948897888767533
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:00,188 INFO epoch # 441 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.009270946314789788-> 0.009270946314789788 - loss = 0.0014273462584242225
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:00,312 INFO epoch # 442 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.009270946314789788-> 0.009270946314789788 - loss = 0.0049114358553197235
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:00,434 INFO epoch # 443 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.009270946314789788-> 0.009270946314789788 - loss = 0.004214924876578152
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:00,555 INFO epoch # 444 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.009270946314789788-> 0.009270946314789788 - loss = 0.008125712527544238
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:00,682 INFO epoch # 445 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.009270946314789788-> 0.009270946314789788 - loss = 0.004290208758902736
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:00,811 INFO epoch # 446 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.009270946314789788-> 0.00834385168331081 - loss = 0.0030030089110368863
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:00,950 INFO epoch # 447 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00834385168331081-> 0.00834385168331081 - loss = 0.004337395104812458
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:01,090 INFO epoch # 448 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00834385168331081-> 0.00834385168331081 - loss = 0.0031202692189253867
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:01,230 INFO epoch # 449 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00834385168331081-> 0.00834385168331081 - loss = 0.004528253222815692
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:01,362 INFO epoch # 450 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00834385168331081-> 0.00834385168331081 - loss = 0.0013529515999834985
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:20:01,362 INFO *** epoch 450, rolling-avg-loss (window=10)= 0.003931150633434299
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:01,486 INFO epoch # 451 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00834385168331081-> 0.00834385168331081 - loss = 0.0022307344479486346
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:01,608 INFO epoch # 452 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00834385168331081-> 0.00834385168331081 - loss = 0.0022018780291546136
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:01,730 INFO epoch # 453 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00834385168331081-> 0.00834385168331081 - loss = 0.0019798218563664705
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:01,852 INFO epoch # 454 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00834385168331081-> 0.00834385168331081 - loss = 0.0012524038611445576
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:01,973 INFO epoch # 455 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00834385168331081-> 0.00834385168331081 - loss = 0.006260415088036098
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:02,096 INFO epoch # 456 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00834385168331081-> 0.00834385168331081 - loss = 0.0037099751352798194
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:02,220 INFO epoch # 457 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00834385168331081-> 0.00834385168331081 - loss = 0.0019975605682702735
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:02,342 INFO epoch # 458 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00834385168331081-> 0.00834385168331081 - loss = 0.002111724315909669
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:02,463 INFO epoch # 459 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00834385168331081-> 0.00834385168331081 - loss = 0.0014784714076085947
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:02,586 INFO epoch # 460 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00834385168331081-> 0.00834385168331081 - loss = 0.002134130394551903
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:20:02,587 INFO *** epoch 460, rolling-avg-loss (window=10)= 0.0025357115104270634
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:02,709 INFO epoch # 461 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00834385168331081-> 0.00834385168331081 - loss = 0.002996973169501871
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:02,832 INFO epoch # 462 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00834385168331081-> 0.00834385168331081 - loss = 0.0019955188472522423
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:02,955 INFO epoch # 463 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00834385168331081-> 0.00834385168331081 - loss = 0.002356629556743428
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:03,078 INFO epoch # 464 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00834385168331081-> 0.00834385168331081 - loss = 0.001886093319626525
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:03,200 INFO epoch # 465 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00834385168331081-> 0.007509466514979729 - loss = 0.002506446442566812
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:03,324 INFO epoch # 466 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.007509466514979729-> 0.007509466514979729 - loss = 0.0025826815399341285
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:03,448 INFO epoch # 467 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.007509466514979729-> 0.007509466514979729 - loss = 0.002820916153723374
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:03,571 INFO epoch # 468 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.007509466514979729-> 0.007509466514979729 - loss = 0.00240045806276612
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:03,693 INFO epoch # 469 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.007509466514979729-> 0.007509466514979729 - loss = 0.0016011556144803762
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:03,816 INFO epoch # 470 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.007509466514979729-> 0.007509466514979729 - loss = 0.0045302401995286345
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:20:03,816 INFO *** epoch 470, rolling-avg-loss (window=10)= 0.0025677112906123513
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:03,940 INFO epoch # 471 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.007509466514979729-> 0.007509466514979729 - loss = 0.0031549346749670804
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:04,063 INFO epoch # 472 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.007509466514979729-> 0.007509466514979729 - loss = 0.0021133290720172226
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:04,189 INFO epoch # 473 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.007509466514979729-> 0.007509466514979729 - loss = 0.002324460234376602
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:04,332 INFO epoch # 474 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.007509466514979729-> 0.007509466514979729 - loss = 0.0022396440035663545
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:04,474 INFO epoch # 475 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.007509466514979729-> 0.007509466514979729 - loss = 0.00525855747400783
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:04,616 INFO epoch # 476 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.007509466514979729-> 0.006758519863481757 - loss = 0.002061362669337541
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:04,749 INFO epoch # 477 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.006758519863481757-> 0.006758519863481757 - loss = 0.002714711823500693
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:04,880 INFO epoch # 478 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.006758519863481757-> 0.006758519863481757 - loss = 0.0030870723421685398
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:05,003 INFO epoch # 479 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.006758519863481757-> 0.006758519863481757 - loss = 0.001892234809929505
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:05,128 INFO epoch # 480 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.006758519863481757-> 0.006758519863481757 - loss = 0.002444309735437855
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:20:05,128 INFO *** epoch 480, rolling-avg-loss (window=10)= 0.0027290616839309224
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:05,252 INFO epoch # 481 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.006758519863481757-> 0.006758519863481757 - loss = 0.001862648263340816
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:05,382 INFO epoch # 482 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.006758519863481757-> 0.006758519863481757 - loss = 0.0019142374367220327
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:05,521 INFO epoch # 483 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.006758519863481757-> 0.006758519863481757 - loss = 0.0025574896426405758
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:05,652 INFO epoch # 484 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.006758519863481757-> 0.006758519863481757 - loss = 0.005164099275134504
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:05,777 INFO epoch # 485 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.006758519863481757-> 0.006758519863481757 - loss = 0.0033096800616476685
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:05,923 INFO epoch # 486 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.006758519863481757-> 0.006758519863481757 - loss = 0.0019154300971422344
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:06,046 INFO epoch # 487 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.006758519863481757-> 0.006082667877133581 - loss = 0.0018238399206893519
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:06,173 INFO epoch # 488 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.006082667877133581-> 0.006082667877133581 - loss = 0.007795744852046482
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:06,297 INFO epoch # 489 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.006082667877133581-> 0.006082667877133581 - loss = 0.003717755200341344
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:06,422 INFO epoch # 490 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.006082667877133581-> 0.006082667877133581 - loss = 0.002930457441834733
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:20:06,423 INFO *** epoch 490, rolling-avg-loss (window=10)= 0.003299138219153974
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:06,667 INFO epoch # 491 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.006082667877133581-> 0.006082667877133581 - loss = 0.004967597313225269
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:06,821 INFO epoch # 492 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.006082667877133581-> 0.006082667877133581 - loss = 0.0024785864807199687
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:06,944 INFO epoch # 493 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.006082667877133581-> 0.006082667877133581 - loss = 0.0018184445216320455
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:07,068 INFO epoch # 494 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.006082667877133581-> 0.006082667877133581 - loss = 0.00224599294597283
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:07,192 INFO epoch # 495 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.006082667877133581-> 0.006082667877133581 - loss = 0.008878188382368535
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:07,315 INFO epoch # 496 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.006082667877133581-> 0.006082667877133581 - loss = 0.0019956325413659215
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:07,438 INFO epoch # 497 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.006082667877133581-> 0.006082667877133581 - loss = 0.0023159192060120404
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:07,560 INFO epoch # 498 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.006082667877133581-> 0.005474401089420223 - loss = 0.003995468665380031
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:07,684 INFO epoch # 499 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.005474401089420223-> 0.005474401089420223 - loss = 0.004947981855366379
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:07,806 INFO epoch # 500 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.005474401089420223-> 0.005474401089420223 - loss = 0.005157135674380697
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:20:07,806 INFO *** epoch 500, rolling-avg-loss (window=10)= 0.0038800947586423717
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:07,931 INFO epoch # 501 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.005474401089420223-> 0.005474401089420223 - loss = 0.002240162662928924
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:08,055 INFO epoch # 502 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.005474401089420223-> 0.005474401089420223 - loss = 0.003020866570295766
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:08,179 INFO epoch # 503 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.005474401089420223-> 0.005474401089420223 - loss = 0.0017052697367034853
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:08,303 INFO epoch # 504 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.005474401089420223-> 0.005474401089420223 - loss = 0.0015767508884891868
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:08,427 INFO epoch # 505 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.005474401089420223-> 0.005474401089420223 - loss = 0.003360859089298174
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:08,551 INFO epoch # 506 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.005474401089420223-> 0.005474401089420223 - loss = 0.0024280718353111297
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:08,675 INFO epoch # 507 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.005474401089420223-> 0.005474401089420223 - loss = 0.002570110053056851
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:08,798 INFO epoch # 508 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.005474401089420223-> 0.005474401089420223 - loss = 0.002667876789928414
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:08,921 INFO epoch # 509 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.005474401089420223-> 0.004926960980478201 - loss = 0.002458157454384491
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:09,047 INFO epoch # 510 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.004926960980478201-> 0.004926960980478201 - loss = 0.002959214005386457
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:20:09,047 INFO *** epoch 510, rolling-avg-loss (window=10)= 0.0024987339085782876
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:09,171 INFO epoch # 511 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.004926960980478201-> 0.004926960980478201 - loss = 0.003095194377237931
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:09,294 INFO epoch # 512 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.004926960980478201-> 0.004926960980478201 - loss = 0.002386569103691727
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:09,418 INFO epoch # 513 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.004926960980478201-> 0.004926960980478201 - loss = 0.001500047612353228
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:09,540 INFO epoch # 514 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.004926960980478201-> 0.004926960980478201 - loss = 0.0024280280922539532
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:09,665 INFO epoch # 515 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.004926960980478201-> 0.004926960980478201 - loss = 0.002148186933482066
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:09,788 INFO epoch # 516 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.004926960980478201-> 0.004926960980478201 - loss = 0.0016927207761909813
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:09,912 INFO epoch # 517 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.004926960980478201-> 0.004926960980478201 - loss = 0.003162386012263596
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:10,035 INFO epoch # 518 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.004926960980478201-> 0.004926960980478201 - loss = 0.0044833068968728185
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:10,177 INFO epoch # 519 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.004926960980478201-> 0.004926960980478201 - loss = 0.002478324167896062
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:10,313 INFO epoch # 520 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.004926960980478201-> 0.004434264882430382 - loss = 0.0015811753983143717
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:20:10,313 INFO *** epoch 520, rolling-avg-loss (window=10)= 0.0024955939370556735
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:10,493 INFO epoch # 521 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.004434264882430382-> 0.004434264882430382 - loss = 0.0029271138191688806
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:10,636 INFO epoch # 522 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.004434264882430382-> 0.004434264882430382 - loss = 0.001517344790045172
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:10,770 INFO epoch # 523 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.004434264882430382-> 0.004434264882430382 - loss = 0.002525979303754866
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:10,912 INFO epoch # 524 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.004434264882430382-> 0.004434264882430382 - loss = 0.001538926488137804
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:11,051 INFO epoch # 525 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.004434264882430382-> 0.004434264882430382 - loss = 0.0023318656676565297
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:11,175 INFO epoch # 526 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.004434264882430382-> 0.004434264882430382 - loss = 0.001904631091747433
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:11,299 INFO epoch # 527 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.004434264882430382-> 0.004434264882430382 - loss = 0.0016058070177678019
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:11,423 INFO epoch # 528 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.004434264882430382-> 0.004434264882430382 - loss = 0.0012839817136409692
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:11,548 INFO epoch # 529 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.004434264882430382-> 0.004434264882430382 - loss = 0.003273928799899295
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:11,672 INFO epoch # 530 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.004434264882430382-> 0.004434264882430382 - loss = 0.006579970329767093
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:20:11,672 INFO *** epoch 530, rolling-avg-loss (window=10)= 0.0025489549021585844
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:11,795 INFO epoch # 531 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.004434264882430382-> 0.003990838394187343 - loss = 0.0012663525412790477
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:11,918 INFO epoch # 532 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.003990838394187343-> 0.003990838394187343 - loss = 0.003274715505540371
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:12,041 INFO epoch # 533 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.003990838394187343-> 0.003990838394187343 - loss = 0.0019466852099867538
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:12,164 INFO epoch # 534 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.003990838394187343-> 0.003990838394187343 - loss = 0.0017589546769158915
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:12,287 INFO epoch # 535 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.003990838394187343-> 0.003990838394187343 - loss = 0.00377669335284736
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:12,408 INFO epoch # 536 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.003990838394187343-> 0.003990838394187343 - loss = 0.004130008921492845
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:12,530 INFO epoch # 537 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.003990838394187343-> 0.003990838394187343 - loss = 0.0013302146398928016
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:12,652 INFO epoch # 538 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.003990838394187343-> 0.003990838394187343 - loss = 0.0031637225474696606
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:12,775 INFO epoch # 539 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.003990838394187343-> 0.003990838394187343 - loss = 0.001869330255431123
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:12,897 INFO epoch # 540 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.003990838394187343-> 0.003990838394187343 - loss = 0.0023816208995413035
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:20:12,897 INFO *** epoch 540, rolling-avg-loss (window=10)= 0.002489829855039716
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:13,021 INFO epoch # 541 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.003990838394187343-> 0.003990838394187343 - loss = 0.002522213093470782
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:13,144 INFO epoch # 542 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.003990838394187343-> 0.003591754554768609 - loss = 0.0026750884135253727
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:13,267 INFO epoch # 543 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.003591754554768609-> 0.003591754554768609 - loss = 0.001592055952642113
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:13,391 INFO epoch # 544 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.003591754554768609-> 0.003591754554768609 - loss = 0.0033839688694570214
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:13,516 INFO epoch # 545 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.003591754554768609-> 0.003591754554768609 - loss = 0.0017799165507312864
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:13,639 INFO epoch # 546 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.003591754554768609-> 0.003591754554768609 - loss = 0.0015892782539594918
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:13,762 INFO epoch # 547 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.003591754554768609-> 0.003591754554768609 - loss = 0.0053361910686362535
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:13,886 INFO epoch # 548 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.003591754554768609-> 0.003591754554768609 - loss = 0.002159871408366598
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:14,015 INFO epoch # 549 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.003591754554768609-> 0.003591754554768609 - loss = 0.002698879485251382
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:14,142 INFO epoch # 550 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.003591754554768609-> 0.003591754554768609 - loss = 0.0016791476809885353
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:20:14,142 INFO *** epoch 550, rolling-avg-loss (window=10)= 0.002541661077702884
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:14,267 INFO epoch # 551 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.003591754554768609-> 0.003591754554768609 - loss = 0.001780938750016503
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:14,390 INFO epoch # 552 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.003591754554768609-> 0.003591754554768609 - loss = 0.0037586024263873696
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:14,520 INFO epoch # 553 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.003591754554768609-> 0.003232579099291748 - loss = 0.002405403327429667
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:14,647 INFO epoch # 554 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.003232579099291748-> 0.003232579099291748 - loss = 0.00155635952251032
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:14,771 INFO epoch # 555 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.003232579099291748-> 0.003232579099291748 - loss = 0.0036244142975192517
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:14,894 INFO epoch # 556 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.003232579099291748-> 0.003232579099291748 - loss = 0.0019206095021218061
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:15,017 INFO epoch # 557 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.003232579099291748-> 0.003232579099291748 - loss = 0.0018307208374608308
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:15,139 INFO epoch # 558 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.003232579099291748-> 0.003232579099291748 - loss = 0.0015659163254895248
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:15,263 INFO epoch # 559 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.003232579099291748-> 0.003232579099291748 - loss = 0.003889383893692866
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:15,386 INFO epoch # 560 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.003232579099291748-> 0.003232579099291748 - loss = 0.0014707242953591049
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:20:15,386 INFO *** epoch 560, rolling-avg-loss (window=10)= 0.0023803073177987243
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:15,510 INFO epoch # 561 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.003232579099291748-> 0.003232579099291748 - loss = 0.0014063070120755583
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:15,633 INFO epoch # 562 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.003232579099291748-> 0.003232579099291748 - loss = 0.0019437814771663398
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:15,756 INFO epoch # 563 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.003232579099291748-> 0.003232579099291748 - loss = 0.003222973391530104
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:15,879 INFO epoch # 564 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.003232579099291748-> 0.0029093211893625732 - loss = 0.0023898463987279683
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:16,002 INFO epoch # 565 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0029093211893625732-> 0.0029093211893625732 - loss = 0.00202426066971384
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:16,125 INFO epoch # 566 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0029093211893625732-> 0.0029093211893625732 - loss = 0.001994716003537178
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:16,248 INFO epoch # 567 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0029093211893625732-> 0.0029093211893625732 - loss = 0.0017310654511675239
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:16,371 INFO epoch # 568 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0029093211893625732-> 0.0029093211893625732 - loss = 0.0014628804347012192
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:16,494 INFO epoch # 569 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0029093211893625732-> 0.0029093211893625732 - loss = 0.0027396586374379694
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:16,616 INFO epoch # 570 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0029093211893625732-> 0.0029093211893625732 - loss = 0.0032611947099212557
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:20:16,616 INFO *** epoch 570, rolling-avg-loss (window=10)= 0.002217668418597896
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:16,739 INFO epoch # 571 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0029093211893625732-> 0.0029093211893625732 - loss = 0.004789950151462108
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:16,862 INFO epoch # 572 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0029093211893625732-> 0.0029093211893625732 - loss = 0.003729603748070076
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:16,985 INFO epoch # 573 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0029093211893625732-> 0.0029093211893625732 - loss = 0.0030797356157563627
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:17,108 INFO epoch # 574 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0029093211893625732-> 0.0029093211893625732 - loss = 0.001997967134229839
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:17,230 INFO epoch # 575 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0029093211893625732-> 0.002618389070426316 - loss = 0.001655446831136942
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:17,353 INFO epoch # 576 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.002618389070426316-> 0.002618389070426316 - loss = 0.0024840613259584643
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:17,475 INFO epoch # 577 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.002618389070426316-> 0.002618389070426316 - loss = 0.0022257536329561844
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:17,598 INFO epoch # 578 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.002618389070426316-> 0.002618389070426316 - loss = 0.0013246089511085302
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:17,720 INFO epoch # 579 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.002618389070426316-> 0.002618389070426316 - loss = 0.0034367358894087374
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:17,843 INFO epoch # 580 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.002618389070426316-> 0.002618389070426316 - loss = 0.0013563250831793994
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:20:17,843 INFO *** epoch 580, rolling-avg-loss (window=10)= 0.0026080188363266643
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:17,966 INFO epoch # 581 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.002618389070426316-> 0.002618389070426316 - loss = 0.003507658781018108
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:18,088 INFO epoch # 582 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.002618389070426316-> 0.002618389070426316 - loss = 0.006114317060564645
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:18,210 INFO epoch # 583 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.002618389070426316-> 0.002618389070426316 - loss = 0.006324885078356601
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:18,335 INFO epoch # 584 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.002618389070426316-> 0.002618389070426316 - loss = 0.007935968897072598
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:18,457 INFO epoch # 585 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.002618389070426316-> 0.002618389070426316 - loss = 0.0033840267860796303
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:18,579 INFO epoch # 586 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.002618389070426316-> 0.0023565501633836844 - loss = 0.0032666737533872947
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:18,702 INFO epoch # 587 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0023565501633836844-> 0.0023565501633836844 - loss = 0.0031569580896757543
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:18,825 INFO epoch # 588 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0023565501633836844-> 0.0023565501633836844 - loss = 0.002826544485287741
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:18,948 INFO epoch # 589 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0023565501633836844-> 0.0023565501633836844 - loss = 0.0020098015083931386
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:19,071 INFO epoch # 590 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0023565501633836844-> 0.0023565501633836844 - loss = 0.0030288862762972713
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:20:19,071 INFO *** epoch 590, rolling-avg-loss (window=10)= 0.004155572071613278
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:19,194 INFO epoch # 591 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0023565501633836844-> 0.0023565501633836844 - loss = 0.0027295585023239255
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:19,317 INFO epoch # 592 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0023565501633836844-> 0.0023565501633836844 - loss = 0.0017932284972630441
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:19,440 INFO epoch # 593 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0023565501633836844-> 0.0023565501633836844 - loss = 0.0019302761647850275
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:19,563 INFO epoch # 594 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0023565501633836844-> 0.0023565501633836844 - loss = 0.0018926808552350849
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:19,685 INFO epoch # 595 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0023565501633836844-> 0.0023565501633836844 - loss = 0.004537280969088897
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:19,809 INFO epoch # 596 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0023565501633836844-> 0.0023565501633836844 - loss = 0.002673518974916078
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:19,931 INFO epoch # 597 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0023565501633836844-> 0.002120895147045316 - loss = 0.0038127439911477268
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:20,054 INFO epoch # 598 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.002120895147045316-> 0.002120895147045316 - loss = 0.002497209090506658
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:20,177 INFO epoch # 599 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.002120895147045316-> 0.002120895147045316 - loss = 0.0015765285497764125
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:20,300 INFO epoch # 600 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.002120895147045316-> 0.002120895147045316 - loss = 0.002082658465951681
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:20:20,300 INFO *** epoch 600, rolling-avg-loss (window=10)= 0.0025525684060994534
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:20,424 INFO epoch # 601 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.002120895147045316-> 0.002120895147045316 - loss = 0.0013893854047637433
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:20,546 INFO epoch # 602 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.002120895147045316-> 0.002120895147045316 - loss = 0.007780843254295178
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:20,668 INFO epoch # 603 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.002120895147045316-> 0.002120895147045316 - loss = 0.003304926009150222
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:20,791 INFO epoch # 604 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.002120895147045316-> 0.002120895147045316 - loss = 0.0013090808570268564
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:20,914 INFO epoch # 605 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.002120895147045316-> 0.002120895147045316 - loss = 0.0029340929177124053
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:21,036 INFO epoch # 606 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.002120895147045316-> 0.002120895147045316 - loss = 0.0031489003740716726
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:21,159 INFO epoch # 607 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.002120895147045316-> 0.002120895147045316 - loss = 0.003386062104254961
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:21,281 INFO epoch # 608 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.002120895147045316-> 0.0019088056323407843 - loss = 0.002628112750244327
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:21,404 INFO epoch # 609 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0019088056323407843-> 0.0019088056323407843 - loss = 0.0019264972070232034
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:21,526 INFO epoch # 610 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0019088056323407843-> 0.0019088056323407843 - loss = 0.005658866866724566
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:20:21,526 INFO *** epoch 610, rolling-avg-loss (window=10)= 0.0033466767745267134
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:21,651 INFO epoch # 611 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0019088056323407843-> 0.0019088056323407843 - loss = 0.0019594105542637408
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:21,776 INFO epoch # 612 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0019088056323407843-> 0.0019088056323407843 - loss = 0.0015581971674691886
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:21,916 INFO epoch # 613 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0019088056323407843-> 0.0019088056323407843 - loss = 0.0018741915264399722
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:22,056 INFO epoch # 614 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0019088056323407843-> 0.0019088056323407843 - loss = 0.001628614729270339
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:22,183 INFO epoch # 615 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0019088056323407843-> 0.0019088056323407843 - loss = 0.0015575152210658416
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:22,305 INFO epoch # 616 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0019088056323407843-> 0.0019088056323407843 - loss = 0.0018782782135531306
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:22,428 INFO epoch # 617 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0019088056323407843-> 0.0019088056323407843 - loss = 0.0014077072264626622
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:22,550 INFO epoch # 618 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0019088056323407843-> 0.0019088056323407843 - loss = 0.001933716717758216
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:22,673 INFO epoch # 619 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0019088056323407843-> 0.001717925069106706 - loss = 0.002601944259367883
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:22,795 INFO epoch # 620 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.001717925069106706-> 0.001717925069106706 - loss = 0.0019337968260515481
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:20:22,795 INFO *** epoch 620, rolling-avg-loss (window=10)= 0.0018333372441702521
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:22,918 INFO epoch # 621 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.001717925069106706-> 0.001717925069106706 - loss = 0.002005005459068343
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:23,040 INFO epoch # 622 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.001717925069106706-> 0.001717925069106706 - loss = 0.0014313813589978963
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:23,162 INFO epoch # 623 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.001717925069106706-> 0.001717925069106706 - loss = 0.00374535599257797
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:23,285 INFO epoch # 624 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.001717925069106706-> 0.001717925069106706 - loss = 0.0016020145994843915
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:23,423 INFO epoch # 625 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.001717925069106706-> 0.001717925069106706 - loss = 0.0018416829989291728
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:23,555 INFO epoch # 626 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.001717925069106706-> 0.001717925069106706 - loss = 0.0017230121593456715
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:23,678 INFO epoch # 627 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.001717925069106706-> 0.001717925069106706 - loss = 0.001635809865547344
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:23,800 INFO epoch # 628 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.001717925069106706-> 0.001717925069106706 - loss = 0.0020965492440154776
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:23,923 INFO epoch # 629 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.001717925069106706-> 0.001717925069106706 - loss = 0.0015969387859513517
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:24,045 INFO epoch # 630 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.001717925069106706-> 0.0015461325621960354 - loss = 0.0029624338349094614
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:20:24,045 INFO *** epoch 630, rolling-avg-loss (window=10)= 0.002064018429882708
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:24,168 INFO epoch # 631 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0015461325621960354-> 0.0015461325621960354 - loss = 0.002554669452365488
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:24,293 INFO epoch # 632 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0015461325621960354-> 0.0015461325621960354 - loss = 0.002034812088822946
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:24,416 INFO epoch # 633 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0015461325621960354-> 0.0015461325621960354 - loss = 0.0013327230117283762
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:24,543 INFO epoch # 634 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0015461325621960354-> 0.0015461325621960354 - loss = 0.0018967372889164835
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:24,667 INFO epoch # 635 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0015461325621960354-> 0.0015461325621960354 - loss = 0.0012524879202828743
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:24,790 INFO epoch # 636 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0015461325621960354-> 0.0015461325621960354 - loss = 0.0014400707004824653
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:24,913 INFO epoch # 637 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0015461325621960354-> 0.0015461325621960354 - loss = 0.001321519539487781
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:25,036 INFO epoch # 638 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0015461325621960354-> 0.0015461325621960354 - loss = 0.003370327554875985
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:25,160 INFO epoch # 639 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0015461325621960354-> 0.0015461325621960354 - loss = 0.0018818456010194495
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:25,282 INFO epoch # 640 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0015461325621960354-> 0.0015461325621960354 - loss = 0.0032176723470911384
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:20:25,282 INFO *** epoch 640, rolling-avg-loss (window=10)= 0.0020302865505072987
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:25,406 INFO epoch # 641 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0015461325621960354-> 0.0013915193059764318 - loss = 0.0043366795289330184
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:25,529 INFO epoch # 642 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0013915193059764318-> 0.0013915193059764318 - loss = 0.001980665751034394
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:25,651 INFO epoch # 643 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0013915193059764318-> 0.0013915193059764318 - loss = 0.0017565625603310764
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:25,774 INFO epoch # 644 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0013915193059764318-> 0.0013915193059764318 - loss = 0.0025950206618290395
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:25,895 INFO epoch # 645 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0013915193059764318-> 0.0013915193059764318 - loss = 0.0018687748233787715
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:26,018 INFO epoch # 646 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0013915193059764318-> 0.0013915193059764318 - loss = 0.002925347813288681
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:26,139 INFO epoch # 647 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0013915193059764318-> 0.0013915193059764318 - loss = 0.001425579539500177
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:26,261 INFO epoch # 648 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0013915193059764318-> 0.0013915193059764318 - loss = 0.001167458074633032
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:26,384 INFO epoch # 649 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0013915193059764318-> 0.0013915193059764318 - loss = 0.004755048110382631
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:26,507 INFO epoch # 650 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0013915193059764318-> 0.0013915193059764318 - loss = 0.0020442037493921816
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:20:26,507 INFO *** epoch 650, rolling-avg-loss (window=10)= 0.0024855340612703
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:26,629 INFO epoch # 651 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0013915193059764318-> 0.0013915193059764318 - loss = 0.005662723400746472
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:26,751 INFO epoch # 652 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0013915193059764318-> 0.0013915193059764318 - loss = 0.0030895780364517123
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:26,875 INFO epoch # 653 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0013915193059764318-> 0.0013915193059764318 - loss = 0.0029731409158557653
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:26,997 INFO epoch # 654 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0013915193059764318-> 0.0013915193059764318 - loss = 0.002431358036119491
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:27,120 INFO epoch # 655 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0013915193059764318-> 0.0013915193059764318 - loss = 0.002079248515656218
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:27,242 INFO epoch # 656 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0013915193059764318-> 0.0013915193059764318 - loss = 0.001905791403260082
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:27,365 INFO epoch # 657 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0013915193059764318-> 0.0013915193059764318 - loss = 0.004324237030232325
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:27,490 INFO epoch # 658 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0013915193059764318-> 0.0013915193059764318 - loss = 0.002327984111616388
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:27,612 INFO epoch # 659 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0013915193059764318-> 0.0012523673753787887 - loss = 0.003204937282134779
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:27,733 INFO epoch # 660 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0012523673753787887-> 0.0012523673753787887 - loss = 0.002115324401529506
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:20:27,734 INFO *** epoch 660, rolling-avg-loss (window=10)= 0.003011432313360274
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:27,861 INFO epoch # 661 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0012523673753787887-> 0.0012523673753787887 - loss = 0.002825398260029033
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:27,992 INFO epoch # 662 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0012523673753787887-> 0.0012523673753787887 - loss = 0.004284110968001187
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:28,116 INFO epoch # 663 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0012523673753787887-> 0.0012523673753787887 - loss = 0.0014510487962979823
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:28,237 INFO epoch # 664 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0012523673753787887-> 0.0012523673753787887 - loss = 0.0022930591367185116
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:28,360 INFO epoch # 665 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0012523673753787887-> 0.0012523673753787887 - loss = 0.005581808334682137
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:28,482 INFO epoch # 666 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0012523673753787887-> 0.0012523673753787887 - loss = 0.0015918162243906409
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:28,605 INFO epoch # 667 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0012523673753787887-> 0.0012523673753787887 - loss = 0.0027435204247012734
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:28,727 INFO epoch # 668 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0012523673753787887-> 0.0012523673753787887 - loss = 0.0019486929522827268
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:28,851 INFO epoch # 669 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0012523673753787887-> 0.0012523673753787887 - loss = 0.0016307537734974176
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:28,974 INFO epoch # 670 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0012523673753787887-> 0.00112713063784091 - loss = 0.001794224008335732
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:20:28,974 INFO *** epoch 670, rolling-avg-loss (window=10)= 0.002614443287893664
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:29,097 INFO epoch # 671 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00112713063784091-> 0.00112713063784091 - loss = 0.0009943820514308754
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:29,219 INFO epoch # 672 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00112713063784091-> 0.00112713063784091 - loss = 0.005627674254355952
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:29,341 INFO epoch # 673 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00112713063784091-> 0.00112713063784091 - loss = 0.002193931955844164
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:29,468 INFO epoch # 674 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00112713063784091-> 0.00112713063784091 - loss = 0.003842651582090184
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:29,591 INFO epoch # 675 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00112713063784091-> 0.00112713063784091 - loss = 0.00407191037083976
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:29,713 INFO epoch # 676 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00112713063784091-> 0.00112713063784091 - loss = 0.0051375167386140674
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:29,836 INFO epoch # 677 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00112713063784091-> 0.00112713063784091 - loss = 0.004002843197667971
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:29,958 INFO epoch # 678 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00112713063784091-> 0.00112713063784091 - loss = 0.0022273662907537073
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:30,081 INFO epoch # 679 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00112713063784091-> 0.00112713063784091 - loss = 0.0015567882801406085
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:30,206 INFO epoch # 680 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00112713063784091-> 0.00112713063784091 - loss = 0.002322239539353177
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:20:30,206 INFO *** epoch 680, rolling-avg-loss (window=10)= 0.0031977304261090467
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:30,335 INFO epoch # 681 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00112713063784091-> 0.00112713063784091 - loss = 0.003103680006461218
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:30,459 INFO epoch # 682 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00112713063784091-> 0.0010144175740568189 - loss = 0.0011353447625879198
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:30,583 INFO epoch # 683 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0010144175740568189-> 0.0010144175740568189 - loss = 0.0014768225519219413
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:30,706 INFO epoch # 684 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0010144175740568189-> 0.0010144175740568189 - loss = 0.001841211662394926
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:30,829 INFO epoch # 685 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0010144175740568189-> 0.0010144175740568189 - loss = 0.0017922089027706534
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:30,964 INFO epoch # 686 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0010144175740568189-> 0.0010144175740568189 - loss = 0.0016029436083044857
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:31,091 INFO epoch # 687 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0010144175740568189-> 0.0010144175740568189 - loss = 0.0015937531716190279
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:31,215 INFO epoch # 688 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0010144175740568189-> 0.0010144175740568189 - loss = 0.0017975723021663725
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:31,339 INFO epoch # 689 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0010144175740568189-> 0.0010144175740568189 - loss = 0.0013011328846914694
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:31,477 INFO epoch # 690 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0010144175740568189-> 0.0010144175740568189 - loss = 0.001702756286249496
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:20:31,477 INFO *** epoch 690, rolling-avg-loss (window=10)= 0.001734742613916751
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:31,617 INFO epoch # 691 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0010144175740568189-> 0.0010144175740568189 - loss = 0.003950833546696231
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:31,749 INFO epoch # 692 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0010144175740568189-> 0.0010144175740568189 - loss = 0.0011419969232520089
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:31,893 INFO epoch # 693 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0010144175740568189-> 0.000912975816651137 - loss = 0.002640087390318513
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:32,037 INFO epoch # 694 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.000912975816651137-> 0.000912975816651137 - loss = 0.0021656284225173295
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:32,179 INFO epoch # 695 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.000912975816651137-> 0.000912975816651137 - loss = 0.0023709310626145452
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:32,320 INFO epoch # 696 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.000912975816651137-> 0.000912975816651137 - loss = 0.0029086096910759807
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:32,465 INFO epoch # 697 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.000912975816651137-> 0.000912975816651137 - loss = 0.0016670982877258211
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:32,609 INFO epoch # 698 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.000912975816651137-> 0.000912975816651137 - loss = 0.0014788847620366141
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:32,745 INFO epoch # 699 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.000912975816651137-> 0.000912975816651137 - loss = 0.0016404367925133556
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:32,872 INFO epoch # 700 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.000912975816651137-> 0.000912975816651137 - loss = 0.002015111400396563
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:20:32,872 INFO *** epoch 700, rolling-avg-loss (window=10)= 0.002197961827914696
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:33,001 INFO epoch # 701 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.000912975816651137-> 0.000912975816651137 - loss = 0.00242006778717041
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:33,145 INFO epoch # 702 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.000912975816651137-> 0.000912975816651137 - loss = 0.002175851142965257
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:33,281 INFO epoch # 703 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.000912975816651137-> 0.000912975816651137 - loss = 0.002228620884125121
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:33,404 INFO epoch # 704 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.000912975816651137-> 0.0008216782349860233 - loss = 0.0015561387699563056
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:33,530 INFO epoch # 705 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0008216782349860233-> 0.0008216782349860233 - loss = 0.003248064109357074
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:33,656 INFO epoch # 706 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0008216782349860233-> 0.0008216782349860233 - loss = 0.0025603702233638614
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:33,781 INFO epoch # 707 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0008216782349860233-> 0.0008216782349860233 - loss = 0.0017624968604650348
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:33,905 INFO epoch # 708 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0008216782349860233-> 0.0008216782349860233 - loss = 0.0020494556229095906
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:34,035 INFO epoch # 709 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0008216782349860233-> 0.0008216782349860233 - loss = 0.0017920953687280416
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:34,177 INFO epoch # 710 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0008216782349860233-> 0.0008216782349860233 - loss = 0.001351179467746988
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:20:34,177 INFO *** epoch 710, rolling-avg-loss (window=10)= 0.0021144340236787683
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:34,319 INFO epoch # 711 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0008216782349860233-> 0.0008216782349860233 - loss = 0.001959749875823036
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:34,460 INFO epoch # 712 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0008216782349860233-> 0.0008216782349860233 - loss = 0.0029253705142764375
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:34,602 INFO epoch # 713 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0008216782349860233-> 0.0008216782349860233 - loss = 0.0016003801429178566
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:34,734 INFO epoch # 714 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0008216782349860233-> 0.0008216782349860233 - loss = 0.0031715022632852197
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:34,867 INFO epoch # 715 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0008216782349860233-> 0.000739510411487421 - loss = 0.0016989684518193826
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:35,012 INFO epoch # 716 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.000739510411487421-> 0.000739510411487421 - loss = 0.0023304685309994966
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:35,161 INFO epoch # 717 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.000739510411487421-> 0.000739510411487421 - loss = 0.0016166919958777726
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:35,304 INFO epoch # 718 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.000739510411487421-> 0.000739510411487421 - loss = 0.002931648021331057
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:35,448 INFO epoch # 719 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.000739510411487421-> 0.000739510411487421 - loss = 0.002614789962535724
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:35,592 INFO epoch # 720 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.000739510411487421-> 0.000739510411487421 - loss = 0.0014712642005179077
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:20:35,592 INFO *** epoch 720, rolling-avg-loss (window=10)= 0.002232083395938389
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:35,735 INFO epoch # 721 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.000739510411487421-> 0.000739510411487421 - loss = 0.0013440866605378687
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:35,874 INFO epoch # 722 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.000739510411487421-> 0.000739510411487421 - loss = 0.0013996772468090057
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:35,997 INFO epoch # 723 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.000739510411487421-> 0.000739510411487421 - loss = 0.001504858082626015
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:36,123 INFO epoch # 724 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.000739510411487421-> 0.000739510411487421 - loss = 0.004604090107022785
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:36,248 INFO epoch # 725 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.000739510411487421-> 0.000739510411487421 - loss = 0.0020574997179210186
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:36,373 INFO epoch # 726 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.000739510411487421-> 0.0006655593703386789 - loss = 0.0014416604972211644
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:36,497 INFO epoch # 727 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0006655593703386789-> 0.0006655593703386789 - loss = 0.0015455872344318777
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:36,621 INFO epoch # 728 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0006655593703386789-> 0.0006655593703386789 - loss = 0.0019180943054379895
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:36,759 INFO epoch # 729 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0006655593703386789-> 0.0006655593703386789 - loss = 0.0019095847965218127
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:36,896 INFO epoch # 730 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0006655593703386789-> 0.0006655593703386789 - loss = 0.0023650107759749517
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:20:36,896 INFO *** epoch 730, rolling-avg-loss (window=10)= 0.002009014942450449
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:37,026 INFO epoch # 731 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0006655593703386789-> 0.0006655593703386789 - loss = 0.00218867594958283
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:37,162 INFO epoch # 732 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0006655593703386789-> 0.0006655593703386789 - loss = 0.0016301967261824757
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:37,300 INFO epoch # 733 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0006655593703386789-> 0.0006655593703386789 - loss = 0.001890385668957606
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:37,449 INFO epoch # 734 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0006655593703386789-> 0.0006655593703386789 - loss = 0.0017792497310438193
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:37,590 INFO epoch # 735 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0006655593703386789-> 0.0006655593703386789 - loss = 0.0018746191635727882
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:37,712 INFO epoch # 736 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0006655593703386789-> 0.0006655593703386789 - loss = 0.0017361783829983324
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:37,835 INFO epoch # 737 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0006655593703386789-> 0.0005990034333048111 - loss = 0.0013081099750706926
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:37,957 INFO epoch # 738 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0005990034333048111-> 0.0005990034333048111 - loss = 0.004794510256033391
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:38,082 INFO epoch # 739 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0005990034333048111-> 0.0005990034333048111 - loss = 0.002322435029782355
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:38,205 INFO epoch # 740 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0005990034333048111-> 0.0005990034333048111 - loss = 0.001678150292718783
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:20:38,205 INFO *** epoch 740, rolling-avg-loss (window=10)= 0.002120251117594307
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:38,330 INFO epoch # 741 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0005990034333048111-> 0.0005990034333048111 - loss = 0.001385961179039441
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:38,452 INFO epoch # 742 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0005990034333048111-> 0.0005990034333048111 - loss = 0.003762421983992681
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:38,575 INFO epoch # 743 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0005990034333048111-> 0.0005990034333048111 - loss = 0.001782730920240283
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:38,698 INFO epoch # 744 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0005990034333048111-> 0.0005990034333048111 - loss = 0.0021231620921753347
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:38,823 INFO epoch # 745 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0005990034333048111-> 0.0005990034333048111 - loss = 0.0038266307237790897
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:38,955 INFO epoch # 746 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0005990034333048111-> 0.0005990034333048111 - loss = 0.0016010608051146846
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:39,080 INFO epoch # 747 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0005990034333048111-> 0.0005990034333048111 - loss = 0.0015652290894649923
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:39,202 INFO epoch # 748 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0005990034333048111-> 0.0005391030899743299 - loss = 0.002529381134081632
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:39,324 INFO epoch # 749 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0005391030899743299-> 0.0005391030899743299 - loss = 0.0025948573311325163
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:39,446 INFO epoch # 750 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0005391030899743299-> 0.0005391030899743299 - loss = 0.0020336816378403455
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:20:39,446 INFO *** epoch 750, rolling-avg-loss (window=10)= 0.0023205116896861
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:39,568 INFO epoch # 751 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0005391030899743299-> 0.0005391030899743299 - loss = 0.0012343436319497414
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:39,710 INFO epoch # 752 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0005391030899743299-> 0.0005391030899743299 - loss = 0.0017293463024543598
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:39,856 INFO epoch # 753 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0005391030899743299-> 0.0005391030899743299 - loss = 0.0015661165671190247
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:40,004 INFO epoch # 754 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0005391030899743299-> 0.0005391030899743299 - loss = 0.0016888166137505323
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:40,128 INFO epoch # 755 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0005391030899743299-> 0.0005391030899743299 - loss = 0.001780322170816362
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:40,254 INFO epoch # 756 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0005391030899743299-> 0.0005391030899743299 - loss = 0.0012351391778793186
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:40,377 INFO epoch # 757 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0005391030899743299-> 0.0005391030899743299 - loss = 0.001811635731428396
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:40,519 INFO epoch # 758 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0005391030899743299-> 0.0005391030899743299 - loss = 0.002643612853717059
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:40,643 INFO epoch # 759 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0005391030899743299-> 0.00048519278097689693 - loss = 0.0017332255083601922
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:40,768 INFO epoch # 760 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00048519278097689693-> 0.00048519278097689693 - loss = 0.0014958898536860943
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:20:40,768 INFO *** epoch 760, rolling-avg-loss (window=10)= 0.001691844841116108
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:40,892 INFO epoch # 761 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00048519278097689693-> 0.00048519278097689693 - loss = 0.0026696566201280802
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:41,021 INFO epoch # 762 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00048519278097689693-> 0.00048519278097689693 - loss = 0.0013816349965054542
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:41,164 INFO epoch # 763 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00048519278097689693-> 0.00048519278097689693 - loss = 0.001475939090596512
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:41,307 INFO epoch # 764 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00048519278097689693-> 0.00048519278097689693 - loss = 0.0014925059076631442
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:41,450 INFO epoch # 765 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00048519278097689693-> 0.00048519278097689693 - loss = 0.0020157213730271906
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:41,591 INFO epoch # 766 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00048519278097689693-> 0.00048519278097689693 - loss = 0.0021680152422050014
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:41,745 INFO epoch # 767 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00048519278097689693-> 0.00048519278097689693 - loss = 0.0024808408634271473
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:41,887 INFO epoch # 768 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00048519278097689693-> 0.00048519278097689693 - loss = 0.004945387350744568
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:42,013 INFO epoch # 769 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00048519278097689693-> 0.00048519278097689693 - loss = 0.0020853736059507355
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:42,138 INFO epoch # 770 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00048519278097689693-> 0.00043667350287920724 - loss = 0.0027860360860358924
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:20:42,139 INFO *** epoch 770, rolling-avg-loss (window=10)= 0.0023501111136283726
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:42,273 INFO epoch # 771 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00043667350287920724-> 0.00043667350287920724 - loss = 0.003511737013468519
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:42,398 INFO epoch # 772 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00043667350287920724-> 0.00043667350287920724 - loss = 0.0019449038663879037
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:42,522 INFO epoch # 773 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00043667350287920724-> 0.00043667350287920724 - loss = 0.0034704275894910097
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:42,648 INFO epoch # 774 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00043667350287920724-> 0.00043667350287920724 - loss = 0.0015398484028992243
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:42,771 INFO epoch # 775 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00043667350287920724-> 0.00043667350287920724 - loss = 0.001684936578385532
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:42,904 INFO epoch # 776 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00043667350287920724-> 0.00043667350287920724 - loss = 0.002154034096747637
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:43,037 INFO epoch # 777 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00043667350287920724-> 0.00043667350287920724 - loss = 0.005318515803082846
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:43,176 INFO epoch # 778 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00043667350287920724-> 0.00043667350287920724 - loss = 0.0018529768130974844
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:43,311 INFO epoch # 779 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00043667350287920724-> 0.00043667350287920724 - loss = 0.00435258261859417
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:43,454 INFO epoch # 780 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00043667350287920724-> 0.00043667350287920724 - loss = 0.0012239892821526155
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:20:43,454 INFO *** epoch 780, rolling-avg-loss (window=10)= 0.002705395206430694
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:43,588 INFO epoch # 781 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00043667350287920724-> 0.0003930061525912865 - loss = 0.001385841955197975
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:43,725 INFO epoch # 782 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0003930061525912865-> 0.0003930061525912865 - loss = 0.005917173228226602
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:43,856 INFO epoch # 783 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0003930061525912865-> 0.0003930061525912865 - loss = 0.0053038135811220855
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:43,979 INFO epoch # 784 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0003930061525912865-> 0.0003930061525912865 - loss = 0.0017149432969745249
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:44,102 INFO epoch # 785 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0003930061525912865-> 0.0003930061525912865 - loss = 0.002486452125594951
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:44,226 INFO epoch # 786 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0003930061525912865-> 0.0003930061525912865 - loss = 0.001772258066921495
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:44,356 INFO epoch # 787 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0003930061525912865-> 0.0003930061525912865 - loss = 0.001904259348521009
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:44,506 INFO epoch # 788 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0003930061525912865-> 0.0003930061525912865 - loss = 0.0014435973353101872
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:44,643 INFO epoch # 789 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0003930061525912865-> 0.0003930061525912865 - loss = 0.006202680422575213
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:44,765 INFO epoch # 790 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0003930061525912865-> 0.0003930061525912865 - loss = 0.0018552941037341952
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:20:44,765 INFO *** epoch 790, rolling-avg-loss (window=10)= 0.002998631346417824
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:44,889 INFO epoch # 791 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0003930061525912865-> 0.0003930061525912865 - loss = 0.0018789851892506704
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:45,014 INFO epoch # 792 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0003930061525912865-> 0.0003537055373321579 - loss = 0.004856796818785369
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:45,137 INFO epoch # 793 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0003537055373321579-> 0.0003537055373321579 - loss = 0.001975591789232567
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:45,259 INFO epoch # 794 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0003537055373321579-> 0.0003537055373321579 - loss = 0.0017003288812702522
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:45,384 INFO epoch # 795 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0003537055373321579-> 0.0003537055373321579 - loss = 0.0015148748934734613
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:45,509 INFO epoch # 796 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0003537055373321579-> 0.0003537055373321579 - loss = 0.0028069848922314122
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:45,632 INFO epoch # 797 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0003537055373321579-> 0.0003537055373321579 - loss = 0.0015689958818256855
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:45,754 INFO epoch # 798 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0003537055373321579-> 0.0003537055373321579 - loss = 0.0018705757684074342
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:45,879 INFO epoch # 799 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0003537055373321579-> 0.0003537055373321579 - loss = 0.00864778141840361
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:46,004 INFO epoch # 800 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0003537055373321579-> 0.0003537055373321579 - loss = 0.0025957274629035965
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:20:46,004 INFO *** epoch 800, rolling-avg-loss (window=10)= 0.002941664299578406
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:46,130 INFO epoch # 801 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0003537055373321579-> 0.0003537055373321579 - loss = 0.0027457614487502724
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:46,253 INFO epoch # 802 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0003537055373321579-> 0.0003537055373321579 - loss = 0.0018264334357809275
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:46,377 INFO epoch # 803 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0003537055373321579-> 0.00031833498359894213 - loss = 0.0030687270336784422
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:46,502 INFO epoch # 804 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00031833498359894213-> 0.00031833498359894213 - loss = 0.004287727497285232
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:46,625 INFO epoch # 805 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00031833498359894213-> 0.00031833498359894213 - loss = 0.0015894890821073204
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:46,748 INFO epoch # 806 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00031833498359894213-> 0.00031833498359894213 - loss = 0.0014388734998647124
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:46,875 INFO epoch # 807 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00031833498359894213-> 0.00031833498359894213 - loss = 0.0037367815675679594
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:47,005 INFO epoch # 808 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00031833498359894213-> 0.00031833498359894213 - loss = 0.001192823903693352
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:47,128 INFO epoch # 809 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00031833498359894213-> 0.00031833498359894213 - loss = 0.003971735772211105
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:47,250 INFO epoch # 810 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00031833498359894213-> 0.00031833498359894213 - loss = 0.0030912570364307612
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:20:47,250 INFO *** epoch 810, rolling-avg-loss (window=10)= 0.0026949610277370085
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:47,373 INFO epoch # 811 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00031833498359894213-> 0.00031833498359894213 - loss = 0.0022211312607396394
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:47,500 INFO epoch # 812 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00031833498359894213-> 0.00031833498359894213 - loss = 0.0025383271713508293
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:47,623 INFO epoch # 813 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00031833498359894213-> 0.00031833498359894213 - loss = 0.001651566126383841
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:47,745 INFO epoch # 814 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00031833498359894213-> 0.00028650148523904793 - loss = 0.0017019439837895334
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:47,869 INFO epoch # 815 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00028650148523904793-> 0.00028650148523904793 - loss = 0.0017427630664315075
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:47,993 INFO epoch # 816 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00028650148523904793-> 0.00028650148523904793 - loss = 0.0036951867514289916
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:48,116 INFO epoch # 817 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00028650148523904793-> 0.00028650148523904793 - loss = 0.007923630109871738
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:48,238 INFO epoch # 818 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00028650148523904793-> 0.00028650148523904793 - loss = 0.0016894315485842526
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:48,360 INFO epoch # 819 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00028650148523904793-> 0.00028650148523904793 - loss = 0.0020561277051456273
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:48,486 INFO epoch # 820 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00028650148523904793-> 0.00028650148523904793 - loss = 0.0016156359342858195
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:20:48,486 INFO *** epoch 820, rolling-avg-loss (window=10)= 0.0026835743658011777
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:48,611 INFO epoch # 821 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00028650148523904793-> 0.00028650148523904793 - loss = 0.0028136036853538826
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:48,738 INFO epoch # 822 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00028650148523904793-> 0.00028650148523904793 - loss = 0.0032301774190273136
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:48,862 INFO epoch # 823 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00028650148523904793-> 0.00028650148523904793 - loss = 0.001577282208018005
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:48,989 INFO epoch # 824 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00028650148523904793-> 0.00028650148523904793 - loss = 0.0026777746388688684
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:49,113 INFO epoch # 825 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00028650148523904793-> 0.00025785133671514315 - loss = 0.002522655879147351
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:49,236 INFO epoch # 826 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00025785133671514315-> 0.00025785133671514315 - loss = 0.0017330585978925228
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:49,360 INFO epoch # 827 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00025785133671514315-> 0.00025785133671514315 - loss = 0.001487419256591238
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:49,485 INFO epoch # 828 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00025785133671514315-> 0.00025785133671514315 - loss = 0.001496192126069218
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:49,610 INFO epoch # 829 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00025785133671514315-> 0.00025785133671514315 - loss = 0.005872538720723242
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:49,737 INFO epoch # 830 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00025785133671514315-> 0.00025785133671514315 - loss = 0.0017875967896543443
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:20:49,737 INFO *** epoch 830, rolling-avg-loss (window=10)= 0.0025198299321345986
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:49,863 INFO epoch # 831 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00025785133671514315-> 0.00025785133671514315 - loss = 0.003321005468023941
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:49,988 INFO epoch # 832 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00025785133671514315-> 0.00025785133671514315 - loss = 0.002316951271495782
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:50,113 INFO epoch # 833 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00025785133671514315-> 0.00025785133671514315 - loss = 0.0032701374730095267
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:50,237 INFO epoch # 834 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00025785133671514315-> 0.00025785133671514315 - loss = 0.002052061870926991
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:50,361 INFO epoch # 835 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00025785133671514315-> 0.00025785133671514315 - loss = 0.0018209166009910405
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:50,486 INFO epoch # 836 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00025785133671514315-> 0.00023206620304362885 - loss = 0.00197708752239123
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:50,609 INFO epoch # 837 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00023206620304362885-> 0.00023206620304362885 - loss = 0.0033905828604474664
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:50,732 INFO epoch # 838 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00023206620304362885-> 0.00023206620304362885 - loss = 0.0013743995514232665
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:50,856 INFO epoch # 839 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00023206620304362885-> 0.00023206620304362885 - loss = 0.002225946358521469
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:50,981 INFO epoch # 840 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00023206620304362885-> 0.00023206620304362885 - loss = 0.001799632009351626
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:20:50,981 INFO *** epoch 840, rolling-avg-loss (window=10)= 0.002354872098658234
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:51,105 INFO epoch # 841 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00023206620304362885-> 0.00023206620304362885 - loss = 0.002163995843147859
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:51,228 INFO epoch # 842 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00023206620304362885-> 0.00023206620304362885 - loss = 0.001196858604089357
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:51,352 INFO epoch # 843 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00023206620304362885-> 0.00023206620304362885 - loss = 0.0013112091546645388
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:51,476 INFO epoch # 844 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00023206620304362885-> 0.00023206620304362885 - loss = 0.0016997979837469757
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:51,600 INFO epoch # 845 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00023206620304362885-> 0.00023206620304362885 - loss = 0.002086381515255198
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:51,723 INFO epoch # 846 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00023206620304362885-> 0.00023206620304362885 - loss = 0.002552665799157694
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:51,860 INFO epoch # 847 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00023206620304362885-> 0.00020885958273926598 - loss = 0.003346971541759558
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:52,001 INFO epoch # 848 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00020885958273926598-> 0.00020885958273926598 - loss = 0.0027204257785342634
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:52,127 INFO epoch # 849 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00020885958273926598-> 0.00020885958273926598 - loss = 0.0015637924370821565
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:52,252 INFO epoch # 850 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00020885958273926598-> 0.00020885958273926598 - loss = 0.002671888636541553
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:20:52,252 INFO *** epoch 850, rolling-avg-loss (window=10)= 0.0021313987293979154
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:52,386 INFO epoch # 851 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00020885958273926598-> 0.00020885958273926598 - loss = 0.0011966988604399376
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:52,514 INFO epoch # 852 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00020885958273926598-> 0.00020885958273926598 - loss = 0.001672244950896129
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:52,643 INFO epoch # 853 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00020885958273926598-> 0.00020885958273926598 - loss = 0.0013210604156483896
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:52,771 INFO epoch # 854 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00020885958273926598-> 0.00020885958273926598 - loss = 0.001586357830092311
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:52,896 INFO epoch # 855 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00020885958273926598-> 0.00020885958273926598 - loss = 0.0064657830516807735
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:53,020 INFO epoch # 856 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00020885958273926598-> 0.00020885958273926598 - loss = 0.0016278392577078193
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:53,143 INFO epoch # 857 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00020885958273926598-> 0.00020885958273926598 - loss = 0.003709586861077696
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:53,268 INFO epoch # 858 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00020885958273926598-> 0.00018797362446533938 - loss = 0.0016038338944781572
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:53,395 INFO epoch # 859 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00018797362446533938-> 0.00018797362446533938 - loss = 0.0019563577661756426
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:53,521 INFO epoch # 860 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00018797362446533938-> 0.00018797362446533938 - loss = 0.0025332126242574304
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:20:53,521 INFO *** epoch 860, rolling-avg-loss (window=10)= 0.0023672975512454286
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:53,645 INFO epoch # 861 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00018797362446533938-> 0.00018797362446533938 - loss = 0.0038063541578594595
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:53,770 INFO epoch # 862 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00018797362446533938-> 0.00018797362446533938 - loss = 0.0031415470002684742
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:53,896 INFO epoch # 863 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00018797362446533938-> 0.00018797362446533938 - loss = 0.0016296268731821328
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:54,021 INFO epoch # 864 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00018797362446533938-> 0.00018797362446533938 - loss = 0.001430383650586009
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:54,147 INFO epoch # 865 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00018797362446533938-> 0.00018797362446533938 - loss = 0.0013974482280900702
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:54,275 INFO epoch # 866 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00018797362446533938-> 0.00018797362446533938 - loss = 0.001499867852544412
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:54,403 INFO epoch # 867 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00018797362446533938-> 0.00018797362446533938 - loss = 0.0017363087099511176
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:54,528 INFO epoch # 868 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00018797362446533938-> 0.00018797362446533938 - loss = 0.0017655014817137271
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:54,660 INFO epoch # 869 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00018797362446533938-> 0.00016917626201880544 - loss = 0.0021834344952367246
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:54,791 INFO epoch # 870 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00016917626201880544-> 0.00016917626201880544 - loss = 0.002367042805417441
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:20:54,791 INFO *** epoch 870, rolling-avg-loss (window=10)= 0.0020957515254849566
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:54,916 INFO epoch # 871 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00016917626201880544-> 0.00016917626201880544 - loss = 0.0013148809812264517
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:55,039 INFO epoch # 872 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00016917626201880544-> 0.00016917626201880544 - loss = 0.0016462223138660192
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:55,167 INFO epoch # 873 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00016917626201880544-> 0.00016917626201880544 - loss = 0.0014906461437931284
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:55,310 INFO epoch # 874 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00016917626201880544-> 0.00016917626201880544 - loss = 0.0020349543483462185
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:55,452 INFO epoch # 875 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00016917626201880544-> 0.00016917626201880544 - loss = 0.0016092704172478989
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:55,581 INFO epoch # 876 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00016917626201880544-> 0.00016917626201880544 - loss = 0.0018488269997760653
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:55,713 INFO epoch # 877 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00016917626201880544-> 0.00016917626201880544 - loss = 0.0021808438177686185
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:55,850 INFO epoch # 878 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00016917626201880544-> 0.00016917626201880544 - loss = 0.0020277741132304072
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:55,982 INFO epoch # 879 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00016917626201880544-> 0.00016917626201880544 - loss = 0.0021876020182389766
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:56,105 INFO epoch # 880 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00016917626201880544-> 0.00015225863581692489 - loss = 0.00355749529262539
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:20:56,105 INFO *** epoch 880, rolling-avg-loss (window=10)= 0.0019898516446119176
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:56,228 INFO epoch # 881 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00015225863581692489-> 0.00015225863581692489 - loss = 0.0011526830639922991
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:56,350 INFO epoch # 882 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00015225863581692489-> 0.00015225863581692489 - loss = 0.0015233835729304701
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:56,474 INFO epoch # 883 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00015225863581692489-> 0.00015225863581692489 - loss = 0.003128470867522992
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:56,597 INFO epoch # 884 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00015225863581692489-> 0.00015225863581692489 - loss = 0.0014030412130523473
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:56,723 INFO epoch # 885 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00015225863581692489-> 0.00015225863581692489 - loss = 0.0032251286902464926
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:56,846 INFO epoch # 886 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00015225863581692489-> 0.00015225863581692489 - loss = 0.0019764892640523612
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:56,970 INFO epoch # 887 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00015225863581692489-> 0.00015225863581692489 - loss = 0.0018052923842333257
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:57,099 INFO epoch # 888 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00015225863581692489-> 0.00015225863581692489 - loss = 0.0014602873416151851
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:57,227 INFO epoch # 889 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00015225863581692489-> 0.00015225863581692489 - loss = 0.0016562143864575773
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:57,349 INFO epoch # 890 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00015225863581692489-> 0.00015225863581692489 - loss = 0.002060793311102316
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:20:57,350 INFO *** epoch 890, rolling-avg-loss (window=10)= 0.0019391784095205366
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:57,479 INFO epoch # 891 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00015225863581692489-> 0.0001370327722352324 - loss = 0.004451309476280585
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:57,621 INFO epoch # 892 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0001370327722352324-> 0.0001370327722352324 - loss = 0.0028067181701771915
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:57,763 INFO epoch # 893 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0001370327722352324-> 0.0001370327722352324 - loss = 0.0015324743726523593
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:57,904 INFO epoch # 894 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0001370327722352324-> 0.0001370327722352324 - loss = 0.0020417244522832334
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:58,047 INFO epoch # 895 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0001370327722352324-> 0.0001370327722352324 - loss = 0.0015707303246017545
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:58,188 INFO epoch # 896 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0001370327722352324-> 0.0001370327722352324 - loss = 0.003761123211006634
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:58,327 INFO epoch # 897 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0001370327722352324-> 0.0001370327722352324 - loss = 0.0020290494721848518
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:58,469 INFO epoch # 898 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0001370327722352324-> 0.0001370327722352324 - loss = 0.0016334933461621404
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:58,607 INFO epoch # 899 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0001370327722352324-> 0.0001370327722352324 - loss = 0.00421021923830267
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:58,744 INFO epoch # 900 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0001370327722352324-> 0.0001370327722352324 - loss = 0.002941405400633812
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:20:58,745 INFO *** epoch 900, rolling-avg-loss (window=10)= 0.0026978247464285233
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:58,885 INFO epoch # 901 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0001370327722352324-> 0.0001370327722352324 - loss = 0.0016551602457184345
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:59,023 INFO epoch # 902 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.0001370327722352324-> 0.00012332949501170915 - loss = 0.0013212965714046732
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:59,166 INFO epoch # 903 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00012332949501170915-> 0.00012332949501170915 - loss = 0.002881392356357537
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:59,307 INFO epoch # 904 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00012332949501170915-> 0.00012332949501170915 - loss = 0.0014864298718748614
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:59,451 INFO epoch # 905 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00012332949501170915-> 0.00012332949501170915 - loss = 0.001852143759606406
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:59,576 INFO epoch # 906 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00012332949501170915-> 0.00012332949501170915 - loss = 0.004318325853091665
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:59,709 INFO epoch # 907 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00012332949501170915-> 0.00012332949501170915 - loss = 0.002463801996782422
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:59,851 INFO epoch # 908 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00012332949501170915-> 0.00012332949501170915 - loss = 0.002381053869612515
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:20:59,992 INFO epoch # 909 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00012332949501170915-> 0.00012332949501170915 - loss = 0.002101322024827823
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:21:00,132 INFO epoch # 910 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00012332949501170915-> 0.00012332949501170915 - loss = 0.0028301207057666034
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:21:00,132 INFO *** epoch 910, rolling-avg-loss (window=10)= 0.002329104725504294
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:21:00,276 INFO epoch # 911 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00012332949501170915-> 0.00012332949501170915 - loss = 0.001963870774488896
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:21:00,413 INFO epoch # 912 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00012332949501170915-> 0.00012332949501170915 - loss = 0.0016798116848804057
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:21:00,538 INFO epoch # 913 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00012332949501170915-> 0.00011099654551053824 - loss = 0.0020871683955192566
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:21:00,675 INFO epoch # 914 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00011099654551053824-> 0.00011099654551053824 - loss = 0.0012798291427316144
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:21:00,812 INFO epoch # 915 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00011099654551053824-> 0.00011099654551053824 - loss = 0.0023483675031457096
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:21:00,947 INFO epoch # 916 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00011099654551053824-> 0.00011099654551053824 - loss = 0.0011247084621572867
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:21:01,086 INFO epoch # 917 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00011099654551053824-> 0.00011099654551053824 - loss = 0.0017288568487856537
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:21:01,213 INFO epoch # 918 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00011099654551053824-> 0.00011099654551053824 - loss = 0.003387346339877695
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:21:01,355 INFO epoch # 919 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00011099654551053824-> 0.00011099654551053824 - loss = 0.0013713445296161808
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:21:01,496 INFO epoch # 920 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00011099654551053824-> 0.00011099654551053824 - loss = 0.002415415830910206
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:21:01,496 INFO *** epoch 920, rolling-avg-loss (window=10)= 0.0019386719512112904
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:21:01,627 INFO epoch # 921 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00011099654551053824-> 0.00011099654551053824 - loss = 0.002933313313405961
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:21:01,759 INFO epoch # 922 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00011099654551053824-> 0.00011099654551053824 - loss = 0.0034022096660919487
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:21:01,899 INFO epoch # 923 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00011099654551053824-> 0.00011099654551053824 - loss = 0.0024749614822212607
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:21:02,041 INFO epoch # 924 - for optimizer <class 'torch.optim.adam.Adam'> lr : 0.00011099654551053824-> 9.989689095948442e-05 - loss = 0.001917475339723751
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:21:02,177 INFO epoch # 925 - for optimizer <class 'torch.optim.adam.Adam'> lr : 9.989689095948442e-05-> 9.989689095948442e-05 - loss = 0.006111470866017044
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:21:02,317 INFO epoch # 926 - for optimizer <class 'torch.optim.adam.Adam'> lr : 9.989689095948442e-05-> 9.989689095948442e-05 - loss = 0.0011207489151274785
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:21:02,452 INFO epoch # 927 - for optimizer <class 'torch.optim.adam.Adam'> lr : 9.989689095948442e-05-> 9.989689095948442e-05 - loss = 0.0011811388321802951
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:21:02,584 INFO epoch # 928 - for optimizer <class 'torch.optim.adam.Adam'> lr : 9.989689095948442e-05-> 9.989689095948442e-05 - loss = 0.003676027525216341
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:21:02,714 INFO epoch # 929 - for optimizer <class 'torch.optim.adam.Adam'> lr : 9.989689095948442e-05-> 9.989689095948442e-05 - loss = 0.0013897016615374014
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:21:02,844 INFO epoch # 930 - for optimizer <class 'torch.optim.adam.Adam'> lr : 9.989689095948442e-05-> 9.989689095948442e-05 - loss = 0.002033620170550421
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:21:02,844 INFO *** epoch 930, rolling-avg-loss (window=10)= 0.00262406677720719
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:21:02,969 INFO epoch # 931 - for optimizer <class 'torch.optim.adam.Adam'> lr : 9.989689095948442e-05-> 9.989689095948442e-05 - loss = 0.002186646015616134
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:21:03,096 INFO epoch # 932 - for optimizer <class 'torch.optim.adam.Adam'> lr : 9.989689095948442e-05-> 9.989689095948442e-05 - loss = 0.0019237362139392644
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:21:03,233 INFO epoch # 933 - for optimizer <class 'torch.optim.adam.Adam'> lr : 9.989689095948442e-05-> 9.989689095948442e-05 - loss = 0.0029450450383592397
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:21:03,373 INFO epoch # 934 - for optimizer <class 'torch.optim.adam.Adam'> lr : 9.989689095948442e-05-> 9.989689095948442e-05 - loss = 0.001202230341732502
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:21:03,497 INFO epoch # 935 - for optimizer <class 'torch.optim.adam.Adam'> lr : 9.989689095948442e-05-> 8.990720186353598e-05 - loss = 0.0029719079029746354
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:21:03,623 INFO epoch # 936 - for optimizer <class 'torch.optim.adam.Adam'> lr : 8.990720186353598e-05-> 8.990720186353598e-05 - loss = 0.0018200915947090834
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:21:03,754 INFO epoch # 937 - for optimizer <class 'torch.optim.adam.Adam'> lr : 8.990720186353598e-05-> 8.990720186353598e-05 - loss = 0.004082177838427015
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:21:03,899 INFO epoch # 938 - for optimizer <class 'torch.optim.adam.Adam'> lr : 8.990720186353598e-05-> 8.990720186353598e-05 - loss = 0.003750505653442815
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:21:04,028 INFO epoch # 939 - for optimizer <class 'torch.optim.adam.Adam'> lr : 8.990720186353598e-05-> 8.990720186353598e-05 - loss = 0.0015725180128356442
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:21:04,162 INFO epoch # 940 - for optimizer <class 'torch.optim.adam.Adam'> lr : 8.990720186353598e-05-> 8.990720186353598e-05 - loss = 0.002298741484992206
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:21:04,163 INFO *** epoch 940, rolling-avg-loss (window=10)= 0.0024753600097028538
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:21:04,305 INFO epoch # 941 - for optimizer <class 'torch.optim.adam.Adam'> lr : 8.990720186353598e-05-> 8.990720186353598e-05 - loss = 0.0016132670280057937
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:21:04,434 INFO epoch # 942 - for optimizer <class 'torch.optim.adam.Adam'> lr : 8.990720186353598e-05-> 8.990720186353598e-05 - loss = 0.0024305163242388517
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:21:04,561 INFO epoch # 943 - for optimizer <class 'torch.optim.adam.Adam'> lr : 8.990720186353598e-05-> 8.990720186353598e-05 - loss = 0.0044488536514109
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:21:04,685 INFO epoch # 944 - for optimizer <class 'torch.optim.adam.Adam'> lr : 8.990720186353598e-05-> 8.990720186353598e-05 - loss = 0.0020799908379558474
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:21:04,818 INFO epoch # 945 - for optimizer <class 'torch.optim.adam.Adam'> lr : 8.990720186353598e-05-> 8.990720186353598e-05 - loss = 0.0016644745774101466
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:21:04,942 INFO epoch # 946 - for optimizer <class 'torch.optim.adam.Adam'> lr : 8.990720186353598e-05-> 8.091648167718239e-05 - loss = 0.0015533508267253637
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:21:05,070 INFO epoch # 947 - for optimizer <class 'torch.optim.adam.Adam'> lr : 8.091648167718239e-05-> 8.091648167718239e-05 - loss = 0.0022091594873927534
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:21:05,212 INFO epoch # 948 - for optimizer <class 'torch.optim.adam.Adam'> lr : 8.091648167718239e-05-> 8.091648167718239e-05 - loss = 0.003868462285026908
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:21:05,341 INFO epoch # 949 - for optimizer <class 'torch.optim.adam.Adam'> lr : 8.091648167718239e-05-> 8.091648167718239e-05 - loss = 0.001846318889874965
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:21:05,463 INFO epoch # 950 - for optimizer <class 'torch.optim.adam.Adam'> lr : 8.091648167718239e-05-> 8.091648167718239e-05 - loss = 0.002819371147779748
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:21:05,463 INFO *** epoch 950, rolling-avg-loss (window=10)= 0.0024533765055821275
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:21:05,587 INFO epoch # 951 - for optimizer <class 'torch.optim.adam.Adam'> lr : 8.091648167718239e-05-> 8.091648167718239e-05 - loss = 0.005784313063486479
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:21:05,718 INFO epoch # 952 - for optimizer <class 'torch.optim.adam.Adam'> lr : 8.091648167718239e-05-> 8.091648167718239e-05 - loss = 0.0019404395716264844
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:21:05,844 INFO epoch # 953 - for optimizer <class 'torch.optim.adam.Adam'> lr : 8.091648167718239e-05-> 8.091648167718239e-05 - loss = 0.002070306203677319
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:21:05,975 INFO epoch # 954 - for optimizer <class 'torch.optim.adam.Adam'> lr : 8.091648167718239e-05-> 8.091648167718239e-05 - loss = 0.005622091892291792
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:21:06,103 INFO epoch # 955 - for optimizer <class 'torch.optim.adam.Adam'> lr : 8.091648167718239e-05-> 8.091648167718239e-05 - loss = 0.0022684910509269685
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:21:06,229 INFO epoch # 956 - for optimizer <class 'torch.optim.adam.Adam'> lr : 8.091648167718239e-05-> 8.091648167718239e-05 - loss = 0.001713190387818031
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:21:06,353 INFO epoch # 957 - for optimizer <class 'torch.optim.adam.Adam'> lr : 8.091648167718239e-05-> 7.282483350946415e-05 - loss = 0.0013729101774515584
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:21:06,476 INFO epoch # 958 - for optimizer <class 'torch.optim.adam.Adam'> lr : 7.282483350946415e-05-> 7.282483350946415e-05 - loss = 0.0030577757279388607
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:21:06,598 INFO epoch # 959 - for optimizer <class 'torch.optim.adam.Adam'> lr : 7.282483350946415e-05-> 7.282483350946415e-05 - loss = 0.0029133877833373845
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:21:06,721 INFO epoch # 960 - for optimizer <class 'torch.optim.adam.Adam'> lr : 7.282483350946415e-05-> 7.282483350946415e-05 - loss = 0.00142182748822961
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:21:06,721 INFO *** epoch 960, rolling-avg-loss (window=10)= 0.002816473334678449
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:21:06,847 INFO epoch # 961 - for optimizer <class 'torch.optim.adam.Adam'> lr : 7.282483350946415e-05-> 7.282483350946415e-05 - loss = 0.001990988035686314
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:21:06,973 INFO epoch # 962 - for optimizer <class 'torch.optim.adam.Adam'> lr : 7.282483350946415e-05-> 7.282483350946415e-05 - loss = 0.0013069181877654046
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:21:07,101 INFO epoch # 963 - for optimizer <class 'torch.optim.adam.Adam'> lr : 7.282483350946415e-05-> 7.282483350946415e-05 - loss = 0.0035106903524138033
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:21:07,226 INFO epoch # 964 - for optimizer <class 'torch.optim.adam.Adam'> lr : 7.282483350946415e-05-> 7.282483350946415e-05 - loss = 0.0033786607964430004
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:21:07,353 INFO epoch # 965 - for optimizer <class 'torch.optim.adam.Adam'> lr : 7.282483350946415e-05-> 7.282483350946415e-05 - loss = 0.0032855153549462557
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:21:07,478 INFO epoch # 966 - for optimizer <class 'torch.optim.adam.Adam'> lr : 7.282483350946415e-05-> 7.282483350946415e-05 - loss = 0.0018454545643180609
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:21:07,601 INFO epoch # 967 - for optimizer <class 'torch.optim.adam.Adam'> lr : 7.282483350946415e-05-> 7.282483350946415e-05 - loss = 0.00297504075570032
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:21:07,724 INFO epoch # 968 - for optimizer <class 'torch.optim.adam.Adam'> lr : 7.282483350946415e-05-> 6.554235015851773e-05 - loss = 0.002067119174171239
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:21:07,848 INFO epoch # 969 - for optimizer <class 'torch.optim.adam.Adam'> lr : 6.554235015851773e-05-> 6.554235015851773e-05 - loss = 0.00237909697170835
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:21:07,976 INFO epoch # 970 - for optimizer <class 'torch.optim.adam.Adam'> lr : 6.554235015851773e-05-> 6.554235015851773e-05 - loss = 0.004097098426427692
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:21:07,976 INFO *** epoch 970, rolling-avg-loss (window=10)= 0.002683658261958044
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:21:08,106 INFO epoch # 971 - for optimizer <class 'torch.optim.adam.Adam'> lr : 6.554235015851773e-05-> 6.554235015851773e-05 - loss = 0.0014124208555585938
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:21:08,245 INFO epoch # 972 - for optimizer <class 'torch.optim.adam.Adam'> lr : 6.554235015851773e-05-> 6.554235015851773e-05 - loss = 0.0013348307547857985
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:21:08,376 INFO epoch # 973 - for optimizer <class 'torch.optim.adam.Adam'> lr : 6.554235015851773e-05-> 6.554235015851773e-05 - loss = 0.005143875619978644
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:21:08,501 INFO epoch # 974 - for optimizer <class 'torch.optim.adam.Adam'> lr : 6.554235015851773e-05-> 6.554235015851773e-05 - loss = 0.0029593709332402796
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:21:08,629 INFO epoch # 975 - for optimizer <class 'torch.optim.adam.Adam'> lr : 6.554235015851773e-05-> 6.554235015851773e-05 - loss = 0.002544698363635689
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:21:08,753 INFO epoch # 976 - for optimizer <class 'torch.optim.adam.Adam'> lr : 6.554235015851773e-05-> 6.554235015851773e-05 - loss = 0.0015923348837532103
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:21:08,877 INFO epoch # 977 - for optimizer <class 'torch.optim.adam.Adam'> lr : 6.554235015851773e-05-> 6.554235015851773e-05 - loss = 0.0030512124358210713
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:21:09,003 INFO epoch # 978 - for optimizer <class 'torch.optim.adam.Adam'> lr : 6.554235015851773e-05-> 6.554235015851773e-05 - loss = 0.001215540622069966
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:21:09,132 INFO epoch # 979 - for optimizer <class 'torch.optim.adam.Adam'> lr : 6.554235015851773e-05-> 5.898811514266596e-05 - loss = 0.0019680959812831134
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:21:09,259 INFO epoch # 980 - for optimizer <class 'torch.optim.adam.Adam'> lr : 5.898811514266596e-05-> 5.898811514266596e-05 - loss = 0.0017227847129106522
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:21:09,259 INFO *** epoch 980, rolling-avg-loss (window=10)= 0.002294516516303702
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:21:09,386 INFO epoch # 981 - for optimizer <class 'torch.optim.adam.Adam'> lr : 5.898811514266596e-05-> 5.898811514266596e-05 - loss = 0.004654998119804077
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:21:09,510 INFO epoch # 982 - for optimizer <class 'torch.optim.adam.Adam'> lr : 5.898811514266596e-05-> 5.898811514266596e-05 - loss = 0.0014059426175663248
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:21:09,635 INFO epoch # 983 - for optimizer <class 'torch.optim.adam.Adam'> lr : 5.898811514266596e-05-> 5.898811514266596e-05 - loss = 0.002930412592831999
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:21:09,760 INFO epoch # 984 - for optimizer <class 'torch.optim.adam.Adam'> lr : 5.898811514266596e-05-> 5.898811514266596e-05 - loss = 0.0027150830283062533
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:21:09,897 INFO epoch # 985 - for optimizer <class 'torch.optim.adam.Adam'> lr : 5.898811514266596e-05-> 5.898811514266596e-05 - loss = 0.001861165335867554
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:21:10,028 INFO epoch # 986 - for optimizer <class 'torch.optim.adam.Adam'> lr : 5.898811514266596e-05-> 5.898811514266596e-05 - loss = 0.0016489747213199735
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:21:10,152 INFO epoch # 987 - for optimizer <class 'torch.optim.adam.Adam'> lr : 5.898811514266596e-05-> 5.898811514266596e-05 - loss = 0.0018986739014508203
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:21:10,275 INFO epoch # 988 - for optimizer <class 'torch.optim.adam.Adam'> lr : 5.898811514266596e-05-> 5.898811514266596e-05 - loss = 0.0016840713215060532
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:21:10,402 INFO epoch # 989 - for optimizer <class 'torch.optim.adam.Adam'> lr : 5.898811514266596e-05-> 5.898811514266596e-05 - loss = 0.0016399715386796743
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:21:10,529 INFO epoch # 990 - for optimizer <class 'torch.optim.adam.Adam'> lr : 5.898811514266596e-05-> 5.3089303628399366e-05 - loss = 0.00157878540630918
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:21:10,529 INFO *** epoch 990, rolling-avg-loss (window=10)= 0.002201807858364191
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:21:10,653 INFO epoch # 991 - for optimizer <class 'torch.optim.adam.Adam'> lr : 5.3089303628399366e-05-> 5.3089303628399366e-05 - loss = 0.002500403323210776
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:21:10,777 INFO epoch # 992 - for optimizer <class 'torch.optim.adam.Adam'> lr : 5.3089303628399366e-05-> 5.3089303628399366e-05 - loss = 0.0015898441197350621
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:21:10,900 INFO epoch # 993 - for optimizer <class 'torch.optim.adam.Adam'> lr : 5.3089303628399366e-05-> 5.3089303628399366e-05 - loss = 0.0022803769388701767
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:21:11,023 INFO epoch # 994 - for optimizer <class 'torch.optim.adam.Adam'> lr : 5.3089303628399366e-05-> 5.3089303628399366e-05 - loss = 0.0010498418168936041
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:21:11,149 INFO epoch # 995 - for optimizer <class 'torch.optim.adam.Adam'> lr : 5.3089303628399366e-05-> 5.3089303628399366e-05 - loss = 0.0018759995582513511
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:21:11,292 INFO epoch # 996 - for optimizer <class 'torch.optim.adam.Adam'> lr : 5.3089303628399366e-05-> 5.3089303628399366e-05 - loss = 0.0028730182675644755
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:21:11,431 INFO epoch # 997 - for optimizer <class 'torch.optim.adam.Adam'> lr : 5.3089303628399366e-05-> 5.3089303628399366e-05 - loss = 0.001508369081420824
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:21:11,570 INFO epoch # 998 - for optimizer <class 'torch.optim.adam.Adam'> lr : 5.3089303628399366e-05-> 5.3089303628399366e-05 - loss = 0.004056232624861877
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:21:11,709 INFO epoch # 999 - for optimizer <class 'torch.optim.adam.Adam'> lr : 5.3089303628399366e-05-> 5.3089303628399366e-05 - loss = 0.0035930899321101606
[experiments_sandbox.py:555 -   <module>()] 2023-04-22 02:21:11,849 INFO epoch # 1000 - for optimizer <class 'torch.optim.adam.Adam'> lr : 5.3089303628399366e-05-> 5.3089303628399366e-05 - loss = 0.002700702680158429
[experiments_sandbox.py:564 -   <module>()] 2023-04-22 02:21:11,849 INFO *** epoch 1000, rolling-avg-loss (window=10)= 0.0024027878343076737
[experiments_sandbox.py:572 -   <module>()] 2023-04-22 02:21:11,849 INFO training time in seconds = 129
[experiments_sandbox.py:576 -   <module>()] 2023-04-22 02:21:11,850 INFO epochs-loss curve df :
[experiments_sandbox.py:577 -   <module>()] 2023-04-22 02:21:11,855 INFO 
    epochs  rolling-avg-loss
0       10          9.752427
1       20          0.168524
2       30          0.013369
3       40          0.008389
4       50          0.007246
5       60          0.005047
6       70          0.004315
7       80          0.004571
8       90          0.007844
9      100          0.009056
10     110          0.002929
11     120          0.004319
12     130          0.005761
13     140          0.004491
14     150          0.005337
15     160          0.002974
16     170          0.003225
17     180          0.003125
18     190          0.003439
19     200          0.003196
20     210          0.003794
21     220          0.006337
22     230          0.004157
23     240          0.002986
24     250          0.003893
25     260          0.002128
26     270          0.002858
27     280          0.003867
28     290          0.003504
29     300          0.004779
30     310          0.002831
31     320          0.003110
32     330          0.003422
33     340          0.002671
34     350          0.003174
35     360          0.005079
36     370          0.003189
37     380          0.003150
38     390          0.002993
39     400          0.002216
40     410          0.002416
41     420          0.002886
42     430          0.003296
43     440          0.002895
44     450          0.003931
45     460          0.002536
46     470          0.002568
47     480          0.002729
48     490          0.003299
49     500          0.003880
50     510          0.002499
51     520          0.002496
52     530          0.002549
53     540          0.002490
54     550          0.002542
55     560          0.002380
56     570          0.002218
57     580          0.002608
58     590          0.004156
59     600          0.002553
60     610          0.003347
61     620          0.001833
62     630          0.002064
63     640          0.002030
64     650          0.002486
65     660          0.003011
66     670          0.002614
67     680          0.003198
68     690          0.001735
69     700          0.002198
70     710          0.002114
71     720          0.002232
72     730          0.002009
73     740          0.002120
74     750          0.002321
75     760          0.001692
76     770          0.002350
77     780          0.002705
78     790          0.002999
79     800          0.002942
80     810          0.002695
81     820          0.002684
82     830          0.002520
83     840          0.002355
84     850          0.002131
85     860          0.002367
86     870          0.002096
87     880          0.001990
88     890          0.001939
89     900          0.002698
90     910          0.002329
91     920          0.001939
92     930          0.002624
93     940          0.002475
94     950          0.002453
95     960          0.002816
96     970          0.002684
97     980          0.002295
98     990          0.002202
99    1000          0.002403
