[experiments_sandbox.py:611 -   <module>()] 2023-04-24 14:53:44,530 INFO SEED = 42
[experiments_sandbox.py:677 -   <module>()] 2023-04-24 14:53:44,531 INFO model = 
***
RBFN
in_dim=2
n_centres=20
out_dim=2
basis_fn=gaussian
numel_learnable=102
***

[experiments_sandbox.py:678 -   <module>()] 2023-04-24 14:53:44,531 INFO optimizer  = SGD (
Parameter Group 0
    dampening: 0
    differentiable: False
    foreach: None
    lr: 0.01
    maximize: False
    momentum: 0
    nesterov: False
    weight_decay: 0
)
[experiments_sandbox.py:685 -   <module>()] 2023-04-24 14:53:44,531 INFO lr_scheduler = <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7fb29658b1f0>
[experiments_sandbox.py:688 -   <module>()] 2023-04-24 14:53:44,531 INFO Normalize-Data-source-X-train = True
[experiments_sandbox.py:689 -   <module>()] 2023-04-24 14:53:44,531 INFO Normalize-Data-source-Y-train = True
[experiments_sandbox.py:690 -   <module>()] 2023-04-24 14:53:44,531 INFO Normalize-Data-source-X-test = True
[experiments_sandbox.py:691 -   <module>()] 2023-04-24 14:53:44,531 INFO Normalize-Data-source-Y-test = True
[experiments_sandbox.py:710 -   <module>()] 2023-04-24 14:53:44,532 INFO train-dataset = ***
VDP Dataset
N=1000
mio = 0.5
x_gen_norm_mean = 10
x_gen_norm_std = 100
normalize_X = True
normalize_Y = True
train-or-test = train
***
[experiments_sandbox.py:711 -   <module>()] 2023-04-24 14:53:44,532 INFO test-dataset = ***
VDP Dataset
N=1000
mio = 0.5
x_gen_norm_mean = 10
x_gen_norm_std = 100
normalize_X = True
normalize_Y = True
train-or-test = test
***
[experiments_sandbox.py:712 -   <module>()] 2023-04-24 14:53:44,532 INFO train-epochs = 10000
[experiments_sandbox.py:716 -   <module>()] 2023-04-24 14:53:44,532 INFO Input batch normalization = False
[experiments_sandbox.py:717 -   <module>()] 2023-04-24 14:53:44,532 INFO Output Normalization = None
[experiments_sandbox.py:718 -   <module>()] 2023-04-24 14:53:44,533 INFO Gradient-clipping max-norm = 10
[experiments_sandbox.py:720 -   <module>()] 2023-04-24 14:53:44,533 INFO epochs_losses_window = 10
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:46,126 INFO epoch # 0 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.9544269517064095
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:46,148 INFO epoch # 1 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.8993877163156867
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:46,169 INFO epoch # 2 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.851645102724433
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:46,191 INFO epoch # 3 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.8013392705470324
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:46,213 INFO epoch # 4 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.7684553423896432
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:46,235 INFO epoch # 5 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.7569900704547763
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:46,256 INFO epoch # 6 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.7038476467132568
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:46,278 INFO epoch # 7 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.6864915490150452
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:46,299 INFO epoch # 8 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.6600940097123384
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:46,321 INFO epoch # 9 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.6398373516276479
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:46,342 INFO epoch # 10 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.6401039585471153
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:53:46,342 INFO *** epoch 10, rolling-avg-loss (window=10)= 0.7408192018046975
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:46,364 INFO epoch # 11 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.6166909830644727
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:46,386 INFO epoch # 12 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.6022624189499766
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:46,407 INFO epoch # 13 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.5814808660652488
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:46,429 INFO epoch # 14 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.5744682063814253
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:46,450 INFO epoch # 15 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.5762989575741813
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:46,471 INFO epoch # 16 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.5653985291719437
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:46,493 INFO epoch # 17 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.5595344594912603
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:46,514 INFO epoch # 18 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.5433610961772501
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:46,535 INFO epoch # 19 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.5247374268947169
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:46,557 INFO epoch # 20 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.5558353634551167
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:53:46,557 INFO *** epoch 20, rolling-avg-loss (window=10)= 0.5700068307225592
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:46,579 INFO epoch # 21 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.5125842636916786
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:46,600 INFO epoch # 22 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.5070202281931415
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:46,622 INFO epoch # 23 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.5170833338052034
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:46,644 INFO epoch # 24 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.5199374118819833
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:46,665 INFO epoch # 25 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.49150088732130826
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:46,687 INFO epoch # 26 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.48532739031361416
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:46,708 INFO epoch # 27 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.48060185712529346
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:46,729 INFO epoch # 28 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.47631386609282345
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:46,751 INFO epoch # 29 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.47726509254425764
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:46,773 INFO epoch # 30 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.47322552173864096
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:53:46,773 INFO *** epoch 30, rolling-avg-loss (window=10)= 0.4940859852707945
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:46,795 INFO epoch # 31 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.5044704678002745
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:46,816 INFO epoch # 32 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.4688598602078855
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:46,838 INFO epoch # 33 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.4666394970845431
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:46,860 INFO epoch # 34 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.4498530651326291
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:46,881 INFO epoch # 35 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.46548163320403546
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:46,904 INFO epoch # 36 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.47292543901130557
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:46,926 INFO epoch # 37 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.4383625501068309
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:46,947 INFO epoch # 38 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.4411558238789439
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:46,968 INFO epoch # 39 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.4700720028486103
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:46,990 INFO epoch # 40 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.4398655778495595
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:53:46,990 INFO *** epoch 40, rolling-avg-loss (window=10)= 0.46176859171246176
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:47,012 INFO epoch # 41 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.423609851161018
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:47,033 INFO epoch # 42 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.42246448004152626
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:47,055 INFO epoch # 43 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.4186838688328862
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:47,076 INFO epoch # 44 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.4155246317386627
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:47,097 INFO epoch # 45 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.4611543258652091
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:47,118 INFO epoch # 46 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.41305658721830696
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:47,140 INFO epoch # 47 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.4256585941184312
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:47,161 INFO epoch # 48 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.39894657488912344
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:47,182 INFO epoch # 49 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.3940285071148537
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:47,204 INFO epoch # 50 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.3905820014770143
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:53:47,204 INFO *** epoch 50, rolling-avg-loss (window=10)= 0.4163709422457032
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:47,226 INFO epoch # 51 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.39349943480920047
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:47,247 INFO epoch # 52 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.3840631908387877
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:47,269 INFO epoch # 53 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.3825648014899343
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:47,290 INFO epoch # 54 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.3780364705598913
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:47,311 INFO epoch # 55 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.39290270721539855
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:47,333 INFO epoch # 56 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.37165072053903714
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:47,354 INFO epoch # 57 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.380402515293099
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:47,375 INFO epoch # 58 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.4001657641492784
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:47,397 INFO epoch # 59 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.3757385761709884
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:47,418 INFO epoch # 60 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.35971041885204613
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:53:47,418 INFO *** epoch 60, rolling-avg-loss (window=10)= 0.38187345999176614
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:47,440 INFO epoch # 61 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.367312143498566
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:47,461 INFO epoch # 62 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.3534940918907523
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:47,483 INFO epoch # 63 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.39877279265783727
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:47,504 INFO epoch # 64 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.3689959478797391
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:47,525 INFO epoch # 65 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.3643570718122646
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:47,547 INFO epoch # 66 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.34206640493357554
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:47,568 INFO epoch # 67 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.34176114143338054
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:47,589 INFO epoch # 68 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.33777988189831376
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:47,610 INFO epoch # 69 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.3446431427728385
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:47,632 INFO epoch # 70 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.335951236076653
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:53:47,632 INFO *** epoch 70, rolling-avg-loss (window=10)= 0.3555133854853921
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:47,654 INFO epoch # 71 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.33386051177512854
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:47,676 INFO epoch # 72 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.32585752446902916
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:47,697 INFO epoch # 73 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.3258358684834093
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:47,719 INFO epoch # 74 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.3373565243673511
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:47,740 INFO epoch # 75 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.3212009238777682
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:47,762 INFO epoch # 76 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.3159179677022621
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:47,783 INFO epoch # 77 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.33837672270601615
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:47,804 INFO epoch # 78 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.31461307033896446
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:47,825 INFO epoch # 79 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.33072990039363503
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:47,847 INFO epoch # 80 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.3057348620495759
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:53:47,847 INFO *** epoch 80, rolling-avg-loss (window=10)= 0.324948387616314
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:47,868 INFO epoch # 81 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.34361198084661737
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:47,890 INFO epoch # 82 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.3014557062415406
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:47,911 INFO epoch # 83 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.3097979654558003
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:47,932 INFO epoch # 84 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.29632585222134367
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:47,954 INFO epoch # 85 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.2937923646240961
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:47,975 INFO epoch # 86 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.2925074662780389
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:47,996 INFO epoch # 87 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.289627282647416
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:48,017 INFO epoch # 88 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.2903740726178512
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:48,039 INFO epoch # 89 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.3026356126065366
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:48,060 INFO epoch # 90 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.2868613004684448
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:53:48,060 INFO *** epoch 90, rolling-avg-loss (window=10)= 0.30069896040076854
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:48,081 INFO epoch # 91 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.3270386927179061
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:48,103 INFO epoch # 92 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.27942242205608636
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:48,124 INFO epoch # 93 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.28405277244746685
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:48,146 INFO epoch # 94 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.275981608661823
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:48,167 INFO epoch # 95 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.28987476869951934
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:48,188 INFO epoch # 96 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.2708908087806776
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:48,209 INFO epoch # 97 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.26899578113807365
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:48,231 INFO epoch # 98 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.267096619179938
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:48,252 INFO epoch # 99 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.2648078499478288
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:48,274 INFO epoch # 100 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.26353130460483953
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:53:48,274 INFO *** epoch 100, rolling-avg-loss (window=10)= 0.2791692628234159
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:48,295 INFO epoch # 101 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.26132750837132335
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:48,317 INFO epoch # 102 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.2600164799951017
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:48,338 INFO epoch # 103 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.2580721706035547
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:48,360 INFO epoch # 104 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.2559501553187147
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:48,381 INFO epoch # 105 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.25408490147674456
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:48,402 INFO epoch # 106 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.28001483203843236
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:48,424 INFO epoch # 107 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.25039090384962037
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:48,445 INFO epoch # 108 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.25082370755262673
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:48,466 INFO epoch # 109 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.2469837072712835
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:48,487 INFO epoch # 110 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.2480597522808239
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:53:48,488 INFO *** epoch 110, rolling-avg-loss (window=10)= 0.2565724118758226
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:48,509 INFO epoch # 111 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.24413612758507952
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:48,531 INFO epoch # 112 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.25204600376309827
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:48,552 INFO epoch # 113 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.2487013234058395
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:48,574 INFO epoch # 114 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.23839986266102642
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:48,595 INFO epoch # 115 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.23696555168135092
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:48,617 INFO epoch # 116 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.23739974288037047
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:48,638 INFO epoch # 117 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.23482570284977555
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:48,659 INFO epoch # 118 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.23527874593855813
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:48,680 INFO epoch # 119 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.23030180323985405
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:48,702 INFO epoch # 120 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.27256078296341
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:53:48,702 INFO *** epoch 120, rolling-avg-loss (window=10)= 0.2430615646968363
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:48,723 INFO epoch # 121 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.22743148493464105
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:48,745 INFO epoch # 122 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.2576558815781027
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:48,767 INFO epoch # 123 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.22513863979838789
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:48,788 INFO epoch # 124 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.22300106586772017
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:48,809 INFO epoch # 125 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.22133291207137518
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:48,831 INFO epoch # 126 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.2250948799191974
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:48,852 INFO epoch # 127 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.21838309135637246
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:48,873 INFO epoch # 128 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.21700587321538478
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:48,894 INFO epoch # 129 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.21542567218421027
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:48,915 INFO epoch # 130 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.21403510570235085
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:53:48,915 INFO *** epoch 130, rolling-avg-loss (window=10)= 0.22445046066277427
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:48,937 INFO epoch # 131 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.22172964148921892
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:48,958 INFO epoch # 132 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.21294439825578593
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:48,979 INFO epoch # 133 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.210160780698061
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:49,000 INFO epoch # 134 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.20895746716996655
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:49,022 INFO epoch # 135 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.2072992535540834
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:49,043 INFO epoch # 136 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.21165997168282047
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:49,064 INFO epoch # 137 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.21132422384107485
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:49,086 INFO epoch # 138 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.20341922526131384
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:49,107 INFO epoch # 139 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.2021215550485067
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:49,128 INFO epoch # 140 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.20241853583138436
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:53:49,128 INFO *** epoch 140, rolling-avg-loss (window=10)= 0.2092035052832216
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:49,150 INFO epoch # 141 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.19979638379300013
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:49,171 INFO epoch # 142 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.1982339580426924
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:49,192 INFO epoch # 143 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.19773372742929496
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:49,214 INFO epoch # 144 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.19581930813728832
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:49,235 INFO epoch # 145 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.19584398460574448
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:49,257 INFO epoch # 146 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.19358983490383253
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:49,278 INFO epoch # 147 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.2032153667532839
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:49,300 INFO epoch # 148 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.19955261050199624
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:49,321 INFO epoch # 149 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.1898922290711198
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:49,343 INFO epoch # 150 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.18876936921151355
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:53:49,343 INFO *** epoch 150, rolling-avg-loss (window=10)= 0.19624467724497663
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:49,364 INFO epoch # 151 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.1898245528282132
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:49,386 INFO epoch # 152 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.18815550568979234
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:49,407 INFO epoch # 153 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.18729972909204662
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:49,429 INFO epoch # 154 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.18748313281685114
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:49,450 INFO epoch # 155 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.19455714744981378
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:49,471 INFO epoch # 156 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.18173434777418151
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:49,492 INFO epoch # 157 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.18083836042205803
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:49,514 INFO epoch # 158 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.17960753515944816
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:49,535 INFO epoch # 159 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.17977368884021416
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:49,556 INFO epoch # 160 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.17766139106242917
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:53:49,556 INFO *** epoch 160, rolling-avg-loss (window=10)= 0.1846935391135048
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:49,578 INFO epoch # 161 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.1766243602905888
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:49,599 INFO epoch # 162 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.1756229790044017
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:49,621 INFO epoch # 163 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.17456468075397424
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:49,642 INFO epoch # 164 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.1743016592808999
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:49,663 INFO epoch # 165 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.17267680310760625
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:49,685 INFO epoch # 166 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.17357837260351516
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:49,706 INFO epoch # 167 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.17070666057406925
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:49,728 INFO epoch # 168 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.1718478719703853
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:49,749 INFO epoch # 169 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.16871660665492527
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:49,771 INFO epoch # 170 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.16861000063363463
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:53:49,771 INFO *** epoch 170, rolling-avg-loss (window=10)= 0.17272499948740005
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:49,792 INFO epoch # 171 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.18793049703526776
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:49,814 INFO epoch # 172 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.16573418818006758
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:49,835 INFO epoch # 173 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.16893878014525399
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:49,856 INFO epoch # 174 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.16488090570783243
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:49,878 INFO epoch # 175 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.16873065405525267
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:49,899 INFO epoch # 176 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.17337335579213686
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:49,920 INFO epoch # 177 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.16162352511310019
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:49,941 INFO epoch # 178 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.16017133623245172
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:49,962 INFO epoch # 179 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.16042364059831016
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:49,984 INFO epoch # 180 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.15839036798570305
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:53:49,984 INFO *** epoch 180, rolling-avg-loss (window=10)= 0.16701972508453763
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:50,005 INFO epoch # 181 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.15746499124361435
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:50,027 INFO epoch # 182 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.1570180279086344
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:50,048 INFO epoch # 183 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.15617917489726096
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:50,069 INFO epoch # 184 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.1552851204178296
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:50,091 INFO epoch # 185 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.1595926227455493
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:50,112 INFO epoch # 186 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.1536655429226812
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:50,133 INFO epoch # 187 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.15319706700393
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:50,154 INFO epoch # 188 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.17258363342261873
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:50,176 INFO epoch # 189 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.15133736282587051
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:50,197 INFO epoch # 190 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.15089362423168495
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:53:50,197 INFO *** epoch 190, rolling-avg-loss (window=10)= 0.1567217167619674
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:50,219 INFO epoch # 191 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.15131106082117185
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:50,240 INFO epoch # 192 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.14977512403856963
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:50,262 INFO epoch # 193 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.1478752569819335
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:50,283 INFO epoch # 194 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.14739349963201676
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:50,304 INFO epoch # 195 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.14655563249834813
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:50,326 INFO epoch # 196 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.1686253894586116
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:50,347 INFO epoch # 197 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.1614992987306323
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:50,368 INFO epoch # 198 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.15835555412922986
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:50,389 INFO epoch # 199 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.1433158553118119
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:50,411 INFO epoch # 200 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.1477734512591269
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:53:50,411 INFO *** epoch 200, rolling-avg-loss (window=10)= 0.15224801228614523
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:50,432 INFO epoch # 201 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.142018382466631
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:50,453 INFO epoch # 202 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.1412090485682711
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:50,475 INFO epoch # 203 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.1403962637996301
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:50,496 INFO epoch # 204 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.14003810842405073
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:50,517 INFO epoch # 205 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.14286510420788545
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:50,538 INFO epoch # 206 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.13916887823143043
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:50,559 INFO epoch # 207 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.14645465392095502
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:50,580 INFO epoch # 208 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.1370143090171041
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:50,602 INFO epoch # 209 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.13764854305190966
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:50,623 INFO epoch # 210 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.13576473036664538
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:53:50,624 INFO *** epoch 210, rolling-avg-loss (window=10)= 0.1402578022054513
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:50,645 INFO epoch # 211 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.13506325241178274
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:50,667 INFO epoch # 212 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.1350653819681611
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:50,689 INFO epoch # 213 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.13397613193956204
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:50,711 INFO epoch # 214 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.1332288227567915
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:50,733 INFO epoch # 215 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.13298044723342173
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:50,754 INFO epoch # 216 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.13190815554844448
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:50,775 INFO epoch # 217 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.13145246301428415
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:50,797 INFO epoch # 218 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.13216518989065662
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:50,818 INFO epoch # 219 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.13510932968347333
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:50,839 INFO epoch # 220 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.1296315687650349
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:53:50,839 INFO *** epoch 220, rolling-avg-loss (window=10)= 0.13305807432116126
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:50,861 INFO epoch # 221 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.13059126178268343
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:50,882 INFO epoch # 222 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.13262123156164307
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:50,903 INFO epoch # 223 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.12797811414930038
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:50,925 INFO epoch # 224 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.13227684912271798
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:50,946 INFO epoch # 225 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.12658221456513274
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:50,967 INFO epoch # 226 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.12652298714965582
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:50,988 INFO epoch # 227 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.12553471402497962
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:51,009 INFO epoch # 228 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.12503519048914313
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:51,031 INFO epoch # 229 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.12468937988160178
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:51,052 INFO epoch # 230 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.12404040386900306
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:53:51,052 INFO *** epoch 230, rolling-avg-loss (window=10)= 0.1275872346595861
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:51,074 INFO epoch # 231 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.12355977858533151
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:51,095 INFO epoch # 232 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.12331060992437415
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:51,117 INFO epoch # 233 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.12292079109465703
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:51,138 INFO epoch # 234 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.1221751973789651
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:51,159 INFO epoch # 235 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.12108546704985201
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:51,181 INFO epoch # 236 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.12101079581771046
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:51,202 INFO epoch # 237 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.12412223350838758
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:51,224 INFO epoch # 238 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.11993602079746779
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:51,245 INFO epoch # 239 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.12182199078961276
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:51,266 INFO epoch # 240 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.11863433658436406
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:53:51,266 INFO *** epoch 240, rolling-avg-loss (window=10)= 0.12185772215307225
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:51,288 INFO epoch # 241 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.11829513135307934
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:51,309 INFO epoch # 242 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.12123478503781371
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:51,331 INFO epoch # 243 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.11718063305306714
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:51,352 INFO epoch # 244 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.11870972478936892
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:51,373 INFO epoch # 245 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.11686752288369462
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:51,395 INFO epoch # 246 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.11577781374217011
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:51,416 INFO epoch # 247 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.11501959964516573
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:51,437 INFO epoch # 248 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.11676421505399048
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:51,458 INFO epoch # 249 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.11415797390509397
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:51,479 INFO epoch # 250 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.11585643510625232
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:53:51,480 INFO *** epoch 250, rolling-avg-loss (window=10)= 0.11698638345696963
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:51,501 INFO epoch # 251 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.11324288205651101
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:51,522 INFO epoch # 252 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.11328485730336979
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:51,544 INFO epoch # 253 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.1123597685364075
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:51,565 INFO epoch # 254 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.1118287849240005
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:51,586 INFO epoch # 255 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.11439045760198496
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:51,607 INFO epoch # 256 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.11980268795741722
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:51,629 INFO epoch # 257 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.11507662871736102
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:51,650 INFO epoch # 258 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.11074295311118476
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:51,671 INFO epoch # 259 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.10975855114520527
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:51,692 INFO epoch # 260 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.11478915458428673
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:53:51,692 INFO *** epoch 260, rolling-avg-loss (window=10)= 0.11352767259377287
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:51,714 INFO epoch # 261 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.10863549151690677
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:51,736 INFO epoch # 262 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.10940131958341226
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:51,757 INFO epoch # 263 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.10857311866129749
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:51,779 INFO epoch # 264 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.11081332436879165
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:51,800 INFO epoch # 265 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.1070689104963094
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:51,821 INFO epoch # 266 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.10677023718017153
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:51,842 INFO epoch # 267 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.12374063464812934
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:51,864 INFO epoch # 268 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.10569147486239672
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:51,885 INFO epoch # 269 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.10706268067588098
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:51,907 INFO epoch # 270 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.10494461582857184
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:53:51,907 INFO *** epoch 270, rolling-avg-loss (window=10)= 0.1092701807821868
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:51,928 INFO epoch # 271 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.10491018972243182
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:51,949 INFO epoch # 272 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.10506542534858454
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:51,971 INFO epoch # 273 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.1301773171289824
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:51,992 INFO epoch # 274 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.10686945157067385
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:52,013 INFO epoch # 275 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.10304156021447852
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:52,035 INFO epoch # 276 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.10308193450327963
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:52,056 INFO epoch # 277 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.10216253361431882
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:52,077 INFO epoch # 278 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.11347496003145352
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:52,099 INFO epoch # 279 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.10404985616332851
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:52,120 INFO epoch # 280 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.10136525286361575
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:53:52,120 INFO *** epoch 280, rolling-avg-loss (window=10)= 0.10741984811611474
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:52,141 INFO epoch # 281 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.1010746332758572
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:52,163 INFO epoch # 282 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.1019130816712277
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:52,184 INFO epoch # 283 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.13857987280061934
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:52,206 INFO epoch # 284 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.09963811536727007
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:52,227 INFO epoch # 285 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.09899786952883005
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:52,248 INFO epoch # 286 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.09902147846878506
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:52,269 INFO epoch # 287 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.09850940975593403
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:52,290 INFO epoch # 288 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.09794469046755694
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:52,312 INFO epoch # 289 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.09851307955977973
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:52,333 INFO epoch # 290 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.10270839161239564
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:53:52,333 INFO *** epoch 290, rolling-avg-loss (window=10)= 0.10369006225082558
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:52,356 INFO epoch # 291 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.09686783290817402
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:52,377 INFO epoch # 292 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.09946464367385488
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:52,399 INFO epoch # 293 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.09624800001620315
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:52,420 INFO epoch # 294 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.09592187538510188
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:52,441 INFO epoch # 295 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.09548209099739324
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:52,462 INFO epoch # 296 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0972658320388291
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:52,483 INFO epoch # 297 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.09521051801857539
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:52,505 INFO epoch # 298 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.09497841272968799
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:52,526 INFO epoch # 299 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.09439571035909466
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:52,547 INFO epoch # 300 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.09382327213825192
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:53:52,547 INFO *** epoch 300, rolling-avg-loss (window=10)= 0.09596581882651663
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:52,570 INFO epoch # 301 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.09393302880926058
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:52,591 INFO epoch # 302 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.09322648202942219
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:52,613 INFO epoch # 303 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0936001227091765
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:52,635 INFO epoch # 304 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0957453009323217
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:52,656 INFO epoch # 305 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.11494918657990638
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:52,677 INFO epoch # 306 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.09207889225217514
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:52,699 INFO epoch # 307 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.09489420398313086
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:52,720 INFO epoch # 308 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0917379731690744
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:52,741 INFO epoch # 309 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.09090095644933172
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:52,763 INFO epoch # 310 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0913668898283504
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:53:52,763 INFO *** epoch 310, rolling-avg-loss (window=10)= 0.09524330367421499
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:52,784 INFO epoch # 311 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.09109879103198182
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:52,806 INFO epoch # 312 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.09026911816908978
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:52,827 INFO epoch # 313 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.08964776957873255
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:52,849 INFO epoch # 314 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.08940895744308364
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:52,870 INFO epoch # 315 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.08925303768774029
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:52,891 INFO epoch # 316 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.09195621259277686
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:52,912 INFO epoch # 317 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0890929351298837
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:52,933 INFO epoch # 318 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.08832712206640281
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:52,955 INFO epoch # 319 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.09251078343368135
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:52,976 INFO epoch # 320 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.09070280470768921
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:53:52,976 INFO *** epoch 320, rolling-avg-loss (window=10)= 0.0902267531841062
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:52,998 INFO epoch # 321 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.08732559242343996
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:53,019 INFO epoch # 322 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.10856337932636961
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:53,041 INFO epoch # 323 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.08668555918120546
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:53,062 INFO epoch # 324 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.08644265549082775
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:53,083 INFO epoch # 325 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0968623475782806
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:53,105 INFO epoch # 326 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.08830809987557586
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:53,126 INFO epoch # 327 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.08614584000315517
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:53,147 INFO epoch # 328 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.08540003365487792
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:53,168 INFO epoch # 329 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.08562296646414325
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:53,190 INFO epoch # 330 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.08744015116826631
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:53:53,190 INFO *** epoch 330, rolling-avg-loss (window=10)= 0.0898796625166142
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:53,211 INFO epoch # 331 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0844965905562276
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:53,233 INFO epoch # 332 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.08419581888301764
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:53,255 INFO epoch # 333 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.08393931706086732
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:53,276 INFO epoch # 334 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.08409646076324861
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:53,297 INFO epoch # 335 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0834970731229987
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:53,319 INFO epoch # 336 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.08357902319403365
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:53,340 INFO epoch # 337 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.08313790659303777
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:53,361 INFO epoch # 338 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.08463045312964823
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:53,382 INFO epoch # 339 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.08239247095480096
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:53,404 INFO epoch # 340 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.08215438698243815
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:53:53,404 INFO *** epoch 340, rolling-avg-loss (window=10)= 0.08361195012403186
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:53,425 INFO epoch # 341 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.08203150334884413
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:53,447 INFO epoch # 342 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.08167426381260157
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:53,468 INFO epoch # 343 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0814046615123516
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:53,489 INFO epoch # 344 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.08579235640354455
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:53,511 INFO epoch # 345 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.08284684100362938
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:53,532 INFO epoch # 346 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.08065092531614937
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:53,553 INFO epoch # 347 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.08040499451453798
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:53,574 INFO epoch # 348 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.08072091358189937
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:53,596 INFO epoch # 349 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.09392955760995392
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:53,617 INFO epoch # 350 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.07973175730148796
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:53:53,617 INFO *** epoch 350, rolling-avg-loss (window=10)= 0.08291877744049998
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:53,638 INFO epoch # 351 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.07956979513983242
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:53,660 INFO epoch # 352 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.08943902894679923
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:53,681 INFO epoch # 353 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.07885791733133374
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:53,703 INFO epoch # 354 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.07864826896548038
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:53,724 INFO epoch # 355 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0784124955025618
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:53,746 INFO epoch # 356 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.07827689706755336
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:53,767 INFO epoch # 357 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.08077380279428326
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:53,788 INFO epoch # 358 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.08125566635862924
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:53,809 INFO epoch # 359 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.07765927363652736
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:53,831 INFO epoch # 360 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.07753119061817415
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:53:53,831 INFO *** epoch 360, rolling-avg-loss (window=10)= 0.08004243363611749
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:53,852 INFO epoch # 361 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.07726947953051422
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:53,874 INFO epoch # 362 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.076883535948582
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:53,895 INFO epoch # 363 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0885525849298574
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:53,917 INFO epoch # 364 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.07636295112024527
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:53,938 INFO epoch # 365 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.07652594437240623
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:53,959 INFO epoch # 366 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.07605897884059232
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:53,980 INFO epoch # 367 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.07585635723080486
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:54,001 INFO epoch # 368 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.076627215516055
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:54,023 INFO epoch # 369 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.07813558830821421
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:54,044 INFO epoch # 370 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.07969553739530966
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:53:54,044 INFO *** epoch 370, rolling-avg-loss (window=10)= 0.07819681731925812
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:54,066 INFO epoch # 371 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.07523327181115746
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:54,087 INFO epoch # 372 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.07466599754116032
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:54,108 INFO epoch # 373 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.07485228580480907
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:54,130 INFO epoch # 374 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.07422854746982921
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:54,151 INFO epoch # 375 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.07412104519607965
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:54,172 INFO epoch # 376 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.07382458884967491
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:54,193 INFO epoch # 377 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.07377409139007796
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:54,215 INFO epoch # 378 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.07354886532993987
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:54,237 INFO epoch # 379 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.07324446528218687
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:54,258 INFO epoch # 380 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.07300603471230716
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:53:54,258 INFO *** epoch 380, rolling-avg-loss (window=10)= 0.07404991933872225
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:54,279 INFO epoch # 381 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.07299082691315562
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:54,301 INFO epoch # 382 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0727153253974393
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:54,322 INFO epoch # 383 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.07272925061988644
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:54,344 INFO epoch # 384 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.07245716123725288
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:54,365 INFO epoch # 385 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.07210302643943578
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:54,386 INFO epoch # 386 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.07197200747032184
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:54,407 INFO epoch # 387 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.07168537490360904
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:54,428 INFO epoch # 388 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.07343581503664609
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:54,450 INFO epoch # 389 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0803062601480633
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:54,471 INFO epoch # 390 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.07122212093963753
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:53:54,471 INFO *** epoch 390, rolling-avg-loss (window=10)= 0.07316171691054478
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:54,493 INFO epoch # 391 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.07117604294035118
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:54,514 INFO epoch # 392 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.07071937283035368
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:54,536 INFO epoch # 393 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.07044831797247753
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:54,557 INFO epoch # 394 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.07022455291007645
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:54,578 INFO epoch # 395 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.07019134314032272
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:54,600 INFO epoch # 396 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.07178611897688825
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:54,621 INFO epoch # 397 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.06998718953400385
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:54,642 INFO epoch # 398 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0695287507987814
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:54,663 INFO epoch # 399 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.06928579766099574
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:54,684 INFO epoch # 400 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.06952973078296054
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:53:54,684 INFO *** epoch 400, rolling-avg-loss (window=10)= 0.07028772175472113
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:54,706 INFO epoch # 401 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.06917507917387411
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:54,728 INFO epoch # 402 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.06885238199902233
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:54,749 INFO epoch # 403 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0686209313425934
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:54,771 INFO epoch # 404 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.06843416886113118
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:54,792 INFO epoch # 405 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.06831358298950363
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:54,813 INFO epoch # 406 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.06885319035791326
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:54,834 INFO epoch # 407 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.06879882782232016
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:54,855 INFO epoch # 408 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.06788958443212323
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:54,876 INFO epoch # 409 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.06766745338973124
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:54,897 INFO epoch # 410 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0673788838321343
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:53:54,898 INFO *** epoch 410, rolling-avg-loss (window=10)= 0.06839840842003468
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:54,919 INFO epoch # 411 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.06870328489458188
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:54,940 INFO epoch # 412 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.06813352744211443
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:54,961 INFO epoch # 413 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.06681128674244974
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:54,983 INFO epoch # 414 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.06668941647512838
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:55,004 INFO epoch # 415 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.06656282512994949
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:55,025 INFO epoch # 416 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.06632883180282079
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:55,046 INFO epoch # 417 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.09053090539237019
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:55,067 INFO epoch # 418 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.06624932185513899
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:55,089 INFO epoch # 419 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.06597224711731542
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:55,110 INFO epoch # 420 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0671503787743859
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:53:55,110 INFO *** epoch 420, rolling-avg-loss (window=10)= 0.06931320256262552
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:55,131 INFO epoch # 421 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.06604125784360804
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:55,153 INFO epoch # 422 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.07496698890463449
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:55,174 INFO epoch # 423 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.06523965965607204
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:55,195 INFO epoch # 424 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.06515337718883529
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:55,217 INFO epoch # 425 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.07436508915270679
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:55,238 INFO epoch # 426 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.06849505296850111
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:55,260 INFO epoch # 427 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.06452117205481045
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:55,281 INFO epoch # 428 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.06432752501859795
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:55,302 INFO epoch # 429 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.06445912434719503
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:55,323 INFO epoch # 430 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.06728863633179571
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:53:55,323 INFO *** epoch 430, rolling-avg-loss (window=10)= 0.06748578834667569
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:55,345 INFO epoch # 431 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0642669905355433
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:55,366 INFO epoch # 432 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.06372521795856301
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:55,387 INFO epoch # 433 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.06537471555930097
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:55,409 INFO epoch # 434 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.064723188203061
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:55,430 INFO epoch # 435 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.06326244292722549
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:55,452 INFO epoch # 436 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.06330346790491603
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:55,473 INFO epoch # 437 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.06290018797153607
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:55,494 INFO epoch # 438 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.06305489109945484
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:55,516 INFO epoch # 439 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0629326555354055
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:55,537 INFO epoch # 440 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.06282615904638078
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:53:55,537 INFO *** epoch 440, rolling-avg-loss (window=10)= 0.0636369916741387
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:55,558 INFO epoch # 441 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.06395297871495131
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:55,580 INFO epoch # 442 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.06215783076186199
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:55,601 INFO epoch # 443 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.06218803141382523
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:55,622 INFO epoch # 444 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.06223426089854911
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:55,644 INFO epoch # 445 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.06167711422313005
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:55,665 INFO epoch # 446 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.06182253199222032
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:55,686 INFO epoch # 447 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.061565757234347984
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:55,707 INFO epoch # 448 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.06798218141193502
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:55,729 INFO epoch # 449 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.06119358021533117
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:55,750 INFO epoch # 450 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.062309525805176236
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:53:55,750 INFO *** epoch 450, rolling-avg-loss (window=10)= 0.06270837926713284
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:55,772 INFO epoch # 451 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.06108107330510393
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:55,793 INFO epoch # 452 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.060718049557181075
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:55,814 INFO epoch # 453 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.06049750868260162
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:55,850 INFO epoch # 454 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.06035227912798291
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:55,871 INFO epoch # 455 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.06031528688617982
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:55,892 INFO epoch # 456 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.060155595230753534
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:55,914 INFO epoch # 457 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.059946600304101594
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:55,935 INFO epoch # 458 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.06785851404129062
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:55,956 INFO epoch # 459 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.059665772001608275
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:55,977 INFO epoch # 460 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.059530618898861576
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:53:55,977 INFO *** epoch 460, rolling-avg-loss (window=10)= 0.061012129803566496
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:55,999 INFO epoch # 461 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.059398142228019424
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:56,020 INFO epoch # 462 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.059663795414962806
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:56,042 INFO epoch # 463 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.05920763488393277
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:56,063 INFO epoch # 464 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0591090183443157
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:56,084 INFO epoch # 465 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.05894989268563222
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:56,105 INFO epoch # 466 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.058801392777240835
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:56,126 INFO epoch # 467 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.05869400140363723
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:56,147 INFO epoch # 468 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.06043012977170292
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:56,169 INFO epoch # 469 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0595669070025906
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:56,190 INFO epoch # 470 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.059893191035371274
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:53:56,190 INFO *** epoch 470, rolling-avg-loss (window=10)= 0.05937141055474058
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:56,212 INFO epoch # 471 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.058127952899667434
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:56,234 INFO epoch # 472 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.07950103394978214
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:56,255 INFO epoch # 473 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.05806781095452607
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:56,276 INFO epoch # 474 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.06057626956317108
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:56,298 INFO epoch # 475 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.057820656773401424
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:56,319 INFO epoch # 476 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.05755321616015863
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:56,340 INFO epoch # 477 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.06197593473189045
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:56,361 INFO epoch # 478 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.057192045234842226
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:56,382 INFO epoch # 479 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.07641729278111598
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:56,404 INFO epoch # 480 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.057305953159811907
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:53:56,404 INFO *** epoch 480, rolling-avg-loss (window=10)= 0.06245381662083673
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:56,425 INFO epoch # 481 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.056832748028682545
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:56,447 INFO epoch # 482 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.056710873628617264
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:56,468 INFO epoch # 483 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.05740832397714257
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:56,489 INFO epoch # 484 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.061979247446288355
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:56,510 INFO epoch # 485 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.056390528377960436
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:56,531 INFO epoch # 486 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.05616514649591409
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:56,553 INFO epoch # 487 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.07801659467804711
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:56,574 INFO epoch # 488 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.056216658107587136
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:56,595 INFO epoch # 489 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0557259590132162
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:56,617 INFO epoch # 490 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.05563746302505024
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:53:56,617 INFO *** epoch 490, rolling-avg-loss (window=10)= 0.05910835427785059
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:56,638 INFO epoch # 491 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.05548628879478201
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:56,660 INFO epoch # 492 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.05531472808797844
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:56,681 INFO epoch # 493 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.055269429241889156
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:56,702 INFO epoch # 494 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.055197167486767285
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:56,723 INFO epoch # 495 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.055036787380231544
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:56,745 INFO epoch # 496 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.054854871952557005
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:56,766 INFO epoch # 497 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0547574926604284
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:56,787 INFO epoch # 498 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0545759808155708
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:56,809 INFO epoch # 499 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.054492842755280435
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:56,830 INFO epoch # 500 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.054456123121781275
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:53:56,830 INFO *** epoch 500, rolling-avg-loss (window=10)= 0.054944171229726634
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:56,852 INFO epoch # 501 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.05431424676498864
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:56,873 INFO epoch # 502 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.054143878871400375
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:56,894 INFO epoch # 503 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.055787750738090836
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:56,916 INFO epoch # 504 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.06173570788814686
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:56,937 INFO epoch # 505 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.05402596357453149
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:56,958 INFO epoch # 506 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.05430490412982181
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:56,980 INFO epoch # 507 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.053641784958017524
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:57,001 INFO epoch # 508 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.053457402471394744
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:57,022 INFO epoch # 509 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.05944962240755558
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:57,043 INFO epoch # 510 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.054324401484336704
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:53:57,044 INFO *** epoch 510, rolling-avg-loss (window=10)= 0.055518566328828456
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:57,065 INFO epoch # 511 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.053962618723744527
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:57,086 INFO epoch # 512 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.05310587251733523
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:57,108 INFO epoch # 513 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.053238953405525535
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:57,129 INFO epoch # 514 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.05294916016282514
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:57,150 INFO epoch # 515 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.053703972153016366
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:57,172 INFO epoch # 516 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.05375083602848463
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:57,193 INFO epoch # 517 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.05248734448105097
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:57,215 INFO epoch # 518 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0540978492499562
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:57,236 INFO epoch # 519 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.052303001255495474
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:57,257 INFO epoch # 520 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.052087853855482535
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:53:57,258 INFO *** epoch 520, rolling-avg-loss (window=10)= 0.05316874618329166
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:57,279 INFO epoch # 521 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.05210677275317721
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:57,300 INFO epoch # 522 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0522579735115869
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:57,322 INFO epoch # 523 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.05225851216528099
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:57,343 INFO epoch # 524 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.055615010467590764
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:57,364 INFO epoch # 525 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.05268531291221734
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:57,385 INFO epoch # 526 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.05155518538958859
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:57,406 INFO epoch # 527 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.05148628348251805
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:57,428 INFO epoch # 528 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0512770301575074
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:57,449 INFO epoch # 529 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.05132187358685769
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:57,470 INFO epoch # 530 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.05827923082688358
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:53:57,470 INFO *** epoch 530, rolling-avg-loss (window=10)= 0.05288431852532085
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:57,492 INFO epoch # 531 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0510720669553848
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:57,513 INFO epoch # 532 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.05092529823014047
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:57,535 INFO epoch # 533 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.05077328166225925
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:57,556 INFO epoch # 534 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.05179870418214705
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:57,577 INFO epoch # 535 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.050682358487392776
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:57,599 INFO epoch # 536 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.05738438412663527
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:57,620 INFO epoch # 537 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.050616144930245355
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:57,641 INFO epoch # 538 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.05033136863494292
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:57,662 INFO epoch # 539 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.05033919995184988
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:57,684 INFO epoch # 540 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.05297553101263475
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:53:57,684 INFO *** epoch 540, rolling-avg-loss (window=10)= 0.05168983381736325
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:57,705 INFO epoch # 541 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.05010671910713427
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:57,728 INFO epoch # 542 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0501105018920498
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:57,749 INFO epoch # 543 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.049790312492405064
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:57,771 INFO epoch # 544 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0496897867124062
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:57,792 INFO epoch # 545 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.04973039736796636
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:57,813 INFO epoch # 546 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.04951465324847959
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:57,834 INFO epoch # 547 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.04940448091656435
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:57,856 INFO epoch # 548 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.050729660913930275
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:57,877 INFO epoch # 549 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.050705262008705176
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:57,898 INFO epoch # 550 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.04907972670480376
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:53:57,898 INFO *** epoch 550, rolling-avg-loss (window=10)= 0.049886150136444485
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:57,920 INFO epoch # 551 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0490219101193361
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:57,941 INFO epoch # 552 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.04916918053640984
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:57,962 INFO epoch # 553 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.04915093432646245
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:57,983 INFO epoch # 554 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.048835902256541885
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:58,004 INFO epoch # 555 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.04891273633984383
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:58,026 INFO epoch # 556 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.05292365739296656
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:58,047 INFO epoch # 557 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.04904974906821735
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:58,068 INFO epoch # 558 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.048800458083860576
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:58,089 INFO epoch # 559 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.06753560394281521
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:58,111 INFO epoch # 560 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.048110514020663686
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:53:58,111 INFO *** epoch 560, rolling-avg-loss (window=10)= 0.05115106460871175
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:58,132 INFO epoch # 561 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.048390137308160774
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:58,154 INFO epoch # 562 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.04807894938858226
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:58,175 INFO epoch # 563 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.048206135325017385
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:58,196 INFO epoch # 564 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.048051158868474886
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:58,217 INFO epoch # 565 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.04764937823347282
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:58,239 INFO epoch # 566 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.04773281315283384
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:58,260 INFO epoch # 567 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.04751751246658387
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:58,281 INFO epoch # 568 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.047495305436314084
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:58,303 INFO epoch # 569 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.04726916081563104
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:58,324 INFO epoch # 570 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0471997973145335
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:53:58,324 INFO *** epoch 570, rolling-avg-loss (window=10)= 0.047759034830960445
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:58,346 INFO epoch # 571 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.04722637700615451
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:58,368 INFO epoch # 572 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.052922628303349484
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:58,390 INFO epoch # 573 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.046963897184468806
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:58,411 INFO epoch # 574 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.04684914937388385
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:58,432 INFO epoch # 575 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.04781705865752883
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:58,454 INFO epoch # 576 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.05360144087171648
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:58,475 INFO epoch # 577 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.04664447841059882
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:58,497 INFO epoch # 578 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.04654111970739905
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:58,518 INFO epoch # 579 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.046437334844085854
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:58,540 INFO epoch # 580 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.04668598463467788
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:53:58,540 INFO *** epoch 580, rolling-avg-loss (window=10)= 0.048168946899386354
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:58,562 INFO epoch # 581 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.046322768612299114
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:58,583 INFO epoch # 582 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.047047173538885545
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:58,604 INFO epoch # 583 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.04650962757295929
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:58,625 INFO epoch # 584 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.04645617883943487
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:58,647 INFO epoch # 585 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.04644789043231867
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:58,668 INFO epoch # 586 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.045857952878577635
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:58,689 INFO epoch # 587 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0458516294893343
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:58,710 INFO epoch # 588 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.04565286134311464
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:58,732 INFO epoch # 589 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.04557290759839816
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:58,754 INFO epoch # 590 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.05156661247019656
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:53:58,754 INFO *** epoch 590, rolling-avg-loss (window=10)= 0.04672856027755188
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:58,775 INFO epoch # 591 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.04544549997081049
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:58,797 INFO epoch # 592 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.04552269243868068
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:58,818 INFO epoch # 593 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.04526156395149883
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:58,839 INFO epoch # 594 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0452853138995124
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:58,861 INFO epoch # 595 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.04530572792282328
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:58,882 INFO epoch # 596 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.04509551514638588
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:58,903 INFO epoch # 597 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.04496526256843936
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:58,924 INFO epoch # 598 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.044831552426330745
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:58,946 INFO epoch # 599 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.04493509871826973
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:58,967 INFO epoch # 600 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.044765300626750104
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:53:58,967 INFO *** epoch 600, rolling-avg-loss (window=10)= 0.04514135276695015
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:58,988 INFO epoch # 601 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.045184131027781405
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:59,010 INFO epoch # 602 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.044511483087262604
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:59,032 INFO epoch # 603 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.044581569512956776
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:59,053 INFO epoch # 604 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.04455261082330253
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:59,074 INFO epoch # 605 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.04449588354327716
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:59,095 INFO epoch # 606 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.04435868904693052
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:59,116 INFO epoch # 607 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.04437046087696217
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:59,138 INFO epoch # 608 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.04428094614559086
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:59,159 INFO epoch # 609 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.04398870604200056
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:59,180 INFO epoch # 610 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.043864548028068384
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:53:59,181 INFO *** epoch 610, rolling-avg-loss (window=10)= 0.0444189028134133
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:59,202 INFO epoch # 611 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.055443778284825385
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:59,224 INFO epoch # 612 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.04490434407489374
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:59,245 INFO epoch # 613 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.04369957929884549
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:59,266 INFO epoch # 614 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.043852647140738554
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:59,287 INFO epoch # 615 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.05005998622800689
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:59,309 INFO epoch # 616 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.043588994405581616
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:59,330 INFO epoch # 617 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.04881503370415885
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:59,351 INFO epoch # 618 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.04412739344115835
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:59,372 INFO epoch # 619 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.04334377311170101
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:59,393 INFO epoch # 620 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.04490304154751357
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:53:59,394 INFO *** epoch 620, rolling-avg-loss (window=10)= 0.046273857123742344
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:59,415 INFO epoch # 621 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.04322774623869918
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:59,436 INFO epoch # 622 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.04301180288166506
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:59,457 INFO epoch # 623 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.04290268904151162
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:59,479 INFO epoch # 624 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.04282788147975225
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:59,500 INFO epoch # 625 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.044071015596273355
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:59,521 INFO epoch # 626 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.04328647935471963
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:59,542 INFO epoch # 627 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.042684335276135243
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:59,563 INFO epoch # 628 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0477554833778413
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:59,585 INFO epoch # 629 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.042579636923619546
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:59,606 INFO epoch # 630 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.04252431158965919
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:53:59,606 INFO *** epoch 630, rolling-avg-loss (window=10)= 0.043487138175987636
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:59,627 INFO epoch # 631 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.04298020890564658
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:59,649 INFO epoch # 632 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.04218006307200994
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:59,670 INFO epoch # 633 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.04218511193903396
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:59,691 INFO epoch # 634 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.04832840236485936
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:59,712 INFO epoch # 635 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.04205943218403263
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:59,734 INFO epoch # 636 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0421123221894959
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:59,755 INFO epoch # 637 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.042509523322223686
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:59,776 INFO epoch # 638 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.04935718855995219
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:59,797 INFO epoch # 639 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.04182557959575206
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:59,819 INFO epoch # 640 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.04179521697369637
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:53:59,819 INFO *** epoch 640, rolling-avg-loss (window=10)= 0.04353330491067027
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:59,840 INFO epoch # 641 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.041960263581131585
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:59,861 INFO epoch # 642 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.04156813977169804
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:59,883 INFO epoch # 643 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.04203519716975279
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:59,904 INFO epoch # 644 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.04156285597127862
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:59,925 INFO epoch # 645 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.04136036871932447
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:59,946 INFO epoch # 646 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.04133252939209342
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:59,967 INFO epoch # 647 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.04127435516420519
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:53:59,988 INFO epoch # 648 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.041058770002564415
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:00,010 INFO epoch # 649 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0410463798471028
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:00,031 INFO epoch # 650 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.04720211966196075
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:00,031 INFO *** epoch 650, rolling-avg-loss (window=10)= 0.04204009792811121
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:00,053 INFO epoch # 651 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.04093960332102142
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:00,074 INFO epoch # 652 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.04091393106500618
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:00,095 INFO epoch # 653 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0408004639466526
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:00,117 INFO epoch # 654 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.040699651319300756
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:00,138 INFO epoch # 655 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.04171506465354469
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:00,159 INFO epoch # 656 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.04073939408408478
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:00,180 INFO epoch # 657 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.05171963288739789
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:00,201 INFO epoch # 658 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.041166394876199774
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:00,223 INFO epoch # 659 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.040468708306434564
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:00,245 INFO epoch # 660 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.04021381547136116
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:00,245 INFO *** epoch 660, rolling-avg-loss (window=10)= 0.04193766599310038
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:00,266 INFO epoch # 661 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.04039410541008692
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:00,288 INFO epoch # 662 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.04012044893897837
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:00,309 INFO epoch # 663 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.04056980676978128
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:00,331 INFO epoch # 664 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.04025073006050661
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:00,352 INFO epoch # 665 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03993460092169698
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:00,373 INFO epoch # 666 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03998565206711646
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:00,394 INFO epoch # 667 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03984397010935936
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:00,416 INFO epoch # 668 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.04003912064945325
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:00,437 INFO epoch # 669 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03975160948175471
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:00,458 INFO epoch # 670 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.04467052967811469
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:00,458 INFO *** epoch 670, rolling-avg-loss (window=10)= 0.04055605740868486
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:00,480 INFO epoch # 671 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.04003832949092612
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:00,501 INFO epoch # 672 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.04011630761669949
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:00,522 INFO epoch # 673 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03948839078657329
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:00,544 INFO epoch # 674 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.039362096998956986
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:00,565 INFO epoch # 675 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03979386303399224
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:00,586 INFO epoch # 676 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03951503387361299
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:00,607 INFO epoch # 677 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03924132835527416
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:00,629 INFO epoch # 678 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.039307256796746515
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:00,650 INFO epoch # 679 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.039018839357595425
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:00,672 INFO epoch # 680 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03947168438025983
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:00,672 INFO *** epoch 680, rolling-avg-loss (window=10)= 0.0395353130690637
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:00,693 INFO epoch # 681 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03889504267499433
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:00,715 INFO epoch # 682 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03889193323266227
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:00,736 INFO epoch # 683 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.049445039985585026
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:00,758 INFO epoch # 684 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03870021242983057
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:00,779 INFO epoch # 685 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0388655809147167
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:00,800 INFO epoch # 686 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03946171195275383
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:00,822 INFO epoch # 687 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.038941462291404605
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:00,843 INFO epoch # 688 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03862962719722418
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:00,865 INFO epoch # 689 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.038717038463801146
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:00,886 INFO epoch # 690 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03834529943560483
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:00,886 INFO *** epoch 690, rolling-avg-loss (window=10)= 0.03988929485785775
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:00,907 INFO epoch # 691 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.04305566420953255
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:00,928 INFO epoch # 692 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03826918989943806
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:00,950 INFO epoch # 693 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03825215788674541
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:00,971 INFO epoch # 694 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.038151177890540566
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:00,992 INFO epoch # 695 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03817394319048617
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:01,013 INFO epoch # 696 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.05215651396429166
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:01,034 INFO epoch # 697 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03816999499395024
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:01,055 INFO epoch # 698 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.039131560231908225
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:01,077 INFO epoch # 699 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.037803180057380814
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:01,098 INFO epoch # 700 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03782856761245057
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:01,098 INFO *** epoch 700, rolling-avg-loss (window=10)= 0.04009919499367243
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:01,120 INFO epoch # 701 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0378189952170942
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:01,141 INFO epoch # 702 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03773643757449463
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:01,162 INFO epoch # 703 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03785678412532434
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:01,183 INFO epoch # 704 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03765128152735997
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:01,204 INFO epoch # 705 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03769474275759421
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:01,226 INFO epoch # 706 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03756924971821718
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:01,247 INFO epoch # 707 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0384794989367947
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:01,269 INFO epoch # 708 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03741972516581882
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:01,290 INFO epoch # 709 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.04316053300863132
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:01,311 INFO epoch # 710 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.037418795909616165
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:01,311 INFO *** epoch 710, rolling-avg-loss (window=10)= 0.03828060439409455
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:01,333 INFO epoch # 711 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.037104775503394194
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:01,354 INFO epoch # 712 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0513540430329158
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:01,376 INFO epoch # 713 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03708422304043779
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:01,397 INFO epoch # 714 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03693427585676545
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:01,418 INFO epoch # 715 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03684125751897227
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:01,439 INFO epoch # 716 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.037070872363983653
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:01,461 INFO epoch # 717 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03683993028244004
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:01,482 INFO epoch # 718 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03746837837388739
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:01,503 INFO epoch # 719 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03684661813895218
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:01,525 INFO epoch # 720 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03659555772173917
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:01,525 INFO *** epoch 720, rolling-avg-loss (window=10)= 0.038413993183348795
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:01,546 INFO epoch # 721 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03664376720553264
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:01,568 INFO epoch # 722 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03651438969245646
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:01,589 INFO epoch # 723 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03655019657162484
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:01,611 INFO epoch # 724 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03668809952796437
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:01,632 INFO epoch # 725 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.036487616307567805
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:01,653 INFO epoch # 726 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.036296531070547644
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:01,674 INFO epoch # 727 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.036249197597499005
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:01,695 INFO epoch # 728 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.037587766055366956
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:01,717 INFO epoch # 729 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.038132659217808396
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:01,739 INFO epoch # 730 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03664029926585499
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:01,739 INFO *** epoch 730, rolling-avg-loss (window=10)= 0.03677905225122231
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:01,760 INFO epoch # 731 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.036068554923986085
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:01,781 INFO epoch # 732 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03706142477312824
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:01,803 INFO epoch # 733 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03622808875661576
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:01,824 INFO epoch # 734 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03591813532693777
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:01,845 INFO epoch # 735 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03609476040583104
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:01,866 INFO epoch # 736 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03578087378991768
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:01,887 INFO epoch # 737 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.035760510894760955
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:01,908 INFO epoch # 738 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.035700888562132604
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:01,930 INFO epoch # 739 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03565586940385401
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:01,951 INFO epoch # 740 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03558809733658563
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:01,951 INFO *** epoch 740, rolling-avg-loss (window=10)= 0.03598572041737498
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:01,973 INFO epoch # 741 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03927390133321751
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:01,994 INFO epoch # 742 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03550084721064195
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:02,016 INFO epoch # 743 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.035536991388653405
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:02,037 INFO epoch # 744 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.040093215109664015
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:02,058 INFO epoch # 745 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03529964388872031
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:02,079 INFO epoch # 746 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03531818046758417
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:02,100 INFO epoch # 747 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.035282744851429015
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:02,121 INFO epoch # 748 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0351336920648464
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:02,143 INFO epoch # 749 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.035112411344016436
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:02,164 INFO epoch # 750 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.035097968495392706
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:02,165 INFO *** epoch 750, rolling-avg-loss (window=10)= 0.03616495961541659
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:02,186 INFO epoch # 751 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03499634163745213
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:02,207 INFO epoch # 752 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.035086384596070275
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:02,230 INFO epoch # 753 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03485580379492603
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:02,251 INFO epoch # 754 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03485113560600439
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:02,272 INFO epoch # 755 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.034885979592218064
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:02,294 INFO epoch # 756 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.034736426612653304
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:02,315 INFO epoch # 757 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03475746848562267
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:02,336 INFO epoch # 758 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.034661837518797256
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:02,358 INFO epoch # 759 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03473337533068843
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:02,379 INFO epoch # 760 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.034510875957494136
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:02,379 INFO *** epoch 760, rolling-avg-loss (window=10)= 0.03480756291319267
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:02,401 INFO epoch # 761 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.034612333722179756
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:02,422 INFO epoch # 762 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03459428645146545
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:02,443 INFO epoch # 763 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0343933317126357
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:02,464 INFO epoch # 764 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03450614048051648
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:02,486 INFO epoch # 765 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03442591790371807
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:02,507 INFO epoch # 766 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03423748708155472
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:02,528 INFO epoch # 767 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.04525702793034725
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:02,549 INFO epoch # 768 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0342643929325277
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:02,570 INFO epoch # 769 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03409427275619237
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:02,592 INFO epoch # 770 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.034125473073800094
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:02,592 INFO *** epoch 770, rolling-avg-loss (window=10)= 0.03545106640449376
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:02,613 INFO epoch # 771 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.038099414348835126
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:02,635 INFO epoch # 772 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03392091720888857
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:02,660 INFO epoch # 773 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03405026628024643
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:02,681 INFO epoch # 774 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03448655655665789
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:02,703 INFO epoch # 775 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03397380407113815
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:02,726 INFO epoch # 776 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03378018138027983
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:02,748 INFO epoch # 777 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.034049961424898356
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:02,770 INFO epoch # 778 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.033682688139379025
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:02,796 INFO epoch # 779 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.033620671259996016
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:02,826 INFO epoch # 780 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03913887125236215
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:02,827 INFO *** epoch 780, rolling-avg-loss (window=10)= 0.03488033319226815
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:02,853 INFO epoch # 781 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03371844766661525
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:02,879 INFO epoch # 782 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03367177548352629
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:02,904 INFO epoch # 783 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.033695244463160634
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:02,927 INFO epoch # 784 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.033464389118307736
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:02,949 INFO epoch # 785 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03333943948382512
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:02,970 INFO epoch # 786 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03337365596962627
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:02,992 INFO epoch # 787 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03414986397547182
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:03,013 INFO epoch # 788 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03320170534425415
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:03,034 INFO epoch # 789 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.033166867069667205
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:03,055 INFO epoch # 790 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03315553060383536
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:03,055 INFO *** epoch 790, rolling-avg-loss (window=10)= 0.033493691917828985
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:03,077 INFO epoch # 791 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.033529061533045024
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:03,098 INFO epoch # 792 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.045726764627033845
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:03,119 INFO epoch # 793 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.036073608353035524
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:03,140 INFO epoch # 794 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03290722714518779
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:03,161 INFO epoch # 795 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03376818035758333
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:03,182 INFO epoch # 796 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.032858892242074944
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:03,204 INFO epoch # 797 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.032784650080429856
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:03,225 INFO epoch # 798 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03654757253389107
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:03,246 INFO epoch # 799 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03444495068106335
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:03,268 INFO epoch # 800 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03259792100288905
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:03,268 INFO *** epoch 800, rolling-avg-loss (window=10)= 0.03512388285562338
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:03,289 INFO epoch # 801 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03255770658142865
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:03,310 INFO epoch # 802 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.032807286421302706
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:03,331 INFO epoch # 803 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03261911071604118
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:03,353 INFO epoch # 804 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03244844290748006
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:03,374 INFO epoch # 805 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0323869602943887
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:03,395 INFO epoch # 806 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03242999031499494
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:03,416 INFO epoch # 807 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03234825099934824
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:03,438 INFO epoch # 808 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03405024734820472
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:03,459 INFO epoch # 809 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03221718969507492
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:03,480 INFO epoch # 810 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03226316978543764
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:03,480 INFO *** epoch 810, rolling-avg-loss (window=10)= 0.032612835506370175
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:03,501 INFO epoch # 811 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0322371667061816
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:03,523 INFO epoch # 812 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.032435462075227406
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:03,544 INFO epoch # 813 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.035798557779344264
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:03,565 INFO epoch # 814 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.041121821035631
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:03,586 INFO epoch # 815 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03202494663128164
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:03,607 INFO epoch # 816 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03204028803156689
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:03,629 INFO epoch # 817 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03329085017321631
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:03,650 INFO epoch # 818 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03185623045283137
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:03,671 INFO epoch # 819 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03177905025950167
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:03,693 INFO epoch # 820 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03172708584315842
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:03,693 INFO *** epoch 820, rolling-avg-loss (window=10)= 0.033431145898794055
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:03,715 INFO epoch # 821 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.031705450630397536
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:03,736 INFO epoch # 822 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.031687581140431575
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:03,758 INFO epoch # 823 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03325750461954158
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:03,779 INFO epoch # 824 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03166578185482649
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:03,800 INFO epoch # 825 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03152905655588256
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:03,821 INFO epoch # 826 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03147663182608085
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:03,842 INFO epoch # 827 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0314758212552988
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:03,864 INFO epoch # 828 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03155806422000751
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:03,885 INFO epoch # 829 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.031442028121091425
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:03,906 INFO epoch # 830 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.031466641143197194
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:03,906 INFO *** epoch 830, rolling-avg-loss (window=10)= 0.03172645613667555
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:03,928 INFO epoch # 831 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03162872159737162
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:03,949 INFO epoch # 832 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03200964775896864
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:03,970 INFO epoch # 833 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03133235686982516
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:03,991 INFO epoch # 834 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0312939250288764
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:04,012 INFO epoch # 835 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.031308121237088926
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:04,033 INFO epoch # 836 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03145287116058171
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:04,054 INFO epoch # 837 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03125334713695338
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:04,076 INFO epoch # 838 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.04082007933902787
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:04,097 INFO epoch # 839 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.031483619575737976
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:04,118 INFO epoch # 840 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.030974248409620486
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:04,118 INFO *** epoch 840, rolling-avg-loss (window=10)= 0.03235569381140522
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:04,140 INFO epoch # 841 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.030905233492376283
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:04,161 INFO epoch # 842 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03579633247136371
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:04,182 INFO epoch # 843 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03083972679451108
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:04,203 INFO epoch # 844 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03077140505774878
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:04,225 INFO epoch # 845 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.030805345159024
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:04,246 INFO epoch # 846 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.030786631163209677
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:04,267 INFO epoch # 847 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.030643338337540627
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:04,288 INFO epoch # 848 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.031337844804511406
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:04,310 INFO epoch # 849 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03192645417584572
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:04,332 INFO epoch # 850 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.030513850193528924
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:04,332 INFO *** epoch 850, rolling-avg-loss (window=10)= 0.031432616164966024
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:04,353 INFO epoch # 851 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03055333647353109
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:04,375 INFO epoch # 852 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.030482371228572447
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:04,396 INFO epoch # 853 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.030396037371247075
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:04,417 INFO epoch # 854 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.030354806294781156
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:04,438 INFO epoch # 855 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03896734374575317
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:04,459 INFO epoch # 856 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03033459756989032
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:04,481 INFO epoch # 857 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.030502477784466464
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:04,502 INFO epoch # 858 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03027198219206184
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:04,523 INFO epoch # 859 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.030340669021825306
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:04,545 INFO epoch # 860 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03019325952482177
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:04,545 INFO *** epoch 860, rolling-avg-loss (window=10)= 0.031239688120695063
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:04,567 INFO epoch # 861 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.030376252318092156
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:04,588 INFO epoch # 862 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03255712064856198
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:04,610 INFO epoch # 863 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.029999604757904308
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:04,631 INFO epoch # 864 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.030048394604818895
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:04,652 INFO epoch # 865 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03320651117246598
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:04,673 INFO epoch # 866 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0322163461605669
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:04,694 INFO epoch # 867 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.029892076840042137
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:04,716 INFO epoch # 868 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.029854019870981574
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:04,737 INFO epoch # 869 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.029863889030821156
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:04,759 INFO epoch # 870 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.030899964025593363
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:04,759 INFO *** epoch 870, rolling-avg-loss (window=10)= 0.030891417942984844
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:04,780 INFO epoch # 871 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.029776097704598214
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:04,801 INFO epoch # 872 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.029932393961644266
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:04,822 INFO epoch # 873 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.029664947505807504
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:04,843 INFO epoch # 874 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.030186589196091518
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:04,864 INFO epoch # 875 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.029852578052668832
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:04,886 INFO epoch # 876 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.030177361957612447
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:04,907 INFO epoch # 877 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.029640788859978784
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:04,928 INFO epoch # 878 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02952404024108546
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:04,950 INFO epoch # 879 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.029431442613713443
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:04,971 INFO epoch # 880 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.029417903380817734
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:04,971 INFO *** epoch 880, rolling-avg-loss (window=10)= 0.02976041434740182
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:04,993 INFO epoch # 881 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.029373735778790433
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:05,014 INFO epoch # 882 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02949002992681926
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:05,035 INFO epoch # 883 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.029577099623566028
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:05,056 INFO epoch # 884 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02937666920479387
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:05,077 INFO epoch # 885 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.029461027588695288
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:05,099 INFO epoch # 886 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03161915969394613
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:05,120 INFO epoch # 887 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02930418778123567
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:05,141 INFO epoch # 888 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.029510458756703883
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:05,163 INFO epoch # 889 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.029107498354278505
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:05,184 INFO epoch # 890 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03156549769482808
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:05,184 INFO *** epoch 890, rolling-avg-loss (window=10)= 0.029838536440365715
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:05,205 INFO epoch # 891 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02907934508402832
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:05,227 INFO epoch # 892 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.028993536296184175
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:05,248 INFO epoch # 893 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02903329906257568
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:05,270 INFO epoch # 894 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.028888099172036164
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:05,291 INFO epoch # 895 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0288318040111335
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:05,312 INFO epoch # 896 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.028908946325827856
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:05,333 INFO epoch # 897 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02884694484237116
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:05,355 INFO epoch # 898 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.028793138000764884
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:05,376 INFO epoch # 899 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.028746387695719022
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:05,397 INFO epoch # 900 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02873018363607116
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:05,397 INFO *** epoch 900, rolling-avg-loss (window=10)= 0.02888516841267119
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:05,419 INFO epoch # 901 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.028725822325213812
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:05,440 INFO epoch # 902 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02864638655591989
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:05,461 INFO epoch # 903 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02866638742852956
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:05,482 INFO epoch # 904 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.028569429683557246
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:05,503 INFO epoch # 905 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.028860260819783434
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:05,524 INFO epoch # 906 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02872252657834906
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:05,546 INFO epoch # 907 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.028590959707798902
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:05,567 INFO epoch # 908 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03961749610607512
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:05,588 INFO epoch # 909 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.028370164027364808
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:05,609 INFO epoch # 910 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.028623814447200857
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:05,609 INFO *** epoch 910, rolling-avg-loss (window=10)= 0.029739324767979268
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:05,631 INFO epoch # 911 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.028525473266199697
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:05,652 INFO epoch # 912 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.028310457950283308
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:05,673 INFO epoch # 913 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.028349625601549633
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:05,694 INFO epoch # 914 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.028564930325956084
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:05,715 INFO epoch # 915 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.028511279102531262
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:05,736 INFO epoch # 916 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02819678197556641
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:05,758 INFO epoch # 917 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02810761487489799
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:05,779 INFO epoch # 918 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02815369355812436
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:05,800 INFO epoch # 919 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02810393285471946
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:05,821 INFO epoch # 920 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.028064958707545884
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:05,821 INFO *** epoch 920, rolling-avg-loss (window=10)= 0.02828887482173741
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:05,842 INFO epoch # 921 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.028256132107344456
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:05,864 INFO epoch # 922 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.028195895843964536
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:05,885 INFO epoch # 923 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.028255894059839193
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:05,906 INFO epoch # 924 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02787948362310999
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:05,927 INFO epoch # 925 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.028079299969249405
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:05,948 INFO epoch # 926 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.027874184721440542
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:05,970 INFO epoch # 927 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.027786572805780452
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:05,991 INFO epoch # 928 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.027777714451076463
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:06,013 INFO epoch # 929 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02773686114232987
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:06,034 INFO epoch # 930 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.027818952257803176
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:06,034 INFO *** epoch 930, rolling-avg-loss (window=10)= 0.02796609909819381
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:06,056 INFO epoch # 931 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03123481165675912
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:06,078 INFO epoch # 932 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02819368920609122
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:06,099 INFO epoch # 933 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.027566357824980514
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:06,120 INFO epoch # 934 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.027521011827047914
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:06,141 INFO epoch # 935 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.031113194359932095
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:06,162 INFO epoch # 936 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.027634175879938994
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:06,183 INFO epoch # 937 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.027540727889572736
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:06,205 INFO epoch # 938 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02745402647269657
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:06,227 INFO epoch # 939 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02882494593359297
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:06,248 INFO epoch # 940 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.027400139675592072
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:06,248 INFO *** epoch 940, rolling-avg-loss (window=10)= 0.028448308072620422
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:06,269 INFO epoch # 941 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.027350970718543977
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:06,291 INFO epoch # 942 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.027475353119370993
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:06,312 INFO epoch # 943 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.027261336530500557
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:06,333 INFO epoch # 944 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.027233001084823627
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:06,354 INFO epoch # 945 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.027338491127011366
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:06,375 INFO epoch # 946 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.027154570241691545
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:06,396 INFO epoch # 947 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02716192985099042
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:06,418 INFO epoch # 948 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.030395950823731255
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:06,439 INFO epoch # 949 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02711804165301146
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:06,460 INFO epoch # 950 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.027160578378243372
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:06,460 INFO *** epoch 950, rolling-avg-loss (window=10)= 0.027565022352791856
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:06,482 INFO epoch # 951 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.027047476862207986
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:06,503 INFO epoch # 952 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.027123417807160877
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:06,525 INFO epoch # 953 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.027151572467118967
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:06,546 INFO epoch # 954 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.027553420470212586
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:06,567 INFO epoch # 955 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.028432488965336233
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:06,588 INFO epoch # 956 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.026956278408761136
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:06,609 INFO epoch # 957 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02681406339070236
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:06,630 INFO epoch # 958 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.026827164387213998
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:06,652 INFO epoch # 959 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.026797464379342273
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:06,673 INFO epoch # 960 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.026759775071695913
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:06,673 INFO *** epoch 960, rolling-avg-loss (window=10)= 0.027146312220975233
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:06,694 INFO epoch # 961 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.026743752554466482
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:06,716 INFO epoch # 962 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.026764170412207022
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:06,737 INFO epoch # 963 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.027271871389530133
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:06,758 INFO epoch # 964 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.026723856572061777
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:06,779 INFO epoch # 965 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.026712137747381348
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:06,801 INFO epoch # 966 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02709360435255803
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:06,822 INFO epoch # 967 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02660135951009579
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:06,844 INFO epoch # 968 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02651190312462859
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:06,865 INFO epoch # 969 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.026643947792763356
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:06,886 INFO epoch # 970 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.026761436922242865
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:06,886 INFO *** epoch 970, rolling-avg-loss (window=10)= 0.02678280403779354
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:06,908 INFO epoch # 971 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0266281809163047
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:06,929 INFO epoch # 972 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.028781353670638055
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:06,950 INFO epoch # 973 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.026383221444120863
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:06,972 INFO epoch # 974 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0367090331055806
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:06,993 INFO epoch # 975 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02650693105533719
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:07,014 INFO epoch # 976 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.028636390699830372
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:07,035 INFO epoch # 977 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02638462183676893
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:07,057 INFO epoch # 978 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.027452785696368665
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:07,078 INFO epoch # 979 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02636486142728245
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:07,099 INFO epoch # 980 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.026354383007856086
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:07,099 INFO *** epoch 980, rolling-avg-loss (window=10)= 0.02802017628600879
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:07,121 INFO epoch # 981 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.029088853902067058
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:07,142 INFO epoch # 982 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02617292443756014
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:07,163 INFO epoch # 983 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02621041667589452
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:07,185 INFO epoch # 984 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.026083953656780068
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:07,206 INFO epoch # 985 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.026340994947531726
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:07,227 INFO epoch # 986 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02602655187365599
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:07,248 INFO epoch # 987 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.026207780611002818
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:07,270 INFO epoch # 988 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.026051128865219653
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:07,291 INFO epoch # 989 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.026103475342097227
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:07,313 INFO epoch # 990 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.025919225634424947
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:07,313 INFO *** epoch 990, rolling-avg-loss (window=10)= 0.026420530594623414
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:07,334 INFO epoch # 991 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.025835137414105702
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:07,356 INFO epoch # 992 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.025842138486041222
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:07,377 INFO epoch # 993 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.025909837888320908
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:07,398 INFO epoch # 994 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.025851544734905474
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:07,420 INFO epoch # 995 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.025754470538231544
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:07,441 INFO epoch # 996 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.025717914293636568
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:07,463 INFO epoch # 997 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02569199250865495
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:07,484 INFO epoch # 998 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.025767286781047005
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:07,506 INFO epoch # 999 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.025649509894719813
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:07,527 INFO epoch # 1000 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.025635935548052657
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:07,527 INFO *** epoch 1000, rolling-avg-loss (window=10)= 0.025765576808771583
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:07,548 INFO epoch # 1001 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.025738518525031395
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:07,570 INFO epoch # 1002 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.025629351504903752
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:07,591 INFO epoch # 1003 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.025982121303968597
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:07,612 INFO epoch # 1004 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.025528137492074165
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:07,633 INFO epoch # 1005 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.025536336965160444
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:07,655 INFO epoch # 1006 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.029185617313487455
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:07,676 INFO epoch # 1007 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03300597832276253
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:07,697 INFO epoch # 1008 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03419338884850731
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:07,718 INFO epoch # 1009 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.025379534796229564
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:07,740 INFO epoch # 1010 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.025415466785489116
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:07,740 INFO *** epoch 1010, rolling-avg-loss (window=10)= 0.027559445185761432
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:07,762 INFO epoch # 1011 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02583112084539607
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:07,783 INFO epoch # 1012 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02524579135570093
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:07,804 INFO epoch # 1013 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.028766219176759478
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:07,825 INFO epoch # 1014 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.025191413529682904
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:07,847 INFO epoch # 1015 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02574536111933412
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:07,868 INFO epoch # 1016 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.025132646813290194
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:07,889 INFO epoch # 1017 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.025258626410504803
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:07,911 INFO epoch # 1018 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02512842739088228
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:07,932 INFO epoch # 1019 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.025296071064076386
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:07,953 INFO epoch # 1020 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.027063482280937023
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:07,953 INFO *** epoch 1020, rolling-avg-loss (window=10)= 0.025865915998656418
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:07,975 INFO epoch # 1021 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.025089907183428295
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:07,996 INFO epoch # 1022 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.025097833975451067
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:08,018 INFO epoch # 1023 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.024964131065644324
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:08,039 INFO epoch # 1024 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02492373277345905
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:08,060 INFO epoch # 1025 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02510892217833316
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:08,081 INFO epoch # 1026 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02735182282049209
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:08,102 INFO epoch # 1027 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.025332916156912688
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:08,124 INFO epoch # 1028 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02496443220297806
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:08,145 INFO epoch # 1029 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.024803555937978672
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:08,166 INFO epoch # 1030 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02526366435631644
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:08,166 INFO *** epoch 1030, rolling-avg-loss (window=10)= 0.025290091865099385
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:08,188 INFO epoch # 1031 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.025501342184725218
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:08,209 INFO epoch # 1032 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02471715737192426
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:08,230 INFO epoch # 1033 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02468009498261381
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:08,252 INFO epoch # 1034 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02795263662119396
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:08,273 INFO epoch # 1035 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02466800809634151
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:08,294 INFO epoch # 1036 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.025993004925112473
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:08,315 INFO epoch # 1037 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.024817531535518356
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:08,337 INFO epoch # 1038 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.024633559864014387
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:08,358 INFO epoch # 1039 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.024717805747059174
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:08,379 INFO epoch # 1040 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0245876535991556
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:08,379 INFO *** epoch 1040, rolling-avg-loss (window=10)= 0.025226879492765874
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:08,401 INFO epoch # 1041 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.024734344442549627
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:08,422 INFO epoch # 1042 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02546972878917586
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:08,443 INFO epoch # 1043 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.024442285633995198
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:08,464 INFO epoch # 1044 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.024638306233100593
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:08,485 INFO epoch # 1045 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.024470903510518838
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:08,506 INFO epoch # 1046 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0243667523318436
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:08,528 INFO epoch # 1047 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.024421312962658703
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:08,549 INFO epoch # 1048 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02432137581126881
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:08,570 INFO epoch # 1049 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.024288537926622666
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:08,592 INFO epoch # 1050 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.024991779195261188
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:08,592 INFO *** epoch 1050, rolling-avg-loss (window=10)= 0.024614532683699508
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:08,614 INFO epoch # 1051 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.024482758628437296
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:08,636 INFO epoch # 1052 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02463984642236028
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:08,658 INFO epoch # 1053 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02423570137034403
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:08,679 INFO epoch # 1054 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.024197582446504384
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:08,700 INFO epoch # 1055 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02427516104944516
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:08,721 INFO epoch # 1056 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02413867508585099
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:08,743 INFO epoch # 1057 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.024170461438188795
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:08,764 INFO epoch # 1058 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02410046596924076
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:08,786 INFO epoch # 1059 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0245401092179236
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:08,807 INFO epoch # 1060 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.024967356759589165
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:08,807 INFO *** epoch 1060, rolling-avg-loss (window=10)= 0.024374811838788445
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:08,829 INFO epoch # 1061 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.024069845443591475
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:08,850 INFO epoch # 1062 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02466589442337863
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:08,871 INFO epoch # 1063 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.024087562451313715
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:08,892 INFO epoch # 1064 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.023965454842254985
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:08,913 INFO epoch # 1065 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.026844850137422327
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:08,934 INFO epoch # 1066 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02395028060709592
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:08,955 INFO epoch # 1067 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.023997971882636193
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:08,977 INFO epoch # 1068 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.023924550579977222
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:08,998 INFO epoch # 1069 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.025430932226299774
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:09,019 INFO epoch # 1070 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.023899764266388956
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:09,020 INFO *** epoch 1070, rolling-avg-loss (window=10)= 0.02448371068603592
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:09,041 INFO epoch # 1071 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02374363670605817
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:09,062 INFO epoch # 1072 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.023769871950207744
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:09,083 INFO epoch # 1073 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.023715039336821064
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:09,104 INFO epoch # 1074 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.023713210022833664
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:09,125 INFO epoch # 1075 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.023670660302741453
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:09,147 INFO epoch # 1076 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.023687049026193563
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:09,168 INFO epoch # 1077 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.023683425482886378
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:09,189 INFO epoch # 1078 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02389083381422097
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:09,211 INFO epoch # 1079 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.023592253630340565
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:09,233 INFO epoch # 1080 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.023566548305097967
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:09,233 INFO *** epoch 1080, rolling-avg-loss (window=10)= 0.023703252857740154
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:09,254 INFO epoch # 1081 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.023766007398080546
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:09,276 INFO epoch # 1082 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.023519404145190492
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:09,297 INFO epoch # 1083 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.023569893317471724
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:09,318 INFO epoch # 1084 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.023628790469956584
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:09,339 INFO epoch # 1085 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.023438102623913437
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:09,361 INFO epoch # 1086 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.023620735330041498
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:09,382 INFO epoch # 1087 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.023508974634751212
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:09,404 INFO epoch # 1088 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.023373086150968447
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:09,425 INFO epoch # 1089 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.026902079953288194
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:09,446 INFO epoch # 1090 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.030472748003376182
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:09,446 INFO *** epoch 1090, rolling-avg-loss (window=10)= 0.024579982202703833
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:09,467 INFO epoch # 1091 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.023367189198324922
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:09,489 INFO epoch # 1092 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.023484725767048076
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:09,510 INFO epoch # 1093 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.029725800377491396
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:09,531 INFO epoch # 1094 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.023593387493747286
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:09,552 INFO epoch # 1095 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.023211099309264682
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:09,573 INFO epoch # 1096 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0232755704128067
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:09,595 INFO epoch # 1097 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.023273188751772977
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:09,616 INFO epoch # 1098 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.023102265447960235
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:09,638 INFO epoch # 1099 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02315966260357527
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:09,659 INFO epoch # 1100 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02306615347697516
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:09,659 INFO *** epoch 1100, rolling-avg-loss (window=10)= 0.02392590428389667
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:09,681 INFO epoch # 1101 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.023049183379043825
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:09,702 INFO epoch # 1102 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02298311645972717
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:09,724 INFO epoch # 1103 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.023247027325851377
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:09,745 INFO epoch # 1104 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02307040100276936
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:09,766 INFO epoch # 1105 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.023031385346257593
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:09,787 INFO epoch # 1106 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.024229699876741506
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:09,809 INFO epoch # 1107 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.023116057440347504
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:09,830 INFO epoch # 1108 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02538267451018328
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:09,851 INFO epoch # 1109 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0232190751885355
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:09,872 INFO epoch # 1110 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.022874037276778836
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:09,872 INFO *** epoch 1110, rolling-avg-loss (window=10)= 0.023420265780623596
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:09,894 INFO epoch # 1111 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.022834396768303122
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:09,915 INFO epoch # 1112 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02282602649211185
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:09,936 INFO epoch # 1113 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.023516087770985905
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:09,957 INFO epoch # 1114 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.022781263724027667
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:09,978 INFO epoch # 1115 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.022760463849408552
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:09,999 INFO epoch # 1116 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02270706480339868
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:10,021 INFO epoch # 1117 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.022705829389451537
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:10,042 INFO epoch # 1118 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.022685999887471553
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:10,064 INFO epoch # 1119 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02597109926500707
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:10,085 INFO epoch # 1120 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02264037170971278
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:10,085 INFO *** epoch 1120, rolling-avg-loss (window=10)= 0.023142860365987873
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:10,106 INFO epoch # 1121 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.022579596925424994
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:10,128 INFO epoch # 1122 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02878631650673924
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:10,149 INFO epoch # 1123 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0226844218414044
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:10,170 INFO epoch # 1124 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02256737869902281
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:10,191 INFO epoch # 1125 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02259777712606592
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:10,212 INFO epoch # 1126 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.022520992664794903
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:10,234 INFO epoch # 1127 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.023161847013398074
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:10,256 INFO epoch # 1128 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.022520727790833917
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:10,277 INFO epoch # 1129 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.022612146138271783
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:10,298 INFO epoch # 1130 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.022451792501669843
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:10,298 INFO *** epoch 1130, rolling-avg-loss (window=10)= 0.02324829972076259
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:10,320 INFO epoch # 1131 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.022472532116807997
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:10,341 INFO epoch # 1132 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.022443752255639993
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:10,363 INFO epoch # 1133 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02235650210059248
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:10,384 INFO epoch # 1134 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.022389970094081946
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:10,405 INFO epoch # 1135 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.022427847026847303
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:10,426 INFO epoch # 1136 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.022535923722898588
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:10,447 INFO epoch # 1137 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02225378667935729
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:10,468 INFO epoch # 1138 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.023180966127256397
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:10,490 INFO epoch # 1139 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02225337631534785
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:10,512 INFO epoch # 1140 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.022216006480448414
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:10,512 INFO *** epoch 1140, rolling-avg-loss (window=10)= 0.022453066291927826
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:10,533 INFO epoch # 1141 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.022164484464155976
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:10,555 INFO epoch # 1142 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02219035228335997
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:10,576 INFO epoch # 1143 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.022126183808723
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:10,597 INFO epoch # 1144 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02406955921469489
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:10,619 INFO epoch # 1145 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.022440896354964934
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:10,640 INFO epoch # 1146 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.022278606913459953
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:10,661 INFO epoch # 1147 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.022069343853218015
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:10,682 INFO epoch # 1148 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.025105137792706955
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:10,703 INFO epoch # 1149 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.022112499660579488
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:10,725 INFO epoch # 1150 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.022021349941496737
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:10,726 INFO *** epoch 1150, rolling-avg-loss (window=10)= 0.022657841428735993
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:10,747 INFO epoch # 1151 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.024620909338409547
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:10,769 INFO epoch # 1152 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.022155799793836195
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:10,790 INFO epoch # 1153 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02203273875056766
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:10,811 INFO epoch # 1154 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02323054600856267
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:10,832 INFO epoch # 1155 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02191915595176397
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:10,854 INFO epoch # 1156 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02195426017715363
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:10,875 INFO epoch # 1157 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02182224900025176
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:10,896 INFO epoch # 1158 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.021895714991842397
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:10,918 INFO epoch # 1159 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02188139869394945
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:10,939 INFO epoch # 1160 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.021927880552539136
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:10,939 INFO *** epoch 1160, rolling-avg-loss (window=10)= 0.02234406532588764
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:10,960 INFO epoch # 1161 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02195077339274576
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:10,982 INFO epoch # 1162 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.021821464579261374
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:11,003 INFO epoch # 1163 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.021805101812788052
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:11,024 INFO epoch # 1164 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.022096133849117905
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:11,045 INFO epoch # 1165 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02167339198422269
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:11,067 INFO epoch # 1166 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.021973384129523765
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:11,088 INFO epoch # 1167 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.021869400698051322
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:11,109 INFO epoch # 1168 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.021656373311998323
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:11,130 INFO epoch # 1169 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0220919902130845
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:11,152 INFO epoch # 1170 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.021602082437311765
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:11,152 INFO *** epoch 1170, rolling-avg-loss (window=10)= 0.021854009640810544
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:11,173 INFO epoch # 1171 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.021536854710575426
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:11,195 INFO epoch # 1172 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.021669341913366225
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:11,216 INFO epoch # 1173 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.021582334527920466
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:11,238 INFO epoch # 1174 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.021585996302746935
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:11,259 INFO epoch # 1175 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0215510142952553
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:11,280 INFO epoch # 1176 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02164818422170356
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:11,302 INFO epoch # 1177 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.021435238584672334
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:11,323 INFO epoch # 1178 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.021434914709971054
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:11,344 INFO epoch # 1179 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02143662823800696
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:11,365 INFO epoch # 1180 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02329401668976061
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:11,366 INFO *** epoch 1180, rolling-avg-loss (window=10)= 0.021717452419397886
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:11,387 INFO epoch # 1181 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02141652943828376
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:11,408 INFO epoch # 1182 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02140810676792171
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:11,429 INFO epoch # 1183 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.021392422462668037
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:11,450 INFO epoch # 1184 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.021363663363445085
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:11,471 INFO epoch # 1185 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.021300668435287662
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:11,493 INFO epoch # 1186 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02204152726699249
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:11,514 INFO epoch # 1187 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.021404795836133417
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:11,535 INFO epoch # 1188 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.021275532140862197
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:11,557 INFO epoch # 1189 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.021249636833090335
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:11,578 INFO epoch # 1190 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02126130257965997
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:11,578 INFO *** epoch 1190, rolling-avg-loss (window=10)= 0.021411418512434464
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:11,600 INFO epoch # 1191 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.021192624801187776
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:11,621 INFO epoch # 1192 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.021526931232074276
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:11,643 INFO epoch # 1193 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.021582554447377333
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:11,664 INFO epoch # 1194 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02416997295222245
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:11,685 INFO epoch # 1195 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02113060721603688
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:11,706 INFO epoch # 1196 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.021099557510751765
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:11,728 INFO epoch # 1197 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02109097416541772
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:11,749 INFO epoch # 1198 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.021081025959574617
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:11,770 INFO epoch # 1199 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02285503732127836
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:11,791 INFO epoch # 1200 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02100244228131487
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:11,792 INFO *** epoch 1200, rolling-avg-loss (window=10)= 0.021673172788723605
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:11,813 INFO epoch # 1201 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02279796414222801
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:11,834 INFO epoch # 1202 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.020969779307051795
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:11,856 INFO epoch # 1203 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02148185698024463
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:11,877 INFO epoch # 1204 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.020949042445863597
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:11,898 INFO epoch # 1205 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.021317200567864347
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:11,919 INFO epoch # 1206 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.020896107933367603
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:11,940 INFO epoch # 1207 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.021091598668135703
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:11,962 INFO epoch # 1208 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.023337600534432568
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:11,983 INFO epoch # 1209 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.020821205691390787
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:12,004 INFO epoch # 1210 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02083839244005503
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:12,004 INFO *** epoch 1210, rolling-avg-loss (window=10)= 0.02145007487106341
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:12,026 INFO epoch # 1211 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.020827393120271154
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:12,047 INFO epoch # 1212 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02085275838180678
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:12,068 INFO epoch # 1213 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.020855949325778056
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:12,089 INFO epoch # 1214 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.020739972289447905
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:12,111 INFO epoch # 1215 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.020920678834954742
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:12,133 INFO epoch # 1216 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02245213642163435
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:12,155 INFO epoch # 1217 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.020834963936067652
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:12,177 INFO epoch # 1218 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02066140303213615
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:12,198 INFO epoch # 1219 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.020745117297337856
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:12,220 INFO epoch # 1220 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02070046770677436
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:12,220 INFO *** epoch 1220, rolling-avg-loss (window=10)= 0.0209590840346209
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:12,242 INFO epoch # 1221 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.020679951907368377
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:12,263 INFO epoch # 1222 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.020669768593506888
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:12,285 INFO epoch # 1223 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.020787188441317994
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:12,306 INFO epoch # 1224 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02136915516166482
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:12,327 INFO epoch # 1225 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.020636464774725027
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:12,348 INFO epoch # 1226 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.023761872806062456
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:12,370 INFO epoch # 1227 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.020530855021206662
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:12,391 INFO epoch # 1228 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.020819152836338617
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:12,412 INFO epoch # 1229 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.020489336784521583
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:12,434 INFO epoch # 1230 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.020587170714861713
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:12,434 INFO *** epoch 1230, rolling-avg-loss (window=10)= 0.021033091704157413
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:12,455 INFO epoch # 1231 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.020441541921172757
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:12,476 INFO epoch # 1232 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.020447176684683654
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:12,498 INFO epoch # 1233 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.020451699459954398
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:12,519 INFO epoch # 1234 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.020365304942970397
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:12,540 INFO epoch # 1235 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.020733177494548727
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:12,561 INFO epoch # 1236 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02199924978776835
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:12,582 INFO epoch # 1237 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.020514738076599315
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:12,604 INFO epoch # 1238 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.026044521342555527
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:12,625 INFO epoch # 1239 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.021654528827639297
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:12,646 INFO epoch # 1240 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02029441385093378
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:12,646 INFO *** epoch 1240, rolling-avg-loss (window=10)= 0.02129463523888262
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:12,668 INFO epoch # 1241 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.020251784022548236
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:12,689 INFO epoch # 1242 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02024693369457964
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:12,710 INFO epoch # 1243 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02028488511859905
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:12,732 INFO epoch # 1244 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02029577842040453
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:12,753 INFO epoch # 1245 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02018977817715495
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:12,774 INFO epoch # 1246 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02024471526965499
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:12,796 INFO epoch # 1247 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.020765090768691152
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:12,817 INFO epoch # 1248 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.020743727072840557
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:12,838 INFO epoch # 1249 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02015315249809646
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:12,859 INFO epoch # 1250 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.020127843657974154
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:12,859 INFO *** epoch 1250, rolling-avg-loss (window=10)= 0.02033036887005437
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:12,880 INFO epoch # 1251 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.020151763637841213
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:12,902 INFO epoch # 1252 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.020254118913726415
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:12,923 INFO epoch # 1253 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02022849735658383
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:12,944 INFO epoch # 1254 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.020069302190677263
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:12,965 INFO epoch # 1255 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.020026315622089896
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:12,986 INFO epoch # 1256 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.020039050832565408
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:13,007 INFO epoch # 1257 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.020246554115146864
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:13,028 INFO epoch # 1258 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0199848240299616
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:13,050 INFO epoch # 1259 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.020051294202858116
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:13,071 INFO epoch # 1260 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.020003613542940002
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:13,071 INFO *** epoch 1260, rolling-avg-loss (window=10)= 0.02010553344443906
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:13,092 INFO epoch # 1261 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02010845443146536
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:13,114 INFO epoch # 1262 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.019956255426222924
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:13,135 INFO epoch # 1263 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0198715852056921
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:13,156 INFO epoch # 1264 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.019861165674228687
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:13,177 INFO epoch # 1265 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01996934087947011
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:13,198 INFO epoch # 1266 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.019931864182581194
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:13,220 INFO epoch # 1267 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.020011660068121273
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:13,242 INFO epoch # 1268 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.019828184638754465
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:13,264 INFO epoch # 1269 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01987062419357244
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:13,285 INFO epoch # 1270 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01977727656776551
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:13,286 INFO *** epoch 1270, rolling-avg-loss (window=10)= 0.019918641126787408
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:13,307 INFO epoch # 1271 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0209413611664786
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:13,328 INFO epoch # 1272 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.019766333905863576
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:13,349 INFO epoch # 1273 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.019737557639018632
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:13,370 INFO epoch # 1274 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.019723099449038273
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:13,391 INFO epoch # 1275 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.019646249260404147
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:13,412 INFO epoch # 1276 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01972246244258713
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:13,434 INFO epoch # 1277 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.019653165778436232
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:13,455 INFO epoch # 1278 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.019657734723296016
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:13,477 INFO epoch # 1279 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.019608730457548518
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:13,498 INFO epoch # 1280 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02184066511472338
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:13,498 INFO *** epoch 1280, rolling-avg-loss (window=10)= 0.020029735993739452
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:13,519 INFO epoch # 1281 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01972405207925476
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:13,541 INFO epoch # 1282 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01955973929943866
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:13,562 INFO epoch # 1283 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.019899289727618452
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:13,584 INFO epoch # 1284 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01949285716546001
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:13,605 INFO epoch # 1285 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.019530854464392178
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:13,626 INFO epoch # 1286 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.022521521193993976
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:13,648 INFO epoch # 1287 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.019536834508471657
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:13,669 INFO epoch # 1288 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.019501563838275615
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:13,690 INFO epoch # 1289 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01945574857018073
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:13,711 INFO epoch # 1290 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.019626452471129596
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:13,711 INFO *** epoch 1290, rolling-avg-loss (window=10)= 0.019884891331821565
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:13,733 INFO epoch # 1291 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.019434745525359176
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:13,754 INFO epoch # 1292 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.019480099181237165
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:13,776 INFO epoch # 1293 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.020463109824049752
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:13,797 INFO epoch # 1294 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01937163395996322
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:13,818 INFO epoch # 1295 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.019607805901614483
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:13,839 INFO epoch # 1296 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.019402837850066135
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:13,860 INFO epoch # 1297 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01932466525613563
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:13,881 INFO epoch # 1298 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.019301192140119383
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:13,903 INFO epoch # 1299 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.019341611670824932
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:13,924 INFO epoch # 1300 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.019290691445348784
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:13,924 INFO *** epoch 1300, rolling-avg-loss (window=10)= 0.019501839275471868
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:13,945 INFO epoch # 1301 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.019341392180649564
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:13,967 INFO epoch # 1302 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01946852502442198
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:13,988 INFO epoch # 1303 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01921704060441698
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:14,009 INFO epoch # 1304 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.019286923779873177
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:14,030 INFO epoch # 1305 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.019166456363564066
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:14,051 INFO epoch # 1306 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.019333976524649188
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:14,073 INFO epoch # 1307 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.019376914824533742
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:14,094 INFO epoch # 1308 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.019150115469528828
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:14,115 INFO epoch # 1309 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.019789300524280407
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:14,136 INFO epoch # 1310 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01927822555444436
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:14,137 INFO *** epoch 1310, rolling-avg-loss (window=10)= 0.01934088708503623
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:14,158 INFO epoch # 1311 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.019132800967781805
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:14,179 INFO epoch # 1312 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.019171561660186853
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:14,200 INFO epoch # 1313 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.019211195045500062
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:14,222 INFO epoch # 1314 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01907120072064572
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:14,243 INFO epoch # 1315 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.020105850802792702
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:14,264 INFO epoch # 1316 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.019055982105783187
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:14,286 INFO epoch # 1317 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0189803764296812
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:14,307 INFO epoch # 1318 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01903303151630098
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:14,328 INFO epoch # 1319 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.019120451266644523
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:14,350 INFO epoch # 1320 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.018942826751299435
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:14,350 INFO *** epoch 1320, rolling-avg-loss (window=10)= 0.019182527726661645
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:14,371 INFO epoch # 1321 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.022301189790596254
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:14,392 INFO epoch # 1322 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.019169469946064055
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:14,413 INFO epoch # 1323 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.018946611548017245
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:14,434 INFO epoch # 1324 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.018895862995123025
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:14,455 INFO epoch # 1325 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01895044442062499
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:14,477 INFO epoch # 1326 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.018944123010442127
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:14,498 INFO epoch # 1327 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01889004682379891
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:14,519 INFO epoch # 1328 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.018926990363979712
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:14,540 INFO epoch # 1329 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.018998083214682993
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:14,561 INFO epoch # 1330 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.018934521023766138
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:14,562 INFO *** epoch 1330, rolling-avg-loss (window=10)= 0.019295734313709546
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:14,583 INFO epoch # 1331 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.018788176057569217
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:14,604 INFO epoch # 1332 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.018923439842183143
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:14,626 INFO epoch # 1333 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.018765545188216493
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:14,647 INFO epoch # 1334 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.018743531636573607
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:14,668 INFO epoch # 1335 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.018744992070423905
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:14,689 INFO epoch # 1336 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.018701164222875377
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:14,710 INFO epoch # 1337 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01868593525432516
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:14,732 INFO epoch # 1338 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0187125251541147
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:14,753 INFO epoch # 1339 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01878436362676439
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:14,774 INFO epoch # 1340 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.021387597582361195
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:14,775 INFO *** epoch 1340, rolling-avg-loss (window=10)= 0.01902372706354072
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:14,796 INFO epoch # 1341 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0187578054064943
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:14,817 INFO epoch # 1342 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.018663627706700936
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:14,838 INFO epoch # 1343 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.018859554478694918
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:14,859 INFO epoch # 1344 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.018649821209692163
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:14,881 INFO epoch # 1345 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.018603190175781492
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:14,902 INFO epoch # 1346 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.018639213623828255
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:14,923 INFO epoch # 1347 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.018583604040031787
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:14,944 INFO epoch # 1348 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.018578688410343602
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:14,966 INFO epoch # 1349 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.020165257032203954
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:14,987 INFO epoch # 1350 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.018711396038270323
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:14,987 INFO *** epoch 1350, rolling-avg-loss (window=10)= 0.018821215812204174
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:15,008 INFO epoch # 1351 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.018662939652131172
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:15,030 INFO epoch # 1352 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01856348747969605
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:15,051 INFO epoch # 1353 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01852367956234957
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:15,072 INFO epoch # 1354 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01854592710151337
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:15,093 INFO epoch # 1355 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.018523980696045328
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:15,115 INFO epoch # 1356 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.018727753595157992
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:15,136 INFO epoch # 1357 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.024245081789558753
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:15,157 INFO epoch # 1358 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01848462021735031
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:15,179 INFO epoch # 1359 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.018386760839348426
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:15,200 INFO epoch # 1360 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.018367739805398742
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:15,200 INFO *** epoch 1360, rolling-avg-loss (window=10)= 0.019103197073854973
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:15,222 INFO epoch # 1361 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01858908062786213
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:15,244 INFO epoch # 1362 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.018445392528519733
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:15,265 INFO epoch # 1363 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0183134693725151
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:15,286 INFO epoch # 1364 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.018321611714782193
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:15,307 INFO epoch # 1365 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.018359141828113934
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:15,328 INFO epoch # 1366 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01926265899601276
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:15,350 INFO epoch # 1367 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.018323005322599784
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:15,371 INFO epoch # 1368 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01824761827083421
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:15,393 INFO epoch # 1369 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0182231932067225
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:15,414 INFO epoch # 1370 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.018246492538310122
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:15,414 INFO *** epoch 1370, rolling-avg-loss (window=10)= 0.018433166440627247
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:15,435 INFO epoch # 1371 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01883789454586804
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:15,457 INFO epoch # 1372 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.018768467823974788
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:15,478 INFO epoch # 1373 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.018176039742684225
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:15,499 INFO epoch # 1374 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01815327170334058
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:15,520 INFO epoch # 1375 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.018207068984338548
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:15,541 INFO epoch # 1376 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.018212815029983176
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:15,562 INFO epoch # 1377 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.018125592439901084
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:15,584 INFO epoch # 1378 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02496795514889527
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:15,605 INFO epoch # 1379 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01815786264342023
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:15,626 INFO epoch # 1380 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.018114842674549436
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:15,627 INFO *** epoch 1380, rolling-avg-loss (window=10)= 0.018972181073695537
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:15,648 INFO epoch # 1381 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.018737969796347897
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:15,669 INFO epoch # 1382 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.018035849643638358
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:15,691 INFO epoch # 1383 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.018535096111008897
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:15,712 INFO epoch # 1384 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.018079676949128043
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:15,733 INFO epoch # 1385 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0181058269154164
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:15,755 INFO epoch # 1386 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.017966651920687582
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:15,777 INFO epoch # 1387 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.017967045398108894
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:15,798 INFO epoch # 1388 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01797974558212445
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:15,820 INFO epoch # 1389 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.017994718240515795
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:15,841 INFO epoch # 1390 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.017989523272262886
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:15,841 INFO *** epoch 1390, rolling-avg-loss (window=10)= 0.01813921038292392
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:15,862 INFO epoch # 1391 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.018027765785518568
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:15,884 INFO epoch # 1392 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0179652017322951
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:15,905 INFO epoch # 1393 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.017959786877327133
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:15,926 INFO epoch # 1394 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.017914298448886257
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:15,947 INFO epoch # 1395 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0182219823327614
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:15,968 INFO epoch # 1396 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.017853156685305294
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:15,990 INFO epoch # 1397 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.017841924469394144
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:16,011 INFO epoch # 1398 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01782289235779899
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:16,033 INFO epoch # 1399 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01856282140215626
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:16,054 INFO epoch # 1400 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.017911225360876415
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:16,054 INFO *** epoch 1400, rolling-avg-loss (window=10)= 0.018008105545231957
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:16,076 INFO epoch # 1401 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.017772402927221265
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:16,097 INFO epoch # 1402 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.017847831833933014
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:16,119 INFO epoch # 1403 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.017832718305726303
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:16,140 INFO epoch # 1404 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.017751936851709615
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:16,161 INFO epoch # 1405 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.017868851369712502
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:16,182 INFO epoch # 1406 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.017724022596667055
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:16,204 INFO epoch # 1407 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.023347740785538917
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:16,225 INFO epoch # 1408 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0178898878293694
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:16,247 INFO epoch # 1409 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.017709068280964857
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:16,268 INFO epoch # 1410 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01766760060127126
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:16,268 INFO *** epoch 1410, rolling-avg-loss (window=10)= 0.01834120613821142
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:16,290 INFO epoch # 1411 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01772014458401827
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:16,312 INFO epoch # 1412 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.017705378581013065
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:16,333 INFO epoch # 1413 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.020277635274396744
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:16,355 INFO epoch # 1414 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.017590494935575407
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:16,376 INFO epoch # 1415 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01759863416009466
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:16,397 INFO epoch # 1416 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0176052693350357
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:16,419 INFO epoch # 1417 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.017685847873508465
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:16,440 INFO epoch # 1418 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01766272070017294
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:16,461 INFO epoch # 1419 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.017538106250867713
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:16,482 INFO epoch # 1420 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01771636329795001
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:16,482 INFO *** epoch 1420, rolling-avg-loss (window=10)= 0.017910059499263296
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:16,503 INFO epoch # 1421 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.017695813734462718
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:16,525 INFO epoch # 1422 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01763639319324284
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:16,546 INFO epoch # 1423 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.017486052805907093
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:16,567 INFO epoch # 1424 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.017493620289315004
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:16,588 INFO epoch # 1425 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.017625747721467633
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:16,609 INFO epoch # 1426 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0174786525676609
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:16,630 INFO epoch # 1427 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.017428593651857227
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:16,652 INFO epoch # 1428 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.017398364632754237
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:16,674 INFO epoch # 1429 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.017602784515474923
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:16,695 INFO epoch # 1430 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.017841599030361976
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:16,695 INFO *** epoch 1430, rolling-avg-loss (window=10)= 0.017568762214250456
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:16,717 INFO epoch # 1431 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01743716072087409
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:16,739 INFO epoch # 1432 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02284466574928956
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:16,760 INFO epoch # 1433 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.017400252239895053
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:16,781 INFO epoch # 1434 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01740979339228943
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:16,802 INFO epoch # 1435 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.017327973615465453
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:16,823 INFO epoch # 1436 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01734993507125182
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:16,844 INFO epoch # 1437 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.017524223312648246
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:16,866 INFO epoch # 1438 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01766204428713536
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:16,887 INFO epoch # 1439 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.017348137058434077
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:16,908 INFO epoch # 1440 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01725743697170401
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:16,909 INFO *** epoch 1440, rolling-avg-loss (window=10)= 0.01795616224189871
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:16,930 INFO epoch # 1441 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.017833080448326655
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:16,951 INFO epoch # 1442 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01725147297111107
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:16,972 INFO epoch # 1443 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01719416728701617
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:16,996 INFO epoch # 1444 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.017223489958269056
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:17,018 INFO epoch # 1445 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.017213780363817932
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:17,039 INFO epoch # 1446 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.017230474386451533
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:17,061 INFO epoch # 1447 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.017151507521703024
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:17,082 INFO epoch # 1448 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.017261413766391343
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:17,103 INFO epoch # 1449 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01714183812146075
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:17,125 INFO epoch # 1450 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01711682944369386
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:17,125 INFO *** epoch 1450, rolling-avg-loss (window=10)= 0.01726180542682414
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:17,146 INFO epoch # 1451 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.017145380061265314
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:17,168 INFO epoch # 1452 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01712273040902801
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:17,189 INFO epoch # 1453 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01706752972495451
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:17,210 INFO epoch # 1454 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01785481194019667
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:17,231 INFO epoch # 1455 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.017056228429282783
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:17,253 INFO epoch # 1456 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.017097102929255925
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:17,274 INFO epoch # 1457 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.017350500595057383
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:17,295 INFO epoch # 1458 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.017151055617432576
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:17,317 INFO epoch # 1459 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.017266543010919122
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:17,338 INFO epoch # 1460 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.017036680852470454
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:17,338 INFO *** epoch 1460, rolling-avg-loss (window=10)= 0.017214856356986274
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:17,360 INFO epoch # 1461 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.019118819418508792
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:17,381 INFO epoch # 1462 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01703915244070231
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:17,402 INFO epoch # 1463 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.017909380698256427
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:17,423 INFO epoch # 1464 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.018584242992801592
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:17,444 INFO epoch # 1465 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.016917659970204113
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:17,466 INFO epoch # 1466 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.016958213651378173
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:17,487 INFO epoch # 1467 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.017011472686135676
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:17,509 INFO epoch # 1468 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.017077699932997348
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:17,530 INFO epoch # 1469 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01697225505267852
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:17,551 INFO epoch # 1470 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.016913502404349856
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:17,552 INFO *** epoch 1470, rolling-avg-loss (window=10)= 0.01745023992480128
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:17,573 INFO epoch # 1471 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.016842554772665608
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:17,594 INFO epoch # 1472 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01689388876548037
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:17,616 INFO epoch # 1473 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01686241572315339
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:17,637 INFO epoch # 1474 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01681630434541148
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:17,658 INFO epoch # 1475 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.016822318746562814
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:17,679 INFO epoch # 1476 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.016973649537249003
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:17,701 INFO epoch # 1477 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.018336566623474937
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:17,722 INFO epoch # 1478 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.016807676573080244
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:17,744 INFO epoch # 1479 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01677636947715655
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:17,765 INFO epoch # 1480 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01676236492494354
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:17,765 INFO *** epoch 1480, rolling-avg-loss (window=10)= 0.016989410948917795
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:17,786 INFO epoch # 1481 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.016805423389087082
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:17,808 INFO epoch # 1482 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.016755231888964772
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:17,829 INFO epoch # 1483 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.016709043526134337
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:17,850 INFO epoch # 1484 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01667850459489273
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:17,871 INFO epoch # 1485 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.018190170721936738
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:17,892 INFO epoch # 1486 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01685037936840672
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:17,914 INFO epoch # 1487 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01668071157473605
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:17,935 INFO epoch # 1488 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.017821303990785964
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:17,956 INFO epoch # 1489 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0219574188668048
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:17,978 INFO epoch # 1490 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.016650335663143778
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:17,978 INFO *** epoch 1490, rolling-avg-loss (window=10)= 0.017509852358489297
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:17,999 INFO epoch # 1491 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.016622858274786267
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:18,021 INFO epoch # 1492 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.016613869156572036
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:18,042 INFO epoch # 1493 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.016596562800259562
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:18,063 INFO epoch # 1494 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.016586556808761088
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:18,084 INFO epoch # 1495 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.017049188747478183
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:18,105 INFO epoch # 1496 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.016605477776465705
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:18,126 INFO epoch # 1497 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.016545347221835982
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:18,148 INFO epoch # 1498 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.017003602468321333
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:18,169 INFO epoch # 1499 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01655439142268733
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:18,191 INFO epoch # 1500 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.016525060433195904
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:18,191 INFO *** epoch 1500, rolling-avg-loss (window=10)= 0.01667029151103634
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:18,212 INFO epoch # 1501 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0166029423562577
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:18,236 INFO epoch # 1502 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.016631677382974885
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:18,257 INFO epoch # 1503 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01649757531049545
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:18,278 INFO epoch # 1504 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.016730252355046105
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:18,299 INFO epoch # 1505 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.016471925697260303
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:18,320 INFO epoch # 1506 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.016559498857532162
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:18,341 INFO epoch # 1507 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01647842014062917
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:18,363 INFO epoch # 1508 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.016545462338399375
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:18,384 INFO epoch # 1509 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.017371221911162138
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:18,405 INFO epoch # 1510 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01751737385711749
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:18,405 INFO *** epoch 1510, rolling-avg-loss (window=10)= 0.016740635020687476
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:18,427 INFO epoch # 1511 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0164539112993225
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:18,448 INFO epoch # 1512 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0163813100734842
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:18,469 INFO epoch # 1513 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01656181729049422
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:18,490 INFO epoch # 1514 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.016390556967962766
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:18,511 INFO epoch # 1515 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01680053220843547
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:18,532 INFO epoch # 1516 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01638451378676109
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:18,554 INFO epoch # 1517 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01639411265932722
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:18,575 INFO epoch # 1518 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0163010300238966
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:18,597 INFO epoch # 1519 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01649687138706213
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:18,618 INFO epoch # 1520 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.016899549395020586
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:18,618 INFO *** epoch 1520, rolling-avg-loss (window=10)= 0.016506420509176677
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:18,640 INFO epoch # 1521 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.017420530934032286
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:18,661 INFO epoch # 1522 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.016312159485096345
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:18,682 INFO epoch # 1523 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.016367620086384704
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:18,704 INFO epoch # 1524 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01628544633058482
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:18,725 INFO epoch # 1525 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.016237876214290736
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:18,746 INFO epoch # 1526 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.016344277588359546
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:18,768 INFO epoch # 1527 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.016204089610255323
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:18,789 INFO epoch # 1528 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01637971408854355
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:18,811 INFO epoch # 1529 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.016182202656636946
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:18,832 INFO epoch # 1530 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.016229214597842656
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:18,832 INFO *** epoch 1530, rolling-avg-loss (window=10)= 0.016396313159202692
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:18,853 INFO epoch # 1531 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.016246668383246288
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:18,875 INFO epoch # 1532 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01668507529393537
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:18,896 INFO epoch # 1533 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.016084029881312745
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:18,917 INFO epoch # 1534 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.016145369663718157
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:18,938 INFO epoch # 1535 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.016099640939501114
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:18,959 INFO epoch # 1536 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01611060888535576
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:18,981 INFO epoch # 1537 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01624379930217401
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:19,002 INFO epoch # 1538 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01855115619400749
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:19,023 INFO epoch # 1539 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.016254987564025214
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:19,044 INFO epoch # 1540 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.016051306811277755
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:19,045 INFO *** epoch 1540, rolling-avg-loss (window=10)= 0.01644726429185539
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:19,066 INFO epoch # 1541 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.016085285242297687
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:19,087 INFO epoch # 1542 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.017479530597483972
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:19,109 INFO epoch # 1543 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.017163808515761048
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:19,130 INFO epoch # 1544 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.015997764083294896
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:19,151 INFO epoch # 1545 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01600398149821558
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:19,173 INFO epoch # 1546 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.016020652597944718
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:19,194 INFO epoch # 1547 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01599744748818921
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:19,216 INFO epoch # 1548 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01598861206366564
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:19,237 INFO epoch # 1549 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.016381843201088486
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:19,259 INFO epoch # 1550 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.016043202278524404
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:19,259 INFO *** epoch 1550, rolling-avg-loss (window=10)= 0.016316212756646565
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:19,281 INFO epoch # 1551 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01595678096418851
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:19,303 INFO epoch # 1552 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.016113501995278057
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:19,324 INFO epoch # 1553 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.015997822159988573
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:19,346 INFO epoch # 1554 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.015900888643955113
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:19,367 INFO epoch # 1555 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.018779710509988945
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:19,388 INFO epoch # 1556 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01596484578840318
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:19,410 INFO epoch # 1557 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.017382841873768484
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:19,431 INFO epoch # 1558 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.015955192706314847
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:19,453 INFO epoch # 1559 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.015949075932439882
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:19,474 INFO epoch # 1560 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.015890796548774233
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:19,474 INFO *** epoch 1560, rolling-avg-loss (window=10)= 0.016389145712309983
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:19,496 INFO epoch # 1561 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.015834283705771668
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:19,517 INFO epoch # 1562 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.015799829445313662
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:19,539 INFO epoch # 1563 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01580695018856204
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:19,560 INFO epoch # 1564 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.015829193664103514
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:19,581 INFO epoch # 1565 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01602205751260044
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:19,602 INFO epoch # 1566 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.015745215325296158
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:19,624 INFO epoch # 1567 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.015773377068398986
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:19,645 INFO epoch # 1568 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.015989826715667732
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:19,667 INFO epoch # 1569 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01666356967689353
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:19,688 INFO epoch # 1570 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.015719015260401648
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:19,688 INFO *** epoch 1570, rolling-avg-loss (window=10)= 0.015918331856300937
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:19,710 INFO epoch # 1571 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01624411290686112
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:19,732 INFO epoch # 1572 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.015685956637753407
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:19,753 INFO epoch # 1573 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01569723111606436
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:19,775 INFO epoch # 1574 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01566063736572687
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:19,796 INFO epoch # 1575 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01678103577796719
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:19,817 INFO epoch # 1576 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.015663967860746197
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:19,839 INFO epoch # 1577 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.017140571362688206
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:19,860 INFO epoch # 1578 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.017113234556745738
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:19,881 INFO epoch # 1579 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.015658344298572047
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:19,903 INFO epoch # 1580 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.015842112283280585
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:19,903 INFO *** epoch 1580, rolling-avg-loss (window=10)= 0.01614872041664057
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:19,924 INFO epoch # 1581 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01577236081357114
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:19,946 INFO epoch # 1582 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01558988644683268
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:19,967 INFO epoch # 1583 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.015637580421753228
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:19,988 INFO epoch # 1584 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01555205297881912
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:20,009 INFO epoch # 1585 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.015566135487460997
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:20,030 INFO epoch # 1586 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01692265052406583
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:20,052 INFO epoch # 1587 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01556760764651699
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:20,073 INFO epoch # 1588 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01551600149832666
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:20,095 INFO epoch # 1589 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.015528451771388063
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:20,116 INFO epoch # 1590 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.015502545360504882
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:20,116 INFO *** epoch 1590, rolling-avg-loss (window=10)= 0.01571552729492396
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:20,138 INFO epoch # 1591 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.015496330182941165
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:20,160 INFO epoch # 1592 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.015553929268207867
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:20,181 INFO epoch # 1593 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01548532265223912
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:20,202 INFO epoch # 1594 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01727938594558509
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:20,223 INFO epoch # 1595 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.015532443150732433
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:20,245 INFO epoch # 1596 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.015635201867553405
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:20,266 INFO epoch # 1597 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.015451959097845247
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:20,288 INFO epoch # 1598 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.015407015485834563
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:20,309 INFO epoch # 1599 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01539758014405379
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:20,331 INFO epoch # 1600 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.015410352531034732
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:20,331 INFO *** epoch 1600, rolling-avg-loss (window=10)= 0.015664952032602743
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:20,352 INFO epoch # 1601 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.015420712006743997
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:20,374 INFO epoch # 1602 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01546932651399402
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:20,395 INFO epoch # 1603 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.015716934882220812
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:20,416 INFO epoch # 1604 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.015473109240701888
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:20,437 INFO epoch # 1605 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01591682812795625
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:20,458 INFO epoch # 1606 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01538906646965188
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:20,480 INFO epoch # 1607 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.015382060330011882
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:20,501 INFO epoch # 1608 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.015498652530368418
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:20,523 INFO epoch # 1609 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.015328670222515939
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:20,544 INFO epoch # 1610 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.015413724479003577
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:20,544 INFO *** epoch 1610, rolling-avg-loss (window=10)= 0.015500908480316867
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:20,566 INFO epoch # 1611 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.015438941041793441
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:20,587 INFO epoch # 1612 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01529749803012237
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:20,608 INFO epoch # 1613 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.015340100530011114
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:20,630 INFO epoch # 1614 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.015661670575354947
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:20,651 INFO epoch # 1615 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.015301448471291224
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:20,672 INFO epoch # 1616 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.015327144974435214
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:20,693 INFO epoch # 1617 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.015261019168974599
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:20,715 INFO epoch # 1618 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.015313943757064408
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:20,737 INFO epoch # 1619 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.015219520795653807
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:20,758 INFO epoch # 1620 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.015210385907266755
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:20,759 INFO *** epoch 1620, rolling-avg-loss (window=10)= 0.015337167325196788
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:20,780 INFO epoch # 1621 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0156632170874218
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:20,801 INFO epoch # 1622 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01518985858274391
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:20,822 INFO epoch # 1623 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01526937468588585
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:20,844 INFO epoch # 1624 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.015179903257376282
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:20,865 INFO epoch # 1625 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.015158730020630173
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:20,886 INFO epoch # 1626 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.015118629336939193
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:20,907 INFO epoch # 1627 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.015136487803829368
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:20,928 INFO epoch # 1628 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.015093717089257552
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:20,950 INFO epoch # 1629 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.015093090107257012
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:20,971 INFO epoch # 1630 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01509910620370647
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:20,971 INFO *** epoch 1630, rolling-avg-loss (window=10)= 0.015200211417504762
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:20,993 INFO epoch # 1631 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01650492550834315
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:21,014 INFO epoch # 1632 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.015144326622248627
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:21,036 INFO epoch # 1633 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01506922844419023
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:21,057 INFO epoch # 1634 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01505523618470761
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:21,078 INFO epoch # 1635 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.015035924478070228
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:21,099 INFO epoch # 1636 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.015026091696199728
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:21,121 INFO epoch # 1637 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01674787993033533
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:21,142 INFO epoch # 1638 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.015005257257143967
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:21,164 INFO epoch # 1639 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.015007650064944755
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:21,185 INFO epoch # 1640 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.014997235386545071
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:21,185 INFO *** epoch 1640, rolling-avg-loss (window=10)= 0.01535937555727287
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:21,207 INFO epoch # 1641 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.015472932638658676
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:21,229 INFO epoch # 1642 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01501241906589712
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:21,250 INFO epoch # 1643 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.015057631011586636
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:21,271 INFO epoch # 1644 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.014990283125371207
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:21,292 INFO epoch # 1645 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.014947537933039712
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:21,314 INFO epoch # 1646 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01600947469341918
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:21,335 INFO epoch # 1647 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01501483013635152
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:21,356 INFO epoch # 1648 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.014953409845475107
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:21,378 INFO epoch # 1649 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.014885696044075303
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:21,399 INFO epoch # 1650 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.014923750750313047
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:21,399 INFO *** epoch 1650, rolling-avg-loss (window=10)= 0.015126796524418751
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:21,420 INFO epoch # 1651 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.014914769380993675
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:21,442 INFO epoch # 1652 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.014885835200402653
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:21,463 INFO epoch # 1653 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.014863802874970133
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:21,484 INFO epoch # 1654 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.014857715788821224
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:21,505 INFO epoch # 1655 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.014850552208372392
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:21,527 INFO epoch # 1656 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.014858482645649929
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:21,548 INFO epoch # 1657 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.016176346609427128
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:21,570 INFO epoch # 1658 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.014816031491136528
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:21,591 INFO epoch # 1659 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.014967480405175593
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:21,613 INFO epoch # 1660 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.014832171149464557
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:21,613 INFO *** epoch 1660, rolling-avg-loss (window=10)= 0.015002318775441382
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:21,634 INFO epoch # 1661 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.015016394205304096
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:21,656 INFO epoch # 1662 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01482885995937977
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:21,677 INFO epoch # 1663 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.014769936380616855
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:21,698 INFO epoch # 1664 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.014791376510402188
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:21,719 INFO epoch # 1665 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.014751051628991263
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:21,740 INFO epoch # 1666 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.014794310405704891
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:21,761 INFO epoch # 1667 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.014734474800206954
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:21,783 INFO epoch # 1668 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.021409737375506666
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:21,804 INFO epoch # 1669 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01474275561486138
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:21,826 INFO epoch # 1670 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.014737856079591438
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:21,826 INFO *** epoch 1670, rolling-avg-loss (window=10)= 0.01545767529605655
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:21,847 INFO epoch # 1671 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.014699031267809914
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:21,868 INFO epoch # 1672 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.014706930742249824
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:21,890 INFO epoch # 1673 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.014667182229459286
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:21,911 INFO epoch # 1674 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.014641357296568458
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:21,932 INFO epoch # 1675 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.014686516718938947
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:21,953 INFO epoch # 1676 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.014648738018877339
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:21,974 INFO epoch # 1677 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.015160436181758996
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:21,996 INFO epoch # 1678 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.014619912592024775
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:22,017 INFO epoch # 1679 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.014884795564285014
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:22,038 INFO epoch # 1680 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.017666406940406887
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:22,038 INFO *** epoch 1680, rolling-avg-loss (window=10)= 0.015038130755237944
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:22,060 INFO epoch # 1681 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.014676476635941071
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:22,081 INFO epoch # 1682 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.014587623936677119
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:22,103 INFO epoch # 1683 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01457974476943491
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:22,124 INFO epoch # 1684 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.014615076572226826
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:22,145 INFO epoch # 1685 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01459145962871844
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:22,166 INFO epoch # 1686 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01456141688322532
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:22,187 INFO epoch # 1687 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01644928516179789
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:22,210 INFO epoch # 1688 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.014552336002452648
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:22,233 INFO epoch # 1689 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.014540222724463092
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:22,255 INFO epoch # 1690 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.014589951308153104
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:22,255 INFO *** epoch 1690, rolling-avg-loss (window=10)= 0.014774359362309041
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:22,277 INFO epoch # 1691 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01458294985422981
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:22,298 INFO epoch # 1692 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.015257591010595206
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:22,320 INFO epoch # 1693 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.014511807818053057
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:22,341 INFO epoch # 1694 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.014998506234405795
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:22,362 INFO epoch # 1695 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.014483145198028069
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:22,383 INFO epoch # 1696 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.017255899856536416
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:22,404 INFO epoch # 1697 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01444801512388949
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:22,426 INFO epoch # 1698 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01451668270965456
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:22,448 INFO epoch # 1699 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.014435864628467243
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:22,469 INFO epoch # 1700 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.014461892933468334
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:22,469 INFO *** epoch 1700, rolling-avg-loss (window=10)= 0.014895235536732799
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:22,491 INFO epoch # 1701 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.014620836300309747
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:22,513 INFO epoch # 1702 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.014403228557057446
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:22,534 INFO epoch # 1703 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.014769406596315093
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:22,556 INFO epoch # 1704 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.016683342488249764
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:22,577 INFO epoch # 1705 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.014544389821821824
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:22,598 INFO epoch # 1706 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01447756164270686
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:22,619 INFO epoch # 1707 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.014610102050937712
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:22,641 INFO epoch # 1708 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.014649467946583172
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:22,662 INFO epoch # 1709 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.014679355121188564
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:22,684 INFO epoch # 1710 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01432146120168909
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:22,684 INFO *** epoch 1710, rolling-avg-loss (window=10)= 0.014775915172685927
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:22,706 INFO epoch # 1711 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.014349814449815312
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:22,727 INFO epoch # 1712 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.014343933820782695
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:22,748 INFO epoch # 1713 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.014331156948173884
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:22,770 INFO epoch # 1714 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01436294609811739
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:22,791 INFO epoch # 1715 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.014274225912231486
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:22,812 INFO epoch # 1716 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.014357010019011796
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:22,833 INFO epoch # 1717 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.014480016281595454
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:22,855 INFO epoch # 1718 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.014234682841561153
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:22,876 INFO epoch # 1719 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.014659157099231379
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:22,897 INFO epoch # 1720 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.016174671516637318
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:22,897 INFO *** epoch 1720, rolling-avg-loss (window=10)= 0.014556761498715787
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:22,919 INFO epoch # 1721 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01478587578094448
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:22,940 INFO epoch # 1722 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.014482408838375704
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:22,961 INFO epoch # 1723 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.016072194903244963
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:22,982 INFO epoch # 1724 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.014218961096048588
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:23,003 INFO epoch # 1725 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.014194109451636905
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:23,024 INFO epoch # 1726 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.014198194327036617
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:23,046 INFO epoch # 1727 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.014159928146909806
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:23,067 INFO epoch # 1728 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.014929793538613012
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:23,088 INFO epoch # 1729 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.014188686280249385
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:23,110 INFO epoch # 1730 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.014144975757517386
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:23,110 INFO *** epoch 1730, rolling-avg-loss (window=10)= 0.014537512812057684
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:23,131 INFO epoch # 1731 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0141715648896934
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:23,153 INFO epoch # 1732 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01420205026079202
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:23,174 INFO epoch # 1733 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.016005133609723998
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:23,195 INFO epoch # 1734 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.014138606165943202
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:23,216 INFO epoch # 1735 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.014177164168359013
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:23,237 INFO epoch # 1736 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.014849279206828214
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:23,258 INFO epoch # 1737 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0141629746358376
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:23,280 INFO epoch # 1738 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.014102207594987703
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:23,301 INFO epoch # 1739 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.014135283105133567
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:23,322 INFO epoch # 1740 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.014108161773037864
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:23,322 INFO *** epoch 1740, rolling-avg-loss (window=10)= 0.014405242541033658
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:23,343 INFO epoch # 1741 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.014499288095976226
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:23,365 INFO epoch # 1742 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.014046336378669366
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:23,386 INFO epoch # 1743 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01440090826508822
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:23,407 INFO epoch # 1744 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.014055136565730209
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:23,428 INFO epoch # 1745 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.014034362149686785
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:23,449 INFO epoch # 1746 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01405280749531812
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:23,470 INFO epoch # 1747 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.014012509953317931
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:23,492 INFO epoch # 1748 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0139942696550861
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:23,513 INFO epoch # 1749 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.014024578595126513
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:23,535 INFO epoch # 1750 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.014337120082927868
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:23,535 INFO *** epoch 1750, rolling-avg-loss (window=10)= 0.014145731723692734
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:23,556 INFO epoch # 1751 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.014012357365572825
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:23,578 INFO epoch # 1752 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01399828875582898
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:23,599 INFO epoch # 1753 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.013968594907055376
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:23,620 INFO epoch # 1754 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.013924468163168058
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:23,641 INFO epoch # 1755 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.013945971921202727
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:23,662 INFO epoch # 1756 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.013910700270571397
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:23,684 INFO epoch # 1757 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.013919415516284062
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:23,705 INFO epoch # 1758 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.014726905032148352
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:23,727 INFO epoch # 1759 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01392385815961461
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:23,749 INFO epoch # 1760 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.013980617630295455
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:23,749 INFO *** epoch 1760, rolling-avg-loss (window=10)= 0.014031117772174185
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:23,770 INFO epoch # 1761 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.014093177880567964
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:23,792 INFO epoch # 1762 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.013852651689376216
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:23,814 INFO epoch # 1763 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.014119683524768334
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:23,835 INFO epoch # 1764 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.013919734992668964
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:23,856 INFO epoch # 1765 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.014088440850173356
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:23,877 INFO epoch # 1766 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01396590541844489
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:23,898 INFO epoch # 1767 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.013910506808315404
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:23,920 INFO epoch # 1768 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.013882419014407787
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:23,941 INFO epoch # 1769 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.013948296713351738
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:23,962 INFO epoch # 1770 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.013850766725227004
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:23,962 INFO *** epoch 1770, rolling-avg-loss (window=10)= 0.013963158361730166
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:23,984 INFO epoch # 1771 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.013842176191246836
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:24,005 INFO epoch # 1772 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.013771153518973733
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:24,027 INFO epoch # 1773 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.013789027249003993
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:24,048 INFO epoch # 1774 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01829725399511517
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:24,069 INFO epoch # 1775 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.013788987649604678
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:24,090 INFO epoch # 1776 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.013836038157023722
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:24,111 INFO epoch # 1777 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.013783316440822091
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:24,132 INFO epoch # 1778 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.013777855321677634
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:24,154 INFO epoch # 1779 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.013766272670181934
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:24,175 INFO epoch # 1780 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.014401506123249419
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:24,175 INFO *** epoch 1780, rolling-avg-loss (window=10)= 0.014305358731689921
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:24,197 INFO epoch # 1781 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.014034556741535198
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:24,218 INFO epoch # 1782 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.013674146350240335
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:24,240 INFO epoch # 1783 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01374527444204432
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:24,261 INFO epoch # 1784 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.013705728997592814
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:24,282 INFO epoch # 1785 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.013721479441301199
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:24,303 INFO epoch # 1786 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.013647197863974725
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:24,325 INFO epoch # 1787 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.013737864006543532
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:24,346 INFO epoch # 1788 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.013660295437148307
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:24,367 INFO epoch # 1789 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01367226261572796
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:24,389 INFO epoch # 1790 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.013642669957334874
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:24,389 INFO *** epoch 1790, rolling-avg-loss (window=10)= 0.013724147585344326
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:24,411 INFO epoch # 1791 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.013713392138015479
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:24,432 INFO epoch # 1792 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.013696002890355885
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:24,453 INFO epoch # 1793 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.013604856396341347
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:24,474 INFO epoch # 1794 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.013673342873516958
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:24,495 INFO epoch # 1795 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.013669475240021711
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:24,516 INFO epoch # 1796 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.013722314753977116
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:24,538 INFO epoch # 1797 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01529461447353242
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:24,559 INFO epoch # 1798 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.013803902962536085
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:24,580 INFO epoch # 1799 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.013628814711410087
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:24,601 INFO epoch # 1800 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01357454624667298
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:24,601 INFO *** epoch 1800, rolling-avg-loss (window=10)= 0.013838126268638007
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:24,623 INFO epoch # 1801 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.013575716573541285
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:24,645 INFO epoch # 1802 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01361608076331322
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:24,666 INFO epoch # 1803 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01353599345384282
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:24,687 INFO epoch # 1804 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.013534445482946467
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:24,708 INFO epoch # 1805 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0140002824482508
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:24,730 INFO epoch # 1806 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01351751497713849
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:24,751 INFO epoch # 1807 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.013516827864805236
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:24,772 INFO epoch # 1808 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.013473206188791664
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:24,794 INFO epoch # 1809 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01552330933554913
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:24,815 INFO epoch # 1810 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.013709529066545656
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:24,815 INFO *** epoch 1810, rolling-avg-loss (window=10)= 0.013800290615472477
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:24,837 INFO epoch # 1811 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.013497497639036737
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:24,858 INFO epoch # 1812 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.015661066616303287
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:24,879 INFO epoch # 1813 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.013550768006098224
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:24,900 INFO epoch # 1814 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0134873374045128
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:24,921 INFO epoch # 1815 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.013438957575999666
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:24,943 INFO epoch # 1816 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.013498455817170907
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:24,964 INFO epoch # 1817 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.013406627089352696
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:24,985 INFO epoch # 1818 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.013408972103206906
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:25,007 INFO epoch # 1819 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.013401154639723245
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:25,028 INFO epoch # 1820 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.013403873757852125
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:25,028 INFO *** epoch 1820, rolling-avg-loss (window=10)= 0.01367547106492566
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:25,049 INFO epoch # 1821 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.013397343609540258
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:25,071 INFO epoch # 1822 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.013400798587099416
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:25,092 INFO epoch # 1823 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.013367328527237987
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:25,113 INFO epoch # 1824 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.013656532180903014
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:25,134 INFO epoch # 1825 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01360695270341239
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:25,155 INFO epoch # 1826 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.013331874477444217
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:25,177 INFO epoch # 1827 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01949566935218172
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:25,198 INFO epoch # 1828 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.013335152246327198
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:25,220 INFO epoch # 1829 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.014903271505318116
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:25,242 INFO epoch # 1830 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.013517895436962135
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:25,242 INFO *** epoch 1830, rolling-avg-loss (window=10)= 0.014201281862642644
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:25,263 INFO epoch # 1831 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.013302879877301166
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:25,284 INFO epoch # 1832 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.013358214815525571
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:25,306 INFO epoch # 1833 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.013296755401825067
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:25,327 INFO epoch # 1834 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01325920463023067
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:25,348 INFO epoch # 1835 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.013316628734173719
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:25,369 INFO epoch # 1836 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.013273996661155252
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:25,390 INFO epoch # 1837 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.013271405412524473
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:25,412 INFO epoch # 1838 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.013246033935502055
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:25,433 INFO epoch # 1839 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.013251791107904864
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:25,455 INFO epoch # 1840 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.013299641042976873
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:25,455 INFO *** epoch 1840, rolling-avg-loss (window=10)= 0.01328765516191197
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:25,476 INFO epoch # 1841 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01328028154966887
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:25,498 INFO epoch # 1842 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.013309937894518953
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:25,519 INFO epoch # 1843 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.013232520628662314
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:25,540 INFO epoch # 1844 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01321277261195064
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:25,562 INFO epoch # 1845 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.013263099164760206
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:25,583 INFO epoch # 1846 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.013212648667831672
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:25,604 INFO epoch # 1847 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.013171170312489267
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:25,626 INFO epoch # 1848 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.013172376209695358
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:25,648 INFO epoch # 1849 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.013167633609555196
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:25,669 INFO epoch # 1850 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.013203396785684163
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:25,669 INFO *** epoch 1850, rolling-avg-loss (window=10)= 0.013222583743481665
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:25,691 INFO epoch # 1851 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.013193747552577406
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:25,713 INFO epoch # 1852 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.013188789580453886
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:25,734 INFO epoch # 1853 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.013142951844201889
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:25,755 INFO epoch # 1854 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.013136404999386286
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:25,776 INFO epoch # 1855 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01310166247367306
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:25,797 INFO epoch # 1856 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01315342215821147
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:25,819 INFO epoch # 1857 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.013153226986105437
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:25,840 INFO epoch # 1858 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01563536558751366
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:25,861 INFO epoch # 1859 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.013744393734668847
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:25,882 INFO epoch # 1860 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.013283930431498447
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:25,883 INFO *** epoch 1860, rolling-avg-loss (window=10)= 0.01347338953482904
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:25,904 INFO epoch # 1861 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01306901123462012
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:25,925 INFO epoch # 1862 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.013098191786411917
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:25,947 INFO epoch # 1863 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.013127273712598253
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:25,968 INFO epoch # 1864 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.013070253677142318
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:25,989 INFO epoch # 1865 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.013021863635003683
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:26,010 INFO epoch # 1866 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.013077815543510951
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:26,032 INFO epoch # 1867 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.013048822838754859
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:26,053 INFO epoch # 1868 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.013138554932083935
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:26,075 INFO epoch # 1869 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.013075865110295126
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:26,096 INFO epoch # 1870 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.012974026387382764
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:26,096 INFO *** epoch 1870, rolling-avg-loss (window=10)= 0.013070167885780392
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:26,118 INFO epoch # 1871 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01298146389399335
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:26,139 INFO epoch # 1872 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01301544789748732
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:26,161 INFO epoch # 1873 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.012967690665391274
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:26,182 INFO epoch # 1874 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.012983045635337476
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:26,203 INFO epoch # 1875 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01712564262925298
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:26,224 INFO epoch # 1876 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.013442513009067625
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:26,246 INFO epoch # 1877 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0130285707564326
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:26,267 INFO epoch # 1878 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.013940191001893254
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:26,288 INFO epoch # 1879 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.013094824887957657
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:26,310 INFO epoch # 1880 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.012939377764269011
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:26,310 INFO *** epoch 1880, rolling-avg-loss (window=10)= 0.013551876814108254
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:26,332 INFO epoch # 1881 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.012905652338304208
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:26,353 INFO epoch # 1882 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.013070116630842676
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:26,374 INFO epoch # 1883 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.013007602294237586
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:26,395 INFO epoch # 1884 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.013510687091184082
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:26,416 INFO epoch # 1885 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.012908481490740087
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:26,437 INFO epoch # 1886 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.012925666098453803
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:26,459 INFO epoch # 1887 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.012902444541396108
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:26,481 INFO epoch # 1888 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01291660989227239
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:26,502 INFO epoch # 1889 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.012864062806329457
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:26,523 INFO epoch # 1890 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.012875025317043765
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:26,523 INFO *** epoch 1890, rolling-avg-loss (window=10)= 0.012988634850080416
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:26,545 INFO epoch # 1891 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.012843226350014447
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:26,566 INFO epoch # 1892 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.015192175083939219
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:26,588 INFO epoch # 1893 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.012888943845609901
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:26,609 INFO epoch # 1894 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.013038077027886175
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:26,630 INFO epoch # 1895 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01283231897832593
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:26,651 INFO epoch # 1896 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.012808710147510283
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:26,673 INFO epoch # 1897 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01284738349932013
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:26,694 INFO epoch # 1898 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.012904504736070521
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:26,716 INFO epoch # 1899 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.012880212514573941
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:26,737 INFO epoch # 1900 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.012823927565477788
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:26,737 INFO *** epoch 1900, rolling-avg-loss (window=10)= 0.013105947974872833
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:26,759 INFO epoch # 1901 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01286124871330685
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:26,780 INFO epoch # 1902 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.012750210413287277
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:26,801 INFO epoch # 1903 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.012777216539689107
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:26,823 INFO epoch # 1904 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.012739602227156865
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:26,844 INFO epoch # 1905 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.012837053236580687
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:26,865 INFO epoch # 1906 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.012852517204009928
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:26,886 INFO epoch # 1907 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.013726993751333794
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:26,908 INFO epoch # 1908 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.012743146871798672
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:26,929 INFO epoch # 1909 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01486002388628549
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:26,951 INFO epoch # 1910 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.013152727151464205
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:26,951 INFO *** epoch 1910, rolling-avg-loss (window=10)= 0.013130073999491287
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:26,972 INFO epoch # 1911 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.012775113827956375
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:26,994 INFO epoch # 1912 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.012711846677120775
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:27,016 INFO epoch # 1913 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.012760420670019812
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:27,037 INFO epoch # 1914 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01274963054311229
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:27,058 INFO epoch # 1915 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.012772390837199055
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:27,079 INFO epoch # 1916 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01266257762654277
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:27,100 INFO epoch # 1917 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.012646750543353846
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:27,122 INFO epoch # 1918 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01267268591982429
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:27,143 INFO epoch # 1919 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.012641429570066975
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:27,165 INFO epoch # 1920 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.012621236350241816
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:27,165 INFO *** epoch 1920, rolling-avg-loss (window=10)= 0.012701408256543801
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:27,187 INFO epoch # 1921 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.012626050560356816
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:27,208 INFO epoch # 1922 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.012626492854906246
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:27,229 INFO epoch # 1923 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.012667346585658379
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:27,251 INFO epoch # 1924 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01260523513701628
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:27,272 INFO epoch # 1925 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.012624198341654846
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:27,293 INFO epoch # 1926 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.012599071651493432
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:27,314 INFO epoch # 1927 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.012646230956306681
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:27,336 INFO epoch # 1928 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.012736064025375526
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:27,357 INFO epoch # 1929 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01260488912157598
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:27,379 INFO epoch # 1930 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.012586640681547578
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:27,379 INFO *** epoch 1930, rolling-avg-loss (window=10)= 0.012632221991589176
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:27,400 INFO epoch # 1931 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.014430424071179004
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:27,422 INFO epoch # 1932 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.012546748881504755
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:27,443 INFO epoch # 1933 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.012608712229848607
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:27,464 INFO epoch # 1934 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.012564146956719924
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:27,485 INFO epoch # 1935 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.012537077964225318
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:27,506 INFO epoch # 1936 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.012545866680738982
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:27,527 INFO epoch # 1937 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.012543248683869024
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:27,549 INFO epoch # 1938 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.012549612350994721
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:27,570 INFO epoch # 1939 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.012852021012804471
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:27,592 INFO epoch # 1940 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.012487157968280371
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:27,592 INFO *** epoch 1940, rolling-avg-loss (window=10)= 0.012766501680016518
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:27,614 INFO epoch # 1941 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.012855197142926045
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:27,635 INFO epoch # 1942 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.012712995299807517
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:27,656 INFO epoch # 1943 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.012496910896516056
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:27,677 INFO epoch # 1944 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.014237983428756706
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:27,699 INFO epoch # 1945 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.012528542014479171
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:27,720 INFO epoch # 1946 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.012507503197412007
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:27,741 INFO epoch # 1947 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.012540725008875597
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:27,763 INFO epoch # 1948 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.012441100108844694
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:27,784 INFO epoch # 1949 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01311736792922602
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:27,806 INFO epoch # 1950 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.012408147180394735
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:27,806 INFO *** epoch 1950, rolling-avg-loss (window=10)= 0.012784647220723856
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:27,827 INFO epoch # 1951 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01637600602407474
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:27,849 INFO epoch # 1952 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.012451500246243086
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:27,870 INFO epoch # 1953 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.012697377700533252
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:27,891 INFO epoch # 1954 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.012396288399031619
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:27,912 INFO epoch # 1955 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01244746935844887
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:27,933 INFO epoch # 1956 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0123833665093116
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:27,955 INFO epoch # 1957 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.012406419731632923
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:27,976 INFO epoch # 1958 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.012352023613857455
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:27,998 INFO epoch # 1959 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.012391390671837144
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:28,019 INFO epoch # 1960 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.012374788231682032
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:28,020 INFO *** epoch 1960, rolling-avg-loss (window=10)= 0.012827663048665273
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:28,041 INFO epoch # 1961 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.012449239464331185
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:28,063 INFO epoch # 1962 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01361977648048196
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:28,084 INFO epoch # 1963 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01245797093724832
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:28,105 INFO epoch # 1964 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.012370024545816705
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:28,126 INFO epoch # 1965 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.012456059417672805
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:28,147 INFO epoch # 1966 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.012329269000474596
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:28,169 INFO epoch # 1967 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.012326628420851193
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:28,190 INFO epoch # 1968 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.012407522954163142
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:28,212 INFO epoch # 1969 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.012265291376934329
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:28,235 INFO epoch # 1970 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.012289304855585215
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:28,235 INFO *** epoch 1970, rolling-avg-loss (window=10)= 0.012497108745355945
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:28,257 INFO epoch # 1971 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.012308742498134961
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:28,278 INFO epoch # 1972 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.013259292511065723
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:28,300 INFO epoch # 1973 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.012307806846365565
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:28,321 INFO epoch # 1974 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01230312777988729
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:28,343 INFO epoch # 1975 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.012256872785656014
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:28,364 INFO epoch # 1976 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.012263756769243628
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:28,386 INFO epoch # 1977 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.012483835176681168
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:28,407 INFO epoch # 1978 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.012224300186062464
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:28,428 INFO epoch # 1979 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01225414099462796
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:28,450 INFO epoch # 1980 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.012297952569497284
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:28,450 INFO *** epoch 1980, rolling-avg-loss (window=10)= 0.012395982811722207
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:28,471 INFO epoch # 1981 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.012531965474408935
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:28,492 INFO epoch # 1982 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.012225354748807149
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:28,514 INFO epoch # 1983 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.012227049424836878
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:28,535 INFO epoch # 1984 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01217924346565269
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:28,556 INFO epoch # 1985 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.012201831177662825
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:28,577 INFO epoch # 1986 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.012164157352344773
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:28,599 INFO epoch # 1987 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.012265715133253252
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:28,620 INFO epoch # 1988 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.012155178323155269
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:28,641 INFO epoch # 1989 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.016030305707317893
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:28,663 INFO epoch # 1990 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.012147600422395044
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:28,663 INFO *** epoch 1990, rolling-avg-loss (window=10)= 0.01261284012298347
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:28,684 INFO epoch # 1991 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.012150258569818106
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:28,706 INFO epoch # 1992 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.012141774917836301
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:28,727 INFO epoch # 1993 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.017918088760779938
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:28,748 INFO epoch # 1994 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.012159961384895723
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:28,769 INFO epoch # 1995 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01360383227802231
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:28,791 INFO epoch # 1996 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.012212985831865808
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:28,812 INFO epoch # 1997 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01208953306559124
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:28,833 INFO epoch # 1998 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.012156291228166083
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:28,855 INFO epoch # 1999 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01212789836426964
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:28,876 INFO epoch # 2000 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01209228146035457
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:28,876 INFO *** epoch 2000, rolling-avg-loss (window=10)= 0.012865290586159973
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:28,898 INFO epoch # 2001 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.012090211621398339
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:28,919 INFO epoch # 2002 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.012187291584268678
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:28,940 INFO epoch # 2003 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01205221524105582
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:28,962 INFO epoch # 2004 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01205074865356437
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:28,983 INFO epoch # 2005 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.012034988475534192
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:29,004 INFO epoch # 2006 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.013831889529683394
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:29,025 INFO epoch # 2007 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.012107904560252791
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:29,047 INFO epoch # 2008 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.012412374380801339
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:29,068 INFO epoch # 2009 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.012010672864562366
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:29,089 INFO epoch # 2010 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01402780405987869
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:29,089 INFO *** epoch 2010, rolling-avg-loss (window=10)= 0.012480610097099998
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:29,111 INFO epoch # 2011 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.012028292843751842
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:29,132 INFO epoch # 2012 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.012067829880834324
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:29,153 INFO epoch # 2013 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01211101163062267
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:29,175 INFO epoch # 2014 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.012074367408786202
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:29,196 INFO epoch # 2015 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.012115672088839347
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:29,217 INFO epoch # 2016 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.012009460635454161
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:29,239 INFO epoch # 2017 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.012030588954075938
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:29,260 INFO epoch # 2018 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.012016110624244902
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:29,282 INFO epoch # 2019 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01207452099697548
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:29,303 INFO epoch # 2020 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.011990920869720867
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:29,303 INFO *** epoch 2020, rolling-avg-loss (window=10)= 0.012051877593330573
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:29,325 INFO epoch # 2021 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.012013787581963697
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:29,346 INFO epoch # 2022 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01194628985831514
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:29,367 INFO epoch # 2023 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01225970740961202
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:29,388 INFO epoch # 2024 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.012006673456198769
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:29,410 INFO epoch # 2025 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.011930311338801403
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:29,431 INFO epoch # 2026 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.012897870416054502
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:29,452 INFO epoch # 2027 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.012124470267735887
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:29,473 INFO epoch # 2028 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.011933328953091404
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:29,495 INFO epoch # 2029 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.011898282646143343
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:29,516 INFO epoch # 2030 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.011890195337400655
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:29,517 INFO *** epoch 2030, rolling-avg-loss (window=10)= 0.012090091726531683
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:29,538 INFO epoch # 2031 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01192979332699906
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:29,560 INFO epoch # 2032 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.011876477172336308
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:29,581 INFO epoch # 2033 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.012077029234205838
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:29,602 INFO epoch # 2034 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01186187725761556
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:29,623 INFO epoch # 2035 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.011856072185764788
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:29,645 INFO epoch # 2036 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.013885105505323736
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:29,666 INFO epoch # 2037 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01222253270134388
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:29,687 INFO epoch # 2038 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.011837860805826494
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:29,708 INFO epoch # 2039 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.012004394990071887
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:29,730 INFO epoch # 2040 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.011821081227026298
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:29,730 INFO *** epoch 2040, rolling-avg-loss (window=10)= 0.012137222440651385
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:29,752 INFO epoch # 2041 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.011840337381727295
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:29,773 INFO epoch # 2042 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.011999021557130618
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:29,795 INFO epoch # 2043 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.011852339401229983
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:29,816 INFO epoch # 2044 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01185664728836855
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:29,837 INFO epoch # 2045 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.012009545011096634
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:29,858 INFO epoch # 2046 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.011799033141869586
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:29,879 INFO epoch # 2047 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.011809604839072563
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:29,901 INFO epoch # 2048 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.011838059621368302
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:29,922 INFO epoch # 2049 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.011966245776420692
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:29,944 INFO epoch # 2050 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.015730732411611825
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:29,944 INFO *** epoch 2050, rolling-avg-loss (window=10)= 0.012270156642989605
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:29,965 INFO epoch # 2051 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.011754167948311078
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:29,987 INFO epoch # 2052 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.011815141140687047
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:30,009 INFO epoch # 2053 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.011741844657080946
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:30,030 INFO epoch # 2054 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.011729823761925218
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:30,051 INFO epoch # 2055 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.011720840380803565
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:30,072 INFO epoch # 2056 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0117897489835741
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:30,094 INFO epoch # 2057 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.011712347597494954
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:30,115 INFO epoch # 2058 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.012120365012378898
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:30,136 INFO epoch # 2059 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.011766521754907444
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:30,158 INFO epoch # 2060 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.011715701835782966
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:30,158 INFO *** epoch 2060, rolling-avg-loss (window=10)= 0.011786650307294621
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:30,179 INFO epoch # 2061 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.011694511835230514
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:30,201 INFO epoch # 2062 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01166875218405039
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:30,222 INFO epoch # 2063 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.011685990459227469
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:30,244 INFO epoch # 2064 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.011671061189190368
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:30,265 INFO epoch # 2065 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01166759635816561
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:30,286 INFO epoch # 2066 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.011743090370146092
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:30,307 INFO epoch # 2067 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.011981827330600936
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:30,329 INFO epoch # 2068 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.011834059638204053
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:30,350 INFO epoch # 2069 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.011644173186141415
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:30,372 INFO epoch # 2070 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.011632603596808622
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:30,372 INFO *** epoch 2070, rolling-avg-loss (window=10)= 0.011722366614776547
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:30,393 INFO epoch # 2071 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.011648676780168898
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:30,415 INFO epoch # 2072 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.011597560751397396
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:30,436 INFO epoch # 2073 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.011670690368191572
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:30,457 INFO epoch # 2074 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.011639010477665579
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:30,478 INFO epoch # 2075 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01159845121401304
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:30,499 INFO epoch # 2076 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.011653416357148672
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:30,521 INFO epoch # 2077 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0115957508169231
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:30,542 INFO epoch # 2078 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.011636911360255908
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:30,564 INFO epoch # 2079 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.011572863604669692
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:30,585 INFO epoch # 2080 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.011578396439290373
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:30,585 INFO *** epoch 2080, rolling-avg-loss (window=10)= 0.011619172816972423
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:30,606 INFO epoch # 2081 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.012983252516278299
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:30,629 INFO epoch # 2082 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.011579042242374271
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:30,650 INFO epoch # 2083 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.011620427780144382
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:30,672 INFO epoch # 2084 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.011621686087892158
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:30,693 INFO epoch # 2085 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.011629457210801775
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:30,714 INFO epoch # 2086 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.011532167578479857
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:30,736 INFO epoch # 2087 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.011639832433502306
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:30,757 INFO epoch # 2088 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.011583545594476163
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:30,779 INFO epoch # 2089 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.011515511576362769
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:30,800 INFO epoch # 2090 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01155961467520683
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:30,800 INFO *** epoch 2090, rolling-avg-loss (window=10)= 0.011726453769551882
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:30,821 INFO epoch # 2091 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.011499949408971588
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:30,843 INFO epoch # 2092 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.011498890446091536
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:30,864 INFO epoch # 2093 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.011518489940499421
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:30,885 INFO epoch # 2094 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.011753852137189824
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:30,906 INFO epoch # 2095 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.012513172117905924
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:30,927 INFO epoch # 2096 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.011833720414870186
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:30,949 INFO epoch # 2097 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.011518836006871425
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:30,970 INFO epoch # 2098 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.012581224837049376
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:30,991 INFO epoch # 2099 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01149130187332048
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:31,013 INFO epoch # 2100 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.011835544028144795
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:31,013 INFO *** epoch 2100, rolling-avg-loss (window=10)= 0.011804498121091456
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:31,035 INFO epoch # 2101 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01149106845332426
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:31,056 INFO epoch # 2102 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.011454269082605606
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:31,078 INFO epoch # 2103 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.011434446662860864
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:31,099 INFO epoch # 2104 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.011468968295957893
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:31,120 INFO epoch # 2105 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.011432719151343917
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:31,142 INFO epoch # 2106 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.012330098004895262
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:31,163 INFO epoch # 2107 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.011435974471169175
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:31,185 INFO epoch # 2108 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.011469197786937002
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:31,206 INFO epoch # 2109 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.011399435781640932
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:31,228 INFO epoch # 2110 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.011416086919780355
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:31,228 INFO *** epoch 2110, rolling-avg-loss (window=10)= 0.011533226461051527
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:31,250 INFO epoch # 2111 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.011405975306843175
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:31,271 INFO epoch # 2112 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.011384518918930553
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:31,292 INFO epoch # 2113 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.012341899098828435
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:31,313 INFO epoch # 2114 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.011385977846657624
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:31,334 INFO epoch # 2115 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.011576648632399156
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:31,356 INFO epoch # 2116 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.013738952427956974
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:31,378 INFO epoch # 2117 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01144580245090765
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:31,399 INFO epoch # 2118 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01134221418760717
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:31,421 INFO epoch # 2119 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01143262725599925
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:31,442 INFO epoch # 2120 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.011483024440167355
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:31,442 INFO *** epoch 2120, rolling-avg-loss (window=10)= 0.011753764056629734
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:31,464 INFO epoch # 2121 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01144420128002821
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:31,485 INFO epoch # 2122 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.011347490344633115
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:31,507 INFO epoch # 2123 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.011365139889676357
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:31,528 INFO epoch # 2124 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.011360956021235324
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:31,549 INFO epoch # 2125 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.011569849848456215
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:31,570 INFO epoch # 2126 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.011300415219011484
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:31,592 INFO epoch # 2127 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.011297906199615682
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:31,613 INFO epoch # 2128 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.011368124687578529
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:31,634 INFO epoch # 2129 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.011262573969361256
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:31,656 INFO epoch # 2130 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.011686811387335183
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:31,656 INFO *** epoch 2130, rolling-avg-loss (window=10)= 0.011400346884693135
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:31,677 INFO epoch # 2131 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01134845604246948
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:31,699 INFO epoch # 2132 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.011309405672363937
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:31,720 INFO epoch # 2133 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.011261026742431568
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:31,741 INFO epoch # 2134 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.011551352879905608
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:31,762 INFO epoch # 2135 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01218756937305443
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:31,783 INFO epoch # 2136 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.011273025935224723
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:31,805 INFO epoch # 2137 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01132636430702405
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:31,826 INFO epoch # 2138 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.011254617504164344
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:31,847 INFO epoch # 2139 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.011238293882342987
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:31,869 INFO epoch # 2140 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.011275314049271401
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:31,869 INFO *** epoch 2140, rolling-avg-loss (window=10)= 0.011402542638825253
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:31,890 INFO epoch # 2141 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.011391667434509145
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:31,912 INFO epoch # 2142 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.011213291936655878
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:31,933 INFO epoch # 2143 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.011217110200959723
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:31,955 INFO epoch # 2144 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.011279851525614504
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:31,976 INFO epoch # 2145 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.011192338566615945
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:31,997 INFO epoch # 2146 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01122644848874188
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:32,018 INFO epoch # 2147 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.011188937476617866
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:32,039 INFO epoch # 2148 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.011222994395211572
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:32,061 INFO epoch # 2149 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01120201793673914
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:32,082 INFO epoch # 2150 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.011191310732101556
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:32,082 INFO *** epoch 2150, rolling-avg-loss (window=10)= 0.01123259686937672
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:32,104 INFO epoch # 2151 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.011304801222649985
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:32,125 INFO epoch # 2152 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.011213307247089688
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:32,146 INFO epoch # 2153 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.011307087082968792
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:32,168 INFO epoch # 2154 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0111401080412179
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:32,189 INFO epoch # 2155 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.011119385322672315
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:32,210 INFO epoch # 2156 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01125121655422845
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:32,232 INFO epoch # 2157 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.011248514721955871
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:32,253 INFO epoch # 2158 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01294598049207707
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:32,275 INFO epoch # 2159 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.011294586714939214
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:32,296 INFO epoch # 2160 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.011244744218856795
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:32,296 INFO *** epoch 2160, rolling-avg-loss (window=10)= 0.011406973161865609
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:32,318 INFO epoch # 2161 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.011332645968650468
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:32,340 INFO epoch # 2162 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.011130453716759803
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:32,361 INFO epoch # 2163 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.012525059493782464
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:32,382 INFO epoch # 2164 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.011135218977869954
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:32,403 INFO epoch # 2165 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01165134694383596
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:32,425 INFO epoch # 2166 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.011086753629570012
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:32,447 INFO epoch # 2167 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.011057436046030489
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:32,468 INFO epoch # 2168 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.011078016028477577
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:32,490 INFO epoch # 2169 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.011065993077863823
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:32,511 INFO epoch # 2170 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.011086431441071909
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:32,511 INFO *** epoch 2170, rolling-avg-loss (window=10)= 0.011314935532391246
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:32,533 INFO epoch # 2171 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.011088795781688532
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:32,554 INFO epoch # 2172 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01127466069010552
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:32,576 INFO epoch # 2173 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.011035246954634204
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:32,597 INFO epoch # 2174 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.011109107048469014
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:32,618 INFO epoch # 2175 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.011067707957408857
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:32,640 INFO epoch # 2176 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.011933546516956994
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:32,662 INFO epoch # 2177 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.011095422487414908
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:32,684 INFO epoch # 2178 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.011032417161914054
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:32,705 INFO epoch # 2179 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.011060399319831049
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:32,728 INFO epoch # 2180 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.011031134250515606
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:32,728 INFO *** epoch 2180, rolling-avg-loss (window=10)= 0.011172843816893874
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:32,750 INFO epoch # 2181 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010978977585182292
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:32,771 INFO epoch # 2182 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.011071035129134543
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:32,792 INFO epoch # 2183 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.011009131812897976
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:32,813 INFO epoch # 2184 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.011593548671953613
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:32,834 INFO epoch # 2185 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01111875192327716
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:32,855 INFO epoch # 2186 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01099801907184883
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:32,876 INFO epoch # 2187 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.011737473036191659
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:32,898 INFO epoch # 2188 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.011124520044177189
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:32,919 INFO epoch # 2189 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010973105971061159
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:32,940 INFO epoch # 2190 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010937642305179907
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:32,940 INFO *** epoch 2190, rolling-avg-loss (window=10)= 0.011154220555090433
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:32,962 INFO epoch # 2191 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010958436363580404
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:32,983 INFO epoch # 2192 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01096198967206874
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:33,005 INFO epoch # 2193 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.011073266103267088
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:33,026 INFO epoch # 2194 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010927202090897481
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:33,047 INFO epoch # 2195 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010981898518366506
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:33,068 INFO epoch # 2196 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.012546029422082938
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:33,089 INFO epoch # 2197 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010940139663944137
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:33,111 INFO epoch # 2198 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.011018942379450891
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:33,132 INFO epoch # 2199 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010911299532381236
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:33,154 INFO epoch # 2200 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010911936584307114
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:33,154 INFO *** epoch 2200, rolling-avg-loss (window=10)= 0.011123114033034653
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:33,175 INFO epoch # 2201 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010977728124998976
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:33,196 INFO epoch # 2202 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.011202082096133381
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:33,218 INFO epoch # 2203 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.015907745462754974
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:33,239 INFO epoch # 2204 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010958759048662614
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:33,260 INFO epoch # 2205 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010886696369198035
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:33,281 INFO epoch # 2206 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010859301895834506
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:33,303 INFO epoch # 2207 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010906695632002084
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:33,324 INFO epoch # 2208 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0108822495349159
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:33,345 INFO epoch # 2209 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.011948220586418756
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:33,367 INFO epoch # 2210 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010863654060813133
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:33,367 INFO *** epoch 2210, rolling-avg-loss (window=10)= 0.011539313281173236
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:33,388 INFO epoch # 2211 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010821499363373732
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:33,410 INFO epoch # 2212 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010829257680597948
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:33,431 INFO epoch # 2213 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.012754592255078023
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:33,452 INFO epoch # 2214 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010846785622561583
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:33,473 INFO epoch # 2215 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010852557552425424
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:33,495 INFO epoch # 2216 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010853513253096025
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:33,516 INFO epoch # 2217 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010833804284629878
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:33,537 INFO epoch # 2218 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010796277676490718
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:33,559 INFO epoch # 2219 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010804698566062143
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:33,580 INFO epoch # 2220 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010793795609060908
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:33,580 INFO *** epoch 2220, rolling-avg-loss (window=10)= 0.011018678186337639
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:33,602 INFO epoch # 2221 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010786946568259737
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:33,623 INFO epoch # 2222 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01078367139052716
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:33,644 INFO epoch # 2223 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010762054582301062
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:33,666 INFO epoch # 2224 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010761676954643917
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:33,687 INFO epoch # 2225 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010903582144237589
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:33,708 INFO epoch # 2226 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.011006524102413096
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:33,730 INFO epoch # 2227 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010733041543062427
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:33,751 INFO epoch # 2228 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010760037053842098
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:33,773 INFO epoch # 2229 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01073100609391986
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:33,794 INFO epoch # 2230 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010771557139378274
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:33,794 INFO *** epoch 2230, rolling-avg-loss (window=10)= 0.010800009757258523
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:33,816 INFO epoch # 2231 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010813321172463475
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:33,837 INFO epoch # 2232 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010784357251395704
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:33,859 INFO epoch # 2233 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010842779283848358
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:33,880 INFO epoch # 2234 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010876567137529491
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:33,901 INFO epoch # 2235 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.012053799167915713
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:33,922 INFO epoch # 2236 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010760690423921915
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:33,943 INFO epoch # 2237 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01080832893421757
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:33,965 INFO epoch # 2238 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01098916849696252
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:33,986 INFO epoch # 2239 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010704072567023104
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:34,008 INFO epoch # 2240 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010718397825257853
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:34,008 INFO *** epoch 2240, rolling-avg-loss (window=10)= 0.01093514822605357
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:34,029 INFO epoch # 2241 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010712263192544924
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:34,051 INFO epoch # 2242 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.012702691841695923
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:34,072 INFO epoch # 2243 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01067391195192613
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:34,093 INFO epoch # 2244 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010828900663909735
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:34,114 INFO epoch # 2245 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010975279472404509
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:34,135 INFO epoch # 2246 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01069795801959117
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:34,157 INFO epoch # 2247 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010912045512668556
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:34,178 INFO epoch # 2248 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010668044535123045
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:34,200 INFO epoch # 2249 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010691190114812343
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:34,222 INFO epoch # 2250 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010854869196919026
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:34,222 INFO *** epoch 2250, rolling-avg-loss (window=10)= 0.010971715450159536
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:34,244 INFO epoch # 2251 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01063249104845454
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:34,265 INFO epoch # 2252 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010621880241160397
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:34,286 INFO epoch # 2253 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01065226008722675
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:34,308 INFO epoch # 2254 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01063900148801622
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:34,329 INFO epoch # 2255 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0106374482584215
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:34,350 INFO epoch # 2256 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010609734938043403
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:34,372 INFO epoch # 2257 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010643431549397064
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:34,393 INFO epoch # 2258 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010787403778522275
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:34,414 INFO epoch # 2259 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010582258908470976
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:34,437 INFO epoch # 2260 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010597792079352075
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:34,437 INFO *** epoch 2260, rolling-avg-loss (window=10)= 0.01064037023770652
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:34,459 INFO epoch # 2261 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01059423809783766
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:34,480 INFO epoch # 2262 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010654899404471507
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:34,502 INFO epoch # 2263 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010625185981552931
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:34,523 INFO epoch # 2264 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010655065067112446
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:34,544 INFO epoch # 2265 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010554211037742789
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:34,566 INFO epoch # 2266 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01061386273613607
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:34,588 INFO epoch # 2267 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01059621157037327
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:34,610 INFO epoch # 2268 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010562715677224332
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:34,632 INFO epoch # 2269 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010535884644923499
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:34,653 INFO epoch # 2270 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010582788039755542
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:34,654 INFO *** epoch 2270, rolling-avg-loss (window=10)= 0.010597506225713005
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:34,675 INFO epoch # 2271 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010520203151827445
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:34,697 INFO epoch # 2272 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010528331604291452
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:34,718 INFO epoch # 2273 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01051416658447124
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:34,739 INFO epoch # 2274 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010609507291519549
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:34,760 INFO epoch # 2275 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010503671387596114
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:34,781 INFO epoch # 2276 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.013821218624798348
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:34,803 INFO epoch # 2277 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010587942921119975
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:34,824 INFO epoch # 2278 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.011483804093586514
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:34,846 INFO epoch # 2279 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010511984048207523
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:34,867 INFO epoch # 2280 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010485369191883365
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:34,867 INFO *** epoch 2280, rolling-avg-loss (window=10)= 0.010956619889930153
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:34,889 INFO epoch # 2281 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010462226535310037
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:34,911 INFO epoch # 2282 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01063297088330728
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:34,932 INFO epoch # 2283 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010470278579305159
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:34,953 INFO epoch # 2284 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010457490219778265
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:34,974 INFO epoch # 2285 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01063717818033183
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:34,995 INFO epoch # 2286 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010487420669960557
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:35,017 INFO epoch # 2287 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010455940064275637
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:35,038 INFO epoch # 2288 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.011603073635342298
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:35,060 INFO epoch # 2289 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010464634862728417
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:35,081 INFO epoch # 2290 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010467876545590116
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:35,081 INFO *** epoch 2290, rolling-avg-loss (window=10)= 0.01061390901759296
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:35,103 INFO epoch # 2291 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01042991366921342
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:35,124 INFO epoch # 2292 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010419090360301198
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:35,146 INFO epoch # 2293 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010450180921907304
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:35,167 INFO epoch # 2294 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.011732974620827008
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:35,188 INFO epoch # 2295 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010462570051458897
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:35,209 INFO epoch # 2296 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010452010275912471
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:35,231 INFO epoch # 2297 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010470112152688671
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:35,252 INFO epoch # 2298 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010430822876514867
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:35,274 INFO epoch # 2299 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010559804006334161
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:35,295 INFO epoch # 2300 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.016988270752335666
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:35,295 INFO *** epoch 2300, rolling-avg-loss (window=10)= 0.011239574968749366
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:35,316 INFO epoch # 2301 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010810625859448919
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:35,338 INFO epoch # 2302 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01038635804434307
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:35,359 INFO epoch # 2303 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01044419261143048
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:35,380 INFO epoch # 2304 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010362785655161133
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:35,401 INFO epoch # 2305 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010351028366130777
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:35,422 INFO epoch # 2306 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.015340763611675357
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:35,444 INFO epoch # 2307 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010568118439550744
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:35,465 INFO epoch # 2308 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.014545093930792063
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:35,486 INFO epoch # 2309 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010419690472190268
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:35,508 INFO epoch # 2310 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010467951049577096
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:35,508 INFO *** epoch 2310, rolling-avg-loss (window=10)= 0.01136966080402999
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:35,530 INFO epoch # 2311 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010563034389633685
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:35,551 INFO epoch # 2312 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010340571720007574
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:35,572 INFO epoch # 2313 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010316271831470658
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:35,593 INFO epoch # 2314 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010306341584509937
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:35,614 INFO epoch # 2315 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010343080626626033
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:35,636 INFO epoch # 2316 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010330764129321324
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:35,657 INFO epoch # 2317 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010297639604686992
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:35,678 INFO epoch # 2318 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010292595412465744
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:35,700 INFO epoch # 2319 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010305159117706353
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:35,722 INFO epoch # 2320 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010333811509553925
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:35,722 INFO *** epoch 2320, rolling-avg-loss (window=10)= 0.010342926992598223
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:35,744 INFO epoch # 2321 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010391980580607196
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:35,765 INFO epoch # 2322 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010266778017467004
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:35,786 INFO epoch # 2323 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010297917273419444
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:35,808 INFO epoch # 2324 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01035784757550573
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:35,829 INFO epoch # 2325 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010273066540321452
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:35,850 INFO epoch # 2326 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010378375351137947
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:35,871 INFO epoch # 2327 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.011784404963691486
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:35,893 INFO epoch # 2328 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010250693470879924
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:35,914 INFO epoch # 2329 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010284571038937429
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:35,935 INFO epoch # 2330 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010231331962131662
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:35,935 INFO *** epoch 2330, rolling-avg-loss (window=10)= 0.010451696677409927
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:35,956 INFO epoch # 2331 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010254809118123376
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:35,978 INFO epoch # 2332 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010331678877264494
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:35,999 INFO epoch # 2333 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010282739531248808
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:36,020 INFO epoch # 2334 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010328194270186941
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:36,042 INFO epoch # 2335 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010427440585772274
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:36,063 INFO epoch # 2336 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01106081376565271
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:36,084 INFO epoch # 2337 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.015103517987881787
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:36,105 INFO epoch # 2338 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.013502778325346299
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:36,127 INFO epoch # 2339 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010223682582363836
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:36,148 INFO epoch # 2340 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01150873215374304
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:36,148 INFO *** epoch 2340, rolling-avg-loss (window=10)= 0.011302438719758357
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:36,170 INFO epoch # 2341 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010199759137321962
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:36,192 INFO epoch # 2342 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010174846178415464
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:36,213 INFO epoch # 2343 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.014859961767797358
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:36,234 INFO epoch # 2344 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010255752378725447
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:36,256 INFO epoch # 2345 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010181860583543312
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:36,277 INFO epoch # 2346 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010145960697627743
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:36,298 INFO epoch # 2347 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010189265150984284
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:36,320 INFO epoch # 2348 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010203205587458797
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:36,341 INFO epoch # 2349 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010163389204535633
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:36,363 INFO epoch # 2350 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010233133754809387
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:36,363 INFO *** epoch 2350, rolling-avg-loss (window=10)= 0.01066071344412194
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:36,384 INFO epoch # 2351 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0101275567576522
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:36,406 INFO epoch # 2352 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010207733826973708
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:36,427 INFO epoch # 2353 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010107116033395869
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:36,449 INFO epoch # 2354 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.011916964362171711
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:36,470 INFO epoch # 2355 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.011218072429983295
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:36,491 INFO epoch # 2356 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010261753744998714
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:36,512 INFO epoch # 2357 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010112612257216824
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:36,534 INFO epoch # 2358 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010217533163086046
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:36,555 INFO epoch # 2359 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010097987375047524
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:36,577 INFO epoch # 2360 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010080556599859847
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:36,577 INFO *** epoch 2360, rolling-avg-loss (window=10)= 0.010434788655038574
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:36,598 INFO epoch # 2361 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010141432907403214
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:36,619 INFO epoch # 2362 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010073169378301827
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:36,641 INFO epoch # 2363 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010334149883419741
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:36,662 INFO epoch # 2364 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010134186431969283
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:36,683 INFO epoch # 2365 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010039899714683997
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:36,704 INFO epoch # 2366 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010068400497402763
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:36,727 INFO epoch # 2367 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010934412734059151
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:36,749 INFO epoch # 2368 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010118663882167311
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:36,770 INFO epoch # 2369 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010061720793601125
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:36,791 INFO epoch # 2370 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01041633378554252
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:36,792 INFO *** epoch 2370, rolling-avg-loss (window=10)= 0.010232237000855094
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:36,813 INFO epoch # 2371 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010663809585821582
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:36,835 INFO epoch # 2372 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010082005512231262
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:36,856 INFO epoch # 2373 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010099283150339033
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:36,877 INFO epoch # 2374 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01002273835183587
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:36,898 INFO epoch # 2375 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010044118800578872
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:36,919 INFO epoch # 2376 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01004812494829821
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:36,941 INFO epoch # 2377 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009998492625527433
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:36,962 INFO epoch # 2378 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010184467793806107
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:36,984 INFO epoch # 2379 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010016780681326054
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:37,005 INFO epoch # 2380 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009984365728087141
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:37,005 INFO *** epoch 2380, rolling-avg-loss (window=10)= 0.010114418717785156
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:37,027 INFO epoch # 2381 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.00999017550930148
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:37,048 INFO epoch # 2382 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010117151083250064
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:37,069 INFO epoch # 2383 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009987919467675965
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:37,091 INFO epoch # 2384 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009997453802498057
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:37,112 INFO epoch # 2385 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009969278102289536
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:37,133 INFO epoch # 2386 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010031920355686452
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:37,154 INFO epoch # 2387 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009968617423510295
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:37,175 INFO epoch # 2388 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009955527277270448
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:37,197 INFO epoch # 2389 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009956214162230026
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:37,218 INFO epoch # 2390 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009964700268028537
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:37,219 INFO *** epoch 2390, rolling-avg-loss (window=10)= 0.009993895745174087
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:37,241 INFO epoch # 2391 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009959605515177827
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:37,262 INFO epoch # 2392 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009981281717045931
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:37,284 INFO epoch # 2393 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009934189454725129
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:37,305 INFO epoch # 2394 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009943829514668323
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:37,326 INFO epoch # 2395 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009965706143702846
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:37,347 INFO epoch # 2396 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010979220838635229
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:37,368 INFO epoch # 2397 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009999188276196946
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:37,390 INFO epoch # 2398 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009949847631105513
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:37,411 INFO epoch # 2399 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0098983832540398
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:37,433 INFO epoch # 2400 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009943236595063354
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:37,433 INFO *** epoch 2400, rolling-avg-loss (window=10)= 0.01005544889403609
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:37,454 INFO epoch # 2401 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009912837496813154
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:37,476 INFO epoch # 2402 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.011390158513677306
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:37,497 INFO epoch # 2403 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009890841542073758
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:37,519 INFO epoch # 2404 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.00990807684866013
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:37,540 INFO epoch # 2405 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009945272369805025
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:37,561 INFO epoch # 2406 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.00986862181161996
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:37,583 INFO epoch # 2407 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01078454975868226
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:37,604 INFO epoch # 2408 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009883494101813994
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:37,626 INFO epoch # 2409 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009887147603876656
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:37,647 INFO epoch # 2410 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009846641529293265
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:37,647 INFO *** epoch 2410, rolling-avg-loss (window=10)= 0.010131764157631552
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:37,669 INFO epoch # 2411 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.00991469421205693
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:37,690 INFO epoch # 2412 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009848199253610801
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:37,712 INFO epoch # 2413 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010075391506688902
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:37,733 INFO epoch # 2414 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009850574904703535
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:37,754 INFO epoch # 2415 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009842083161856863
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:37,776 INFO epoch # 2416 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009854489308054326
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:37,797 INFO epoch # 2417 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010032945607235888
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:37,818 INFO epoch # 2418 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009966073339455761
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:37,840 INFO epoch # 2419 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009841744104051031
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:37,861 INFO epoch # 2420 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010661317879566923
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:37,861 INFO *** epoch 2420, rolling-avg-loss (window=10)= 0.009988751327728095
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:37,883 INFO epoch # 2421 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.00986761267631664
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:37,904 INFO epoch # 2422 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009834801003307803
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:37,926 INFO epoch # 2423 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010258061200147495
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:37,947 INFO epoch # 2424 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.00996631335328857
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:37,968 INFO epoch # 2425 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009820580628002062
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:37,989 INFO epoch # 2426 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009809992981899995
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:38,011 INFO epoch # 2427 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009825717066632933
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:38,032 INFO epoch # 2428 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.00980744344451523
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:38,054 INFO epoch # 2429 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.00984729637093551
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:38,075 INFO epoch # 2430 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009786396927665919
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:38,075 INFO *** epoch 2430, rolling-avg-loss (window=10)= 0.009882421565271216
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:38,097 INFO epoch # 2431 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010292305567418225
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:38,118 INFO epoch # 2432 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009753390612331714
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:38,140 INFO epoch # 2433 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0097787889681058
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:38,161 INFO epoch # 2434 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009752768026373815
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:38,182 INFO epoch # 2435 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.00977008709742222
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:38,203 INFO epoch # 2436 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009740185416376335
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:38,225 INFO epoch # 2437 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009738577362440992
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:38,247 INFO epoch # 2438 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009813036434934475
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:38,268 INFO epoch # 2439 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009917921637679683
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:38,290 INFO epoch # 2440 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0097682936466299
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:38,290 INFO *** epoch 2440, rolling-avg-loss (window=10)= 0.009832535476971316
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:38,312 INFO epoch # 2441 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009783623976545641
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:38,333 INFO epoch # 2442 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009732867902130238
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:38,354 INFO epoch # 2443 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009733402433994343
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:38,376 INFO epoch # 2444 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009724680036015343
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:38,397 INFO epoch # 2445 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009744411538122222
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:38,418 INFO epoch # 2446 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009748912558279699
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:38,439 INFO epoch # 2447 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01271828177414136
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:38,460 INFO epoch # 2448 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009753098736837273
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:38,482 INFO epoch # 2449 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009702671683044173
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:38,503 INFO epoch # 2450 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009908214924507774
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:38,503 INFO *** epoch 2450, rolling-avg-loss (window=10)= 0.010055016556361807
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:38,525 INFO epoch # 2451 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.012653180256165797
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:38,546 INFO epoch # 2452 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009688389553048182
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:38,568 INFO epoch # 2453 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009676103551100823
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:38,589 INFO epoch # 2454 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009683031077656779
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:38,610 INFO epoch # 2455 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009776161026820773
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:38,631 INFO epoch # 2456 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009780962260265369
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:38,653 INFO epoch # 2457 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009683652224339312
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:38,674 INFO epoch # 2458 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009830057180806762
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:38,696 INFO epoch # 2459 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009657885442720726
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:38,717 INFO epoch # 2460 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009667332564276876
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:38,717 INFO *** epoch 2460, rolling-avg-loss (window=10)= 0.01000967551372014
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:38,740 INFO epoch # 2461 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009773995612704311
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:38,762 INFO epoch # 2462 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009648148279666202
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:38,783 INFO epoch # 2463 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.00968368056419422
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:38,804 INFO epoch # 2464 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.00963587811565958
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:38,826 INFO epoch # 2465 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009627477353205904
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:38,847 INFO epoch # 2466 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.00960874307929771
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:38,868 INFO epoch # 2467 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.00973622854144196
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:38,890 INFO epoch # 2468 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009692624895251356
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:38,911 INFO epoch # 2469 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009823966463955003
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:38,932 INFO epoch # 2470 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009694896405562758
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:38,933 INFO *** epoch 2470, rolling-avg-loss (window=10)= 0.009692563931093901
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:38,954 INFO epoch # 2471 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009591768842255988
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:38,976 INFO epoch # 2472 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009591701983481471
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:38,997 INFO epoch # 2473 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009611228328139987
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:39,018 INFO epoch # 2474 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009755017454153858
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:39,039 INFO epoch # 2475 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009596336776667158
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:39,061 INFO epoch # 2476 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.00963060147842043
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:39,082 INFO epoch # 2477 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.00959533538116375
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:39,104 INFO epoch # 2478 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009581255191733362
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:39,125 INFO epoch # 2479 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009591038371581817
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:39,147 INFO epoch # 2480 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009578921111824457
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:39,147 INFO *** epoch 2480, rolling-avg-loss (window=10)= 0.009612320491942227
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:39,168 INFO epoch # 2481 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009574903560860548
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:39,190 INFO epoch # 2482 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009628849486034596
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:39,211 INFO epoch # 2483 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009553420284646563
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:39,233 INFO epoch # 2484 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009663431357694208
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:39,254 INFO epoch # 2485 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.00992764397233259
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:39,275 INFO epoch # 2486 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.00956727779157518
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:39,297 INFO epoch # 2487 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009589089029759634
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:39,318 INFO epoch # 2488 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009517736347333994
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:39,340 INFO epoch # 2489 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.00980949230142869
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:39,361 INFO epoch # 2490 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009534050957881846
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:39,361 INFO *** epoch 2490, rolling-avg-loss (window=10)= 0.009636589508954786
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:39,383 INFO epoch # 2491 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009615958668291569
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:39,404 INFO epoch # 2492 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009512547887425171
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:39,425 INFO epoch # 2493 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009532889529509703
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:39,446 INFO epoch # 2494 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009542738742311485
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:39,467 INFO epoch # 2495 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009615362978365738
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:39,489 INFO epoch # 2496 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009491854987572879
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:39,510 INFO epoch # 2497 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.00954130775789963
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:39,532 INFO epoch # 2498 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.00949574816331733
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:39,553 INFO epoch # 2499 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009552521634759614
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:39,575 INFO epoch # 2500 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.00950592089066049
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:39,575 INFO *** epoch 2500, rolling-avg-loss (window=10)= 0.00954068512401136
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:39,597 INFO epoch # 2501 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009501553728114231
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:39,618 INFO epoch # 2502 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009473233727476327
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:39,640 INFO epoch # 2503 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009504392131930217
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:39,661 INFO epoch # 2504 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010854930935238372
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:39,682 INFO epoch # 2505 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009522379858935892
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:39,703 INFO epoch # 2506 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009446940139241633
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:39,725 INFO epoch # 2507 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009875039791950257
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:39,747 INFO epoch # 2508 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009875119660136988
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:39,769 INFO epoch # 2509 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009477918454649625
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:39,790 INFO epoch # 2510 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009484158701525303
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:39,790 INFO *** epoch 2510, rolling-avg-loss (window=10)= 0.009701566712919885
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:39,811 INFO epoch # 2511 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009420506598871725
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:39,833 INFO epoch # 2512 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009559267808072036
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:39,854 INFO epoch # 2513 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009540300810840563
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:39,875 INFO epoch # 2514 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009410016026777157
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:39,896 INFO epoch # 2515 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009425378064406686
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:39,917 INFO epoch # 2516 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009423996110854205
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:39,938 INFO epoch # 2517 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01086963023772114
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:39,960 INFO epoch # 2518 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009415156120667234
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:39,981 INFO epoch # 2519 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009508230399660533
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:40,003 INFO epoch # 2520 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010176589068578323
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:40,003 INFO *** epoch 2520, rolling-avg-loss (window=10)= 0.009674907124644961
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:40,024 INFO epoch # 2521 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.00943864549844875
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:40,046 INFO epoch # 2522 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009705786003905814
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:40,067 INFO epoch # 2523 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.012197970037959749
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:40,088 INFO epoch # 2524 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009395397710250109
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:40,109 INFO epoch # 2525 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009607982225134037
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:40,130 INFO epoch # 2526 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009371180143716629
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:40,152 INFO epoch # 2527 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009360214012303913
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:40,173 INFO epoch # 2528 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009382638536408194
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:40,195 INFO epoch # 2529 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009770702679816168
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:40,216 INFO epoch # 2530 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009376472835356253
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:40,216 INFO *** epoch 2530, rolling-avg-loss (window=10)= 0.009760698968329961
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:40,239 INFO epoch # 2531 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.00935865650899359
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:40,260 INFO epoch # 2532 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.00935814523109002
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:40,282 INFO epoch # 2533 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009385399698658148
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:40,304 INFO epoch # 2534 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009337618394056335
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:40,325 INFO epoch # 2535 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.00936345074660494
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:40,346 INFO epoch # 2536 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009388991446030559
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:40,368 INFO epoch # 2537 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009390763414558023
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:40,389 INFO epoch # 2538 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009379793948028237
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:40,411 INFO epoch # 2539 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009350987820653245
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:40,432 INFO epoch # 2540 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.00940938121493673
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:40,432 INFO *** epoch 2540, rolling-avg-loss (window=10)= 0.009372318842360982
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:40,454 INFO epoch # 2541 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.00930611773765122
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:40,475 INFO epoch # 2542 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0093850469966128
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:40,496 INFO epoch # 2543 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009428231473066262
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:40,518 INFO epoch # 2544 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009339451835330692
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:40,539 INFO epoch # 2545 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.013820562428008998
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:40,560 INFO epoch # 2546 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.00948812322349113
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:40,581 INFO epoch # 2547 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009315575345681282
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:40,603 INFO epoch # 2548 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009276595805204124
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:40,625 INFO epoch # 2549 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009288566490795347
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:40,647 INFO epoch # 2550 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009276082573705935
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:40,647 INFO *** epoch 2550, rolling-avg-loss (window=10)= 0.00979243539095478
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:40,669 INFO epoch # 2551 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009326695973868482
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:40,691 INFO epoch # 2552 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009255349315935746
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:40,712 INFO epoch # 2553 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009409556030732347
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:40,733 INFO epoch # 2554 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009304060808062786
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:40,755 INFO epoch # 2555 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009330744760518428
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:40,776 INFO epoch # 2556 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009250237610103795
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:40,797 INFO epoch # 2557 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009262926050723763
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:40,819 INFO epoch # 2558 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009319723065345897
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:40,841 INFO epoch # 2559 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009329030697699636
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:40,862 INFO epoch # 2560 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009240536764991703
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:40,862 INFO *** epoch 2560, rolling-avg-loss (window=10)= 0.009302886107798258
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:40,884 INFO epoch # 2561 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009243241658623447
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:40,905 INFO epoch # 2562 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009251910661987495
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:40,926 INFO epoch # 2563 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.00921611759258667
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:40,948 INFO epoch # 2564 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009281336213462055
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:40,969 INFO epoch # 2565 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009217717286446714
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:40,990 INFO epoch # 2566 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009257147688913392
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:41,011 INFO epoch # 2567 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009303941777034197
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:41,033 INFO epoch # 2568 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010013741259172093
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:41,054 INFO epoch # 2569 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009228467508364702
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:41,076 INFO epoch # 2570 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009275473428715486
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:41,076 INFO *** epoch 2570, rolling-avg-loss (window=10)= 0.009328909507530625
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:41,097 INFO epoch # 2571 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009176296740406542
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:41,119 INFO epoch # 2572 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009240279956429731
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:41,140 INFO epoch # 2573 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009179191562907363
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:41,161 INFO epoch # 2574 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.00942991273041116
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:41,182 INFO epoch # 2575 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009286533460908686
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:41,203 INFO epoch # 2576 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009229135619534645
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:41,225 INFO epoch # 2577 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009201815320921014
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:41,247 INFO epoch # 2578 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009241139076038962
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:41,268 INFO epoch # 2579 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009243695814802777
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:41,290 INFO epoch # 2580 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009245917894077138
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:41,290 INFO *** epoch 2580, rolling-avg-loss (window=10)= 0.009247391817643802
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:41,311 INFO epoch # 2581 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009458180162255303
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:41,333 INFO epoch # 2582 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009174594106298173
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:41,354 INFO epoch # 2583 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009976041883419384
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:41,375 INFO epoch # 2584 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.00993291255144868
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:41,396 INFO epoch # 2585 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009148092205577996
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:41,417 INFO epoch # 2586 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009169814318738645
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:41,438 INFO epoch # 2587 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009135342201261665
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:41,460 INFO epoch # 2588 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009226724077052495
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:41,481 INFO epoch # 2589 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009194695612677606
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:41,503 INFO epoch # 2590 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009237424752427614
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:41,503 INFO *** epoch 2590, rolling-avg-loss (window=10)= 0.009365382187115755
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:41,524 INFO epoch # 2591 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009356886890600435
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:41,546 INFO epoch # 2592 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.012726027411190444
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:41,568 INFO epoch # 2593 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009146443913778057
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:41,589 INFO epoch # 2594 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.00914543430917547
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:41,610 INFO epoch # 2595 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009563702515151817
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:41,631 INFO epoch # 2596 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009189957670969306
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:41,652 INFO epoch # 2597 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009418451492820168
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:41,674 INFO epoch # 2598 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009120246602833504
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:41,695 INFO epoch # 2599 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010110586614246131
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:41,717 INFO epoch # 2600 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.00984887134109158
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:41,717 INFO *** epoch 2600, rolling-avg-loss (window=10)= 0.009762660876185691
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:41,741 INFO epoch # 2601 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009099352508201264
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:41,762 INFO epoch # 2602 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.00913226036936976
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:41,784 INFO epoch # 2603 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009147362095973222
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:41,805 INFO epoch # 2604 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010878598348426749
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:41,826 INFO epoch # 2605 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009121656545175938
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:41,847 INFO epoch # 2606 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009185793778669904
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:41,869 INFO epoch # 2607 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009109351027291268
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:41,892 INFO epoch # 2608 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009073220682694227
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:41,914 INFO epoch # 2609 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009053719493749668
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:41,937 INFO epoch # 2610 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009174245267786318
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:41,937 INFO *** epoch 2610, rolling-avg-loss (window=10)= 0.009297556011733831
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:41,960 INFO epoch # 2611 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.00907269610252115
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:41,981 INFO epoch # 2612 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009049086786035332
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:42,002 INFO epoch # 2613 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009052591829458834
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:42,023 INFO epoch # 2614 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010419240927149076
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:42,044 INFO epoch # 2615 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010277515293637407
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:42,066 INFO epoch # 2616 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009144456824287772
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:42,088 INFO epoch # 2617 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009062340859600226
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:42,111 INFO epoch # 2618 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009067477109056199
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:42,133 INFO epoch # 2619 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009047600367921405
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:42,155 INFO epoch # 2620 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009078170940483687
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:42,155 INFO *** epoch 2620, rolling-avg-loss (window=10)= 0.00932711770401511
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:42,178 INFO epoch # 2621 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009004256063235516
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:42,199 INFO epoch # 2622 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009015120922413189
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:42,221 INFO epoch # 2623 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009002665989100933
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:42,242 INFO epoch # 2624 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009189462747599464
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:42,264 INFO epoch # 2625 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009081604766834062
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:42,285 INFO epoch # 2626 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009069355037354399
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:42,308 INFO epoch # 2627 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009032101876073284
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:42,331 INFO epoch # 2628 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009072703809579252
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:42,353 INFO epoch # 2629 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008984800924736192
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:42,376 INFO epoch # 2630 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008990978368274227
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:42,376 INFO *** epoch 2630, rolling-avg-loss (window=10)= 0.009044305050520052
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:42,398 INFO epoch # 2631 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008988865731225815
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:42,420 INFO epoch # 2632 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009771663389983587
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:42,441 INFO epoch # 2633 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008979882171843201
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:42,462 INFO epoch # 2634 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009030769757373491
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:42,483 INFO epoch # 2635 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009075721518456703
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:42,504 INFO epoch # 2636 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008947363876359304
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:42,527 INFO epoch # 2637 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009945135565430974
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:42,549 INFO epoch # 2638 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009026793830344104
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:42,570 INFO epoch # 2639 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008946552932684426
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:42,591 INFO epoch # 2640 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008940564268414164
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:42,591 INFO *** epoch 2640, rolling-avg-loss (window=10)= 0.009165331304211577
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:42,613 INFO epoch # 2641 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008985182666947367
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:42,634 INFO epoch # 2642 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.00896472817112226
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:42,655 INFO epoch # 2643 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.00900848389028397
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:42,676 INFO epoch # 2644 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008916463319110335
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:42,697 INFO epoch # 2645 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009023170174259576
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:42,718 INFO epoch # 2646 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008979816366263549
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:42,740 INFO epoch # 2647 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008910589001970948
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:42,761 INFO epoch # 2648 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008944186571170576
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:42,783 INFO epoch # 2649 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008922760851419298
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:42,804 INFO epoch # 2650 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.00892490552723757
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:42,804 INFO *** epoch 2650, rolling-avg-loss (window=10)= 0.008958028653978545
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:42,826 INFO epoch # 2651 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.00892528438635054
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:42,847 INFO epoch # 2652 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008887542751836008
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:42,868 INFO epoch # 2653 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008899429863959085
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:42,890 INFO epoch # 2654 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008998417179100215
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:42,911 INFO epoch # 2655 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008888016260243603
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:42,932 INFO epoch # 2656 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008874285107594915
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:42,953 INFO epoch # 2657 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008939483623180422
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:42,974 INFO epoch # 2658 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.00968131325498689
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:42,996 INFO epoch # 2659 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008863773125995067
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:43,017 INFO epoch # 2660 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008942566350015113
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:43,017 INFO *** epoch 2660, rolling-avg-loss (window=10)= 0.008990011190326186
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:43,039 INFO epoch # 2661 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.013183304605263402
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:43,060 INFO epoch # 2662 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008863423541697557
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:43,081 INFO epoch # 2663 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009034169303049566
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:43,103 INFO epoch # 2664 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008834892813865736
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:43,124 INFO epoch # 2665 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008918814763092087
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:43,145 INFO epoch # 2666 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008869856677847565
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:43,166 INFO epoch # 2667 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008832655292280833
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:43,188 INFO epoch # 2668 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.00917306067640311
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:43,209 INFO epoch # 2669 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008818801813504251
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:43,231 INFO epoch # 2670 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008906453149393201
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:43,231 INFO *** epoch 2670, rolling-avg-loss (window=10)= 0.00934354326363973
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:43,253 INFO epoch # 2671 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009151984286290826
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:43,274 INFO epoch # 2672 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008900608441763325
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:43,295 INFO epoch # 2673 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008855630081598065
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:43,316 INFO epoch # 2674 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008884533952368656
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:43,338 INFO epoch # 2675 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.00881267418662901
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:43,360 INFO epoch # 2676 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008864894283760805
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:43,381 INFO epoch # 2677 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008796157599135768
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:43,403 INFO epoch # 2678 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008808353886706755
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:43,424 INFO epoch # 2679 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008800147938018199
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:43,446 INFO epoch # 2680 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010482937103006407
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:43,446 INFO *** epoch 2680, rolling-avg-loss (window=10)= 0.009035792175927782
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:43,468 INFO epoch # 2681 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008801909440080635
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:43,489 INFO epoch # 2682 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.00881098747595388
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:43,510 INFO epoch # 2683 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008791883363301167
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:43,531 INFO epoch # 2684 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008785105233982904
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:43,552 INFO epoch # 2685 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008789225070358953
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:43,573 INFO epoch # 2686 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008805614055745536
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:43,595 INFO epoch # 2687 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008757524934480898
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:43,616 INFO epoch # 2688 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008761354520174791
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:43,637 INFO epoch # 2689 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008758690280956216
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:43,659 INFO epoch # 2690 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008767144532612292
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:43,659 INFO *** epoch 2690, rolling-avg-loss (window=10)= 0.008782943890764727
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:43,680 INFO epoch # 2691 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.00874658551401808
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:43,702 INFO epoch # 2692 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008762882032897323
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:43,724 INFO epoch # 2693 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008744170350837521
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:43,745 INFO epoch # 2694 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008762366182054393
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:43,767 INFO epoch # 2695 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.00875037918012822
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:43,788 INFO epoch # 2696 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008802794309303863
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:43,809 INFO epoch # 2697 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009530334296869114
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:43,830 INFO epoch # 2698 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008747430092626018
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:43,852 INFO epoch # 2699 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008737321722946945
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:43,873 INFO epoch # 2700 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01157292966672685
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:43,873 INFO *** epoch 2700, rolling-avg-loss (window=10)= 0.009115719334840833
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:43,895 INFO epoch # 2701 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008910373668186367
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:43,916 INFO epoch # 2702 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.010356396904171561
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:43,937 INFO epoch # 2703 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008720366588022443
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:43,958 INFO epoch # 2704 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.00881009675867972
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:43,979 INFO epoch # 2705 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008753927264478989
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:44,000 INFO epoch # 2706 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008692596511536976
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:44,022 INFO epoch # 2707 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008694342097442131
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:44,043 INFO epoch # 2708 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0087159770555445
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:44,065 INFO epoch # 2709 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.013827236940414878
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:44,086 INFO epoch # 2710 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008727983957214747
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:44,086 INFO *** epoch 2710, rolling-avg-loss (window=10)= 0.009420929774569231
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:44,108 INFO epoch # 2711 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008723737846594304
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:44,129 INFO epoch # 2712 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008674440290633356
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:44,150 INFO epoch # 2713 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008698459107108647
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:44,171 INFO epoch # 2714 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.011426157954701921
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:44,192 INFO epoch # 2715 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008699045563844265
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:44,214 INFO epoch # 2716 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008687182042194763
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:44,236 INFO epoch # 2717 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008830258222587872
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:44,257 INFO epoch # 2718 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008729188914003316
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:44,278 INFO epoch # 2719 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008666545974847395
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:44,300 INFO epoch # 2720 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008663740940392017
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:44,300 INFO *** epoch 2720, rolling-avg-loss (window=10)= 0.008979875685690785
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:44,321 INFO epoch # 2721 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008665384137202636
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:44,342 INFO epoch # 2722 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008654110290081007
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:44,364 INFO epoch # 2723 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008686690074682701
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:44,385 INFO epoch # 2724 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008632263871731993
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:44,406 INFO epoch # 2725 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008620399687060853
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:44,427 INFO epoch # 2726 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.012760139088641154
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:44,448 INFO epoch # 2727 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008744806553295348
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:44,471 INFO epoch # 2728 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008635676000267267
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:44,492 INFO epoch # 2729 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008642748936836142
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:44,513 INFO epoch # 2730 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008647868544358062
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:44,514 INFO *** epoch 2730, rolling-avg-loss (window=10)= 0.009069008718415716
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:44,535 INFO epoch # 2731 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008640958183605107
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:44,557 INFO epoch # 2732 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008717981474546832
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:44,578 INFO epoch # 2733 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008629530057078227
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:44,599 INFO epoch # 2734 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008604777896835003
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:44,620 INFO epoch # 2735 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008640361620564363
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:44,642 INFO epoch # 2736 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008599393360782415
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:44,663 INFO epoch # 2737 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008602479199907975
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:44,685 INFO epoch # 2738 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008668136786582181
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:44,706 INFO epoch # 2739 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008627535147752496
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:44,729 INFO epoch # 2740 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008653930835862411
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:44,729 INFO *** epoch 2740, rolling-avg-loss (window=10)= 0.0086385084563517
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:44,750 INFO epoch # 2741 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.00861343830183614
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:44,772 INFO epoch # 2742 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008577215861805598
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:44,793 INFO epoch # 2743 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008999748293717857
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:44,814 INFO epoch # 2744 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008713448776688892
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:44,835 INFO epoch # 2745 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0085788780470466
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:44,857 INFO epoch # 2746 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.00938114503514953
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:44,878 INFO epoch # 2747 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008568619292418589
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:44,899 INFO epoch # 2748 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008549916358788323
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:44,921 INFO epoch # 2749 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008823508720524842
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:44,942 INFO epoch # 2750 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008542842389942962
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:44,942 INFO *** epoch 2750, rolling-avg-loss (window=10)= 0.008734876107791934
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:44,964 INFO epoch # 2751 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008649603178128018
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:44,985 INFO epoch # 2752 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008538777436115197
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:45,007 INFO epoch # 2753 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008569939596782206
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:45,028 INFO epoch # 2754 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008548976091333316
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:45,049 INFO epoch # 2755 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008685648446771665
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:45,070 INFO epoch # 2756 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008554419655411039
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:45,091 INFO epoch # 2757 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008548539452021942
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:45,113 INFO epoch # 2758 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009842127881711349
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:45,134 INFO epoch # 2759 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008551055896532489
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:45,156 INFO epoch # 2760 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008579612764151534
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:45,156 INFO *** epoch 2760, rolling-avg-loss (window=10)= 0.008706870039895875
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:45,178 INFO epoch # 2761 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008578682482038857
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:45,199 INFO epoch # 2762 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008518830147295375
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:45,220 INFO epoch # 2763 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008530727980541997
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:45,242 INFO epoch # 2764 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.00867075172936893
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:45,263 INFO epoch # 2765 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008631983211671468
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:45,284 INFO epoch # 2766 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008494398010952864
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:45,305 INFO epoch # 2767 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.00850672327214852
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:45,327 INFO epoch # 2768 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.00849508026294643
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:45,348 INFO epoch # 2769 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008510922440109425
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:45,370 INFO epoch # 2770 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008821915766020538
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:45,370 INFO *** epoch 2770, rolling-avg-loss (window=10)= 0.00857600153030944
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:45,391 INFO epoch # 2771 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008510037536325399
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:45,413 INFO epoch # 2772 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008514651304722065
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:45,434 INFO epoch # 2773 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008475844804706867
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:45,455 INFO epoch # 2774 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.00851590561796911
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:45,476 INFO epoch # 2775 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008557254815968918
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:45,497 INFO epoch # 2776 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008453641343294294
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:45,519 INFO epoch # 2777 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008475132010062225
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:45,540 INFO epoch # 2778 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008528599675628357
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:45,562 INFO epoch # 2779 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009430438693016185
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:45,583 INFO epoch # 2780 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008464062771963654
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:45,584 INFO *** epoch 2780, rolling-avg-loss (window=10)= 0.008592556857365707
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:45,605 INFO epoch # 2781 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008666163794259774
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:45,627 INFO epoch # 2782 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008531212781235809
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:45,648 INFO epoch # 2783 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008501447839080356
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:45,669 INFO epoch # 2784 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008439395922323456
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:45,690 INFO epoch # 2785 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008443413596978644
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:45,712 INFO epoch # 2786 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008450907356746029
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:45,734 INFO epoch # 2787 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.00843400342091627
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:45,755 INFO epoch # 2788 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008425293241089093
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:45,776 INFO epoch # 2789 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008453015003397013
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:45,798 INFO epoch # 2790 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008535208240573411
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:45,798 INFO *** epoch 2790, rolling-avg-loss (window=10)= 0.008488006119659986
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:45,820 INFO epoch # 2791 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008437004638835788
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:45,841 INFO epoch # 2792 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008411991928369389
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:45,862 INFO epoch # 2793 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.00877535111430916
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:45,883 INFO epoch # 2794 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008397422989219194
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:45,905 INFO epoch # 2795 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008442934582490125
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:45,926 INFO epoch # 2796 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008422787728704861
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:45,947 INFO epoch # 2797 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008425285814155359
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:45,968 INFO epoch # 2798 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008413574996666284
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:45,990 INFO epoch # 2799 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008419310226599919
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:46,011 INFO epoch # 2800 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008611073684733128
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:46,011 INFO *** epoch 2800, rolling-avg-loss (window=10)= 0.00847567377040832
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:46,033 INFO epoch # 2801 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008804468425296363
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:46,054 INFO epoch # 2802 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.00951442429141025
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:46,076 INFO epoch # 2803 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008385086322050483
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:46,097 INFO epoch # 2804 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008370395946258213
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:46,118 INFO epoch # 2805 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008410392973019043
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:46,139 INFO epoch # 2806 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008526897884621576
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:46,160 INFO epoch # 2807 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.00839557312974648
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:46,181 INFO epoch # 2808 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008383621508983197
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:46,203 INFO epoch # 2809 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008351210376531526
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:46,225 INFO epoch # 2810 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008350740768946707
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:46,225 INFO *** epoch 2810, rolling-avg-loss (window=10)= 0.008549281162686384
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:46,247 INFO epoch # 2811 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008354454395885114
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:46,268 INFO epoch # 2812 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008374505838219193
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:46,289 INFO epoch # 2813 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008369347156985896
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:46,311 INFO epoch # 2814 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008340172689713654
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:46,332 INFO epoch # 2815 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008579171988458256
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:46,353 INFO epoch # 2816 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008427162445514114
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:46,374 INFO epoch # 2817 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008410176189499907
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:46,396 INFO epoch # 2818 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008317312611325178
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:46,418 INFO epoch # 2819 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008354635720024817
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:46,440 INFO epoch # 2820 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008330831875355216
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:46,440 INFO *** epoch 2820, rolling-avg-loss (window=10)= 0.008385777091098135
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:46,462 INFO epoch # 2821 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009204080328345299
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:46,484 INFO epoch # 2822 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009649826970417053
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:46,505 INFO epoch # 2823 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008360352247109404
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:46,526 INFO epoch # 2824 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008386285060623777
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:46,547 INFO epoch # 2825 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008321795536176069
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:46,569 INFO epoch # 2826 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008300212653921335
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:46,591 INFO epoch # 2827 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008317713014548644
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:46,613 INFO epoch # 2828 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.00834570529332268
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:46,635 INFO epoch # 2829 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008296061855617154
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:46,656 INFO epoch # 2830 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008315060747918324
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:46,656 INFO *** epoch 2830, rolling-avg-loss (window=10)= 0.008549709370799973
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:46,678 INFO epoch # 2831 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008276717140688561
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:46,699 INFO epoch # 2832 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008358567240065895
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:46,721 INFO epoch # 2833 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008378192576856236
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:46,742 INFO epoch # 2834 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.00835545079462463
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:46,763 INFO epoch # 2835 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008297888200104353
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:46,784 INFO epoch # 2836 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008277118586192955
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:46,806 INFO epoch # 2837 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008256546762822836
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:46,827 INFO epoch # 2838 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008305104607643443
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:46,849 INFO epoch # 2839 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008279864621727029
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:46,870 INFO epoch # 2840 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.00834067702453467
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:46,870 INFO *** epoch 2840, rolling-avg-loss (window=10)= 0.00831261275552606
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:46,891 INFO epoch # 2841 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009579635836416855
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:46,913 INFO epoch # 2842 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008280441765236901
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:46,934 INFO epoch # 2843 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008346774757228559
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:46,955 INFO epoch # 2844 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.00825253443690599
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:46,976 INFO epoch # 2845 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008231321262428537
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:46,998 INFO epoch # 2846 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.00825366677781858
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:47,019 INFO epoch # 2847 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.00831707634642953
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:47,041 INFO epoch # 2848 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008228244701967924
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:47,062 INFO epoch # 2849 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008225967443650006
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:47,084 INFO epoch # 2850 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008522540356352692
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:47,084 INFO *** epoch 2850, rolling-avg-loss (window=10)= 0.008423820368443557
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:47,105 INFO epoch # 2851 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008234640812588623
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:47,127 INFO epoch # 2852 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008214705212594708
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:47,148 INFO epoch # 2853 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008217868820793228
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:47,169 INFO epoch # 2854 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008233020320403739
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:47,191 INFO epoch # 2855 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008212362303311238
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:47,212 INFO epoch # 2856 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008335136331879767
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:47,233 INFO epoch # 2857 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008211720783947385
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:47,255 INFO epoch # 2858 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008212955497583607
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:47,276 INFO epoch # 2859 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008207437731471146
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:47,297 INFO epoch # 2860 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008213590830564499
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:47,298 INFO *** epoch 2860, rolling-avg-loss (window=10)= 0.008229343864513794
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:47,319 INFO epoch # 2861 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008221838797908276
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:47,341 INFO epoch # 2862 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008200357424357207
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:47,362 INFO epoch # 2863 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008281707763671875
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:47,383 INFO epoch # 2864 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.00818849959250656
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:47,404 INFO epoch # 2865 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008185363414668245
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:47,425 INFO epoch # 2866 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008236018096795306
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:47,447 INFO epoch # 2867 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008199425026759855
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:47,468 INFO epoch # 2868 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008213341800001217
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:47,489 INFO epoch # 2869 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008167798887370736
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:47,511 INFO epoch # 2870 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008260132497525774
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:47,511 INFO *** epoch 2870, rolling-avg-loss (window=10)= 0.008215448330156505
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:47,533 INFO epoch # 2871 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008176382712917984
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:47,554 INFO epoch # 2872 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.00818600556704041
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:47,575 INFO epoch # 2873 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008190773438400356
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:47,596 INFO epoch # 2874 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008393238407734316
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:47,618 INFO epoch # 2875 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.00813954191380617
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:47,639 INFO epoch # 2876 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008214591329306131
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:47,660 INFO epoch # 2877 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008171513367415173
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:47,682 INFO epoch # 2878 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009473581374550122
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:47,703 INFO epoch # 2879 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008158887952959049
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:47,725 INFO epoch # 2880 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008152275640895823
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:47,725 INFO *** epoch 2880, rolling-avg-loss (window=10)= 0.008325679170502554
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:47,747 INFO epoch # 2881 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.01066984520002734
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:47,768 INFO epoch # 2882 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008245294678999926
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:47,790 INFO epoch # 2883 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008119184192764806
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:47,811 INFO epoch # 2884 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008183032270608237
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:47,832 INFO epoch # 2885 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008807810063444776
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:47,853 INFO epoch # 2886 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008247960258813691
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:47,874 INFO epoch # 2887 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009371586231281981
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:47,896 INFO epoch # 2888 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008169051718141418
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:47,917 INFO epoch # 2889 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008139278292219387
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:47,938 INFO epoch # 2890 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008142423546814825
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:47,939 INFO *** epoch 2890, rolling-avg-loss (window=10)= 0.008609546645311638
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:47,960 INFO epoch # 2891 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008146334846969694
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:47,981 INFO epoch # 2892 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008185518285245053
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:48,003 INFO epoch # 2893 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008099729786408716
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:48,024 INFO epoch # 2894 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008094485932815587
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:48,045 INFO epoch # 2895 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008824686628940981
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:48,066 INFO epoch # 2896 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.00808614909692551
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:48,087 INFO epoch # 2897 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008097570799691312
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:48,109 INFO epoch # 2898 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008086860960247577
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:48,130 INFO epoch # 2899 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008072489546066208
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:48,151 INFO epoch # 2900 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008138977002090542
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:48,151 INFO *** epoch 2900, rolling-avg-loss (window=10)= 0.008183280288540118
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:48,173 INFO epoch # 2901 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008093773041764507
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:48,194 INFO epoch # 2902 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.00810786843430833
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:48,215 INFO epoch # 2903 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.00816992510772252
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:48,237 INFO epoch # 2904 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008048909160606854
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:48,258 INFO epoch # 2905 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008056161566855735
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:48,280 INFO epoch # 2906 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.00808355190747534
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:48,301 INFO epoch # 2907 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008045134326494008
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:48,322 INFO epoch # 2908 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008165334111254197
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:48,343 INFO epoch # 2909 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008065286805504002
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:48,365 INFO epoch # 2910 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008033726036046573
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:48,365 INFO *** epoch 2910, rolling-avg-loss (window=10)= 0.008086967049803207
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:48,386 INFO epoch # 2911 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008123308267386165
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:48,408 INFO epoch # 2912 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008050497832300607
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:48,429 INFO epoch # 2913 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.00870732123257767
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:48,451 INFO epoch # 2914 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008101652882032795
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:48,472 INFO epoch # 2915 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008025695811738842
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:48,493 INFO epoch # 2916 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008101082217763178
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:48,514 INFO epoch # 2917 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008062448619966744
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:48,535 INFO epoch # 2918 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008091449402854778
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:48,557 INFO epoch # 2919 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008105652461381396
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:48,578 INFO epoch # 2920 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.00802031890998478
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:48,578 INFO *** epoch 2920, rolling-avg-loss (window=10)= 0.008138942763798696
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:48,599 INFO epoch # 2921 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008006885302165756
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:48,621 INFO epoch # 2922 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008022657968467684
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:48,642 INFO epoch # 2923 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.00803655942218029
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:48,664 INFO epoch # 2924 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007998508321179543
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:48,685 INFO epoch # 2925 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.00805229090838111
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:48,706 INFO epoch # 2926 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008142615268297959
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:48,727 INFO epoch # 2927 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007993577505658322
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:48,749 INFO epoch # 2928 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.00799983301476459
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:48,770 INFO epoch # 2929 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008011665287995129
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:48,792 INFO epoch # 2930 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.00954761368848267
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:48,792 INFO *** epoch 2930, rolling-avg-loss (window=10)= 0.008181220668757306
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:48,813 INFO epoch # 2931 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.00802046670105483
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:48,834 INFO epoch # 2932 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007986520446138456
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:48,855 INFO epoch # 2933 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.00797577423236362
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:48,876 INFO epoch # 2934 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007985712398294709
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:48,897 INFO epoch # 2935 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008030670247535454
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:48,919 INFO epoch # 2936 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.00798448621208081
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:48,940 INFO epoch # 2937 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007988550187292276
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:48,961 INFO epoch # 2938 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007987465309270192
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:48,983 INFO epoch # 2939 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007955515126013779
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:49,004 INFO epoch # 2940 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007947677854645008
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:49,004 INFO *** epoch 2940, rolling-avg-loss (window=10)= 0.007986283871468913
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:49,025 INFO epoch # 2941 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007965114678881946
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:49,047 INFO epoch # 2942 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007995695603312925
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:49,069 INFO epoch # 2943 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007972011611855123
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:49,091 INFO epoch # 2944 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007954816204801318
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:49,112 INFO epoch # 2945 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007979250236530788
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:49,134 INFO epoch # 2946 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008101112314761849
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:49,155 INFO epoch # 2947 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007970398793986533
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:49,176 INFO epoch # 2948 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008020386183488881
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:49,197 INFO epoch # 2949 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007929132756544277
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:49,219 INFO epoch # 2950 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007933459764899453
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:49,219 INFO *** epoch 2950, rolling-avg-loss (window=10)= 0.00798213781490631
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:49,241 INFO epoch # 2951 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008006188219951582
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:49,263 INFO epoch # 2952 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008812660011244589
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:49,284 INFO epoch # 2953 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007953505752084311
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:49,305 INFO epoch # 2954 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008037249328481266
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:49,326 INFO epoch # 2955 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.00793462676301715
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:49,347 INFO epoch # 2956 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008007880525838118
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:49,368 INFO epoch # 2957 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007908569416031241
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:49,390 INFO epoch # 2958 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008144876068399753
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:49,411 INFO epoch # 2959 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.00827157954336144
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:49,432 INFO epoch # 2960 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007910886057288735
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:49,432 INFO *** epoch 2960, rolling-avg-loss (window=10)= 0.008098802168569818
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:49,454 INFO epoch # 2961 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007907821662229253
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:49,475 INFO epoch # 2962 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007887836436566431
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:49,497 INFO epoch # 2963 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007985149677551817
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:49,519 INFO epoch # 2964 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007914866821010946
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:49,540 INFO epoch # 2965 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.00828303560410859
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:49,561 INFO epoch # 2966 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007881213943619514
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:49,583 INFO epoch # 2967 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007929043249532697
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:49,604 INFO epoch # 2968 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007950997733132681
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:49,625 INFO epoch # 2969 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007880427408963442
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:49,647 INFO epoch # 2970 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007905625780040282
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:49,647 INFO *** epoch 2970, rolling-avg-loss (window=10)= 0.007952601831675565
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:49,668 INFO epoch # 2971 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007873102931625908
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:49,690 INFO epoch # 2972 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007867723222261702
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:49,711 INFO epoch # 2973 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007879046748712426
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:49,733 INFO epoch # 2974 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007898518144429545
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:49,754 INFO epoch # 2975 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007847026878152974
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:49,775 INFO epoch # 2976 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.00802347651369928
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:49,796 INFO epoch # 2977 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.00788176478818059
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:49,817 INFO epoch # 2978 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007870473074945039
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:49,839 INFO epoch # 2979 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007873465863667661
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:49,860 INFO epoch # 2980 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007842338884074707
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:49,860 INFO *** epoch 2980, rolling-avg-loss (window=10)= 0.007885693704974984
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:49,882 INFO epoch # 2981 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007901466920884559
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:49,904 INFO epoch # 2982 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.00790658618643647
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:49,925 INFO epoch # 2983 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008250413413406932
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:49,946 INFO epoch # 2984 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007856034953874769
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:49,967 INFO epoch # 2985 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.00817120658030035
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:49,989 INFO epoch # 2986 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.00790305238297151
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:50,010 INFO epoch # 2987 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007826053009011957
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:50,032 INFO epoch # 2988 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007881404628278688
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:50,053 INFO epoch # 2989 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007843332401535008
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:50,075 INFO epoch # 2990 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007852421433199197
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:50,075 INFO *** epoch 2990, rolling-avg-loss (window=10)= 0.007939197190989945
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:50,097 INFO epoch # 2991 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009332718414952978
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:50,118 INFO epoch # 2992 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007823162044587662
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:50,139 INFO epoch # 2993 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007809628481481923
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:50,160 INFO epoch # 2994 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.00781647811527364
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:50,181 INFO epoch # 2995 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.00779784352016577
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:50,203 INFO epoch # 2996 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007833210591343231
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:50,224 INFO epoch # 2997 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007795895698109234
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:50,246 INFO epoch # 2998 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007786862996908894
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:50,267 INFO epoch # 2999 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007794853159794002
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:50,289 INFO epoch # 3000 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007806036031979602
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:50,289 INFO *** epoch 3000, rolling-avg-loss (window=10)= 0.007959668905459693
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:50,310 INFO epoch # 3001 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007994525729372981
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:50,332 INFO epoch # 3002 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.00785679114778759
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:50,353 INFO epoch # 3003 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007824235781299649
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:50,374 INFO epoch # 3004 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007775247377139749
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:50,395 INFO epoch # 3005 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007769220494083129
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:50,416 INFO epoch # 3006 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007771436828079459
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:50,437 INFO epoch # 3007 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007818396097718505
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:50,459 INFO epoch # 3008 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007791839794663247
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:50,480 INFO epoch # 3009 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007770198426442221
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:50,501 INFO epoch # 3010 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007861522722123482
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:50,501 INFO *** epoch 3010, rolling-avg-loss (window=10)= 0.007823341439871002
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:50,523 INFO epoch # 3011 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007769528483549948
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:50,544 INFO epoch # 3012 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0077844442221248755
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:50,566 INFO epoch # 3013 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.00777417669451097
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:50,587 INFO epoch # 3014 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007751859905511083
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:50,608 INFO epoch # 3015 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008465446579066338
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:50,629 INFO epoch # 3016 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.00778829054615926
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:50,650 INFO epoch # 3017 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007759984586300561
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:50,672 INFO epoch # 3018 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007764268746541347
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:50,693 INFO epoch # 3019 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007803934602634399
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:50,715 INFO epoch # 3020 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007990494028490502
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:50,715 INFO *** epoch 3020, rolling-avg-loss (window=10)= 0.007865242839488928
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:50,737 INFO epoch # 3021 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007762618879496586
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:50,759 INFO epoch # 3022 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0077605957303603645
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:50,781 INFO epoch # 3023 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007729078866759664
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:50,802 INFO epoch # 3024 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.00772955041975365
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:50,823 INFO epoch # 3025 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007898469859355828
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:50,844 INFO epoch # 3026 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007747709498289623
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:50,866 INFO epoch # 3027 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007740370921965223
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:50,887 INFO epoch # 3028 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007733872622338822
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:50,908 INFO epoch # 3029 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007703250703343656
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:50,930 INFO epoch # 3030 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007905799853688222
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:50,930 INFO *** epoch 3030, rolling-avg-loss (window=10)= 0.007771131735535164
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:50,951 INFO epoch # 3031 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007718274051512708
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:50,973 INFO epoch # 3032 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007870450026530307
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:50,994 INFO epoch # 3033 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007729847598966444
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:51,015 INFO epoch # 3034 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0077003272799629485
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:51,036 INFO epoch # 3035 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007793114476953633
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:51,057 INFO epoch # 3036 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007768489678710466
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:51,079 INFO epoch # 3037 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007706741911533754
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:51,100 INFO epoch # 3038 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.00767866147634777
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:51,121 INFO epoch # 3039 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007674249040974246
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:51,143 INFO epoch # 3040 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007683757939958014
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:51,143 INFO *** epoch 3040, rolling-avg-loss (window=10)= 0.007732391348145029
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:51,164 INFO epoch # 3041 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007774748159135925
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:51,186 INFO epoch # 3042 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007679483751417138
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:51,207 INFO epoch # 3043 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007757648654660443
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:51,229 INFO epoch # 3044 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0076699828041455476
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:51,250 INFO epoch # 3045 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008594184042522102
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:51,271 INFO epoch # 3046 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0076926055353396805
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:51,293 INFO epoch # 3047 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008722265338292345
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:51,314 INFO epoch # 3048 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008770897473368677
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:51,335 INFO epoch # 3049 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007659257444174727
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:51,357 INFO epoch # 3050 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007682828143515508
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:51,357 INFO *** epoch 3050, rolling-avg-loss (window=10)= 0.008000390134657209
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:51,379 INFO epoch # 3051 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007693452900639386
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:51,400 INFO epoch # 3052 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.00764682124099636
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:51,421 INFO epoch # 3053 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007647404030649341
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:51,442 INFO epoch # 3054 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007692314042287762
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:51,464 INFO epoch # 3055 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.011312316170005943
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:51,485 INFO epoch # 3056 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007904178422904806
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:51,506 INFO epoch # 3057 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007681855400733184
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:51,528 INFO epoch # 3058 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009097808313526912
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:51,549 INFO epoch # 3059 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007656871785002295
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:51,571 INFO epoch # 3060 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007681952638449729
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:51,571 INFO *** epoch 3060, rolling-avg-loss (window=10)= 0.008201497494519571
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:51,592 INFO epoch # 3061 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007641807340405649
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:51,614 INFO epoch # 3062 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007924153327621752
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:51,635 INFO epoch # 3063 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007690452039241791
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:51,656 INFO epoch # 3064 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007642837113962742
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:51,677 INFO epoch # 3065 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007660990078875329
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:51,698 INFO epoch # 3066 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007636998452653643
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:51,719 INFO epoch # 3067 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007630261909071123
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:51,742 INFO epoch # 3068 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0076770494033553405
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:51,763 INFO epoch # 3069 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007619144991622306
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:51,784 INFO epoch # 3070 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007627225992109743
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:51,785 INFO *** epoch 3070, rolling-avg-loss (window=10)= 0.007675092064891942
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:51,806 INFO epoch # 3071 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007653757604202838
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:51,827 INFO epoch # 3072 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007877563999500126
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:51,849 INFO epoch # 3073 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007633095781784505
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:51,870 INFO epoch # 3074 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007628554629263817
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:51,891 INFO epoch # 3075 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007604574098877492
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:51,912 INFO epoch # 3076 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0075953805953759
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:51,933 INFO epoch # 3077 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007780847619869746
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:51,955 INFO epoch # 3078 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007583506623632275
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:51,976 INFO epoch # 3079 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007587195192172658
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:51,997 INFO epoch # 3080 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007614529673446668
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:51,998 INFO *** epoch 3080, rolling-avg-loss (window=10)= 0.007655900581812603
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:52,019 INFO epoch # 3081 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007569322539893619
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:52,041 INFO epoch # 3082 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007568317058940011
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:52,062 INFO epoch # 3083 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007595083976411843
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:52,083 INFO epoch # 3084 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007569416920887306
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:52,104 INFO epoch # 3085 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007628759853105294
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:52,126 INFO epoch # 3086 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008272547949673026
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:52,147 INFO epoch # 3087 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007551537206836656
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:52,168 INFO epoch # 3088 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007564189603726845
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:52,190 INFO epoch # 3089 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007539425494542229
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:52,212 INFO epoch # 3090 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007562940660136519
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:52,212 INFO *** epoch 3090, rolling-avg-loss (window=10)= 0.007642154126415335
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:52,234 INFO epoch # 3091 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007545583121100208
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:52,256 INFO epoch # 3092 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007621199138156953
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:52,278 INFO epoch # 3093 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007546292084953166
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:52,299 INFO epoch # 3094 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008609847043771879
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:52,320 INFO epoch # 3095 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007654762947822746
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:52,341 INFO epoch # 3096 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007556818922239472
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:52,362 INFO epoch # 3097 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007622134611665388
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:52,384 INFO epoch # 3098 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007535048081990681
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:52,405 INFO epoch # 3099 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0076434469265223015
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:52,426 INFO epoch # 3100 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.00752884498979256
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:52,426 INFO *** epoch 3100, rolling-avg-loss (window=10)= 0.007686397786801536
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:52,448 INFO epoch # 3101 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007529470894951373
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:52,469 INFO epoch # 3102 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.00839376226940658
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:52,490 INFO epoch # 3103 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007549854657554533
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:52,512 INFO epoch # 3104 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008745626446398092
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:52,533 INFO epoch # 3105 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007548878302259254
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:52,554 INFO epoch # 3106 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007510513580200495
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:52,576 INFO epoch # 3107 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007907456376415212
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:52,598 INFO epoch # 3108 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.00752536699110351
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:52,619 INFO epoch # 3109 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.00790819348549121
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:52,641 INFO epoch # 3110 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0075415208921185695
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:52,641 INFO *** epoch 3110, rolling-avg-loss (window=10)= 0.007816064389589882
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:52,663 INFO epoch # 3111 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007496081087083439
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:52,685 INFO epoch # 3112 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007487140562261629
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:52,706 INFO epoch # 3113 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007480662318812392
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:52,727 INFO epoch # 3114 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007502133896196028
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:52,749 INFO epoch # 3115 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007482539478587569
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:52,770 INFO epoch # 3116 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0075094651019753655
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:52,791 INFO epoch # 3117 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007506299652959569
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:52,813 INFO epoch # 3118 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0074804138639592566
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:52,834 INFO epoch # 3119 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007477865063265199
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:52,856 INFO epoch # 3120 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007490781321394024
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:52,856 INFO *** epoch 3120, rolling-avg-loss (window=10)= 0.007491338234649448
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:52,877 INFO epoch # 3121 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007487947565095965
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:52,899 INFO epoch # 3122 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007457271018211031
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:52,920 INFO epoch # 3123 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007526852134105866
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:52,941 INFO epoch # 3124 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007496843932131014
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:52,962 INFO epoch # 3125 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007477443356037838
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:52,983 INFO epoch # 3126 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007456373248714954
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:53,005 INFO epoch # 3127 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007453925571098807
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:53,026 INFO epoch # 3128 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007452764104527887
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:53,047 INFO epoch # 3129 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007485225942218676
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:53,069 INFO epoch # 3130 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007456309780536685
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:53,069 INFO *** epoch 3130, rolling-avg-loss (window=10)= 0.007475095665267872
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:53,090 INFO epoch # 3131 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007798493594236788
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:53,112 INFO epoch # 3132 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008862709530149004
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:53,133 INFO epoch # 3133 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007450356517438195
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:53,154 INFO epoch # 3134 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007484086609110818
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:53,175 INFO epoch # 3135 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007447029011018458
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:53,196 INFO epoch # 3136 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007456639417796396
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:53,218 INFO epoch # 3137 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0074092871545872185
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:53,239 INFO epoch # 3138 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.00745839918636193
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:53,261 INFO epoch # 3139 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007445165274475585
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:53,282 INFO epoch # 3140 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0074198326728946995
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:53,282 INFO *** epoch 3140, rolling-avg-loss (window=10)= 0.007623199896806909
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:53,304 INFO epoch # 3141 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.00808520607824903
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:53,326 INFO epoch # 3142 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.009892870242765639
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:53,347 INFO epoch # 3143 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007447734669767669
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:53,368 INFO epoch # 3144 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008304839226184413
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:53,389 INFO epoch # 3145 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0074409738153917715
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:53,411 INFO epoch # 3146 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007415758342176559
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:53,432 INFO epoch # 3147 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007401479277177714
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:53,453 INFO epoch # 3148 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.00739738251286326
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:53,475 INFO epoch # 3149 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007432481899741106
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:53,496 INFO epoch # 3150 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007396648878057022
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:53,497 INFO *** epoch 3150, rolling-avg-loss (window=10)= 0.007821537494237418
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:53,518 INFO epoch # 3151 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007407707322272472
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:53,540 INFO epoch # 3152 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.00745197548167198
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:53,561 INFO epoch # 3153 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007391166082015843
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:53,582 INFO epoch # 3154 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007427749016642338
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:53,603 INFO epoch # 3155 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007381345752037305
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:53,625 INFO epoch # 3156 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007444664926879341
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:53,646 INFO epoch # 3157 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007391499129880685
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:53,667 INFO epoch # 3158 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007404436242723023
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:53,689 INFO epoch # 3159 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007376285793725401
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:53,710 INFO epoch # 3160 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007389280761344708
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:53,710 INFO *** epoch 3160, rolling-avg-loss (window=10)= 0.007406611050919309
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:53,732 INFO epoch # 3161 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007380081264273031
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:53,754 INFO epoch # 3162 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0076514833972396445
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:53,775 INFO epoch # 3163 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007368311929894844
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:53,797 INFO epoch # 3164 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007354025674430886
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:53,818 INFO epoch # 3165 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007352050479312311
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:53,839 INFO epoch # 3166 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007354570594543475
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:53,860 INFO epoch # 3167 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007391448909402243
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:53,882 INFO epoch # 3168 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007352350603468949
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:53,903 INFO epoch # 3169 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007388670936052222
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:53,925 INFO epoch # 3170 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0073502073828422
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:53,925 INFO *** epoch 3170, rolling-avg-loss (window=10)= 0.007394320117145981
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:53,947 INFO epoch # 3171 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007526386858444312
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:53,969 INFO epoch # 3172 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007385706252534874
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:53,990 INFO epoch # 3173 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0073885000638256315
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:54,011 INFO epoch # 3174 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007340110341829131
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:54,033 INFO epoch # 3175 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007453071499185171
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:54,054 INFO epoch # 3176 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007324158585106488
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:54,075 INFO epoch # 3177 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007395177937723929
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:54,097 INFO epoch # 3178 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007343556877458468
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:54,119 INFO epoch # 3179 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007407913122733589
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:54,140 INFO epoch # 3180 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007330659223953262
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:54,141 INFO *** epoch 3180, rolling-avg-loss (window=10)= 0.007389524076279486
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:54,162 INFO epoch # 3181 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0073237305205111625
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:54,183 INFO epoch # 3182 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007348077973801992
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:54,204 INFO epoch # 3183 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007325002372454037
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:54,226 INFO epoch # 3184 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.00796971555428172
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:54,247 INFO epoch # 3185 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008388407779420959
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:54,268 INFO epoch # 3186 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007314131067687413
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:54,289 INFO epoch # 3187 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007301609385649499
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:54,311 INFO epoch # 3188 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007528374626417644
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:54,332 INFO epoch # 3189 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007346565618718159
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:54,354 INFO epoch # 3190 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007292658512596972
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:54,355 INFO *** epoch 3190, rolling-avg-loss (window=10)= 0.007513827341153956
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:54,379 INFO epoch # 3191 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008673907237607636
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:54,401 INFO epoch # 3192 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007375709661573637
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:54,423 INFO epoch # 3193 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0072840240645746235
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:54,444 INFO epoch # 3194 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.00729498737200629
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:54,465 INFO epoch # 3195 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007294904753507581
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:54,486 INFO epoch # 3196 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007286600426596124
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:54,508 INFO epoch # 3197 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.00729225449867954
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:54,529 INFO epoch # 3198 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007355110654316377
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:54,551 INFO epoch # 3199 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007276426833414007
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:54,573 INFO epoch # 3200 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007419968598696869
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:54,573 INFO *** epoch 3200, rolling-avg-loss (window=10)= 0.007455389410097268
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:54,594 INFO epoch # 3201 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007469482905435143
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:54,616 INFO epoch # 3202 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007306964474992128
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:54,638 INFO epoch # 3203 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007258959920818597
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:54,659 INFO epoch # 3204 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007262170631292975
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:54,680 INFO epoch # 3205 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.00726222233788576
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:54,701 INFO epoch # 3206 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.00726123640924925
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:54,723 INFO epoch # 3207 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007245732043884345
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:54,744 INFO epoch # 3208 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.00751851986933616
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:54,766 INFO epoch # 3209 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007620041633344954
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:54,788 INFO epoch # 3210 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007242668505568872
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:54,788 INFO *** epoch 3210, rolling-avg-loss (window=10)= 0.007344799873180818
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:54,809 INFO epoch # 3211 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007494775967643363
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:54,831 INFO epoch # 3212 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0072452953427273314
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:54,852 INFO epoch # 3213 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007245282929943642
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:54,874 INFO epoch # 3214 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0072464391887479
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:54,895 INFO epoch # 3215 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007277916585735511
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:54,916 INFO epoch # 3216 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007291522100786096
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:54,937 INFO epoch # 3217 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007238248908834066
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:54,959 INFO epoch # 3218 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.00751397363274009
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:54,980 INFO epoch # 3219 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007237723551952513
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:55,002 INFO epoch # 3220 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007282341222889954
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:55,002 INFO *** epoch 3220, rolling-avg-loss (window=10)= 0.007307351943200047
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:55,023 INFO epoch # 3221 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007221060383017175
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:55,045 INFO epoch # 3222 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0072839857239159755
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:55,066 INFO epoch # 3223 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007217911284897127
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:55,087 INFO epoch # 3224 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007286029602255439
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:55,109 INFO epoch # 3225 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007207878393273859
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:55,130 INFO epoch # 3226 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008389781733058044
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:55,151 INFO epoch # 3227 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007263660792887094
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:55,172 INFO epoch # 3228 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007202920632153109
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:55,194 INFO epoch # 3229 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007202558108474477
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:55,215 INFO epoch # 3230 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007786552090692567
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:55,215 INFO *** epoch 3230, rolling-avg-loss (window=10)= 0.007406233874462487
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:55,238 INFO epoch # 3231 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007235454337205738
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:55,260 INFO epoch # 3232 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007235867849885835
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:55,281 INFO epoch # 3233 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007289804780157283
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:55,302 INFO epoch # 3234 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007291579848242691
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:55,324 INFO epoch # 3235 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007203944986031274
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:55,345 INFO epoch # 3236 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007173709173912357
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:55,367 INFO epoch # 3237 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.00721522116145934
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:55,389 INFO epoch # 3238 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007181994233178557
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:55,410 INFO epoch # 3239 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007260636886712746
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:55,431 INFO epoch # 3240 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007303251466510119
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:55,432 INFO *** epoch 3240, rolling-avg-loss (window=10)= 0.007239146472329594
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:55,453 INFO epoch # 3241 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007216151483589783
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:55,475 INFO epoch # 3242 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007165287166571943
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:55,497 INFO epoch # 3243 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007184745796621428
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:55,518 INFO epoch # 3244 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007202126726042479
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:55,539 INFO epoch # 3245 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007351805545113166
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:55,560 INFO epoch # 3246 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007212847061964567
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:55,582 INFO epoch # 3247 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0071893154809004045
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:55,604 INFO epoch # 3248 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0071899898830452
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:55,625 INFO epoch # 3249 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007146803188788908
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:55,647 INFO epoch # 3250 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007209364772279514
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:55,647 INFO *** epoch 3250, rolling-avg-loss (window=10)= 0.007206843710491739
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:55,668 INFO epoch # 3251 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007159094577218639
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:55,690 INFO epoch # 3252 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007178824531365535
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:55,711 INFO epoch # 3253 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008018427211936796
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:55,733 INFO epoch # 3254 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007152339502226823
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:55,754 INFO epoch # 3255 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007176046161475824
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:55,775 INFO epoch # 3256 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007142723343349644
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:55,796 INFO epoch # 3257 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007224961238534888
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:55,818 INFO epoch # 3258 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007200591711807647
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:55,839 INFO epoch # 3259 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007135273786843754
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:55,861 INFO epoch # 3260 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007173958554631099
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:55,861 INFO *** epoch 3260, rolling-avg-loss (window=10)= 0.007256224061939065
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:55,882 INFO epoch # 3261 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007263974022862385
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:55,904 INFO epoch # 3262 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007140818117477465
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:55,925 INFO epoch # 3263 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0071586542817385634
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:55,946 INFO epoch # 3264 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007117936755093979
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:55,967 INFO epoch # 3265 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007163647132983897
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:55,989 INFO epoch # 3266 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007127842760382919
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:56,010 INFO epoch # 3267 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007136818956496427
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:56,031 INFO epoch # 3268 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007141628868339467
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:56,053 INFO epoch # 3269 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007165313745645108
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:56,074 INFO epoch # 3270 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0073114430997520685
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:56,074 INFO *** epoch 3270, rolling-avg-loss (window=10)= 0.0071728077740772275
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:56,096 INFO epoch # 3271 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007102595187461702
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:56,118 INFO epoch # 3272 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007117151335478411
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:56,139 INFO epoch # 3273 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0072816049887478584
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:56,160 INFO epoch # 3274 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007805598004779313
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:56,181 INFO epoch # 3275 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007082534812070662
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:56,202 INFO epoch # 3276 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007107609637387213
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:56,224 INFO epoch # 3277 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007115933723980561
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:56,246 INFO epoch # 3278 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0071687595736875664
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:56,267 INFO epoch # 3279 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007089937984346761
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:56,289 INFO epoch # 3280 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007118390278264997
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:56,289 INFO *** epoch 3280, rolling-avg-loss (window=10)= 0.007199011552620505
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:56,310 INFO epoch # 3281 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007082368840201525
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:56,332 INFO epoch # 3282 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007125952331989538
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:56,353 INFO epoch # 3283 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007077018513427902
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:56,375 INFO epoch # 3284 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007109744299668819
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:56,396 INFO epoch # 3285 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007093574726241059
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:56,417 INFO epoch # 3286 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007095707505868631
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:56,438 INFO epoch # 3287 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007199974923423724
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:56,460 INFO epoch # 3288 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0071167873647937085
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:56,481 INFO epoch # 3289 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.00709920090957894
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:56,503 INFO epoch # 3290 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007314832089832635
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:56,503 INFO *** epoch 3290, rolling-avg-loss (window=10)= 0.007131516150502648
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:56,524 INFO epoch # 3291 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007075355837514508
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:56,546 INFO epoch # 3292 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.00704728172513569
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:56,567 INFO epoch # 3293 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007109934675099794
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:56,588 INFO epoch # 3294 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007047167251585051
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:56,609 INFO epoch # 3295 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007044058091196348
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:56,631 INFO epoch # 3296 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007431269232256454
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:56,652 INFO epoch # 3297 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007107507515684119
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:56,673 INFO epoch # 3298 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007063892222504364
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:56,694 INFO epoch # 3299 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.00706156152409676
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:56,716 INFO epoch # 3300 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.00736412547485088
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:56,716 INFO *** epoch 3300, rolling-avg-loss (window=10)= 0.007135215354992397
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:56,738 INFO epoch # 3301 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007059209543513134
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:56,759 INFO epoch # 3302 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007107248857209925
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:56,781 INFO epoch # 3303 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.008174631151632639
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:56,802 INFO epoch # 3304 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007062796217724099
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:56,823 INFO epoch # 3305 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.007068457722198218
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:56,845 INFO epoch # 3306 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.0099 -loss = 0.007091088164088433
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:56,866 INFO epoch # 3307 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.007051977161609102
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:56,887 INFO epoch # 3308 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.007020953611572622
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:56,909 INFO epoch # 3309 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.007085661683959188
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:56,930 INFO epoch # 3310 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.007074384258885402
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:56,930 INFO *** epoch 3310, rolling-avg-loss (window=10)= 0.007179640837239276
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:56,952 INFO epoch # 3311 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.007033327854514937
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:56,974 INFO epoch # 3312 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.007139453658965067
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:56,995 INFO epoch # 3313 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.007029543332464527
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:57,016 INFO epoch # 3314 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.007083023896484519
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:57,037 INFO epoch # 3315 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.0070275962934829295
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:57,058 INFO epoch # 3316 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.007169867698394228
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:57,080 INFO epoch # 3317 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.007082288939272985
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:57,101 INFO epoch # 3318 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.007048526187645621
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:57,122 INFO epoch # 3319 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0098 -loss = 0.00706194878603128
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:57,144 INFO epoch # 3320 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.006994974100962281
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:57,144 INFO *** epoch 3320, rolling-avg-loss (window=10)= 0.007067055074821837
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:57,165 INFO epoch # 3321 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.0070083836690173484
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:57,187 INFO epoch # 3322 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.00699756112680916
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:57,208 INFO epoch # 3323 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.0070234367758530425
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:57,230 INFO epoch # 3324 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.007021262048510835
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:57,251 INFO epoch # 3325 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.006977607805310981
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:57,272 INFO epoch # 3326 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.007277654742210871
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:57,294 INFO epoch # 3327 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.007017590542091057
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:57,315 INFO epoch # 3328 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.00843946873465029
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:57,337 INFO epoch # 3329 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.007056812810333213
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:57,358 INFO epoch # 3330 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.009063977835467085
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:57,358 INFO *** epoch 3330, rolling-avg-loss (window=10)= 0.007388375609025388
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:57,380 INFO epoch # 3331 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.007083127386067645
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:57,402 INFO epoch # 3332 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.007006680367339868
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:57,423 INFO epoch # 3333 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.006997234202572145
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:57,444 INFO epoch # 3334 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.006967082361370558
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:57,465 INFO epoch # 3335 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.00711201572266873
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:57,486 INFO epoch # 3336 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.007004850618614
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:57,507 INFO epoch # 3337 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.006950870511900575
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:57,529 INFO epoch # 3338 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.006962243498492171
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:57,550 INFO epoch # 3339 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.0069851991884206655
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:57,572 INFO epoch # 3340 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.006950930272068945
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:57,572 INFO *** epoch 3340, rolling-avg-loss (window=10)= 0.00700202341295153
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:57,593 INFO epoch # 3341 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.006996736268774839
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:57,615 INFO epoch # 3342 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.0069615756310668075
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:57,636 INFO epoch # 3343 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.007000842664638185
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:57,658 INFO epoch # 3344 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.006963561269003549
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:57,679 INFO epoch # 3345 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.006947619145648787
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:57,700 INFO epoch # 3346 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.007976597188644519
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:57,722 INFO epoch # 3347 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.007593086553242756
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:57,743 INFO epoch # 3348 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.006988008126427303
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:57,765 INFO epoch # 3349 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.006949890848773066
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:57,786 INFO epoch # 3350 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.006944368929907796
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:57,786 INFO *** epoch 3350, rolling-avg-loss (window=10)= 0.007132228662612761
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:57,808 INFO epoch # 3351 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.006936107438377803
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:57,830 INFO epoch # 3352 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.006941853009266197
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:57,851 INFO epoch # 3353 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.006964786247408483
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:57,872 INFO epoch # 3354 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.006990146222960902
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:57,893 INFO epoch # 3355 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.006958489337193896
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:57,915 INFO epoch # 3356 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.007672402214666363
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:57,936 INFO epoch # 3357 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.006966006227230537
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:57,958 INFO epoch # 3358 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.006916295582414023
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:57,979 INFO epoch # 3359 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.006897082882460381
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:58,001 INFO epoch # 3360 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.00698997429026349
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:58,001 INFO *** epoch 3360, rolling-avg-loss (window=10)= 0.007023314345224208
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:58,022 INFO epoch # 3361 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.007459563057636842
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:58,044 INFO epoch # 3362 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.0069141049243626185
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:58,065 INFO epoch # 3363 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.007025169556072797
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:58,087 INFO epoch # 3364 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.006896785806020489
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:58,108 INFO epoch # 3365 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.006960603081097361
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:58,129 INFO epoch # 3366 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.00689729302393971
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:58,150 INFO epoch # 3367 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.006966773614294652
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:58,172 INFO epoch # 3368 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.0068940271657993435
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:58,193 INFO epoch # 3369 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.007042484059638809
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:58,217 INFO epoch # 3370 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.00832870648628159
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:58,217 INFO *** epoch 3370, rolling-avg-loss (window=10)= 0.007138551077514421
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:58,240 INFO epoch # 3371 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.0069028815250931075
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:58,262 INFO epoch # 3372 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.006885823346237885
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:58,283 INFO epoch # 3373 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.006882145251438487
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:58,304 INFO epoch # 3374 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.006979341862461297
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:58,326 INFO epoch # 3375 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.007153928594561876
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:58,347 INFO epoch # 3376 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.006901401204231661
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:58,368 INFO epoch # 3377 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.006892834218888311
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:58,390 INFO epoch # 3378 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.006862960371108784
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:58,412 INFO epoch # 3379 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.006886399489303585
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:58,434 INFO epoch # 3380 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.007501081368900486
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:58,434 INFO *** epoch 3380, rolling-avg-loss (window=10)= 0.006984879723222548
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:58,457 INFO epoch # 3381 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.006895103068018216
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:58,478 INFO epoch # 3382 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.00759272567302105
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:58,500 INFO epoch # 3383 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.006885546637931839
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:58,521 INFO epoch # 3384 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.006911930986461812
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:58,542 INFO epoch # 3385 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.006909810384968296
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:58,563 INFO epoch # 3386 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.006904885662152083
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:58,585 INFO epoch # 3387 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.006857645807031076
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:58,607 INFO epoch # 3388 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.006867041583973332
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:58,628 INFO epoch # 3389 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.006945436536625493
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:58,650 INFO epoch # 3390 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.0068408289462240646
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:58,650 INFO *** epoch 3390, rolling-avg-loss (window=10)= 0.006961095528640726
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:58,671 INFO epoch # 3391 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.006855004363387707
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:58,693 INFO epoch # 3392 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.0068385696031327825
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:58,714 INFO epoch # 3393 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.006821237637268496
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:58,736 INFO epoch # 3394 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.006850611687696073
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:58,757 INFO epoch # 3395 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.006834731533672311
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:58,778 INFO epoch # 3396 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.0068414431989367586
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:58,800 INFO epoch # 3397 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.006858718534203945
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:58,821 INFO epoch # 3398 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.007683424157221452
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:58,843 INFO epoch # 3399 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.007472023775335401
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:58,864 INFO epoch # 3400 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.006957211533517693
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:58,864 INFO *** epoch 3400, rolling-avg-loss (window=10)= 0.007001297602437262
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:58,886 INFO epoch # 3401 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.01012339332010015
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:58,908 INFO epoch # 3402 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.0068887029174220515
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:58,929 INFO epoch # 3403 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.006882654135552002
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:58,950 INFO epoch # 3404 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.006814036623836728
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:58,971 INFO epoch # 3405 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.0068526570375979645
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:58,992 INFO epoch # 3406 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.006822337512858212
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:59,014 INFO epoch # 3407 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.006884302840262535
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:59,035 INFO epoch # 3408 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.006837731762061594
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:59,056 INFO epoch # 3409 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.006937958351045381
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:59,079 INFO epoch # 3410 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.006798310169870092
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:59,079 INFO *** epoch 3410, rolling-avg-loss (window=10)= 0.007184208467060671
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:59,100 INFO epoch # 3411 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.0067964180270791985
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:59,122 INFO epoch # 3412 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.006834883457486285
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:59,143 INFO epoch # 3413 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.006985025516769383
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:59,164 INFO epoch # 3414 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.00883112463998259
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:59,185 INFO epoch # 3415 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.006824366999353515
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:59,206 INFO epoch # 3416 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.006820741542469477
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:59,228 INFO epoch # 3417 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.007418417597364169
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:59,250 INFO epoch # 3418 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.006834142384832376
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:59,271 INFO epoch # 3419 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.0067837534415957634
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:59,293 INFO epoch # 3420 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.0067753772309515625
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:59,293 INFO *** epoch 3420, rolling-avg-loss (window=10)= 0.007090425083788432
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:59,314 INFO epoch # 3421 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.006768994512640347
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:59,336 INFO epoch # 3422 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.006814258676968166
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:59,357 INFO epoch # 3423 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.007408468345602159
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:59,378 INFO epoch # 3424 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.007045736307190964
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:59,399 INFO epoch # 3425 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.006832186943938723
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:59,420 INFO epoch # 3426 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.006822392941103317
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:59,442 INFO epoch # 3427 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.006794625322072534
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:59,463 INFO epoch # 3428 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.006794772034481866
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:59,485 INFO epoch # 3429 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.006767272981960559
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:59,506 INFO epoch # 3430 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.006770153124307399
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:59,506 INFO *** epoch 3430, rolling-avg-loss (window=10)= 0.006881886119026603
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:59,527 INFO epoch # 3431 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.006782896289223572
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:59,549 INFO epoch # 3432 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.00678981877717888
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:59,570 INFO epoch # 3433 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.0067416131964819215
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:59,592 INFO epoch # 3434 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.006759371048246976
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:59,613 INFO epoch # 3435 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.007490822103136452
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:59,634 INFO epoch # 3436 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.006793946638936177
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:59,655 INFO epoch # 3437 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.00675815781687561
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:59,677 INFO epoch # 3438 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.006748325868102256
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:59,698 INFO epoch # 3439 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.006759931220585713
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:59,719 INFO epoch # 3440 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.006900129725181614
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:59,719 INFO *** epoch 3440, rolling-avg-loss (window=10)= 0.006852501268394917
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:59,741 INFO epoch # 3441 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.008163060902006691
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:59,763 INFO epoch # 3442 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.006791931977204513
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:59,785 INFO epoch # 3443 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.0068142812906444306
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:59,806 INFO epoch # 3444 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0097 -loss = 0.006807884930822183
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:59,827 INFO epoch # 3445 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006733296301717928
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:59,848 INFO epoch # 3446 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006759949055776815
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:59,870 INFO epoch # 3447 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.007463420970452717
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:59,891 INFO epoch # 3448 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006794500670366688
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:59,913 INFO epoch # 3449 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006729624908984988
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:59,934 INFO epoch # 3450 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006886537634272827
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:54:59,934 INFO *** epoch 3450, rolling-avg-loss (window=10)= 0.006994448864224978
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:59,956 INFO epoch # 3451 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006730227360094432
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:59,978 INFO epoch # 3452 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.00675969634539797
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:54:59,999 INFO epoch # 3453 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006725281129547511
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:00,020 INFO epoch # 3454 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006711747560984804
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:00,042 INFO epoch # 3455 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006785722540371353
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:00,063 INFO epoch # 3456 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006701060379782575
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:00,084 INFO epoch # 3457 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006714650900903507
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:00,105 INFO epoch # 3458 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.0067397039783827495
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:00,126 INFO epoch # 3459 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006785570547435782
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:00,148 INFO epoch # 3460 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006707480921249953
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:00,148 INFO *** epoch 3460, rolling-avg-loss (window=10)= 0.006736114166415064
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:00,169 INFO epoch # 3461 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.007976831000632956
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:00,190 INFO epoch # 3462 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006701030057229218
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:00,211 INFO epoch # 3463 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006721959942296962
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:00,233 INFO epoch # 3464 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006687292523565702
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:00,254 INFO epoch # 3465 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.0067161311981180916
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:00,275 INFO epoch # 3466 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.009861888702289434
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:00,296 INFO epoch # 3467 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006766434191376902
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:00,318 INFO epoch # 3468 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006737712743415614
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:00,339 INFO epoch # 3469 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006684524238153244
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:00,361 INFO epoch # 3470 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.00672261913496186
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:00,361 INFO *** epoch 3470, rolling-avg-loss (window=10)= 0.007157642373203999
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:00,382 INFO epoch # 3471 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.007102420198862092
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:00,404 INFO epoch # 3472 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006672778509710042
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:00,425 INFO epoch # 3473 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.007902385554189095
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:00,446 INFO epoch # 3474 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006744401092873886
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:00,467 INFO epoch # 3475 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006781286670957343
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:00,489 INFO epoch # 3476 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006677290561128757
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:00,511 INFO epoch # 3477 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006715450384945143
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:00,532 INFO epoch # 3478 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006837618373538135
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:00,554 INFO epoch # 3479 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.0068926459480280755
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:00,575 INFO epoch # 3480 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.007008874394159648
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:00,576 INFO *** epoch 3480, rolling-avg-loss (window=10)= 0.006933515168839222
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:00,597 INFO epoch # 3481 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.0066575183375334746
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:00,619 INFO epoch # 3482 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006693808512864052
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:00,640 INFO epoch # 3483 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006687383549433434
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:00,662 INFO epoch # 3484 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.0066863569409179036
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:00,683 INFO epoch # 3485 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006684316991595551
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:00,704 INFO epoch # 3486 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.0066587145720404806
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:00,725 INFO epoch # 3487 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006669303209491773
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:00,747 INFO epoch # 3488 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006654588682977192
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:00,769 INFO epoch # 3489 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.0066639717124417075
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:00,791 INFO epoch # 3490 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006660107339484966
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:00,791 INFO *** epoch 3490, rolling-avg-loss (window=10)= 0.006671606984878053
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:00,812 INFO epoch # 3491 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006841378493845696
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:00,834 INFO epoch # 3492 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006641294326982461
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:00,855 INFO epoch # 3493 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006651548281297437
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:00,877 INFO epoch # 3494 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006632233580603497
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:00,898 INFO epoch # 3495 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.009736520500155166
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:00,919 INFO epoch # 3496 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006654876375250751
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:00,940 INFO epoch # 3497 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006633187495026505
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:00,961 INFO epoch # 3498 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006722492500557564
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:00,983 INFO epoch # 3499 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006638156250119209
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:01,004 INFO epoch # 3500 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006747638231900055
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:01,004 INFO *** epoch 3500, rolling-avg-loss (window=10)= 0.006989932603573834
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:01,026 INFO epoch # 3501 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006626354561376502
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:01,048 INFO epoch # 3502 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006635862566326978
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:01,069 INFO epoch # 3503 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006604268100090849
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:01,091 INFO epoch # 3504 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006623992248933064
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:01,112 INFO epoch # 3505 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.0066157566216134
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:01,133 INFO epoch # 3506 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006671551669569453
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:01,154 INFO epoch # 3507 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006714783557072224
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:01,176 INFO epoch # 3508 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006835134152424871
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:01,197 INFO epoch # 3509 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006592363966774428
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:01,218 INFO epoch # 3510 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006613889219806879
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:01,218 INFO *** epoch 3510, rolling-avg-loss (window=10)= 0.006653395666398864
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:01,241 INFO epoch # 3511 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006685946114885155
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:01,263 INFO epoch # 3512 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006629528803387075
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:01,284 INFO epoch # 3513 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006591063262476382
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:01,306 INFO epoch # 3514 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006617999479203718
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:01,327 INFO epoch # 3515 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006585951129636669
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:01,348 INFO epoch # 3516 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006597387719011749
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:01,370 INFO epoch # 3517 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006591691677385825
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:01,391 INFO epoch # 3518 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006582820656149124
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:01,413 INFO epoch # 3519 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006821624889198574
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:01,434 INFO epoch # 3520 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006652451398622361
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:01,434 INFO *** epoch 3520, rolling-avg-loss (window=10)= 0.0066356465129956636
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:01,456 INFO epoch # 3521 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.0066134220505773555
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:01,478 INFO epoch # 3522 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006575727953531896
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:01,499 INFO epoch # 3523 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006583537207916379
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:01,520 INFO epoch # 3524 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006575239924131893
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:01,541 INFO epoch # 3525 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006845692951173987
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:01,562 INFO epoch # 3526 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006565119772403705
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:01,584 INFO epoch # 3527 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.0065972995944321156
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:01,605 INFO epoch # 3528 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006586745575987152
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:01,627 INFO epoch # 3529 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006724276587192435
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:01,648 INFO epoch # 3530 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006717178677718039
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:01,648 INFO *** epoch 3530, rolling-avg-loss (window=10)= 0.006638424029506496
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:01,670 INFO epoch # 3531 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006556480988365365
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:01,692 INFO epoch # 3532 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006658542057266459
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:01,713 INFO epoch # 3533 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006556026816724625
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:01,734 INFO epoch # 3534 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006565718849742552
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:01,755 INFO epoch # 3535 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.0065970622690656455
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:01,776 INFO epoch # 3536 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006561929387316923
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:01,798 INFO epoch # 3537 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006596633480512537
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:01,819 INFO epoch # 3538 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006551146672791219
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:01,841 INFO epoch # 3539 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006578773096407531
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:01,862 INFO epoch # 3540 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006545986540913873
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:01,862 INFO *** epoch 3540, rolling-avg-loss (window=10)= 0.006576830015910673
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:01,884 INFO epoch # 3541 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006549675668793498
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:01,906 INFO epoch # 3542 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006585429390725039
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:01,927 INFO epoch # 3543 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006559058638231363
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:01,949 INFO epoch # 3544 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.0065367798906663666
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:01,970 INFO epoch # 3545 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006534395975904772
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:01,991 INFO epoch # 3546 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.007550599035312189
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:02,012 INFO epoch # 3547 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006593963618797716
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:02,034 INFO epoch # 3548 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.0066673304409050616
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:02,056 INFO epoch # 3549 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006561454662005417
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:02,077 INFO epoch # 3550 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006557770579092903
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:02,077 INFO *** epoch 3550, rolling-avg-loss (window=10)= 0.006669645790043433
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:02,099 INFO epoch # 3551 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006554152725584572
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:02,120 INFO epoch # 3552 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006519403408674407
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:02,142 INFO epoch # 3553 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006527898543936317
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:02,163 INFO epoch # 3554 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006549812427692814
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:02,184 INFO epoch # 3555 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006526231642055791
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:02,205 INFO epoch # 3556 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006518458016216755
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:02,227 INFO epoch # 3557 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.008057334112891112
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:02,249 INFO epoch # 3558 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.00659600566723384
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:02,271 INFO epoch # 3559 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.007160301813200931
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:02,293 INFO epoch # 3560 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006496052561487886
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:02,293 INFO *** epoch 3560, rolling-avg-loss (window=10)= 0.006750565091897443
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:02,315 INFO epoch # 3561 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006765423255274072
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:02,337 INFO epoch # 3562 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006548174206727708
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:02,358 INFO epoch # 3563 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.0065706255118129775
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:02,379 INFO epoch # 3564 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.0065194302587769926
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:02,400 INFO epoch # 3565 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006506110135887866
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:02,421 INFO epoch # 3566 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.0067454456839186605
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:02,442 INFO epoch # 3567 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006514512941066641
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:02,464 INFO epoch # 3568 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006490990501333727
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:02,485 INFO epoch # 3569 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006487756571004866
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:02,506 INFO epoch # 3570 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006492764058748435
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:02,507 INFO *** epoch 3570, rolling-avg-loss (window=10)= 0.006564123312455194
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:02,528 INFO epoch # 3571 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006491786890364892
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:02,550 INFO epoch # 3572 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.0064914610811683815
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:02,571 INFO epoch # 3573 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006482186732228001
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:02,592 INFO epoch # 3574 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006511994364700513
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:02,614 INFO epoch # 3575 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006514846512800432
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:02,635 INFO epoch # 3576 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.007170329390646657
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:02,656 INFO epoch # 3577 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006490400059192325
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:02,677 INFO epoch # 3578 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006521531287944526
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:02,699 INFO epoch # 3579 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006462728400038031
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:02,720 INFO epoch # 3580 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006451648079746519
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:02,720 INFO *** epoch 3580, rolling-avg-loss (window=10)= 0.006558891279883028
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:02,742 INFO epoch # 3581 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006472785139521875
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:02,764 INFO epoch # 3582 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.007128266868676292
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:02,786 INFO epoch # 3583 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006465013133492903
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:02,807 INFO epoch # 3584 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006492857106422889
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:02,828 INFO epoch # 3585 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006511719010632078
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:02,849 INFO epoch # 3586 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.00657126932128449
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:02,870 INFO epoch # 3587 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006450668824982131
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:02,892 INFO epoch # 3588 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006474906225776067
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:02,913 INFO epoch # 3589 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006613644125536666
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:02,934 INFO epoch # 3590 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.00645741027983604
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:02,935 INFO *** epoch 3590, rolling-avg-loss (window=10)= 0.006563854003616143
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:02,956 INFO epoch # 3591 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006481026270193979
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:02,978 INFO epoch # 3592 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006437377890506468
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:02,999 INFO epoch # 3593 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006453313169913599
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:03,020 INFO epoch # 3594 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006462195751737454
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:03,041 INFO epoch # 3595 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006478473764218506
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:03,062 INFO epoch # 3596 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.0064493817244510865
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:03,084 INFO epoch # 3597 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.0064892509872152004
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:03,105 INFO epoch # 3598 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.0064467948068340775
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:03,127 INFO epoch # 3599 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.0064365950329374755
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:03,149 INFO epoch # 3600 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006470186633123376
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:03,149 INFO *** epoch 3600, rolling-avg-loss (window=10)= 0.006460459603113122
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:03,171 INFO epoch # 3601 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006724693625073996
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:03,192 INFO epoch # 3602 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006441586057917448
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:03,214 INFO epoch # 3603 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006432645503082313
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:03,235 INFO epoch # 3604 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.0064385034656879725
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:03,256 INFO epoch # 3605 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006525572902319254
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:03,277 INFO epoch # 3606 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.0064227824714180315
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:03,299 INFO epoch # 3607 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.00660752116709773
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:03,321 INFO epoch # 3608 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006476754753748537
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:03,343 INFO epoch # 3609 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006527373214339605
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:03,365 INFO epoch # 3610 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.0064300327703676885
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:03,365 INFO *** epoch 3610, rolling-avg-loss (window=10)= 0.006502746593105258
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:03,387 INFO epoch # 3611 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.007601709137816215
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:03,409 INFO epoch # 3612 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.0064752774487715214
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:03,430 INFO epoch # 3613 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006409879782950156
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:03,451 INFO epoch # 3614 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.00644790486421698
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:03,472 INFO epoch # 3615 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006451061983170803
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:03,493 INFO epoch # 3616 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006402186657396669
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:03,515 INFO epoch # 3617 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006566321835634881
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:03,536 INFO epoch # 3618 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006612242774281185
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:03,558 INFO epoch # 3619 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006419325009119348
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:03,580 INFO epoch # 3620 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006437027566789766
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:03,580 INFO *** epoch 3620, rolling-avg-loss (window=10)= 0.006582293706014752
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:03,602 INFO epoch # 3621 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006395672196049418
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:03,623 INFO epoch # 3622 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006496116357084247
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:03,644 INFO epoch # 3623 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006389078237589274
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:03,665 INFO epoch # 3624 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.00640233552439895
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:03,687 INFO epoch # 3625 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006402047412848333
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:03,708 INFO epoch # 3626 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006425547171602375
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:03,730 INFO epoch # 3627 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.0063983195941546
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:03,752 INFO epoch # 3628 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.00637656285380217
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:03,773 INFO epoch # 3629 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006864211421998334
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:03,795 INFO epoch # 3630 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006377005884587561
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:03,795 INFO *** epoch 3630, rolling-avg-loss (window=10)= 0.006452689665411526
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:03,816 INFO epoch # 3631 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006382119388945284
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:03,838 INFO epoch # 3632 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006394330668626935
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:03,860 INFO epoch # 3633 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006372407110120548
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:03,881 INFO epoch # 3634 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006368783031575731
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:03,902 INFO epoch # 3635 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006464099655204336
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:03,923 INFO epoch # 3636 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006366496949794964
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:03,944 INFO epoch # 3637 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006379092445058632
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:03,965 INFO epoch # 3638 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.0064574083935440285
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:03,987 INFO epoch # 3639 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006363888611303992
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:04,008 INFO epoch # 3640 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006358705045386159
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:04,008 INFO *** epoch 3640, rolling-avg-loss (window=10)= 0.006390733129956061
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:04,030 INFO epoch # 3641 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.007000724514000467
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:04,052 INFO epoch # 3642 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006353824477628223
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:04,073 INFO epoch # 3643 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006345463846628263
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:04,094 INFO epoch # 3644 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006366729556248174
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:04,115 INFO epoch # 3645 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006424728384445189
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:04,136 INFO epoch # 3646 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006454635440604761
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:04,158 INFO epoch # 3647 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006356742958814721
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:04,179 INFO epoch # 3648 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006364507396938279
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:04,200 INFO epoch # 3649 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.0063545888569933595
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:04,222 INFO epoch # 3650 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006390874941644142
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:04,222 INFO *** epoch 3650, rolling-avg-loss (window=10)= 0.0064412820373945575
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:04,244 INFO epoch # 3651 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006348126646116725
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:04,265 INFO epoch # 3652 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006826734259448131
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:04,286 INFO epoch # 3653 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.0068316872348077595
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:04,307 INFO epoch # 3654 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006334653860903927
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:04,328 INFO epoch # 3655 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.007099554086380522
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:04,349 INFO epoch # 3656 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006355655075822142
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:04,371 INFO epoch # 3657 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006336737591482233
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:04,392 INFO epoch # 3658 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006369519640429644
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:04,414 INFO epoch # 3659 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006335821284665144
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:04,436 INFO epoch # 3660 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006337359098324669
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:04,436 INFO *** epoch 3660, rolling-avg-loss (window=10)= 0.006517584877838089
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:04,457 INFO epoch # 3661 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006385945540387183
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:04,479 INFO epoch # 3662 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.007206803949884488
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:04,500 INFO epoch # 3663 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.00634084169723792
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:04,521 INFO epoch # 3664 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.006756527041943627
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:04,543 INFO epoch # 3665 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0096 -loss = 0.0074945170563296415
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:04,564 INFO epoch # 3666 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0096-> 0.0096 -loss = 0.006333842309686588
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:04,586 INFO epoch # 3667 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0096-> 0.0096 -loss = 0.006326526405246113
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:04,608 INFO epoch # 3668 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0096-> 0.0096 -loss = 0.006307616978119768
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:04,630 INFO epoch # 3669 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0096-> 0.0096 -loss = 0.006363694092215155
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:04,652 INFO epoch # 3670 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0096-> 0.0096 -loss = 0.0063495579170194105
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:04,652 INFO *** epoch 3670, rolling-avg-loss (window=10)= 0.006586587298806989
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:04,674 INFO epoch # 3671 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0096-> 0.0096 -loss = 0.006385732085618656
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:04,695 INFO epoch # 3672 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0096-> 0.0096 -loss = 0.006328258248686325
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:04,716 INFO epoch # 3673 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0096-> 0.0096 -loss = 0.006568792246980593
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:04,738 INFO epoch # 3674 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0096-> 0.0096 -loss = 0.006445513759899768
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:04,759 INFO epoch # 3675 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0096-> 0.0096 -loss = 0.008902806224796223
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:04,780 INFO epoch # 3676 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0096-> 0.0096 -loss = 0.006322205485048471
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:04,801 INFO epoch # 3677 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0096-> 0.0096 -loss = 0.006901831744471565
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:04,823 INFO epoch # 3678 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0096-> 0.0096 -loss = 0.006398498320777435
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:04,844 INFO epoch # 3679 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0096-> 0.0095 -loss = 0.0063420029819099
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:04,866 INFO epoch # 3680 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0095-> 0.0095 -loss = 0.006283151261413877
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:04,866 INFO *** epoch 3680, rolling-avg-loss (window=10)= 0.006687879235960282
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:04,888 INFO epoch # 3681 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0095-> 0.0095 -loss = 0.006622180173508241
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:04,910 INFO epoch # 3682 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0095-> 0.0095 -loss = 0.006288878106715856
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:04,931 INFO epoch # 3683 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0095-> 0.0095 -loss = 0.007258321275912749
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:04,952 INFO epoch # 3684 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0095-> 0.0095 -loss = 0.006345341751512024
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:04,973 INFO epoch # 3685 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0095-> 0.0095 -loss = 0.006286145424382994
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:04,995 INFO epoch # 3686 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0095-> 0.0095 -loss = 0.006282918748183874
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:05,016 INFO epoch # 3687 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0095-> 0.0095 -loss = 0.0063011545498739
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:05,038 INFO epoch # 3688 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0095-> 0.0095 -loss = 0.006316099599644076
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:05,060 INFO epoch # 3689 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0095-> 0.0095 -loss = 0.0062981908031360945
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:05,081 INFO epoch # 3690 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0095-> 0.0095 -loss = 0.006263049397603027
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:05,081 INFO *** epoch 3690, rolling-avg-loss (window=10)= 0.006426227983047284
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:05,103 INFO epoch # 3691 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0095-> 0.0095 -loss = 0.006299575426965021
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:05,125 INFO epoch # 3692 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0095-> 0.0095 -loss = 0.006320929915091256
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:05,147 INFO epoch # 3693 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0095-> 0.0095 -loss = 0.007421756388794165
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:05,168 INFO epoch # 3694 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0095-> 0.0095 -loss = 0.006270882076933049
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:05,189 INFO epoch # 3695 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0095-> 0.0095 -loss = 0.006282570140683674
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:05,210 INFO epoch # 3696 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0095-> 0.0095 -loss = 0.006273600465647178
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:05,233 INFO epoch # 3697 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0095-> 0.0095 -loss = 0.006253006982660736
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:05,254 INFO epoch # 3698 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0095-> 0.0095 -loss = 0.006283271950451308
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:05,276 INFO epoch # 3699 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0095-> 0.0095 -loss = 0.006248287200833147
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:05,297 INFO epoch # 3700 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0095-> 0.0095 -loss = 0.006264747311433894
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:05,297 INFO *** epoch 3700, rolling-avg-loss (window=10)= 0.006391862785949343
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:05,319 INFO epoch # 3701 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0095-> 0.0095 -loss = 0.006251802178667276
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:05,341 INFO epoch # 3702 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0095-> 0.0095 -loss = 0.0062478267900587525
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:05,362 INFO epoch # 3703 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0095-> 0.0095 -loss = 0.0062722530419705436
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:05,384 INFO epoch # 3704 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0095-> 0.0095 -loss = 0.006338998189676204
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:05,405 INFO epoch # 3705 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0095-> 0.0095 -loss = 0.006335867059533484
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:05,426 INFO epoch # 3706 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0095-> 0.0095 -loss = 0.00624342799619626
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:05,447 INFO epoch # 3707 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0095-> 0.0095 -loss = 0.006275758202718862
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:05,469 INFO epoch # 3708 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0095-> 0.0095 -loss = 0.00625377820142603
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:05,490 INFO epoch # 3709 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0095-> 0.0095 -loss = 0.0062849928053765325
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:05,511 INFO epoch # 3710 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0095-> 0.0095 -loss = 0.006454993104853202
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:05,511 INFO *** epoch 3710, rolling-avg-loss (window=10)= 0.006295969757047715
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:05,533 INFO epoch # 3711 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0095-> 0.0095 -loss = 0.0063044723065104336
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:05,555 INFO epoch # 3712 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0095-> 0.0095 -loss = 0.006338528546621092
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:05,576 INFO epoch # 3713 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0095-> 0.0095 -loss = 0.006280984525801614
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:05,597 INFO epoch # 3714 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0095-> 0.0095 -loss = 0.0063315407915069954
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:05,618 INFO epoch # 3715 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0095-> 0.0095 -loss = 0.006226550051906088
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:05,639 INFO epoch # 3716 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0095-> 0.0095 -loss = 0.006299730881437426
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:05,661 INFO epoch # 3717 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0095-> 0.0095 -loss = 0.006243389201699756
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:05,682 INFO epoch # 3718 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0095-> 0.0095 -loss = 0.006234043285076041
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:05,704 INFO epoch # 3719 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0095-> 0.0095 -loss = 0.006230865730685764
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:05,726 INFO epoch # 3720 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0095-> 0.0095 -loss = 0.006239749329324695
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:05,726 INFO *** epoch 3720, rolling-avg-loss (window=10)= 0.00627298546505699
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:05,747 INFO epoch # 3721 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0095-> 0.0095 -loss = 0.0063580732075934066
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:05,769 INFO epoch # 3722 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0095-> 0.0095 -loss = 0.006228420084880781
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:05,791 INFO epoch # 3723 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0095-> 0.0095 -loss = 0.006298598998910165
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:05,812 INFO epoch # 3724 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0095-> 0.0095 -loss = 0.006209810490872769
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:05,833 INFO epoch # 3725 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0095-> 0.0095 -loss = 0.006207140098922537
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:05,855 INFO epoch # 3726 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0095-> 0.0095 -loss = 0.006269161433010595
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:05,876 INFO epoch # 3727 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0095-> 0.0095 -loss = 0.00624461137704202
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:05,898 INFO epoch # 3728 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0095-> 0.0095 -loss = 0.006310189106443431
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:05,919 INFO epoch # 3729 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0095-> 0.0095 -loss = 0.0066883053459605435
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:05,941 INFO epoch # 3730 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0095-> 0.0095 -loss = 0.00761916027568077
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:05,941 INFO *** epoch 3730, rolling-avg-loss (window=10)= 0.0064433470419317015
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:05,962 INFO epoch # 3731 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0095-> 0.0095 -loss = 0.006264760742851649
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:05,984 INFO epoch # 3732 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0095-> 0.0095 -loss = 0.006220451989065623
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:06,005 INFO epoch # 3733 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0095-> 0.0095 -loss = 0.006243363166504423
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:06,027 INFO epoch # 3734 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0095-> 0.0095 -loss = 0.006304120306594996
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:06,048 INFO epoch # 3735 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0095-> 0.0095 -loss = 0.006221953561180271
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:06,069 INFO epoch # 3736 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0095-> 0.0094 -loss = 0.00632171360666689
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:06,090 INFO epoch # 3737 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0094-> 0.0094 -loss = 0.006404741126971203
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:06,112 INFO epoch # 3738 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0094-> 0.0094 -loss = 0.006195674703121767
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:06,134 INFO epoch # 3739 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0094-> 0.0094 -loss = 0.006258355673708138
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:06,155 INFO epoch # 3740 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0094-> 0.0094 -loss = 0.006199557406034728
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:06,155 INFO *** epoch 3740, rolling-avg-loss (window=10)= 0.006263469228269969
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:06,177 INFO epoch # 3741 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0094-> 0.0094 -loss = 0.006690118865662953
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:06,198 INFO epoch # 3742 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0094-> 0.0094 -loss = 0.006287808584602317
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:06,220 INFO epoch # 3743 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0094-> 0.0094 -loss = 0.0061950981380505254
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:06,241 INFO epoch # 3744 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0094-> 0.0094 -loss = 0.00623991296015447
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:06,262 INFO epoch # 3745 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0094-> 0.0094 -loss = 0.006174717740577762
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:06,283 INFO epoch # 3746 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0094-> 0.0094 -loss = 0.006189249865201418
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:06,305 INFO epoch # 3747 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0094-> 0.0094 -loss = 0.0062038688447501045
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:06,326 INFO epoch # 3748 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0094-> 0.0094 -loss = 0.006183392662933329
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:06,348 INFO epoch # 3749 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0094-> 0.0094 -loss = 0.006919860807101941
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:06,369 INFO epoch # 3750 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0094-> 0.0094 -loss = 0.006179968149808701
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:06,369 INFO *** epoch 3750, rolling-avg-loss (window=10)= 0.006326399661884352
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:06,391 INFO epoch # 3751 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0094-> 0.0094 -loss = 0.006184889199175814
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:06,413 INFO epoch # 3752 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0094-> 0.0094 -loss = 0.006156421080049768
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:06,435 INFO epoch # 3753 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0094-> 0.0094 -loss = 0.006172825736939558
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:06,456 INFO epoch # 3754 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0094-> 0.0094 -loss = 0.006162166038848227
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:06,477 INFO epoch # 3755 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0094-> 0.0094 -loss = 0.006197177035573986
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:06,498 INFO epoch # 3756 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0094-> 0.0094 -loss = 0.00615785083573428
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:06,520 INFO epoch # 3757 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0094-> 0.0094 -loss = 0.0062664850483997725
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:06,541 INFO epoch # 3758 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0094-> 0.0094 -loss = 0.006199348792506498
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:06,562 INFO epoch # 3759 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0094-> 0.0094 -loss = 0.006202903154189698
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:06,584 INFO epoch # 3760 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0094-> 0.0094 -loss = 0.0062225980200310005
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:06,584 INFO *** epoch 3760, rolling-avg-loss (window=10)= 0.0061922664941448605
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:06,606 INFO epoch # 3761 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0094-> 0.0094 -loss = 0.006146967967652017
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:06,628 INFO epoch # 3762 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0094-> 0.0094 -loss = 0.006153652613647864
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:06,649 INFO epoch # 3763 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0094-> 0.0094 -loss = 0.0061522615596913965
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:06,670 INFO epoch # 3764 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0094-> 0.0094 -loss = 0.006135550100225373
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:06,691 INFO epoch # 3765 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0094-> 0.0094 -loss = 0.006136850264738314
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:06,712 INFO epoch # 3766 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0094-> 0.0094 -loss = 0.006171045062728808
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:06,734 INFO epoch # 3767 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0094-> 0.0094 -loss = 0.006186534885273431
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:06,756 INFO epoch # 3768 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0094-> 0.0094 -loss = 0.006142921170976479
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:06,778 INFO epoch # 3769 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0094-> 0.0094 -loss = 0.00614648907640003
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:06,799 INFO epoch # 3770 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0094-> 0.0094 -loss = 0.006392572804543306
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:06,799 INFO *** epoch 3770, rolling-avg-loss (window=10)= 0.006176484550587702
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:06,821 INFO epoch # 3771 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0094-> 0.0094 -loss = 0.006135815238849318
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:06,843 INFO epoch # 3772 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0094-> 0.0094 -loss = 0.006575493713171454
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:06,864 INFO epoch # 3773 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0094-> 0.0094 -loss = 0.006155660625154269
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:06,885 INFO epoch # 3774 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0094-> 0.0094 -loss = 0.006178440287840203
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:06,906 INFO epoch # 3775 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0094-> 0.0094 -loss = 0.006127406290943327
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:06,927 INFO epoch # 3776 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0094-> 0.0094 -loss = 0.006180072748975363
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:06,949 INFO epoch # 3777 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0094-> 0.0094 -loss = 0.006146471962892974
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:06,970 INFO epoch # 3778 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0094-> 0.0094 -loss = 0.006134386345365783
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:06,992 INFO epoch # 3779 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0094-> 0.0094 -loss = 0.006150765699203475
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:07,014 INFO epoch # 3780 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0094-> 0.0094 -loss = 0.0061544307791336905
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:07,014 INFO *** epoch 3780, rolling-avg-loss (window=10)= 0.006193894369152986
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:07,035 INFO epoch # 3781 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0094-> 0.0094 -loss = 0.006202899243362481
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:07,057 INFO epoch # 3782 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0094-> 0.0094 -loss = 0.006406769638488186
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:07,078 INFO epoch # 3783 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0094-> 0.0094 -loss = 0.006252334459531994
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:07,099 INFO epoch # 3784 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0094-> 0.0094 -loss = 0.006111649370723171
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:07,120 INFO epoch # 3785 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0094-> 0.0094 -loss = 0.006109910271334229
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:07,142 INFO epoch # 3786 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0094-> 0.0094 -loss = 0.006256064050830901
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:07,163 INFO epoch # 3787 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0094-> 0.0094 -loss = 0.006132234133474412
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:07,184 INFO epoch # 3788 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0094-> 0.0094 -loss = 0.0062174593931558775
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:07,206 INFO epoch # 3789 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0094-> 0.0094 -loss = 0.006169775249873055
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:07,229 INFO epoch # 3790 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0094-> 0.0094 -loss = 0.006144726738057216
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:07,229 INFO *** epoch 3790, rolling-avg-loss (window=10)= 0.006200382254883152
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:07,251 INFO epoch # 3791 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0094-> 0.0094 -loss = 0.006109047337304219
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:07,273 INFO epoch # 3792 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0094-> 0.0094 -loss = 0.006182613979035523
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:07,294 INFO epoch # 3793 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0094-> 0.0094 -loss = 0.006102423796619405
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:07,316 INFO epoch # 3794 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0094-> 0.0094 -loss = 0.006090111938647169
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:07,337 INFO epoch # 3795 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0094-> 0.0094 -loss = 0.0061440289591701
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:07,359 INFO epoch # 3796 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0094-> 0.0094 -loss = 0.006148712927824818
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:07,380 INFO epoch # 3797 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0094-> 0.0094 -loss = 0.006486501011750079
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:07,402 INFO epoch # 3798 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0094-> 0.0094 -loss = 0.006098822686908534
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:07,424 INFO epoch # 3799 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0094-> 0.0094 -loss = 0.006088692295634246
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:07,446 INFO epoch # 3800 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0094-> 0.0094 -loss = 0.00614489924555528
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:07,446 INFO *** epoch 3800, rolling-avg-loss (window=10)= 0.006159585417844937
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:07,467 INFO epoch # 3801 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0094-> 0.0094 -loss = 0.006109491287134006
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:07,489 INFO epoch # 3802 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0094-> 0.0094 -loss = 0.00763135302986484
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:07,510 INFO epoch # 3803 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0094-> 0.0094 -loss = 0.006105134034442017
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:07,531 INFO epoch # 3804 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0094-> 0.0094 -loss = 0.0061425217099895235
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:07,552 INFO epoch # 3805 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0094-> 0.0094 -loss = 0.0061307328469411
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:07,573 INFO epoch # 3806 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0094-> 0.0094 -loss = 0.006121703496319242
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:07,595 INFO epoch # 3807 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0094-> 0.0094 -loss = 0.008962877100202604
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:07,616 INFO epoch # 3808 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0094-> 0.0094 -loss = 0.006150396458906471
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:07,638 INFO epoch # 3809 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0094-> 0.0094 -loss = 0.006089249691285659
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:07,660 INFO epoch # 3810 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0094-> 0.0093 -loss = 0.00892455194843933
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:07,660 INFO *** epoch 3810, rolling-avg-loss (window=10)= 0.0068368011603524795
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:07,682 INFO epoch # 3811 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.006094205973568023
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:07,704 INFO epoch # 3812 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.006107275818067137
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:07,725 INFO epoch # 3813 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.0060666263261737186
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:07,747 INFO epoch # 3814 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.0063066095990507165
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:07,768 INFO epoch # 3815 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.006145741583168274
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:07,789 INFO epoch # 3816 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.0060517790184349
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:07,810 INFO epoch # 3817 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.006207396187164704
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:07,832 INFO epoch # 3818 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.006069168895919574
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:07,854 INFO epoch # 3819 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.006072580383261084
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:07,875 INFO epoch # 3820 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.006049468876881292
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:07,875 INFO *** epoch 3820, rolling-avg-loss (window=10)= 0.006117085266168942
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:07,897 INFO epoch # 3821 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.006061166088329628
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:07,919 INFO epoch # 3822 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.0061090073413652135
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:07,940 INFO epoch # 3823 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.00608837000982021
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:07,961 INFO epoch # 3824 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.0060475647642306285
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:07,983 INFO epoch # 3825 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.0060392407290237315
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:08,004 INFO epoch # 3826 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.006076794954424258
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:08,025 INFO epoch # 3827 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.00607866799691692
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:08,047 INFO epoch # 3828 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.006064468865588424
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:08,068 INFO epoch # 3829 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.006113482420914806
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:08,089 INFO epoch # 3830 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.006044348261639243
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:08,089 INFO *** epoch 3830, rolling-avg-loss (window=10)= 0.006072311143225306
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:08,111 INFO epoch # 3831 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.006121015683675068
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:08,132 INFO epoch # 3832 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.006036584987668903
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:08,153 INFO epoch # 3833 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.0060335371399560245
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:08,174 INFO epoch # 3834 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.006269599569350248
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:08,195 INFO epoch # 3835 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.00739944250381086
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:08,216 INFO epoch # 3836 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.006068579617931391
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:08,239 INFO epoch # 3837 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.006033015830325894
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:08,260 INFO epoch # 3838 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.006061935133402585
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:08,282 INFO epoch # 3839 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.0060477969782368746
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:08,304 INFO epoch # 3840 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.006084769936933299
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:08,304 INFO *** epoch 3840, rolling-avg-loss (window=10)= 0.006215627738129115
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:08,325 INFO epoch # 3841 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.006038552393874852
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:08,346 INFO epoch # 3842 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.006085230015742127
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:08,368 INFO epoch # 3843 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.0060199516110515106
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:08,389 INFO epoch # 3844 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.006041438929969445
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:08,410 INFO epoch # 3845 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.006102861352701439
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:08,431 INFO epoch # 3846 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.006030459369867458
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:08,452 INFO epoch # 3847 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.006044888483302202
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:08,473 INFO epoch # 3848 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.006016813233145513
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:08,495 INFO epoch # 3849 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.006078805676224874
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:08,516 INFO epoch # 3850 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.006045965242265083
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:08,516 INFO *** epoch 3850, rolling-avg-loss (window=10)= 0.00605049663081445
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:08,538 INFO epoch # 3851 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.0060526029501488665
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:08,560 INFO epoch # 3852 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.006005160985296243
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:08,581 INFO epoch # 3853 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.006019050375471124
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:08,602 INFO epoch # 3854 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.00605595486558741
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:08,623 INFO epoch # 3855 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.006003495561344607
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:08,644 INFO epoch # 3856 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.00598936026199226
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:08,666 INFO epoch # 3857 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.00600815824327583
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:08,687 INFO epoch # 3858 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.006047662889614003
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:08,708 INFO epoch # 3859 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.005997346681397175
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:08,730 INFO epoch # 3860 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.006110830103352782
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:08,730 INFO *** epoch 3860, rolling-avg-loss (window=10)= 0.00602896229174803
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:08,752 INFO epoch # 3861 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.006014217986376025
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:08,773 INFO epoch # 3862 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.006566223784830072
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:08,794 INFO epoch # 3863 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.006072534330087365
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:08,815 INFO epoch # 3864 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.005994178451146581
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:08,837 INFO epoch # 3865 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.006019288653988042
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:08,858 INFO epoch # 3866 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.00606821353903797
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:08,879 INFO epoch # 3867 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.005987193250803102
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:08,901 INFO epoch # 3868 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.005985565381706692
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:08,922 INFO epoch # 3869 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.006977441926210304
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:08,943 INFO epoch # 3870 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.006052372220437974
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:08,943 INFO *** epoch 3870, rolling-avg-loss (window=10)= 0.006173722952462412
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:08,965 INFO epoch # 3871 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.0059905342113779625
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:08,986 INFO epoch # 3872 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.005974954679913935
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:09,007 INFO epoch # 3873 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.005993046341245645
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:09,028 INFO epoch # 3874 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.005981006767797226
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:09,049 INFO epoch # 3875 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.005964289586245286
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:09,070 INFO epoch # 3876 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.00597942139756924
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:09,092 INFO epoch # 3877 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.00605403561348794
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:09,113 INFO epoch # 3878 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.006686795964924386
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:09,135 INFO epoch # 3879 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.005974869994133769
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:09,156 INFO epoch # 3880 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.00599165902895038
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:09,156 INFO *** epoch 3880, rolling-avg-loss (window=10)= 0.006059061358564577
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:09,178 INFO epoch # 3881 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.006049590885595535
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:09,199 INFO epoch # 3882 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.005970870673991158
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:09,220 INFO epoch # 3883 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.005958294707852474
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:09,242 INFO epoch # 3884 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.006019627024215879
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:09,264 INFO epoch # 3885 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.005991920582346211
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:09,285 INFO epoch # 3886 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.005974140116450144
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:09,306 INFO epoch # 3887 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.005962610290225712
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:09,328 INFO epoch # 3888 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.006005797411489766
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:09,349 INFO epoch # 3889 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.00594016914101303
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:09,371 INFO epoch # 3890 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.005951067272690125
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:09,371 INFO *** epoch 3890, rolling-avg-loss (window=10)= 0.005982408810587004
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:09,392 INFO epoch # 3891 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.006013725442244322
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:09,413 INFO epoch # 3892 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.005958538080449216
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:09,435 INFO epoch # 3893 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.005959852034720825
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:09,456 INFO epoch # 3894 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.005958458541499567
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:09,477 INFO epoch # 3895 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.00597151198235224
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:09,498 INFO epoch # 3896 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.005971151989797363
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:09,519 INFO epoch # 3897 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.005939395403402159
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:09,541 INFO epoch # 3898 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.005944625272604753
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:09,562 INFO epoch # 3899 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.006375012275384506
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:09,584 INFO epoch # 3900 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.005942265526755364
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:09,584 INFO *** epoch 3900, rolling-avg-loss (window=10)= 0.006003453654921031
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:09,605 INFO epoch # 3901 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.00593825462510722
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:09,627 INFO epoch # 3902 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.005978243458230281
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:09,648 INFO epoch # 3903 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.006106670505687362
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:09,670 INFO epoch # 3904 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.005969962068775203
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:09,691 INFO epoch # 3905 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.005930529420766106
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:09,712 INFO epoch # 3906 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.006040436128387228
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:09,735 INFO epoch # 3907 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.005943636347183201
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:09,756 INFO epoch # 3908 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.005926667387029738
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:09,777 INFO epoch # 3909 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.005912651266044122
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:09,799 INFO epoch # 3910 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.005974142224658863
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:09,799 INFO *** epoch 3910, rolling-avg-loss (window=10)= 0.0059721193431869326
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:09,820 INFO epoch # 3911 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.005907781081987196
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:09,842 INFO epoch # 3912 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.005924110355408629
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:09,863 INFO epoch # 3913 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.005930247216383577
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:09,884 INFO epoch # 3914 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.005916945808166929
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:09,905 INFO epoch # 3915 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.005960934739050572
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:09,926 INFO epoch # 3916 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.005906938868065481
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:09,948 INFO epoch # 3917 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.006640354231421952
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:09,969 INFO epoch # 3918 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.005916743328270968
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:09,990 INFO epoch # 3919 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.005919454581089667
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:10,012 INFO epoch # 3920 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.005946383598711691
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:10,012 INFO *** epoch 3920, rolling-avg-loss (window=10)= 0.005996989380855666
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:10,034 INFO epoch # 3921 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.005928336127908551
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:10,056 INFO epoch # 3922 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.005897884102523676
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:10,077 INFO epoch # 3923 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.006050974438039702
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:10,098 INFO epoch # 3924 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.005902995359065244
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:10,119 INFO epoch # 3925 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.005947880012172391
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:10,141 INFO epoch # 3926 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.006005770701449364
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:10,162 INFO epoch # 3927 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.005889466322514636
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:10,183 INFO epoch # 3928 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.005875005968391633
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:10,205 INFO epoch # 3929 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.00590412590008782
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:10,227 INFO epoch # 3930 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.005917847276577959
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:10,227 INFO *** epoch 3930, rolling-avg-loss (window=10)= 0.0059320286208730975
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:10,249 INFO epoch # 3931 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.005935117367698695
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:10,271 INFO epoch # 3932 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.005908132296099211
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:10,293 INFO epoch # 3933 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.005916286314459285
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:10,314 INFO epoch # 3934 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.005963825668004574
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:10,335 INFO epoch # 3935 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.006012951793309185
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:10,356 INFO epoch # 3936 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.005897917431866517
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:10,378 INFO epoch # 3937 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.005906460381083889
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:10,400 INFO epoch # 3938 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.0063084678340601386
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:10,422 INFO epoch # 3939 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0092 -loss = 0.005916193249504431
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:10,444 INFO epoch # 3940 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.005911258407650166
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:10,444 INFO *** epoch 3940, rolling-avg-loss (window=10)= 0.005967661074373609
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:10,466 INFO epoch # 3941 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.005894683985388838
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:10,488 INFO epoch # 3942 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.00586748133173387
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:10,509 INFO epoch # 3943 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.00588858295668615
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:10,531 INFO epoch # 3944 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.006299779990513343
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:10,552 INFO epoch # 3945 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.005892616380151594
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:10,573 INFO epoch # 3946 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.00586333354931412
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:10,595 INFO epoch # 3947 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.005879301857930841
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:10,618 INFO epoch # 3948 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.005970928841634304
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:10,640 INFO epoch # 3949 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.005882540250240709
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:10,662 INFO epoch # 3950 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.005913593002333073
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:10,662 INFO *** epoch 3950, rolling-avg-loss (window=10)= 0.005935284214592685
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:10,684 INFO epoch # 3951 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.005996736630550004
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:10,706 INFO epoch # 3952 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.005851014912423125
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:10,728 INFO epoch # 3953 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.005893056762943161
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:10,749 INFO epoch # 3954 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.00586722915613791
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:10,770 INFO epoch # 3955 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.005884160449568299
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:10,791 INFO epoch # 3956 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.006006528931720823
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:10,813 INFO epoch # 3957 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.005871586668035889
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:10,834 INFO epoch # 3958 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.005878248513909057
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:10,856 INFO epoch # 3959 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.005875182052477612
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:10,878 INFO epoch # 3960 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.0058460923755774274
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:10,878 INFO *** epoch 3960, rolling-avg-loss (window=10)= 0.005896983645334331
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:10,900 INFO epoch # 3961 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.005868471595022129
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:10,921 INFO epoch # 3962 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.007151284666178981
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:10,943 INFO epoch # 3963 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.007158924201576156
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:10,964 INFO epoch # 3964 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.00587284781067865
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:10,985 INFO epoch # 3965 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.005833653337958822
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:11,007 INFO epoch # 3966 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.005853667506016791
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:11,028 INFO epoch # 3967 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.005876516816897492
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:11,050 INFO epoch # 3968 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.005828312952871784
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:11,071 INFO epoch # 3969 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.005983016888421844
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:11,093 INFO epoch # 3970 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.0058360533803352155
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:11,093 INFO *** epoch 3970, rolling-avg-loss (window=10)= 0.006126274915595786
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:11,115 INFO epoch # 3971 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.005829494510180666
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:11,137 INFO epoch # 3972 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.005832752411151887
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:11,158 INFO epoch # 3973 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.005878615882465965
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:11,179 INFO epoch # 3974 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.005838479426529375
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:11,200 INFO epoch # 3975 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.005884409900318133
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:11,222 INFO epoch # 3976 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.0058310241238359595
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:11,244 INFO epoch # 3977 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.005850040983204963
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:11,266 INFO epoch # 3978 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.005827953213156434
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:11,288 INFO epoch # 3979 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.005816316794152954
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:11,310 INFO epoch # 3980 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.005810071104860981
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:11,310 INFO *** epoch 3980, rolling-avg-loss (window=10)= 0.005839915834985732
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:11,332 INFO epoch # 3981 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.005844749390234938
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:11,353 INFO epoch # 3982 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.005898615028854692
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:11,374 INFO epoch # 3983 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.005870453545867349
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:11,396 INFO epoch # 3984 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.005870159086043714
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:11,417 INFO epoch # 3985 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.005812650803818542
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:11,438 INFO epoch # 3986 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.005834245307596575
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:11,459 INFO epoch # 3987 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.0058099050820601406
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:11,481 INFO epoch # 3988 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.005831238448081422
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:11,502 INFO epoch # 3989 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.0058070847853741725
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:11,524 INFO epoch # 3990 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.007016018660578993
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:11,524 INFO *** epoch 3990, rolling-avg-loss (window=10)= 0.005959512013851054
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:11,546 INFO epoch # 3991 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.005811144779727329
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:11,567 INFO epoch # 3992 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.005823651208629599
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:11,588 INFO epoch # 3993 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.00579896347153408
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:11,609 INFO epoch # 3994 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.005812065808640909
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:11,631 INFO epoch # 3995 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.00591860322492721
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:11,652 INFO epoch # 3996 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.005840036844347196
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:11,673 INFO epoch # 3997 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.005877474659428117
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:11,695 INFO epoch # 3998 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.0059117411910847295
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:11,716 INFO epoch # 3999 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.005811865834402852
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:11,739 INFO epoch # 4000 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.005816729402795318
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:11,739 INFO *** epoch 4000, rolling-avg-loss (window=10)= 0.005842227642551734
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:11,761 INFO epoch # 4001 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.00598082439864811
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:11,782 INFO epoch # 4002 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.00580469831766095
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:11,804 INFO epoch # 4003 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.005780711081570189
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:11,825 INFO epoch # 4004 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.005781642851616198
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:11,846 INFO epoch # 4005 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.005809104508443852
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:11,867 INFO epoch # 4006 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.00578417936412734
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:11,888 INFO epoch # 4007 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.00600122496689437
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:11,909 INFO epoch # 4008 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.0059608280898828525
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:11,931 INFO epoch # 4009 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.005915101390201016
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:11,952 INFO epoch # 4010 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.005849645869602682
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:11,952 INFO *** epoch 4010, rolling-avg-loss (window=10)= 0.005866796083864756
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:11,974 INFO epoch # 4011 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.005796734001705772
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:11,995 INFO epoch # 4012 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.0057620675333964755
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:12,017 INFO epoch # 4013 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.005755531942668313
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:12,038 INFO epoch # 4014 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.006394414118403802
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:12,059 INFO epoch # 4015 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.005807685663967277
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:12,080 INFO epoch # 4016 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.005798565220175078
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:12,102 INFO epoch # 4017 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.005773361001047306
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:12,123 INFO epoch # 4018 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.005761617247117101
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:12,145 INFO epoch # 4019 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.005764759793237317
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:12,166 INFO epoch # 4020 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.005750058582634665
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:12,166 INFO *** epoch 4020, rolling-avg-loss (window=10)= 0.005836479510435311
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:12,187 INFO epoch # 4021 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.005795167104224674
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:12,209 INFO epoch # 4022 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.006224202180419525
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:12,230 INFO epoch # 4023 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.005972393501906481
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:12,251 INFO epoch # 4024 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.0057543819029888255
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:12,272 INFO epoch # 4025 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.005878564757949789
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:12,293 INFO epoch # 4026 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.0057472989301459165
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:12,315 INFO epoch # 4027 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.005758380993938772
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:12,336 INFO epoch # 4028 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.005753798754085437
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:12,358 INFO epoch # 4029 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.005813699475766043
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:12,379 INFO epoch # 4030 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.006722642554450431
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:12,379 INFO *** epoch 4030, rolling-avg-loss (window=10)= 0.0059420530155875895
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:12,401 INFO epoch # 4031 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.005768096985775628
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:12,422 INFO epoch # 4032 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.007372311671133502
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:12,443 INFO epoch # 4033 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.0057483440068608616
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:12,464 INFO epoch # 4034 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.005747629793404485
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:12,485 INFO epoch # 4035 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.005805121892990428
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:12,507 INFO epoch # 4036 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.005741996463257237
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:12,528 INFO epoch # 4037 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.005769970917754108
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:12,550 INFO epoch # 4038 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.0057230543534387834
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:12,572 INFO epoch # 4039 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.005735277882195078
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:12,594 INFO epoch # 4040 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.005797353565867525
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:12,594 INFO *** epoch 4040, rolling-avg-loss (window=10)= 0.005920915753267764
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:12,616 INFO epoch # 4041 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.005746513901613071
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:12,638 INFO epoch # 4042 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.005776986989076249
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:12,659 INFO epoch # 4043 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.005741567538279924
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:12,680 INFO epoch # 4044 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.006115628993939026
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:12,701 INFO epoch # 4045 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.005721307228668593
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:12,722 INFO epoch # 4046 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.005761029971836251
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:12,744 INFO epoch # 4047 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.0057556150222808355
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:12,766 INFO epoch # 4048 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.005715131716897304
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:12,788 INFO epoch # 4049 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.0057525148113199975
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:12,810 INFO epoch # 4050 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.005728190202717087
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:12,810 INFO *** epoch 4050, rolling-avg-loss (window=10)= 0.005781448637662834
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:12,831 INFO epoch # 4051 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.005731118406401947
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:12,853 INFO epoch # 4052 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.005761821936175693
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:12,875 INFO epoch # 4053 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.0057118970526062185
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:12,896 INFO epoch # 4054 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.005735147398809204
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:12,917 INFO epoch # 4055 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.007533295276516583
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:12,938 INFO epoch # 4056 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.005765349522334873
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:12,959 INFO epoch # 4057 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.00573156099562766
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:12,981 INFO epoch # 4058 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.005708007474822807
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:13,003 INFO epoch # 4059 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.005724031734644086
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:13,025 INFO epoch # 4060 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.005710452920538955
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:13,025 INFO *** epoch 4060, rolling-avg-loss (window=10)= 0.005911268271847803
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:13,047 INFO epoch # 4061 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.005713146034395322
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:13,068 INFO epoch # 4062 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.005819304880787968
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:13,089 INFO epoch # 4063 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.005828473626024788
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:13,111 INFO epoch # 4064 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.0058155966544291005
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:13,132 INFO epoch # 4065 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.005694486542779487
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:13,153 INFO epoch # 4066 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.005721622555938666
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:13,174 INFO epoch # 4067 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.0057415019982727244
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:13,195 INFO epoch # 4068 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.005709100080821372
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:13,217 INFO epoch # 4069 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.005691281422514294
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:13,239 INFO epoch # 4070 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.0057023804965865565
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:13,239 INFO *** epoch 4070, rolling-avg-loss (window=10)= 0.005743689429255028
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:13,261 INFO epoch # 4071 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.005727017617573438
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:13,283 INFO epoch # 4072 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.005688747580279596
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:13,305 INFO epoch # 4073 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.005731578159611672
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:13,326 INFO epoch # 4074 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.00572186621138826
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:13,347 INFO epoch # 4075 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.005808055806483026
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:13,368 INFO epoch # 4076 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.005683020267497341
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:13,389 INFO epoch # 4077 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.005697203905583592
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:13,411 INFO epoch # 4078 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.005694523173588095
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:13,432 INFO epoch # 4079 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.006175527596496977
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:13,455 INFO epoch # 4080 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.005671398257618421
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:13,455 INFO *** epoch 4080, rolling-avg-loss (window=10)= 0.005759893857612042
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:13,477 INFO epoch # 4081 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.006221293046110077
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:13,499 INFO epoch # 4082 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.005676114464222337
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:13,521 INFO epoch # 4083 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.00571031789695553
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:13,542 INFO epoch # 4084 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.005671757833624724
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:13,563 INFO epoch # 4085 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.005706275300326524
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:13,584 INFO epoch # 4086 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.005694014002074255
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:13,606 INFO epoch # 4087 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.005670546315741376
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:13,628 INFO epoch # 4088 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.005666844819643302
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:13,649 INFO epoch # 4089 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.006167136743897572
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:13,671 INFO epoch # 4090 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.005676466709701344
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:13,671 INFO *** epoch 4090, rolling-avg-loss (window=10)= 0.005786076713229704
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:13,693 INFO epoch # 4091 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.006967790770431748
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:13,714 INFO epoch # 4092 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.005734238322474994
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:13,736 INFO epoch # 4093 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.005676790220604744
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:13,758 INFO epoch # 4094 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.005686269353645912
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:13,779 INFO epoch # 4095 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.005682749058905756
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:13,800 INFO epoch # 4096 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.005688044871931197
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:13,821 INFO epoch # 4097 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.005678464835000341
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:13,843 INFO epoch # 4098 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.005662546151143033
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:13,864 INFO epoch # 4099 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.006926807653144351
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:13,886 INFO epoch # 4100 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.005721977080611396
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:13,886 INFO *** epoch 4100, rolling-avg-loss (window=10)= 0.005942567831789347
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:13,907 INFO epoch # 4101 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.005723439458961366
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:13,929 INFO epoch # 4102 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.005746786366216838
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:13,950 INFO epoch # 4103 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.006712259566484136
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:13,972 INFO epoch # 4104 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.005662877515533182
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:13,993 INFO epoch # 4105 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.005648776745147188
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:14,014 INFO epoch # 4106 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.005670420317983371
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:14,037 INFO epoch # 4107 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.006123646318883402
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:14,059 INFO epoch # 4108 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.00587016440476873
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:14,081 INFO epoch # 4109 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.005822920787977637
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:14,103 INFO epoch # 4110 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.005644179307637387
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:14,103 INFO *** epoch 4110, rolling-avg-loss (window=10)= 0.0058625470789593235
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:14,125 INFO epoch # 4111 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.005678780305970577
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:14,147 INFO epoch # 4112 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.00564459820088814
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:14,168 INFO epoch # 4113 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.005669834004038421
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:14,190 INFO epoch # 4114 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.005629017648061563
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:14,211 INFO epoch # 4115 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.0056455521034877165
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:14,233 INFO epoch # 4116 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.00569154695403995
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:14,256 INFO epoch # 4117 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.005828057874168735
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:14,278 INFO epoch # 4118 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.005629133533147979
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:14,300 INFO epoch # 4119 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.005616441852907883
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:14,322 INFO epoch # 4120 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.005631016699226166
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:14,322 INFO *** epoch 4120, rolling-avg-loss (window=10)= 0.005666397917593713
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:14,344 INFO epoch # 4121 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.006096060737036169
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:14,366 INFO epoch # 4122 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.005659243695845362
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:14,388 INFO epoch # 4123 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.005637437508994481
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:14,409 INFO epoch # 4124 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.0056279975397046655
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:14,430 INFO epoch # 4125 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.006092875151807675
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:14,451 INFO epoch # 4126 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.005696579088180442
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:14,473 INFO epoch # 4127 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.006015907543769572
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:14,494 INFO epoch # 4128 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.005661171753672534
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:14,516 INFO epoch # 4129 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.005623637947792304
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:14,539 INFO epoch # 4130 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0091 -loss = 0.006874299211631296
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:14,539 INFO *** epoch 4130, rolling-avg-loss (window=10)= 0.00589852101784345
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:14,561 INFO epoch # 4131 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0091-> 0.0091 -loss = 0.0056438784467900405
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:14,583 INFO epoch # 4132 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0091-> 0.0091 -loss = 0.005617304872430395
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:14,605 INFO epoch # 4133 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0091-> 0.0091 -loss = 0.005604406143902452
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:14,626 INFO epoch # 4134 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0091-> 0.0091 -loss = 0.005612231323539163
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:14,647 INFO epoch # 4135 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0091-> 0.0091 -loss = 0.005600207065072027
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:14,669 INFO epoch # 4136 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0091-> 0.0091 -loss = 0.005588848708157457
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:14,690 INFO epoch # 4137 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0091-> 0.0091 -loss = 0.005613044228084618
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:14,711 INFO epoch # 4138 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0091-> 0.0091 -loss = 0.0055952692455321085
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:14,733 INFO epoch # 4139 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0091-> 0.0091 -loss = 0.0056418965959892375
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:14,755 INFO epoch # 4140 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0091-> 0.0091 -loss = 0.005588169939528598
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:14,755 INFO *** epoch 4140, rolling-avg-loss (window=10)= 0.0056105256569026095
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:14,776 INFO epoch # 4141 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0091-> 0.0091 -loss = 0.00562485767659382
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:14,798 INFO epoch # 4142 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0091-> 0.0091 -loss = 0.005685787060428993
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:14,819 INFO epoch # 4143 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0091-> 0.0091 -loss = 0.005601949518677429
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:14,840 INFO epoch # 4144 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0091-> 0.0091 -loss = 0.005618652641715016
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:14,862 INFO epoch # 4145 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0091-> 0.0091 -loss = 0.005590735566329386
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:14,883 INFO epoch # 4146 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0091-> 0.0091 -loss = 0.005586443878200953
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:14,904 INFO epoch # 4147 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0091-> 0.0091 -loss = 0.006554432860866655
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:14,926 INFO epoch # 4148 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0091-> 0.0091 -loss = 0.005590993795522081
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:14,947 INFO epoch # 4149 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0091-> 0.0091 -loss = 0.005585693830653327
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:14,969 INFO epoch # 4150 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0091-> 0.0091 -loss = 0.005601565129836672
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:14,969 INFO *** epoch 4150, rolling-avg-loss (window=10)= 0.005704111195882433
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:14,991 INFO epoch # 4151 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0091-> 0.0091 -loss = 0.005597885699899052
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:15,012 INFO epoch # 4152 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0091-> 0.0091 -loss = 0.005576197248956305
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:15,034 INFO epoch # 4153 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0091-> 0.0091 -loss = 0.005643559173222457
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:15,055 INFO epoch # 4154 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0091-> 0.0091 -loss = 0.005622036411295994
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:15,076 INFO epoch # 4155 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0091-> 0.0091 -loss = 0.007087263214998529
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:15,097 INFO epoch # 4156 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0091-> 0.0091 -loss = 0.005582790630796808
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:15,118 INFO epoch # 4157 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0091-> 0.0091 -loss = 0.005571146416514239
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:15,140 INFO epoch # 4158 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0091-> 0.0091 -loss = 0.0055612372134419275
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:15,161 INFO epoch # 4159 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0091-> 0.0091 -loss = 0.005613965053271386
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:15,183 INFO epoch # 4160 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0091-> 0.0091 -loss = 0.005617464035822195
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:15,183 INFO *** epoch 4160, rolling-avg-loss (window=10)= 0.005747354509821889
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:15,204 INFO epoch # 4161 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0091-> 0.0091 -loss = 0.00562365366567974
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:15,226 INFO epoch # 4162 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0091-> 0.0091 -loss = 0.005555872012337204
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:15,248 INFO epoch # 4163 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0091-> 0.0091 -loss = 0.005649390903272433
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:15,269 INFO epoch # 4164 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0091-> 0.0091 -loss = 0.0055514946643597796
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:15,290 INFO epoch # 4165 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0091-> 0.0091 -loss = 0.005593108080574893
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:15,312 INFO epoch # 4166 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0091-> 0.0091 -loss = 0.005552977031584305
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:15,333 INFO epoch # 4167 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0091-> 0.0091 -loss = 0.005601595172265661
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:15,355 INFO epoch # 4168 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0091-> 0.0091 -loss = 0.005591879942585365
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:15,376 INFO epoch # 4169 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0091-> 0.0091 -loss = 0.00554197248266064
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:15,398 INFO epoch # 4170 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0091-> 0.0091 -loss = 0.005563092894590227
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:15,398 INFO *** epoch 4170, rolling-avg-loss (window=10)= 0.005582503684991025
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:15,420 INFO epoch # 4171 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0091-> 0.0091 -loss = 0.005555625008128118
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:15,441 INFO epoch # 4172 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0091-> 0.0091 -loss = 0.0055897117581480416
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:15,463 INFO epoch # 4173 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0091-> 0.0091 -loss = 0.005651039438816952
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:15,484 INFO epoch # 4174 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0091-> 0.0091 -loss = 0.005543822167055623
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:15,505 INFO epoch # 4175 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0091-> 0.0091 -loss = 0.005573884055593226
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:15,526 INFO epoch # 4176 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0091-> 0.0091 -loss = 0.005747671122662723
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:15,548 INFO epoch # 4177 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0091-> 0.0091 -loss = 0.005548139786696993
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:15,569 INFO epoch # 4178 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0091-> 0.0091 -loss = 0.005567797077674186
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:15,591 INFO epoch # 4179 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0091-> 0.0091 -loss = 0.005544432025999413
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:15,613 INFO epoch # 4180 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0091-> 0.009 -loss = 0.005570057277509477
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:15,613 INFO *** epoch 4180, rolling-avg-loss (window=10)= 0.005589217971828475
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:15,635 INFO epoch # 4181 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.009 -loss = 0.005539018021408992
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:15,657 INFO epoch # 4182 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.009 -loss = 0.005589128973952029
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:15,678 INFO epoch # 4183 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.009 -loss = 0.0055474195833085105
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:15,699 INFO epoch # 4184 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.009 -loss = 0.005530416590772802
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:15,720 INFO epoch # 4185 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.009 -loss = 0.005555594563702471
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:15,742 INFO epoch # 4186 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.009 -loss = 0.005536327153095044
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:15,764 INFO epoch # 4187 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.009 -loss = 0.008031697350816103
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:15,785 INFO epoch # 4188 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.009 -loss = 0.005564686500292737
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:15,806 INFO epoch # 4189 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.009 -loss = 0.005541108293982688
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:15,828 INFO epoch # 4190 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.009 -loss = 0.006085041579353856
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:15,828 INFO *** epoch 4190, rolling-avg-loss (window=10)= 0.005852043861068523
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:15,850 INFO epoch # 4191 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.009 -loss = 0.005570313280259143
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:15,872 INFO epoch # 4192 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.009 -loss = 0.00555835628802015
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:15,893 INFO epoch # 4193 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.009 -loss = 0.005539834502087615
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:15,914 INFO epoch # 4194 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.009 -loss = 0.005535041498660576
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:15,936 INFO epoch # 4195 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.009 -loss = 0.005608367491731769
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:15,957 INFO epoch # 4196 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.009 -loss = 0.005633682361803949
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:15,979 INFO epoch # 4197 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.009 -loss = 0.005611114848761645
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:16,000 INFO epoch # 4198 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.009 -loss = 0.00552987497394497
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:16,022 INFO epoch # 4199 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.009 -loss = 0.0055152255426946795
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:16,044 INFO epoch # 4200 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.009 -loss = 0.00555627180619922
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:16,044 INFO *** epoch 4200, rolling-avg-loss (window=10)= 0.005565808259416371
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:16,066 INFO epoch # 4201 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.009 -loss = 0.005521942141058389
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:16,088 INFO epoch # 4202 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.009 -loss = 0.005537312315937015
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:16,109 INFO epoch # 4203 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.009 -loss = 0.005587250576354563
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:16,131 INFO epoch # 4204 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.009 -loss = 0.005629697434414993
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:16,152 INFO epoch # 4205 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.009 -loss = 0.005581576675467659
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:16,173 INFO epoch # 4206 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.009 -loss = 0.005510658282219083
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:16,194 INFO epoch # 4207 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.009 -loss = 0.005501797688339138
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:16,216 INFO epoch # 4208 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.009 -loss = 0.006005107785313157
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:16,237 INFO epoch # 4209 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.009 -loss = 0.005512125570021453
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:16,259 INFO epoch # 4210 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.009 -loss = 0.005609349029327859
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:16,259 INFO *** epoch 4210, rolling-avg-loss (window=10)= 0.005599681749845331
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:16,281 INFO epoch # 4211 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.009 -loss = 0.005491986818924488
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:16,302 INFO epoch # 4212 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.009 -loss = 0.005582061427048757
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:16,324 INFO epoch # 4213 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.009 -loss = 0.005515610871952958
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:16,345 INFO epoch # 4214 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.009 -loss = 0.005610068557871273
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:16,366 INFO epoch # 4215 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.009 -loss = 0.00561661508436373
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:16,387 INFO epoch # 4216 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.009 -loss = 0.00555366107255395
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:16,409 INFO epoch # 4217 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.009 -loss = 0.0055259367891267175
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:16,430 INFO epoch # 4218 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.009 -loss = 0.00549412512100389
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:16,452 INFO epoch # 4219 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.009 -loss = 0.005517253212019568
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:16,474 INFO epoch # 4220 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.009 -loss = 0.005489177512572496
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:16,474 INFO *** epoch 4220, rolling-avg-loss (window=10)= 0.0055396496467437824
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:16,495 INFO epoch # 4221 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.009 -loss = 0.005508520485818735
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:16,517 INFO epoch # 4222 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.009 -loss = 0.00643390575714875
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:16,539 INFO epoch # 4223 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.009 -loss = 0.005520644770513172
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:16,560 INFO epoch # 4224 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.009 -loss = 0.005503986818439444
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:16,581 INFO epoch # 4225 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.009 -loss = 0.005509721217094921
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:16,603 INFO epoch # 4226 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.009 -loss = 0.005476268313941546
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:16,624 INFO epoch # 4227 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.009 -loss = 0.005479985773490625
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:16,646 INFO epoch # 4228 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.009 -loss = 0.0055454716512031155
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:16,668 INFO epoch # 4229 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.009 -loss = 0.005529596312044305
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:16,689 INFO epoch # 4230 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.009 -loss = 0.005495073175552534
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:16,689 INFO *** epoch 4230, rolling-avg-loss (window=10)= 0.005600317427524715
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:16,711 INFO epoch # 4231 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.009 -loss = 0.0054684489805367775
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:16,733 INFO epoch # 4232 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.009 -loss = 0.005516335178981535
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:16,754 INFO epoch # 4233 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.009 -loss = 0.0054668700649926905
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:16,776 INFO epoch # 4234 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.009 -loss = 0.005469580635690363
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:16,797 INFO epoch # 4235 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.009 -loss = 0.005483373985043727
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:16,818 INFO epoch # 4236 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.009 -loss = 0.0056864921152737224
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:16,839 INFO epoch # 4237 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.009 -loss = 0.005515159144124482
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:16,861 INFO epoch # 4238 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.009 -loss = 0.005485111461894121
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:16,882 INFO epoch # 4239 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.009 -loss = 0.0054655105850542895
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:16,904 INFO epoch # 4240 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.009 -loss = 0.005955121421720833
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:16,904 INFO *** epoch 4240, rolling-avg-loss (window=10)= 0.005551200357331254
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:16,925 INFO epoch # 4241 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.009 -loss = 0.005463914345455123
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:16,947 INFO epoch # 4242 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.009 -loss = 0.005931500689257518
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:16,968 INFO epoch # 4243 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.009 -loss = 0.005495637204148807
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:16,990 INFO epoch # 4244 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.009 -loss = 0.005475372096043429
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:17,011 INFO epoch # 4245 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.009 -loss = 0.005503904807483195
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:17,032 INFO epoch # 4246 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.009 -loss = 0.005469380423164694
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:17,053 INFO epoch # 4247 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.009 -loss = 0.0054564084766752785
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:17,075 INFO epoch # 4248 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.009 -loss = 0.005459279709612019
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:17,096 INFO epoch # 4249 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.009 -loss = 0.005458986193843884
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:17,118 INFO epoch # 4250 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.009 -loss = 0.005459234509544331
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:17,118 INFO *** epoch 4250, rolling-avg-loss (window=10)= 0.005517361845522828
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:17,140 INFO epoch # 4251 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.009 -loss = 0.00548002208051912
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:17,161 INFO epoch # 4252 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.009 -loss = 0.005458793808429618
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:17,183 INFO epoch # 4253 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.009 -loss = 0.00545992834122444
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:17,204 INFO epoch # 4254 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.009 -loss = 0.00546521854630555
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:17,225 INFO epoch # 4255 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.009 -loss = 0.005664076108587324
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:17,246 INFO epoch # 4256 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.009 -loss = 0.005451381917737308
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:17,268 INFO epoch # 4257 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.009 -loss = 0.00558672352690337
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:17,289 INFO epoch # 4258 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.009 -loss = 0.0054409714466601145
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:17,311 INFO epoch # 4259 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.009 -loss = 0.005479186249431223
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:17,332 INFO epoch # 4260 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.009 -loss = 0.0055824589981057215
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:17,332 INFO *** epoch 4260, rolling-avg-loss (window=10)= 0.005506876102390379
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:17,354 INFO epoch # 4261 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.009 -loss = 0.006491636931968969
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:17,375 INFO epoch # 4262 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.009 -loss = 0.005460259244500776
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:17,397 INFO epoch # 4263 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.009 -loss = 0.005452028619401972
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:17,418 INFO epoch # 4264 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.009 -loss = 0.005439193271740805
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:17,439 INFO epoch # 4265 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.009 -loss = 0.005450749018564238
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:17,461 INFO epoch # 4266 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.009 -loss = 0.0054420484684669646
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:17,482 INFO epoch # 4267 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.009 -loss = 0.005435664912511129
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:17,504 INFO epoch # 4268 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.009 -loss = 0.005447161096526543
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:17,525 INFO epoch # 4269 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.009 -loss = 0.005449961386148061
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:17,547 INFO epoch # 4270 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.009 -loss = 0.005429323826319887
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:17,547 INFO *** epoch 4270, rolling-avg-loss (window=10)= 0.005549802677614934
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:17,569 INFO epoch # 4271 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.009 -loss = 0.005496039133504382
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:17,590 INFO epoch # 4272 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.009 -loss = 0.00555495607022749
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:17,611 INFO epoch # 4273 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.009 -loss = 0.005618128783680731
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:17,632 INFO epoch # 4274 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.009 -loss = 0.005440300219561323
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:17,654 INFO epoch # 4275 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.009 -loss = 0.0054361009315471165
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:17,675 INFO epoch # 4276 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.009 -loss = 0.0055544160823046695
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:17,696 INFO epoch # 4277 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.009 -loss = 0.005433313148387242
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:17,718 INFO epoch # 4278 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.009 -loss = 0.0054372123995563015
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:17,740 INFO epoch # 4279 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.009 -loss = 0.005464963176564197
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:17,762 INFO epoch # 4280 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.009 -loss = 0.005807519491099811
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:17,762 INFO *** epoch 4280, rolling-avg-loss (window=10)= 0.005524294943643327
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:17,783 INFO epoch # 4281 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.0089 -loss = 0.006125205978605663
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:17,805 INFO epoch # 4282 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.005414632520114537
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:17,826 INFO epoch # 4283 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.005411755835666554
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:17,847 INFO epoch # 4284 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.005423676839200198
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:17,868 INFO epoch # 4285 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.005410696720900887
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:17,890 INFO epoch # 4286 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.005843360053404467
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:17,911 INFO epoch # 4287 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.0054121287785164895
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:17,933 INFO epoch # 4288 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.005503669666722999
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:17,954 INFO epoch # 4289 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.00548757023170765
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:17,976 INFO epoch # 4290 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.005502096752024954
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:17,976 INFO *** epoch 4290, rolling-avg-loss (window=10)= 0.00555347933768644
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:17,997 INFO epoch # 4291 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.005428129736174014
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:18,019 INFO epoch # 4292 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.005420026920546661
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:18,040 INFO epoch # 4293 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.005392588695031009
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:18,061 INFO epoch # 4294 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.005388695363308216
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:18,082 INFO epoch # 4295 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.005491606978466734
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:18,104 INFO epoch # 4296 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.005461111724798684
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:18,125 INFO epoch # 4297 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.00540516328146623
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:18,147 INFO epoch # 4298 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.005435943120573938
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:18,168 INFO epoch # 4299 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.005398479393988964
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:18,189 INFO epoch # 4300 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.005393149031078792
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:18,190 INFO *** epoch 4300, rolling-avg-loss (window=10)= 0.005421489424543324
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:18,211 INFO epoch # 4301 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.005387348417571047
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:18,233 INFO epoch # 4302 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.005379228349283949
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:18,255 INFO epoch # 4303 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.005404607978562126
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:18,276 INFO epoch # 4304 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.00538990647328319
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:18,297 INFO epoch # 4305 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.005378815865697106
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:18,318 INFO epoch # 4306 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.005447354245916358
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:18,339 INFO epoch # 4307 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.005422110529252677
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:18,361 INFO epoch # 4308 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.005442418294478557
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:18,382 INFO epoch # 4309 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.005386608076150878
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:18,404 INFO epoch # 4310 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.0053887658832536545
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:18,404 INFO *** epoch 4310, rolling-avg-loss (window=10)= 0.005402716411344955
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:18,426 INFO epoch # 4311 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.00536826013285463
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:18,448 INFO epoch # 4312 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.005368617436943168
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:18,469 INFO epoch # 4313 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.005363255518204824
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:18,490 INFO epoch # 4314 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.005374579444833216
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:18,511 INFO epoch # 4315 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.00539742650835251
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:18,532 INFO epoch # 4316 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.005377308179959073
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:18,554 INFO epoch # 4317 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.005370158681216708
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:18,575 INFO epoch # 4318 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.005389879752328852
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:18,597 INFO epoch # 4319 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.008647654965898255
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:18,619 INFO epoch # 4320 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.005370604661038669
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:18,619 INFO *** epoch 4320, rolling-avg-loss (window=10)= 0.005702774528162991
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:18,640 INFO epoch # 4321 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.005389112222474068
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:18,662 INFO epoch # 4322 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.005452903253171826
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:18,683 INFO epoch # 4323 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.0053583442140734405
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:18,704 INFO epoch # 4324 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.006234680626221234
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:18,726 INFO epoch # 4325 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.005371850817027735
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:18,748 INFO epoch # 4326 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.0053868569411861245
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:18,770 INFO epoch # 4327 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.00535688441414095
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:18,792 INFO epoch # 4328 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.00538809551835584
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:18,814 INFO epoch # 4329 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.0053523381720879115
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:18,835 INFO epoch # 4330 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.0053620609833160415
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:18,836 INFO *** epoch 4330, rolling-avg-loss (window=10)= 0.005465312716205517
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:18,857 INFO epoch # 4331 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.0053584468569169985
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:18,879 INFO epoch # 4332 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.005362812371458858
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:18,900 INFO epoch # 4333 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.0053679254015150946
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:18,921 INFO epoch # 4334 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.0053571853022731375
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:18,942 INFO epoch # 4335 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.005573083826675429
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:18,963 INFO epoch # 4336 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.005466924494612613
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:18,985 INFO epoch # 4337 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.005347760450604255
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:19,006 INFO epoch # 4338 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.005357374244340463
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:19,028 INFO epoch # 4339 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.005584656821156386
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:19,050 INFO epoch # 4340 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.005355012875952525
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:19,050 INFO *** epoch 4340, rolling-avg-loss (window=10)= 0.005413118264550576
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:19,071 INFO epoch # 4341 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.0053599688599206274
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:19,093 INFO epoch # 4342 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.005374991416829289
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:19,114 INFO epoch # 4343 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.0053415951970237074
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:19,135 INFO epoch # 4344 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.0053692229121224955
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:19,156 INFO epoch # 4345 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.005373650662477303
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:19,178 INFO epoch # 4346 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.005354978056857362
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:19,199 INFO epoch # 4347 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.005352273536118446
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:19,220 INFO epoch # 4348 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.005352846623281948
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:19,243 INFO epoch # 4349 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.0054211919032240985
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:19,264 INFO epoch # 4350 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.005396440322328999
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:19,264 INFO *** epoch 4350, rolling-avg-loss (window=10)= 0.005369715949018428
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:19,286 INFO epoch # 4351 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.006199743775141542
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:19,308 INFO epoch # 4352 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.0053285809221961244
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:19,329 INFO epoch # 4353 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.006566307858520304
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:19,350 INFO epoch # 4354 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.005481048825458856
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:19,371 INFO epoch # 4355 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.005546221605982282
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:19,392 INFO epoch # 4356 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.005351232901375624
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:19,414 INFO epoch # 4357 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.005340854706446407
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:19,435 INFO epoch # 4358 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.0053318103400670225
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:19,456 INFO epoch # 4359 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.005455362859720481
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:19,478 INFO epoch # 4360 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.005374622520321282
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:19,478 INFO *** epoch 4360, rolling-avg-loss (window=10)= 0.0055975786315229925
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:19,499 INFO epoch # 4361 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.005381364577260683
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:19,521 INFO epoch # 4362 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.005301233526552096
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:19,542 INFO epoch # 4363 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.005329635056114057
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:19,564 INFO epoch # 4364 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.005322434790286934
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:19,585 INFO epoch # 4365 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.005302786665197345
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:19,607 INFO epoch # 4366 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.00532676548937161
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:19,628 INFO epoch # 4367 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.005404198338510469
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:19,650 INFO epoch # 4368 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.005317660918080946
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:19,671 INFO epoch # 4369 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.005468890529300552
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:19,693 INFO epoch # 4370 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.005295822698826669
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:19,693 INFO *** epoch 4370, rolling-avg-loss (window=10)= 0.0053450792589501365
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:19,715 INFO epoch # 4371 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.005348040734133974
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:19,737 INFO epoch # 4372 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.005297830385643465
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:19,759 INFO epoch # 4373 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.007648280165085453
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:19,780 INFO epoch # 4374 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.007223563261504751
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:19,801 INFO epoch # 4375 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.00534411350145092
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:19,822 INFO epoch # 4376 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.005364679435842845
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:19,843 INFO epoch # 4377 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.005310989521603915
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:19,865 INFO epoch # 4378 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.005310824712069007
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:19,886 INFO epoch # 4379 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.005319104384398088
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:19,907 INFO epoch # 4380 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.005336543155863183
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:19,908 INFO *** epoch 4380, rolling-avg-loss (window=10)= 0.00575039692575956
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:19,929 INFO epoch # 4381 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0088 -loss = 0.005349093740733224
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:19,951 INFO epoch # 4382 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0088-> 0.0088 -loss = 0.005311174158123322
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:19,972 INFO epoch # 4383 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0088-> 0.0088 -loss = 0.0053011395830253605
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:19,993 INFO epoch # 4384 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0088-> 0.0088 -loss = 0.00528222921093402
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:20,014 INFO epoch # 4385 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0088-> 0.0088 -loss = 0.005286100785269809
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:20,036 INFO epoch # 4386 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0088-> 0.0088 -loss = 0.0052941555568395415
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:20,057 INFO epoch # 4387 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0088-> 0.0088 -loss = 0.005285228971843026
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:20,079 INFO epoch # 4388 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0088-> 0.0088 -loss = 0.005287871823384194
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:20,100 INFO epoch # 4389 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0088-> 0.0088 -loss = 0.005341690783097874
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:20,121 INFO epoch # 4390 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0088-> 0.0088 -loss = 0.0053569541523756925
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:20,122 INFO *** epoch 4390, rolling-avg-loss (window=10)= 0.005309563876562606
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:20,144 INFO epoch # 4391 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0088-> 0.0088 -loss = 0.00535067067721684
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:20,165 INFO epoch # 4392 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0088-> 0.0088 -loss = 0.005280460303765722
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:20,187 INFO epoch # 4393 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0088-> 0.0088 -loss = 0.006704739746055566
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:20,208 INFO epoch # 4394 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0088-> 0.0088 -loss = 0.005289511722367024
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:20,230 INFO epoch # 4395 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0088-> 0.0088 -loss = 0.005364593242120463
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:20,251 INFO epoch # 4396 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0088-> 0.0088 -loss = 0.005397626671765465
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:20,273 INFO epoch # 4397 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0088-> 0.0088 -loss = 0.005342400138033554
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:20,294 INFO epoch # 4398 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0088-> 0.0088 -loss = 0.005263963244942715
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:20,316 INFO epoch # 4399 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0088-> 0.0088 -loss = 0.005319500240148045
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:20,338 INFO epoch # 4400 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0088-> 0.0088 -loss = 0.005278254486256628
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:20,338 INFO *** epoch 4400, rolling-avg-loss (window=10)= 0.005459172047267202
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:20,360 INFO epoch # 4401 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0088-> 0.0088 -loss = 0.005276178007989074
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:20,381 INFO epoch # 4402 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0088-> 0.0088 -loss = 0.005315755421179347
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:20,403 INFO epoch # 4403 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0088-> 0.0088 -loss = 0.0052815398612438
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:20,424 INFO epoch # 4404 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0088-> 0.0088 -loss = 0.005258904684069421
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:20,445 INFO epoch # 4405 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0088-> 0.0088 -loss = 0.0053130443338886835
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:20,466 INFO epoch # 4406 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0088-> 0.0088 -loss = 0.005266491467409651
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:20,488 INFO epoch # 4407 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0088-> 0.0088 -loss = 0.005278307497064816
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:20,509 INFO epoch # 4408 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0088-> 0.0088 -loss = 0.005288534443934623
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:20,531 INFO epoch # 4409 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0088-> 0.0088 -loss = 0.005299792608639109
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:20,553 INFO epoch # 4410 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0088-> 0.0088 -loss = 0.005263136666144419
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:20,553 INFO *** epoch 4410, rolling-avg-loss (window=10)= 0.005284168499156294
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:20,575 INFO epoch # 4411 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0088-> 0.0088 -loss = 0.005291663801472168
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:20,597 INFO epoch # 4412 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0088-> 0.0088 -loss = 0.0052748025009350386
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:20,619 INFO epoch # 4413 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0088-> 0.0088 -loss = 0.005280806250084424
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:20,640 INFO epoch # 4414 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0088-> 0.0088 -loss = 0.005268041992167127
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:20,662 INFO epoch # 4415 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0088-> 0.0088 -loss = 0.005245021608061506
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:20,683 INFO epoch # 4416 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0088-> 0.0088 -loss = 0.006152773663416156
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:20,704 INFO epoch # 4417 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0088-> 0.0088 -loss = 0.0052870581439492526
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:20,727 INFO epoch # 4418 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0088-> 0.0088 -loss = 0.005251239852441358
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:20,749 INFO epoch # 4419 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0088-> 0.0088 -loss = 0.005239922306827793
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:20,771 INFO epoch # 4420 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0088-> 0.0088 -loss = 0.0052591137264244026
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:20,771 INFO *** epoch 4420, rolling-avg-loss (window=10)= 0.005355044384577923
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:20,792 INFO epoch # 4421 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0088-> 0.0088 -loss = 0.005431121846413589
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:20,814 INFO epoch # 4422 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0088-> 0.0088 -loss = 0.0053580442272505024
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:20,836 INFO epoch # 4423 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0088-> 0.0088 -loss = 0.005368629033910111
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:20,857 INFO epoch # 4424 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0088-> 0.0088 -loss = 0.005267373962851707
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:20,878 INFO epoch # 4425 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0088-> 0.0088 -loss = 0.005277119807942654
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:20,899 INFO epoch # 4426 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0088-> 0.0088 -loss = 0.005242625784376287
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:20,921 INFO epoch # 4427 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0088-> 0.0088 -loss = 0.005254551109828753
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:20,942 INFO epoch # 4428 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0088-> 0.0088 -loss = 0.005376028910177411
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:20,964 INFO epoch # 4429 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0088-> 0.0088 -loss = 0.005264765972242458
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:20,986 INFO epoch # 4430 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0088-> 0.0087 -loss = 0.0052607039597205585
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:20,986 INFO *** epoch 4430, rolling-avg-loss (window=10)= 0.005310096461471403
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:21,008 INFO epoch # 4431 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.0053181336170382565
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:21,030 INFO epoch # 4432 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.005234550210843736
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:21,052 INFO epoch # 4433 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.005289394437568262
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:21,073 INFO epoch # 4434 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.005249864365396206
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:21,094 INFO epoch # 4435 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.005248096096693189
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:21,115 INFO epoch # 4436 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.005225463937676977
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:21,136 INFO epoch # 4437 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.005235885578258603
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:21,158 INFO epoch # 4438 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.005245646614639554
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:21,179 INFO epoch # 4439 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.005281575490698742
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:21,201 INFO epoch # 4440 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.005325326821548515
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:21,201 INFO *** epoch 4440, rolling-avg-loss (window=10)= 0.005265393717036204
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:21,223 INFO epoch # 4441 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.005220806652232568
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:21,245 INFO epoch # 4442 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.005240556229182403
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:21,267 INFO epoch # 4443 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.005245775970251998
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:21,288 INFO epoch # 4444 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.005220109886977298
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:21,309 INFO epoch # 4445 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.005243570152742905
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:21,330 INFO epoch # 4446 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.005214384646023973
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:21,352 INFO epoch # 4447 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.005279821803924278
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:21,374 INFO epoch # 4448 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.005352577079975163
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:21,396 INFO epoch # 4449 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.005215080072048295
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:21,418 INFO epoch # 4450 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.005216644220126909
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:21,418 INFO *** epoch 4450, rolling-avg-loss (window=10)= 0.005244932671348579
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:21,440 INFO epoch # 4451 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.00520674354993389
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:21,462 INFO epoch # 4452 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.005232385236013215
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:21,483 INFO epoch # 4453 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.005233096804658999
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:21,504 INFO epoch # 4454 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.005213611386352568
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:21,526 INFO epoch # 4455 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.005230437194768456
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:21,547 INFO epoch # 4456 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.005215173387114191
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:21,568 INFO epoch # 4457 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.005204130282436381
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:21,590 INFO epoch # 4458 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.005198630961331219
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:21,611 INFO epoch # 4459 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.0052122664792477735
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:21,633 INFO epoch # 4460 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.006417430444344063
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:21,633 INFO *** epoch 4460, rolling-avg-loss (window=10)= 0.005336390572620075
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:21,655 INFO epoch # 4461 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.0067878467070841
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:21,677 INFO epoch # 4462 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.005222741616307758
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:21,698 INFO epoch # 4463 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.005203023160902376
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:21,720 INFO epoch # 4464 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.005240875970230263
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:21,741 INFO epoch # 4465 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.005222576886808383
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:21,762 INFO epoch # 4466 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.005192561015064712
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:21,783 INFO epoch # 4467 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.0051985447644256055
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:21,805 INFO epoch # 4468 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.0051975220540043665
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:21,827 INFO epoch # 4469 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.00523840905589168
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:21,849 INFO epoch # 4470 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.005185961432289332
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:21,849 INFO *** epoch 4470, rolling-avg-loss (window=10)= 0.005369006266300857
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:21,871 INFO epoch # 4471 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.0052195547559676925
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:21,892 INFO epoch # 4472 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.005195459417336679
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:21,914 INFO epoch # 4473 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.00519826966956316
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:21,935 INFO epoch # 4474 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.005202279724471737
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:21,956 INFO epoch # 4475 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.005204059889365453
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:21,978 INFO epoch # 4476 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.005213827527768444
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:21,999 INFO epoch # 4477 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.0051977762350361445
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:22,020 INFO epoch # 4478 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.005201963278523181
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:22,042 INFO epoch # 4479 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.005183340355870314
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:22,064 INFO epoch # 4480 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.005223552412644494
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:22,064 INFO *** epoch 4480, rolling-avg-loss (window=10)= 0.00520400832665473
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:22,086 INFO epoch # 4481 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.0052423488723434275
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:22,108 INFO epoch # 4482 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.005194834848225582
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:22,129 INFO epoch # 4483 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.005238253535935655
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:22,150 INFO epoch # 4484 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.005173775356524857
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:22,171 INFO epoch # 4485 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.005675503743987065
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:22,192 INFO epoch # 4486 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.0051837928767781705
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:22,214 INFO epoch # 4487 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.005181488815651392
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:22,236 INFO epoch # 4488 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.005656845230078034
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:22,258 INFO epoch # 4489 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.005206990058468364
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:22,280 INFO epoch # 4490 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.005166705575902597
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:22,280 INFO *** epoch 4490, rolling-avg-loss (window=10)= 0.005292053891389514
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:22,302 INFO epoch # 4491 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.005165161522654671
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:22,324 INFO epoch # 4492 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.005200040201088996
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:22,345 INFO epoch # 4493 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.005174321766389767
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:22,367 INFO epoch # 4494 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.005160064570191025
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:22,388 INFO epoch # 4495 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.005659521310008131
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:22,409 INFO epoch # 4496 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.005212825737544335
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:22,431 INFO epoch # 4497 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.005178728230021079
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:22,452 INFO epoch # 4498 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.005161287166629336
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:22,473 INFO epoch # 4499 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.005329623736542999
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:22,495 INFO epoch # 4500 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.005160470711416565
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:22,495 INFO *** epoch 4500, rolling-avg-loss (window=10)= 0.00524020449524869
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:22,516 INFO epoch # 4501 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.00516035003511206
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:22,538 INFO epoch # 4502 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.005190995732846204
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:22,560 INFO epoch # 4503 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.005150976367986004
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:22,582 INFO epoch # 4504 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.0051584601696959
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:22,603 INFO epoch # 4505 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.005183430104807485
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:22,625 INFO epoch # 4506 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.005152142344741151
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:22,646 INFO epoch # 4507 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.005151494693564018
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:22,668 INFO epoch # 4508 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.005150232938831323
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:22,689 INFO epoch # 4509 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.005164092999621062
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:22,711 INFO epoch # 4510 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.005162433797522681
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:22,711 INFO *** epoch 4510, rolling-avg-loss (window=10)= 0.005162460918472789
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:22,733 INFO epoch # 4511 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.005189085992242326
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:22,755 INFO epoch # 4512 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.005176340726393391
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:22,776 INFO epoch # 4513 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.005738403924624436
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:22,798 INFO epoch # 4514 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.005192362772504566
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:22,819 INFO epoch # 4515 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.0051492016900738236
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:22,840 INFO epoch # 4516 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.005297839268678217
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:22,862 INFO epoch # 4517 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.005225920214797952
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:22,883 INFO epoch # 4518 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.005241459675744409
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:22,905 INFO epoch # 4519 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.006486641621449962
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:22,927 INFO epoch # 4520 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.005155011896931683
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:22,927 INFO *** epoch 4520, rolling-avg-loss (window=10)= 0.005385226778344077
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:22,948 INFO epoch # 4521 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.005127323979195353
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:22,970 INFO epoch # 4522 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.005174969654035522
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:22,992 INFO epoch # 4523 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.005187180251596146
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:23,013 INFO epoch # 4524 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.00512881357644801
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:23,034 INFO epoch # 4525 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.005192420698222122
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:23,056 INFO epoch # 4526 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.005165210121049313
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:23,077 INFO epoch # 4527 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.005133118918820401
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:23,099 INFO epoch # 4528 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.005234657268374576
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:23,121 INFO epoch # 4529 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.005260122155959834
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:23,142 INFO epoch # 4530 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.005370809045416536
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:23,142 INFO *** epoch 4530, rolling-avg-loss (window=10)= 0.005197462566911781
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:23,164 INFO epoch # 4531 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.005141563047800446
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:23,186 INFO epoch # 4532 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.005116984599681018
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:23,207 INFO epoch # 4533 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.005131576635903912
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:23,229 INFO epoch # 4534 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.0051255739490443375
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:23,250 INFO epoch # 4535 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.005189718895053375
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:23,271 INFO epoch # 4536 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.006489824529126054
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:23,293 INFO epoch # 4537 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.006450687204051064
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:23,315 INFO epoch # 4538 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.005115161852245365
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:23,337 INFO epoch # 4539 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.005124830391650903
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:23,359 INFO epoch # 4540 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.005119209645272349
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:23,359 INFO *** epoch 4540, rolling-avg-loss (window=10)= 0.005400513074982882
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:23,381 INFO epoch # 4541 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.005123153716340312
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:23,403 INFO epoch # 4542 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.00513435868833767
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:23,425 INFO epoch # 4543 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.005123803237438551
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:23,446 INFO epoch # 4544 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.005116039233143965
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:23,467 INFO epoch # 4545 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.005119019497215049
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:23,489 INFO epoch # 4546 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.005103356248127966
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:23,511 INFO epoch # 4547 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.005191638727410464
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:23,532 INFO epoch # 4548 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.005112062775879167
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:23,554 INFO epoch # 4549 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.005313167892381898
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:23,576 INFO epoch # 4550 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.005110490410515922
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:23,576 INFO *** epoch 4550, rolling-avg-loss (window=10)= 0.005144709042679096
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:23,598 INFO epoch # 4551 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.005097324563394068
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:23,620 INFO epoch # 4552 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.005124410192365758
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:23,641 INFO epoch # 4553 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.005168242847503279
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:23,662 INFO epoch # 4554 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.00514283590746345
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:23,683 INFO epoch # 4555 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.0074676291733339895
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:23,704 INFO epoch # 4556 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.005127829329467204
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:23,726 INFO epoch # 4557 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.005221253812123905
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:23,748 INFO epoch # 4558 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.005167890945813269
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:23,770 INFO epoch # 4559 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.005118466844578506
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:23,791 INFO epoch # 4560 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.005592770756265963
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:23,791 INFO *** epoch 4560, rolling-avg-loss (window=10)= 0.00542286543723094
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:23,813 INFO epoch # 4561 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.005147412843143684
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:23,835 INFO epoch # 4562 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0086 -loss = 0.005171150336536812
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:23,856 INFO epoch # 4563 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0086-> 0.0086 -loss = 0.005076208900845813
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:23,877 INFO epoch # 4564 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0086-> 0.0086 -loss = 0.00511298315905151
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:23,898 INFO epoch # 4565 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0086-> 0.0086 -loss = 0.00509436466745683
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:23,920 INFO epoch # 4566 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0086-> 0.0086 -loss = 0.005092515088108485
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:23,941 INFO epoch # 4567 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0086-> 0.0086 -loss = 0.005089210276310041
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:23,963 INFO epoch # 4568 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0086-> 0.0086 -loss = 0.007018088381300913
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:23,984 INFO epoch # 4569 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0086-> 0.0086 -loss = 0.0050875667352556775
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:24,006 INFO epoch # 4570 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0086-> 0.0086 -loss = 0.005266015865345253
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:24,006 INFO *** epoch 4570, rolling-avg-loss (window=10)= 0.005315551625335502
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:24,028 INFO epoch # 4571 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0086-> 0.0086 -loss = 0.005119900344652706
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:24,051 INFO epoch # 4572 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0086-> 0.0086 -loss = 0.005080791604996193
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:24,072 INFO epoch # 4573 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0086-> 0.0086 -loss = 0.005105047264805762
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:24,093 INFO epoch # 4574 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0086-> 0.0085 -loss = 0.0051221436697233
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:24,114 INFO epoch # 4575 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0085-> 0.0085 -loss = 0.005066057369731425
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:24,136 INFO epoch # 4576 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0085-> 0.0085 -loss = 0.005084041946247453
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:24,157 INFO epoch # 4577 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0085-> 0.0085 -loss = 0.005072260733868461
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:24,179 INFO epoch # 4578 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0085-> 0.0085 -loss = 0.0050784173063220805
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:24,200 INFO epoch # 4579 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0085-> 0.0085 -loss = 0.005099498046547524
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:24,222 INFO epoch # 4580 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0085-> 0.0085 -loss = 0.005067517723546189
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:24,222 INFO *** epoch 4580, rolling-avg-loss (window=10)= 0.005089567601044109
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:24,244 INFO epoch # 4581 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0085-> 0.0085 -loss = 0.005082070716525777
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:24,266 INFO epoch # 4582 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0085-> 0.0085 -loss = 0.005116262045703479
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:24,287 INFO epoch # 4583 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0085-> 0.0085 -loss = 0.005067832349595847
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:24,308 INFO epoch # 4584 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0085-> 0.0085 -loss = 0.005062646836449858
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:24,330 INFO epoch # 4585 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0085-> 0.0085 -loss = 0.0050983132587134605
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:24,351 INFO epoch # 4586 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0085-> 0.0085 -loss = 0.005072923668194562
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:24,372 INFO epoch # 4587 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0085-> 0.0085 -loss = 0.005074856533610728
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:24,394 INFO epoch # 4588 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0085-> 0.0085 -loss = 0.005531601305847289
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:24,416 INFO epoch # 4589 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0085-> 0.0085 -loss = 0.005069351592283056
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:24,438 INFO epoch # 4590 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0085-> 0.0085 -loss = 0.005189181918467511
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:24,438 INFO *** epoch 4590, rolling-avg-loss (window=10)= 0.005136504022539156
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:24,460 INFO epoch # 4591 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0085-> 0.0085 -loss = 0.0050586924744493444
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:24,482 INFO epoch # 4592 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0085-> 0.0085 -loss = 0.00507338103489019
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:24,504 INFO epoch # 4593 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0085-> 0.0085 -loss = 0.00507736349482002
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:24,525 INFO epoch # 4594 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0085-> 0.0085 -loss = 0.0050459097292332444
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:24,546 INFO epoch # 4595 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0085-> 0.0085 -loss = 0.005077714124126942
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:24,567 INFO epoch # 4596 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0085-> 0.0085 -loss = 0.005718482250813395
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:24,589 INFO epoch # 4597 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0085-> 0.0085 -loss = 0.005081628039988573
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:24,611 INFO epoch # 4598 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0085-> 0.0085 -loss = 0.00516181636339752
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:24,633 INFO epoch # 4599 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0085-> 0.0085 -loss = 0.0050812658919312526
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:24,656 INFO epoch # 4600 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0085-> 0.0085 -loss = 0.005114887999297935
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:24,656 INFO *** epoch 4600, rolling-avg-loss (window=10)= 0.0051491141402948415
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:24,678 INFO epoch # 4601 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0085-> 0.0085 -loss = 0.005711545723897871
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:24,700 INFO epoch # 4602 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0085-> 0.0085 -loss = 0.005088801543024601
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:24,721 INFO epoch # 4603 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0085-> 0.0085 -loss = 0.005050953368481714
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:24,743 INFO epoch # 4604 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0085-> 0.0085 -loss = 0.005146286111994414
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:24,764 INFO epoch # 4605 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0085-> 0.0084 -loss = 0.005064930153821479
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:24,785 INFO epoch # 4606 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0084-> 0.0084 -loss = 0.005061798950919183
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:24,807 INFO epoch # 4607 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0084-> 0.0084 -loss = 0.005049337263699272
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:24,829 INFO epoch # 4608 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0084-> 0.0084 -loss = 0.005083164758616476
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:24,851 INFO epoch # 4609 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0084-> 0.0084 -loss = 0.005071896168374224
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:24,872 INFO epoch # 4610 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0084-> 0.0084 -loss = 0.005081382285425207
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:24,873 INFO *** epoch 4610, rolling-avg-loss (window=10)= 0.005141009632825444
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:24,894 INFO epoch # 4611 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0084-> 0.0084 -loss = 0.006340362786431797
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:24,916 INFO epoch # 4612 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0084-> 0.0084 -loss = 0.005031471147958655
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:24,937 INFO epoch # 4613 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0084-> 0.0084 -loss = 0.0050288186148463865
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:24,958 INFO epoch # 4614 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0084-> 0.0084 -loss = 0.006003775948556722
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:24,980 INFO epoch # 4615 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0084-> 0.0084 -loss = 0.005035192130435462
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:25,001 INFO epoch # 4616 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0084-> 0.0084 -loss = 0.005032270545143547
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:25,023 INFO epoch # 4617 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0084-> 0.0084 -loss = 0.005047310436566477
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:25,045 INFO epoch # 4618 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0084-> 0.0084 -loss = 0.005099342289213382
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:25,067 INFO epoch # 4619 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0084-> 0.0084 -loss = 0.005080056413135026
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:25,089 INFO epoch # 4620 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0084-> 0.0084 -loss = 0.005148094787728041
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:25,089 INFO *** epoch 4620, rolling-avg-loss (window=10)= 0.005284669510001549
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:25,111 INFO epoch # 4621 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0084-> 0.0084 -loss = 0.005072704119811533
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:25,133 INFO epoch # 4622 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0084-> 0.0084 -loss = 0.005076125999039505
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:25,154 INFO epoch # 4623 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0084-> 0.0084 -loss = 0.005054222556282184
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:25,175 INFO epoch # 4624 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0084-> 0.0083 -loss = 0.005473524676745001
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:25,196 INFO epoch # 4625 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0083-> 0.0083 -loss = 0.005174193205675692
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:25,217 INFO epoch # 4626 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0083-> 0.0083 -loss = 0.005177758632271434
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:25,239 INFO epoch # 4627 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0083-> 0.0083 -loss = 0.00508731940681173
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:25,262 INFO epoch # 4628 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0083-> 0.0083 -loss = 0.005141924097188166
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:25,284 INFO epoch # 4629 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0083-> 0.0083 -loss = 0.005082430245238356
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:25,306 INFO epoch # 4630 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0083-> 0.0083 -loss = 0.005036075412135688
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:25,306 INFO *** epoch 4630, rolling-avg-loss (window=10)= 0.005137627835119929
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:25,328 INFO epoch # 4631 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0083-> 0.0083 -loss = 0.0051395923419477185
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:25,350 INFO epoch # 4632 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0083-> 0.0083 -loss = 0.005053891452917014
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:25,371 INFO epoch # 4633 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0083-> 0.0083 -loss = 0.005011738893699658
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:25,392 INFO epoch # 4634 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0083-> 0.0083 -loss = 0.00501721098953567
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:25,413 INFO epoch # 4635 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0083-> 0.0083 -loss = 0.005879055379409692
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:25,434 INFO epoch # 4636 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0083-> 0.0083 -loss = 0.005141515828654519
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:25,456 INFO epoch # 4637 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0083-> 0.0083 -loss = 0.005050441841376596
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:25,479 INFO epoch # 4638 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0083-> 0.0083 -loss = 0.005019174648623448
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:25,500 INFO epoch # 4639 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0083-> 0.0083 -loss = 0.0050152735584561015
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:25,522 INFO epoch # 4640 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0083-> 0.0083 -loss = 0.0050419698609402985
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:25,522 INFO *** epoch 4640, rolling-avg-loss (window=10)= 0.005136986479556072
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:25,544 INFO epoch # 4641 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0083-> 0.0083 -loss = 0.005045351595072134
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:25,566 INFO epoch # 4642 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0083-> 0.0083 -loss = 0.0050343343154963804
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:25,587 INFO epoch # 4643 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0083-> 0.0083 -loss = 0.005020335511289886
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:25,609 INFO epoch # 4644 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0083-> 0.0083 -loss = 0.0050047761942551006
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:25,631 INFO epoch # 4645 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0083-> 0.0083 -loss = 0.004999325089556805
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:25,652 INFO epoch # 4646 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0083-> 0.0083 -loss = 0.004993666783775552
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:25,674 INFO epoch # 4647 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0083-> 0.0083 -loss = 0.005033970945078181
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:25,697 INFO epoch # 4648 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0083-> 0.0083 -loss = 0.005004607597584254
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:25,719 INFO epoch # 4649 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0083-> 0.0083 -loss = 0.0050111905602534534
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:25,741 INFO epoch # 4650 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0083-> 0.0083 -loss = 0.005019459731556708
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:25,741 INFO *** epoch 4650, rolling-avg-loss (window=10)= 0.005016701832391846
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:25,763 INFO epoch # 4651 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0083-> 0.0083 -loss = 0.004999207436412689
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:25,785 INFO epoch # 4652 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0083-> 0.0083 -loss = 0.0049838270469990675
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:25,806 INFO epoch # 4653 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0083-> 0.0083 -loss = 0.005072905396446004
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:25,827 INFO epoch # 4654 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0083-> 0.0083 -loss = 0.004995891086764459
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:25,848 INFO epoch # 4655 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0083-> 0.0083 -loss = 0.005006275485357037
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:25,870 INFO epoch # 4656 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0083-> 0.0083 -loss = 0.004996720337658189
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:25,891 INFO epoch # 4657 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0083-> 0.0083 -loss = 0.005012516983697424
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:25,913 INFO epoch # 4658 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0083-> 0.0083 -loss = 0.005018861100325012
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:25,935 INFO epoch # 4659 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0083-> 0.0083 -loss = 0.005012393376091495
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:25,957 INFO epoch # 4660 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0083-> 0.0083 -loss = 0.005052297668953543
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:25,957 INFO *** epoch 4660, rolling-avg-loss (window=10)= 0.005015089591870492
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:25,980 INFO epoch # 4661 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0083-> 0.0083 -loss = 0.005015591133997077
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:26,001 INFO epoch # 4662 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0083-> 0.0083 -loss = 0.005035423579101916
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:26,023 INFO epoch # 4663 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0083-> 0.0083 -loss = 0.00498993582186813
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:26,044 INFO epoch # 4664 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0083-> 0.0083 -loss = 0.0051732691972574685
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:26,065 INFO epoch # 4665 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0083-> 0.0083 -loss = 0.005045738390435872
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:26,087 INFO epoch # 4666 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0083-> 0.0083 -loss = 0.004980741845429293
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:26,108 INFO epoch # 4667 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0083-> 0.0083 -loss = 0.005082602170659811
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:26,130 INFO epoch # 4668 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0083-> 0.0083 -loss = 0.004991728447748756
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:26,151 INFO epoch # 4669 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0083-> 0.0083 -loss = 0.004988491820768104
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:26,173 INFO epoch # 4670 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0083-> 0.0083 -loss = 0.004987252365026507
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:26,173 INFO *** epoch 4670, rolling-avg-loss (window=10)= 0.005029077477229293
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:26,195 INFO epoch # 4671 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0083-> 0.0083 -loss = 0.005283241229335545
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:26,216 INFO epoch # 4672 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0083-> 0.0083 -loss = 0.005008913369238144
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:26,238 INFO epoch # 4673 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0083-> 0.0083 -loss = 0.004989504634067998
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:26,259 INFO epoch # 4674 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0083-> 0.0083 -loss = 0.004977225195034407
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:26,280 INFO epoch # 4675 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0083-> 0.0083 -loss = 0.005073840156910592
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:26,302 INFO epoch # 4676 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0083-> 0.0083 -loss = 0.004967797289282316
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:26,323 INFO epoch # 4677 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0083-> 0.0083 -loss = 0.004972323771653464
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:26,345 INFO epoch # 4678 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0083-> 0.0083 -loss = 0.005080918001112877
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:26,367 INFO epoch # 4679 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0083-> 0.0083 -loss = 0.004990185929273139
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:26,389 INFO epoch # 4680 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0083-> 0.0083 -loss = 0.00497163097588782
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:26,389 INFO *** epoch 4680, rolling-avg-loss (window=10)= 0.00503155805517963
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:26,411 INFO epoch # 4681 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0083-> 0.0083 -loss = 0.00496444966938725
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:26,433 INFO epoch # 4682 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0083-> 0.0083 -loss = 0.004954736858280739
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:26,454 INFO epoch # 4683 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0083-> 0.0083 -loss = 0.004967718747138861
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:26,475 INFO epoch # 4684 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0083-> 0.0083 -loss = 0.0049892146307684015
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:26,496 INFO epoch # 4685 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0083-> 0.0083 -loss = 0.004969904927747848
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:26,518 INFO epoch # 4686 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0083-> 0.0083 -loss = 0.005027904791859328
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:26,539 INFO epoch # 4687 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0083-> 0.0083 -loss = 0.004945724984736444
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:26,561 INFO epoch # 4688 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0083-> 0.0083 -loss = 0.0058244314986950485
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:26,583 INFO epoch # 4689 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0083-> 0.0083 -loss = 0.004964022132298851
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:26,604 INFO epoch # 4690 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0083-> 0.0083 -loss = 0.006251305037949351
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:26,605 INFO *** epoch 4690, rolling-avg-loss (window=10)= 0.0051859413278862124
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:26,627 INFO epoch # 4691 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0083-> 0.0083 -loss = 0.0049594245610933285
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:26,649 INFO epoch # 4692 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0083-> 0.0083 -loss = 0.006413861223336426
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:26,670 INFO epoch # 4693 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0083-> 0.0083 -loss = 0.005084646114482894
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:26,691 INFO epoch # 4694 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0083-> 0.0083 -loss = 0.004951175703354238
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:26,712 INFO epoch # 4695 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0083-> 0.0083 -loss = 0.005018493022362236
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:26,733 INFO epoch # 4696 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0083-> 0.0083 -loss = 0.004967359701367968
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:26,755 INFO epoch # 4697 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0083-> 0.0083 -loss = 0.0062875157163944095
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:26,777 INFO epoch # 4698 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0083-> 0.0082 -loss = 0.004976043035640032
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:26,799 INFO epoch # 4699 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0082-> 0.0082 -loss = 0.004957293331244728
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:26,820 INFO epoch # 4700 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0082-> 0.0082 -loss = 0.005226400877290871
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:26,820 INFO *** epoch 4700, rolling-avg-loss (window=10)= 0.005284221328656713
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:26,842 INFO epoch # 4701 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0082-> 0.0082 -loss = 0.0049554991546756355
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:26,864 INFO epoch # 4702 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0082-> 0.0082 -loss = 0.004964151237800252
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:26,886 INFO epoch # 4703 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0082-> 0.0082 -loss = 0.005010620172470226
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:26,907 INFO epoch # 4704 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0082-> 0.0082 -loss = 0.004940051823723479
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:26,928 INFO epoch # 4705 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0082-> 0.0082 -loss = 0.004943499960063491
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:26,949 INFO epoch # 4706 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0082-> 0.0082 -loss = 0.004967764449247625
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:26,970 INFO epoch # 4707 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0082-> 0.0082 -loss = 0.005023916482969071
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:26,992 INFO epoch # 4708 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0082-> 0.0082 -loss = 0.005005681201510015
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:27,013 INFO epoch # 4709 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0082-> 0.0082 -loss = 0.004954065349011216
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:27,035 INFO epoch # 4710 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0082-> 0.0082 -loss = 0.0049402292679587845
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:27,035 INFO *** epoch 4710, rolling-avg-loss (window=10)= 0.004970547909942979
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:27,057 INFO epoch # 4711 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0082-> 0.0082 -loss = 0.0049308115749227
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:27,079 INFO epoch # 4712 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0082-> 0.0082 -loss = 0.004940595499647316
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:27,101 INFO epoch # 4713 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0082-> 0.0082 -loss = 0.004929425384943897
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:27,122 INFO epoch # 4714 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0082-> 0.0082 -loss = 0.0049702806427376345
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:27,143 INFO epoch # 4715 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0082-> 0.0082 -loss = 0.005246088414423866
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:27,164 INFO epoch # 4716 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0082-> 0.0082 -loss = 0.004933249134410289
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:27,186 INFO epoch # 4717 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0082-> 0.0082 -loss = 0.004981182670235285
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:27,207 INFO epoch # 4718 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0082-> 0.0082 -loss = 0.00511597961303778
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:27,229 INFO epoch # 4719 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0082-> 0.0082 -loss = 0.004956524554927455
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:27,250 INFO epoch # 4720 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0082-> 0.0082 -loss = 0.005495052205333195
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:27,251 INFO *** epoch 4720, rolling-avg-loss (window=10)= 0.005049918969461942
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:27,272 INFO epoch # 4721 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0082-> 0.0082 -loss = 0.004934829417834408
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:27,294 INFO epoch # 4722 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0082-> 0.0082 -loss = 0.004931695058985497
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:27,316 INFO epoch # 4723 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0082-> 0.0082 -loss = 0.004918990252917865
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:27,337 INFO epoch # 4724 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0082-> 0.0082 -loss = 0.004926030875139986
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:27,358 INFO epoch # 4725 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0082-> 0.0082 -loss = 0.004951668109242746
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:27,379 INFO epoch # 4726 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0082-> 0.0082 -loss = 0.004932033361910726
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:27,401 INFO epoch # 4727 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0082-> 0.0082 -loss = 0.004943783143971814
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:27,422 INFO epoch # 4728 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0082-> 0.0082 -loss = 0.004927380050503416
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:27,444 INFO epoch # 4729 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0082-> 0.0082 -loss = 0.0049212167505174875
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:27,466 INFO epoch # 4730 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0082-> 0.0082 -loss = 0.004939547472531558
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:27,466 INFO *** epoch 4730, rolling-avg-loss (window=10)= 0.004932717449355551
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:27,487 INFO epoch # 4731 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0082-> 0.0082 -loss = 0.004966110857822059
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:27,509 INFO epoch # 4732 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0082-> 0.0082 -loss = 0.005017822375521064
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:27,530 INFO epoch # 4733 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0082-> 0.0082 -loss = 0.004976398020517081
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:27,552 INFO epoch # 4734 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0082-> 0.0081 -loss = 0.004946592709529796
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:27,573 INFO epoch # 4735 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.004906481968646403
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:27,594 INFO epoch # 4736 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.00491436200991302
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:27,616 INFO epoch # 4737 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.005006465895348811
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:27,638 INFO epoch # 4738 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.004919263022202358
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:27,660 INFO epoch # 4739 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.007079479773892672
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:27,682 INFO epoch # 4740 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.004977303198756999
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:27,682 INFO *** epoch 4740, rolling-avg-loss (window=10)= 0.005171027983215027
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:27,704 INFO epoch # 4741 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.004907522959911148
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:27,726 INFO epoch # 4742 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.004903177133201098
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:27,748 INFO epoch # 4743 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.004925732155243168
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:27,769 INFO epoch # 4744 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.0049978316892520525
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:27,790 INFO epoch # 4745 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.005047791339165997
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:27,811 INFO epoch # 4746 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.004916856891213683
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:27,832 INFO epoch # 4747 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.0049185831394424895
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:27,854 INFO epoch # 4748 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.004894423991572694
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:27,876 INFO epoch # 4749 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.0048992828642440145
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:27,898 INFO epoch # 4750 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.004950071846906212
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:27,898 INFO *** epoch 4750, rolling-avg-loss (window=10)= 0.004936127401015256
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:27,920 INFO epoch # 4751 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.0048999075315805385
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:27,942 INFO epoch # 4752 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.0049349176606483525
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:27,964 INFO epoch # 4753 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.004890256399903592
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:27,985 INFO epoch # 4754 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.00489078937425802
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:28,006 INFO epoch # 4755 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.00503354408647283
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:28,027 INFO epoch # 4756 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.004916014174341399
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:28,049 INFO epoch # 4757 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.004913930164548219
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:28,070 INFO epoch # 4758 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.00490589738728886
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:28,092 INFO epoch # 4759 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.004915135048577213
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:28,114 INFO epoch # 4760 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.004894127840088913
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:28,114 INFO *** epoch 4760, rolling-avg-loss (window=10)= 0.004919451966770794
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:28,136 INFO epoch # 4761 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.005000940616810112
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:28,158 INFO epoch # 4762 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.004886764010734623
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:28,179 INFO epoch # 4763 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.004886145160526212
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:28,200 INFO epoch # 4764 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.004938172311995004
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:28,221 INFO epoch # 4765 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.004939160902722506
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:28,242 INFO epoch # 4766 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.005112290780743933
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:28,264 INFO epoch # 4767 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.004892540302535053
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:28,286 INFO epoch # 4768 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.004879081634499016
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:28,307 INFO epoch # 4769 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.004907948947220575
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:28,328 INFO epoch # 4770 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.004880927401245572
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:28,328 INFO *** epoch 4770, rolling-avg-loss (window=10)= 0.004932397206903261
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:28,350 INFO epoch # 4771 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.004891592377134657
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:28,371 INFO epoch # 4772 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.004880525257249246
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:28,393 INFO epoch # 4773 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.0048794062195156584
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:28,414 INFO epoch # 4774 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.004880505748587893
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:28,435 INFO epoch # 4775 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.004934673928801203
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:28,456 INFO epoch # 4776 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.004960920767189236
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:28,478 INFO epoch # 4777 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.004889955498583731
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:28,500 INFO epoch # 4778 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.004870280199611443
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:28,522 INFO epoch # 4779 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.0049098402669187635
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:28,544 INFO epoch # 4780 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.004925286977595533
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:28,544 INFO *** epoch 4780, rolling-avg-loss (window=10)= 0.004902298724118737
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:28,566 INFO epoch # 4781 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.004877481902440195
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:28,588 INFO epoch # 4782 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.004881834951447672
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:28,610 INFO epoch # 4783 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.004918096708934172
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:28,632 INFO epoch # 4784 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.005021491606385098
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:28,653 INFO epoch # 4785 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.004873471437349508
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:28,674 INFO epoch # 4786 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.004879731830442324
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:28,696 INFO epoch # 4787 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.00503389976984181
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:28,718 INFO epoch # 4788 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.004964524263414205
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:28,740 INFO epoch # 4789 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.0048610497688059695
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:28,762 INFO epoch # 4790 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.004869637221418088
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:28,762 INFO *** epoch 4790, rolling-avg-loss (window=10)= 0.004918121946047904
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:28,784 INFO epoch # 4791 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.00486516017554095
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:28,806 INFO epoch # 4792 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.004875645368883852
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:28,827 INFO epoch # 4793 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.004888054363618721
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:28,848 INFO epoch # 4794 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.004924214366837987
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:28,869 INFO epoch # 4795 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.004866847444645828
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:28,891 INFO epoch # 4796 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.004877951892922283
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:28,912 INFO epoch # 4797 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.0048604223047732376
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:28,934 INFO epoch # 4798 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.005029668403949472
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:28,955 INFO epoch # 4799 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.004849789391300874
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:28,977 INFO epoch # 4800 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.004948292418703204
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:28,977 INFO *** epoch 4800, rolling-avg-loss (window=10)= 0.004898604613117641
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:28,999 INFO epoch # 4801 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.0048658911655365955
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:29,021 INFO epoch # 4802 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.004848687850426359
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:29,042 INFO epoch # 4803 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.0048551122927165125
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:29,063 INFO epoch # 4804 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.004885791942797368
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:29,084 INFO epoch # 4805 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.004842799223297334
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:29,105 INFO epoch # 4806 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.004879250718659023
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:29,127 INFO epoch # 4807 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.004858123328631336
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:29,148 INFO epoch # 4808 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.006067435699151247
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:29,170 INFO epoch # 4809 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.004962554114172235
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:29,192 INFO epoch # 4810 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.004853056549109169
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:29,192 INFO *** epoch 4810, rolling-avg-loss (window=10)= 0.004991870288449718
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:29,214 INFO epoch # 4811 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.004845704219405889
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:29,236 INFO epoch # 4812 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.004904300269117812
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:29,257 INFO epoch # 4813 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.004859351745835738
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:29,279 INFO epoch # 4814 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.004830935553400195
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:29,300 INFO epoch # 4815 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.004844129666707886
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:29,321 INFO epoch # 4816 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.0048453743947902694
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:29,342 INFO epoch # 4817 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.00486251004076621
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:29,364 INFO epoch # 4818 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.005292055147947394
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:29,385 INFO epoch # 4819 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.00482400893315571
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:29,407 INFO epoch # 4820 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.004920038578347885
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:29,407 INFO *** epoch 4820, rolling-avg-loss (window=10)= 0.0049028408549474985
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:29,429 INFO epoch # 4821 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.004828324198570044
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:29,451 INFO epoch # 4822 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.0048603280793031445
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:29,472 INFO epoch # 4823 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.004837472377403174
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:29,493 INFO epoch # 4824 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.004861132800215273
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:29,514 INFO epoch # 4825 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.00495724565735145
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:29,536 INFO epoch # 4826 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.00489061453663453
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:29,557 INFO epoch # 4827 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.0057246300821134355
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:29,578 INFO epoch # 4828 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.004839026396439294
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:29,600 INFO epoch # 4829 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.004831605059735011
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:29,622 INFO epoch # 4830 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.008 -loss = 0.004853306552831782
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:29,622 INFO *** epoch 4830, rolling-avg-loss (window=10)= 0.004948368574059714
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:29,644 INFO epoch # 4831 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.008-> 0.008 -loss = 0.004815351004253898
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:29,666 INFO epoch # 4832 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.008-> 0.008 -loss = 0.004827381319955748
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:29,688 INFO epoch # 4833 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.008-> 0.008 -loss = 0.004823668468816322
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:29,709 INFO epoch # 4834 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.008-> 0.008 -loss = 0.004826439869248134
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:29,730 INFO epoch # 4835 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.008-> 0.008 -loss = 0.004816206928808242
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:29,751 INFO epoch # 4836 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.008-> 0.008 -loss = 0.005071406607385143
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:29,773 INFO epoch # 4837 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.008-> 0.008 -loss = 0.004825819964025868
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:29,794 INFO epoch # 4838 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.008-> 0.008 -loss = 0.004916811753901129
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:29,816 INFO epoch # 4839 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.008-> 0.008 -loss = 0.004809362834748754
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:29,837 INFO epoch # 4840 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.008-> 0.008 -loss = 0.00484635464817984
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:29,837 INFO *** epoch 4840, rolling-avg-loss (window=10)= 0.004857880339932308
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:29,859 INFO epoch # 4841 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.008-> 0.008 -loss = 0.004888808845862513
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:29,881 INFO epoch # 4842 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.008-> 0.008 -loss = 0.004819841436983552
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:29,902 INFO epoch # 4843 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.008-> 0.008 -loss = 0.004805979246611969
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:29,923 INFO epoch # 4844 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.008-> 0.008 -loss = 0.004806569772426883
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:29,944 INFO epoch # 4845 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.008-> 0.008 -loss = 0.0048031180103862425
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:29,966 INFO epoch # 4846 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.008-> 0.008 -loss = 0.004915903135952249
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:29,987 INFO epoch # 4847 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.008-> 0.008 -loss = 0.0048392203152616275
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:30,009 INFO epoch # 4848 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.008-> 0.008 -loss = 0.005462160897877766
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:30,031 INFO epoch # 4849 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.008-> 0.008 -loss = 0.004813415360331419
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:30,053 INFO epoch # 4850 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.008-> 0.008 -loss = 0.00528181561458041
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:30,053 INFO *** epoch 4850, rolling-avg-loss (window=10)= 0.004943683263627463
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:30,075 INFO epoch # 4851 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.008-> 0.008 -loss = 0.004806570597793325
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:30,096 INFO epoch # 4852 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.008-> 0.008 -loss = 0.004827656734050834
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:30,118 INFO epoch # 4853 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.008-> 0.008 -loss = 0.004857188492678688
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:30,139 INFO epoch # 4854 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.008-> 0.008 -loss = 0.004835790387005545
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:30,160 INFO epoch # 4855 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.008-> 0.008 -loss = 0.00482356216525659
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:30,181 INFO epoch # 4856 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.008-> 0.0079 -loss = 0.005643543274345575
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:30,202 INFO epoch # 4857 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0079-> 0.0079 -loss = 0.0060048879859095905
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:30,224 INFO epoch # 4858 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0079-> 0.0079 -loss = 0.004809279083929141
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:30,246 INFO epoch # 4859 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0079-> 0.0079 -loss = 0.004814568710571621
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:30,268 INFO epoch # 4860 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0079-> 0.0079 -loss = 0.0047886250213196035
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:30,268 INFO *** epoch 4860, rolling-avg-loss (window=10)= 0.005021167245286051
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:30,290 INFO epoch # 4861 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0079-> 0.0079 -loss = 0.00481241918168962
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:30,312 INFO epoch # 4862 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0079-> 0.0079 -loss = 0.004796176575837308
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:30,333 INFO epoch # 4863 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0079-> 0.0079 -loss = 0.004811139359844674
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:30,354 INFO epoch # 4864 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0079-> 0.0079 -loss = 0.004795968157850439
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:30,375 INFO epoch # 4865 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0079-> 0.0079 -loss = 0.00482225388623192
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:30,396 INFO epoch # 4866 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0079-> 0.0079 -loss = 0.0048044885115814395
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:30,418 INFO epoch # 4867 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0079-> 0.0079 -loss = 0.0047940245112840785
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:30,439 INFO epoch # 4868 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0079-> 0.0079 -loss = 0.0047919254639055
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:30,461 INFO epoch # 4869 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0079-> 0.0079 -loss = 0.005636887786749867
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:30,483 INFO epoch # 4870 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0079-> 0.0079 -loss = 0.004814391750187497
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:30,483 INFO *** epoch 4870, rolling-avg-loss (window=10)= 0.004887967518516234
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:30,505 INFO epoch # 4871 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0079-> 0.0079 -loss = 0.004785230229572335
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:30,527 INFO epoch # 4872 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0079-> 0.0079 -loss = 0.004792494706634898
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:30,548 INFO epoch # 4873 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0079-> 0.0079 -loss = 0.004831529419789149
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:30,569 INFO epoch # 4874 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0079-> 0.0079 -loss = 0.004851657960898592
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:30,590 INFO epoch # 4875 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0079-> 0.0079 -loss = 0.004802740237209946
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:30,612 INFO epoch # 4876 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0079-> 0.0079 -loss = 0.004780175377163687
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:30,633 INFO epoch # 4877 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0079-> 0.0079 -loss = 0.004773532715489637
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:30,655 INFO epoch # 4878 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0079-> 0.0079 -loss = 0.00479616302800423
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:30,676 INFO epoch # 4879 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0079-> 0.0079 -loss = 0.004898853947452153
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:30,698 INFO epoch # 4880 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0079-> 0.0079 -loss = 0.004877902241787524
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:30,698 INFO *** epoch 4880, rolling-avg-loss (window=10)= 0.004819027986400215
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:30,720 INFO epoch # 4881 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0079-> 0.0079 -loss = 0.0047817197928452515
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:30,743 INFO epoch # 4882 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0079-> 0.0079 -loss = 0.004796702070962056
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:30,765 INFO epoch # 4883 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0079-> 0.0079 -loss = 0.004775677977704618
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:30,786 INFO epoch # 4884 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0079-> 0.0079 -loss = 0.004835732614083099
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:30,807 INFO epoch # 4885 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0079-> 0.0079 -loss = 0.004773577546075103
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:30,828 INFO epoch # 4886 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0079-> 0.0079 -loss = 0.00492975268389273
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:30,850 INFO epoch # 4887 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0079-> 0.0079 -loss = 0.004972183218342252
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:30,872 INFO epoch # 4888 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0079-> 0.0079 -loss = 0.0048273311058437685
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:30,893 INFO epoch # 4889 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0079-> 0.0079 -loss = 0.004870264689088799
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:30,916 INFO epoch # 4890 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0079-> 0.0079 -loss = 0.0048439654310641345
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:30,916 INFO *** epoch 4890, rolling-avg-loss (window=10)= 0.004840690712990181
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:30,938 INFO epoch # 4891 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0079-> 0.0079 -loss = 0.004798921721885563
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:30,960 INFO epoch # 4892 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0079-> 0.0079 -loss = 0.004871343067861744
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:30,981 INFO epoch # 4893 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0079-> 0.0079 -loss = 0.004801382077857852
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:31,002 INFO epoch # 4894 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0079-> 0.0079 -loss = 0.004794879469045554
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:31,023 INFO epoch # 4895 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0079-> 0.0079 -loss = 0.004904848337901058
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:31,044 INFO epoch # 4896 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0079-> 0.0079 -loss = 0.004816046759515302
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:31,066 INFO epoch # 4897 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0079-> 0.0079 -loss = 0.004772565314851818
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:31,087 INFO epoch # 4898 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0079-> 0.0079 -loss = 0.0047637524985475466
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:31,109 INFO epoch # 4899 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0079-> 0.0079 -loss = 0.006862372007162776
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:31,131 INFO epoch # 4900 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0079-> 0.0079 -loss = 0.004827244711123058
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:31,131 INFO *** epoch 4900, rolling-avg-loss (window=10)= 0.005021335596575227
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:31,153 INFO epoch # 4901 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0079-> 0.0079 -loss = 0.005196364883886417
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:31,175 INFO epoch # 4902 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0079-> 0.0079 -loss = 0.004818685043574078
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:31,196 INFO epoch # 4903 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0079-> 0.0079 -loss = 0.004762036974170769
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:31,217 INFO epoch # 4904 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0079-> 0.0079 -loss = 0.004880711025180062
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:31,239 INFO epoch # 4905 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0079-> 0.0079 -loss = 0.004848135206884763
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:31,260 INFO epoch # 4906 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0079-> 0.0079 -loss = 0.004746129035993363
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:31,281 INFO epoch # 4907 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0079-> 0.0079 -loss = 0.004945901917380979
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:31,303 INFO epoch # 4908 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0079-> 0.0079 -loss = 0.00476672762670205
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:31,325 INFO epoch # 4909 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0079-> 0.0079 -loss = 0.004879436375631485
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:31,346 INFO epoch # 4910 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0079-> 0.0079 -loss = 0.0047658912944825715
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:31,347 INFO *** epoch 4910, rolling-avg-loss (window=10)= 0.0048610019383886535
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:31,368 INFO epoch # 4911 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0079-> 0.0079 -loss = 0.004788506772456458
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:31,390 INFO epoch # 4912 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0079-> 0.0079 -loss = 0.004756510485094623
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:31,412 INFO epoch # 4913 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0079-> 0.0079 -loss = 0.00475997608009493
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:31,433 INFO epoch # 4914 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0079-> 0.0079 -loss = 0.00479740406262863
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:31,454 INFO epoch # 4915 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0079-> 0.0079 -loss = 0.00475571754941484
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:31,475 INFO epoch # 4916 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0079-> 0.0079 -loss = 0.004742787540635618
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:31,497 INFO epoch # 4917 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0079-> 0.0079 -loss = 0.004793270332811517
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:31,518 INFO epoch # 4918 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0079-> 0.0079 -loss = 0.0047775743951206096
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:31,540 INFO epoch # 4919 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0079-> 0.0079 -loss = 0.004756811839797592
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:31,561 INFO epoch # 4920 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0079-> 0.0079 -loss = 0.00473892744139448
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:31,561 INFO *** epoch 4920, rolling-avg-loss (window=10)= 0.00476674864994493
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:31,584 INFO epoch # 4921 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0079-> 0.0079 -loss = 0.004735365802844171
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:31,606 INFO epoch # 4922 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0079-> 0.0079 -loss = 0.004868581652772264
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:31,627 INFO epoch # 4923 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0079-> 0.0079 -loss = 0.004759943497447239
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:31,649 INFO epoch # 4924 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0079-> 0.0079 -loss = 0.00474183461847133
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:31,670 INFO epoch # 4925 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0079-> 0.0079 -loss = 0.004737445839054999
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:31,691 INFO epoch # 4926 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0079-> 0.0079 -loss = 0.0047369772064485005
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:31,712 INFO epoch # 4927 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0079-> 0.0079 -loss = 0.004751067412144039
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:31,734 INFO epoch # 4928 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0079-> 0.0079 -loss = 0.004825024021556601
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:31,756 INFO epoch # 4929 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0079-> 0.0079 -loss = 0.004809098379610077
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:31,778 INFO epoch # 4930 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0079-> 0.0079 -loss = 0.004764707926369738
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:31,778 INFO *** epoch 4930, rolling-avg-loss (window=10)= 0.004773004635671896
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:31,800 INFO epoch # 4931 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0079-> 0.0079 -loss = 0.004756745953272912
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:31,822 INFO epoch # 4932 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0079-> 0.0078 -loss = 0.004743912093545077
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:31,843 INFO epoch # 4933 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0078-> 0.0078 -loss = 0.0047318227061623475
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:31,864 INFO epoch # 4934 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0078-> 0.0078 -loss = 0.00474025302719383
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:31,885 INFO epoch # 4935 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0078-> 0.0078 -loss = 0.004736270442663226
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:31,907 INFO epoch # 4936 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0078-> 0.0078 -loss = 0.004736744969704887
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:31,928 INFO epoch # 4937 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0078-> 0.0078 -loss = 0.0047410242277692305
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:31,949 INFO epoch # 4938 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0078-> 0.0078 -loss = 0.004717593507848505
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:31,971 INFO epoch # 4939 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0078-> 0.0078 -loss = 0.004726196722913301
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:31,992 INFO epoch # 4940 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0078-> 0.0078 -loss = 0.004737381857921719
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:31,993 INFO *** epoch 4940, rolling-avg-loss (window=10)= 0.004736794550899504
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:32,015 INFO epoch # 4941 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0078-> 0.0078 -loss = 0.004831572609873547
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:32,036 INFO epoch # 4942 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0078-> 0.0078 -loss = 0.004868243298915331
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:32,058 INFO epoch # 4943 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0078-> 0.0078 -loss = 0.004747610923004686
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:32,079 INFO epoch # 4944 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0078-> 0.0078 -loss = 0.004910427291179076
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:32,100 INFO epoch # 4945 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0078-> 0.0078 -loss = 0.006746265469701029
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:32,122 INFO epoch # 4946 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0078-> 0.0078 -loss = 0.004778796586833778
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:32,143 INFO epoch # 4947 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0078-> 0.0078 -loss = 0.004729780106572434
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:32,164 INFO epoch # 4948 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0078-> 0.0078 -loss = 0.004729065031824575
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:32,186 INFO epoch # 4949 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0078-> 0.0078 -loss = 0.004713267346687644
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:32,208 INFO epoch # 4950 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0078-> 0.0078 -loss = 0.004856938803641242
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:32,208 INFO *** epoch 4950, rolling-avg-loss (window=10)= 0.004991196746823334
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:32,231 INFO epoch # 4951 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0078-> 0.0078 -loss = 0.0047265585608329275
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:32,253 INFO epoch # 4952 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0078-> 0.0078 -loss = 0.004751555452457978
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:32,274 INFO epoch # 4953 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0078-> 0.0078 -loss = 0.0047377761657116935
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:32,295 INFO epoch # 4954 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0078-> 0.0078 -loss = 0.0047212968065650784
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:32,316 INFO epoch # 4955 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0078-> 0.0078 -loss = 0.004743305164083722
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:32,337 INFO epoch # 4956 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0078-> 0.0078 -loss = 0.006698616154608317
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:32,359 INFO epoch # 4957 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0078-> 0.0078 -loss = 0.004817211856789072
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:32,380 INFO epoch # 4958 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0078-> 0.0078 -loss = 0.004756332341457892
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:32,402 INFO epoch # 4959 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0078-> 0.0078 -loss = 0.0047482798545388505
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:32,424 INFO epoch # 4960 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0078-> 0.0077 -loss = 0.004729183595372888
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:32,424 INFO *** epoch 4960, rolling-avg-loss (window=10)= 0.004943011595241842
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:32,446 INFO epoch # 4961 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0077-> 0.0077 -loss = 0.004724924112451845
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:32,468 INFO epoch # 4962 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0077-> 0.0077 -loss = 0.005382624419326021
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:32,491 INFO epoch # 4963 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0077-> 0.0077 -loss = 0.004703893123405578
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:32,513 INFO epoch # 4964 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0077-> 0.0077 -loss = 0.004702519465354271
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:32,535 INFO epoch # 4965 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0077-> 0.0077 -loss = 0.004698680873843841
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:32,557 INFO epoch # 4966 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0077-> 0.0077 -loss = 0.004792443789483514
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:32,579 INFO epoch # 4967 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0077-> 0.0077 -loss = 0.004789816298398364
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:32,601 INFO epoch # 4968 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0077-> 0.0077 -loss = 0.004709663244284457
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:32,623 INFO epoch # 4969 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0077-> 0.0077 -loss = 0.004887749408226227
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:32,645 INFO epoch # 4970 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0077-> 0.0077 -loss = 0.004694683544585132
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:32,645 INFO *** epoch 4970, rolling-avg-loss (window=10)= 0.004808699827935925
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:32,667 INFO epoch # 4971 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0077-> 0.0077 -loss = 0.004702414034909452
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:32,689 INFO epoch # 4972 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0077-> 0.0077 -loss = 0.004753494815304293
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:32,710 INFO epoch # 4973 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0077-> 0.0077 -loss = 0.004712339507022989
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:32,732 INFO epoch # 4974 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0077-> 0.0077 -loss = 0.004836616659304127
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:32,754 INFO epoch # 4975 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0077-> 0.0077 -loss = 0.004780938123076339
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:32,775 INFO epoch # 4976 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0077-> 0.0077 -loss = 0.004718617676189751
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:32,796 INFO epoch # 4977 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0077-> 0.0077 -loss = 0.004688455788709689
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:32,818 INFO epoch # 4978 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0077-> 0.0077 -loss = 0.004695407937106211
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:32,839 INFO epoch # 4979 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0077-> 0.0077 -loss = 0.004701739695519791
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:32,861 INFO epoch # 4980 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0077-> 0.0077 -loss = 0.004710029721536557
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:32,861 INFO *** epoch 4980, rolling-avg-loss (window=10)= 0.00473000539586792
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:32,883 INFO epoch # 4981 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0077-> 0.0077 -loss = 0.004788507540979481
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:32,905 INFO epoch # 4982 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0077-> 0.0077 -loss = 0.004732413295641891
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:32,926 INFO epoch # 4983 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0077-> 0.0077 -loss = 0.004702071517385775
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:32,947 INFO epoch # 4984 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0077-> 0.0077 -loss = 0.004683501861109107
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:32,968 INFO epoch # 4985 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0077-> 0.0077 -loss = 0.004701246594777331
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:32,989 INFO epoch # 4986 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0077-> 0.0077 -loss = 0.004699526554759359
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:33,011 INFO epoch # 4987 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0077-> 0.0077 -loss = 0.005275262108625611
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:33,033 INFO epoch # 4988 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0077-> 0.0077 -loss = 0.004697698968811892
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:33,054 INFO epoch # 4989 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0077-> 0.0077 -loss = 0.00468638490565354
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:33,076 INFO epoch # 4990 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0077-> 0.0077 -loss = 0.00469366206198174
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:33,076 INFO *** epoch 4990, rolling-avg-loss (window=10)= 0.004766027540972573
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:33,098 INFO epoch # 4991 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0077-> 0.0077 -loss = 0.0047606720099793165
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:33,120 INFO epoch # 4992 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0077-> 0.0077 -loss = 0.004727857227408094
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:33,141 INFO epoch # 4993 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0077-> 0.0077 -loss = 0.0046805660022073425
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:33,162 INFO epoch # 4994 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0077-> 0.0077 -loss = 0.004693644117651274
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:33,183 INFO epoch # 4995 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0077-> 0.0077 -loss = 0.0046742021368118
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:33,204 INFO epoch # 4996 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0077-> 0.0077 -loss = 0.004682817447246634
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:33,226 INFO epoch # 4997 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0077-> 0.0077 -loss = 0.004693843209679471
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:33,248 INFO epoch # 4998 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0077-> 0.0077 -loss = 0.0046814853594696615
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:33,270 INFO epoch # 4999 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0077-> 0.0077 -loss = 0.004851425381275476
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:33,292 INFO epoch # 5000 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0077-> 0.0077 -loss = 0.004709324693976669
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:33,292 INFO *** epoch 5000, rolling-avg-loss (window=10)= 0.004715583758570574
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:33,314 INFO epoch # 5001 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0077-> 0.0077 -loss = 0.004682049795519561
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:33,336 INFO epoch # 5002 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0077-> 0.0077 -loss = 0.005808815643831622
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:33,357 INFO epoch # 5003 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0077-> 0.0077 -loss = 0.004712726039542758
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:33,378 INFO epoch # 5004 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0077-> 0.0077 -loss = 0.004672098419177928
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:33,400 INFO epoch # 5005 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0077-> 0.0077 -loss = 0.005976219148578821
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:33,421 INFO epoch # 5006 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0077-> 0.0077 -loss = 0.004703063802480756
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:33,442 INFO epoch # 5007 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0077-> 0.0077 -loss = 0.004786776402397663
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:33,464 INFO epoch # 5008 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0077-> 0.0077 -loss = 0.00466619252529199
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:33,485 INFO epoch # 5009 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0077-> 0.0077 -loss = 0.004667588635129505
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:33,506 INFO epoch # 5010 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0077-> 0.0077 -loss = 0.004668255194701487
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:33,507 INFO *** epoch 5010, rolling-avg-loss (window=10)= 0.004934378560665209
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:33,528 INFO epoch # 5011 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0077-> 0.0077 -loss = 0.004660918618355936
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:33,550 INFO epoch # 5012 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0077-> 0.0077 -loss = 0.004668521418352611
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:33,571 INFO epoch # 5013 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0077-> 0.0077 -loss = 0.004673003077186877
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:33,593 INFO epoch # 5014 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0077-> 0.0077 -loss = 0.004665122040023562
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:33,614 INFO epoch # 5015 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0077-> 0.0077 -loss = 0.004697555956227006
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:33,636 INFO epoch # 5016 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0077-> 0.0077 -loss = 0.004662736082536867
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:33,658 INFO epoch # 5017 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0077-> 0.0077 -loss = 0.004685185931521119
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:33,679 INFO epoch # 5018 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0077-> 0.0077 -loss = 0.004704397679233807
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:33,701 INFO epoch # 5019 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0077-> 0.0077 -loss = 0.004863741900408058
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:33,723 INFO epoch # 5020 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0077-> 0.0077 -loss = 0.0047252460917661665
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:33,723 INFO *** epoch 5020, rolling-avg-loss (window=10)= 0.004700642879561201
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:33,746 INFO epoch # 5021 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0077-> 0.0077 -loss = 0.004663961291953456
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:33,768 INFO epoch # 5022 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0077-> 0.0076 -loss = 0.004660926317228586
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:33,789 INFO epoch # 5023 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0076-> 0.0076 -loss = 0.004663462110329419
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:33,811 INFO epoch # 5024 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0076-> 0.0076 -loss = 0.004726563847725629
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:33,832 INFO epoch # 5025 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0076-> 0.0076 -loss = 0.004656196454561723
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:33,853 INFO epoch # 5026 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0076-> 0.0076 -loss = 0.004650521899748128
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:33,874 INFO epoch # 5027 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0076-> 0.0076 -loss = 0.004660927741497289
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:33,896 INFO epoch # 5028 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0076-> 0.0076 -loss = 0.004687935255788034
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:33,917 INFO epoch # 5029 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0076-> 0.0076 -loss = 0.004743498506286414
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:33,939 INFO epoch # 5030 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0076-> 0.0076 -loss = 0.00471473544894252
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:33,939 INFO *** epoch 5030, rolling-avg-loss (window=10)= 0.00468287288740612
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:33,960 INFO epoch # 5031 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0076-> 0.0076 -loss = 0.00471862271297141
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:33,982 INFO epoch # 5032 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0076-> 0.0076 -loss = 0.004672269755246816
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:34,004 INFO epoch # 5033 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0076-> 0.0076 -loss = 0.004634147479009698
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:34,025 INFO epoch # 5034 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0076-> 0.0076 -loss = 0.004652653052289679
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:34,046 INFO epoch # 5035 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0076-> 0.0076 -loss = 0.004667841976697673
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:34,067 INFO epoch # 5036 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0076-> 0.0076 -loss = 0.004648525777156465
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:34,089 INFO epoch # 5037 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0076-> 0.0076 -loss = 0.004640768393983308
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:34,110 INFO epoch # 5038 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0076-> 0.0076 -loss = 0.004657822953959112
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:34,132 INFO epoch # 5039 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0076-> 0.0076 -loss = 0.004880242007857305
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:34,154 INFO epoch # 5040 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0076-> 0.0076 -loss = 0.0046691834286320955
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:34,154 INFO *** epoch 5040, rolling-avg-loss (window=10)= 0.004684207753780356
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:34,175 INFO epoch # 5041 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0076-> 0.0076 -loss = 0.004742695214190462
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:34,197 INFO epoch # 5042 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0076-> 0.0076 -loss = 0.00463748512447637
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:34,218 INFO epoch # 5043 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0076-> 0.0076 -loss = 0.004667955462537066
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:34,240 INFO epoch # 5044 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0076-> 0.0076 -loss = 0.0046328433418239
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:34,261 INFO epoch # 5045 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0076-> 0.0076 -loss = 0.004653485248127254
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:34,282 INFO epoch # 5046 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0076-> 0.0076 -loss = 0.004645247003281838
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:34,304 INFO epoch # 5047 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0076-> 0.0076 -loss = 0.004656320057620178
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:34,325 INFO epoch # 5048 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0076-> 0.0076 -loss = 0.004729606375803996
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:34,348 INFO epoch # 5049 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0076-> 0.0076 -loss = 0.00462905064887309
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:34,370 INFO epoch # 5050 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0076-> 0.0076 -loss = 0.004629782087249623
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:34,370 INFO *** epoch 5050, rolling-avg-loss (window=10)= 0.004662447056398377
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:34,392 INFO epoch # 5051 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0076-> 0.0076 -loss = 0.004634422253730008
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:34,414 INFO epoch # 5052 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0076-> 0.0076 -loss = 0.00462718266317097
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:34,435 INFO epoch # 5053 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0076-> 0.0076 -loss = 0.004654823094824678
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:34,456 INFO epoch # 5054 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0076-> 0.0076 -loss = 0.0056767652386042755
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:34,478 INFO epoch # 5055 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0076-> 0.0076 -loss = 0.0047162532773654675
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:34,499 INFO epoch # 5056 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0076-> 0.0076 -loss = 0.004636592164388276
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:34,520 INFO epoch # 5057 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0076-> 0.0076 -loss = 0.004639867172954837
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:34,542 INFO epoch # 5058 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0076-> 0.0076 -loss = 0.0046435610584012466
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:34,564 INFO epoch # 5059 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0076-> 0.0076 -loss = 0.004791995598679932
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:34,586 INFO epoch # 5060 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0076-> 0.0076 -loss = 0.004674453315601568
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:34,586 INFO *** epoch 5060, rolling-avg-loss (window=10)= 0.004769591583772126
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:34,608 INFO epoch # 5061 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0076-> 0.0076 -loss = 0.004617062462330068
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:34,630 INFO epoch # 5062 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0076-> 0.0076 -loss = 0.004628821491678536
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:34,651 INFO epoch # 5063 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0076-> 0.0076 -loss = 0.004610426123463185
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:34,672 INFO epoch # 5064 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0076-> 0.0076 -loss = 0.004680862077293568
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:34,693 INFO epoch # 5065 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0076-> 0.0076 -loss = 0.004637728072339087
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:34,714 INFO epoch # 5066 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0076-> 0.0076 -loss = 0.004616735744093603
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:34,736 INFO epoch # 5067 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0076-> 0.0076 -loss = 0.0046616503241239116
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:34,758 INFO epoch # 5068 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0076-> 0.0076 -loss = 0.004635827885067556
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:34,781 INFO epoch # 5069 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0076-> 0.0076 -loss = 0.004642916748707648
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:34,803 INFO epoch # 5070 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0076-> 0.0076 -loss = 0.004642040672479197
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:34,803 INFO *** epoch 5070, rolling-avg-loss (window=10)= 0.004637407160157636
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:34,825 INFO epoch # 5071 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0076-> 0.0076 -loss = 0.004614563649738557
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:34,846 INFO epoch # 5072 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0076-> 0.0076 -loss = 0.004612176567206916
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:34,868 INFO epoch # 5073 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0076-> 0.0076 -loss = 0.004631412630260456
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:34,889 INFO epoch # 5074 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0076-> 0.0075 -loss = 0.004679003654018743
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:34,910 INFO epoch # 5075 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0075-> 0.0075 -loss = 0.005451181843454833
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:34,931 INFO epoch # 5076 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0075-> 0.0075 -loss = 0.004632740427041426
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:34,953 INFO epoch # 5077 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0075-> 0.0075 -loss = 0.004645361228540423
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:34,974 INFO epoch # 5078 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0075-> 0.0075 -loss = 0.004612043923771125
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:34,996 INFO epoch # 5079 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0075-> 0.0075 -loss = 0.004644928972993512
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:35,018 INFO epoch # 5080 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0075-> 0.0075 -loss = 0.0046068189476500265
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:35,018 INFO *** epoch 5080, rolling-avg-loss (window=10)= 0.004713023184467602
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:35,040 INFO epoch # 5081 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0075-> 0.0075 -loss = 0.004635887806216488
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:35,062 INFO epoch # 5082 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0075-> 0.0075 -loss = 0.004616020958565059
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:35,084 INFO epoch # 5083 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0075-> 0.0075 -loss = 0.004638497139239917
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:35,105 INFO epoch # 5084 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0075-> 0.0075 -loss = 0.004672797373132198
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:35,126 INFO epoch # 5085 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0075-> 0.0075 -loss = 0.004611967633536551
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:35,147 INFO epoch # 5086 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0075-> 0.0075 -loss = 0.004655056147385039
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:35,169 INFO epoch # 5087 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0075-> 0.0075 -loss = 0.004611701782778255
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:35,190 INFO epoch # 5088 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0075-> 0.0075 -loss = 0.005438319578388473
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:35,212 INFO epoch # 5089 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0075-> 0.0075 -loss = 0.004695892559539061
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:35,233 INFO epoch # 5090 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0075-> 0.0075 -loss = 0.004599563303600007
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:35,234 INFO *** epoch 5090, rolling-avg-loss (window=10)= 0.004717570428238105
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:35,256 INFO epoch # 5091 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0075-> 0.0075 -loss = 0.004600388580001891
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:35,278 INFO epoch # 5092 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0075-> 0.0075 -loss = 0.00582577461591427
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:35,299 INFO epoch # 5093 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0075-> 0.0075 -loss = 0.004702366491983412
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:35,320 INFO epoch # 5094 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0075-> 0.0075 -loss = 0.0046052440393395955
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:35,341 INFO epoch # 5095 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0075-> 0.0075 -loss = 0.004600466241754475
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:35,363 INFO epoch # 5096 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0075-> 0.0075 -loss = 0.004660681099267094
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:35,384 INFO epoch # 5097 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0075-> 0.0075 -loss = 0.004592813190356537
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:35,406 INFO epoch # 5098 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0075-> 0.0075 -loss = 0.004601023618306499
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:35,428 INFO epoch # 5099 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0075-> 0.0075 -loss = 0.004589575308273197
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:35,449 INFO epoch # 5100 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0075-> 0.0075 -loss = 0.004589760364069662
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:35,449 INFO *** epoch 5100, rolling-avg-loss (window=10)= 0.004736809354926663
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:35,471 INFO epoch # 5101 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0075-> 0.0075 -loss = 0.0045969375260028755
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:35,493 INFO epoch # 5102 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0075-> 0.0075 -loss = 0.00458899363547971
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:35,514 INFO epoch # 5103 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0075-> 0.0075 -loss = 0.004640220531655359
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:35,535 INFO epoch # 5104 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0075-> 0.0075 -loss = 0.004633750814718951
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:35,556 INFO epoch # 5105 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0075-> 0.0075 -loss = 0.004624133274774067
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:35,577 INFO epoch # 5106 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0075-> 0.0075 -loss = 0.004600512771503418
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:35,599 INFO epoch # 5107 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0075-> 0.0075 -loss = 0.004587915243973839
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:35,623 INFO epoch # 5108 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0075-> 0.0075 -loss = 0.004597989118337864
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:35,645 INFO epoch # 5109 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0075-> 0.0075 -loss = 0.004595149748638505
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:35,667 INFO epoch # 5110 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0075-> 0.0075 -loss = 0.004580684427310189
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:35,667 INFO *** epoch 5110, rolling-avg-loss (window=10)= 0.004604628709239477
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:35,689 INFO epoch # 5111 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0075-> 0.0075 -loss = 0.004599163843522547
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:35,711 INFO epoch # 5112 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0075-> 0.0075 -loss = 0.0046502386321662925
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:35,732 INFO epoch # 5113 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0075-> 0.0075 -loss = 0.004592681782014552
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:35,754 INFO epoch # 5114 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0075-> 0.0075 -loss = 0.004653776187296899
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:35,776 INFO epoch # 5115 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0075-> 0.0075 -loss = 0.004712701780590578
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:35,797 INFO epoch # 5116 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0075-> 0.0075 -loss = 0.004698930926679168
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:35,819 INFO epoch # 5117 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0075-> 0.0075 -loss = 0.0045990673679625615
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:35,841 INFO epoch # 5118 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0075-> 0.0075 -loss = 0.004576597580125963
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:35,863 INFO epoch # 5119 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0075-> 0.0075 -loss = 0.0054146128768479684
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:35,884 INFO epoch # 5120 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0075-> 0.0075 -loss = 0.004625893163392902
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:35,885 INFO *** epoch 5120, rolling-avg-loss (window=10)= 0.004712366414059943
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:35,906 INFO epoch # 5121 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0075-> 0.0075 -loss = 0.004679059002228314
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:35,928 INFO epoch # 5122 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0075-> 0.0075 -loss = 0.004653777801649994
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:35,950 INFO epoch # 5123 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0075-> 0.0075 -loss = 0.004693807373769232
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:35,971 INFO epoch # 5124 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0075-> 0.0075 -loss = 0.004747474014948239
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:35,993 INFO epoch # 5125 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0075-> 0.0075 -loss = 0.004599569601850817
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:36,014 INFO epoch # 5126 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0075-> 0.0075 -loss = 0.004573492695271852
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:36,035 INFO epoch # 5127 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0075-> 0.0075 -loss = 0.004578555079206126
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:36,057 INFO epoch # 5128 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0075-> 0.0075 -loss = 0.0058185300422337605
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:36,079 INFO epoch # 5129 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0075-> 0.0075 -loss = 0.006486087519078865
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:36,101 INFO epoch # 5130 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0075-> 0.0075 -loss = 0.004598061570504797
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:36,101 INFO *** epoch 5130, rolling-avg-loss (window=10)= 0.0049428414700742
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:36,123 INFO epoch # 5131 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0075-> 0.0075 -loss = 0.004572117221869121
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:36,144 INFO epoch # 5132 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0075-> 0.0075 -loss = 0.004585833348755841
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:36,166 INFO epoch # 5133 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0075-> 0.0075 -loss = 0.004572273946905625
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:36,187 INFO epoch # 5134 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0075-> 0.0075 -loss = 0.004569214390357956
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:36,208 INFO epoch # 5135 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0075-> 0.0075 -loss = 0.004584780532240984
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:36,229 INFO epoch # 5136 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0075-> 0.0075 -loss = 0.004575364322590758
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:36,251 INFO epoch # 5137 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0075-> 0.0075 -loss = 0.004628921999028535
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:36,272 INFO epoch # 5138 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0075-> 0.0075 -loss = 0.004552993626020907
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:36,294 INFO epoch # 5139 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0075-> 0.0075 -loss = 0.004560627658065641
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:36,315 INFO epoch # 5140 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0075-> 0.0075 -loss = 0.004596078530084924
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:36,315 INFO *** epoch 5140, rolling-avg-loss (window=10)= 0.004579820557592029
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:36,337 INFO epoch # 5141 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0075-> 0.0075 -loss = 0.0046173982500476995
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:36,359 INFO epoch # 5142 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0075-> 0.0075 -loss = 0.004591843983689614
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:36,381 INFO epoch # 5143 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0075-> 0.0075 -loss = 0.004570933934701316
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:36,402 INFO epoch # 5144 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0075-> 0.0075 -loss = 0.004561042232126056
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:36,423 INFO epoch # 5145 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0075-> 0.0075 -loss = 0.004588942725604284
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:36,444 INFO epoch # 5146 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0075-> 0.0075 -loss = 0.004569254385387467
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:36,465 INFO epoch # 5147 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0075-> 0.0075 -loss = 0.004563406483612198
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:36,487 INFO epoch # 5148 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0075-> 0.0075 -loss = 0.004545181495814177
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:36,509 INFO epoch # 5149 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0075-> 0.0075 -loss = 0.004564573413517792
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:36,531 INFO epoch # 5150 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0075-> 0.0075 -loss = 0.004549322678030876
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:36,531 INFO *** epoch 5150, rolling-avg-loss (window=10)= 0.004572189958253148
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:36,552 INFO epoch # 5151 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0075-> 0.0075 -loss = 0.0045540938972408185
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:36,574 INFO epoch # 5152 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0075-> 0.0075 -loss = 0.00457496044873551
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:36,596 INFO epoch # 5153 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0075-> 0.0075 -loss = 0.004651095117878867
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:36,618 INFO epoch # 5154 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0075-> 0.0075 -loss = 0.004636386247511837
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:36,640 INFO epoch # 5155 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0075-> 0.0075 -loss = 0.004647963965908275
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:36,662 INFO epoch # 5156 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0075-> 0.0075 -loss = 0.004613386507116957
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:36,684 INFO epoch # 5157 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0075-> 0.0075 -loss = 0.004731828646526992
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:36,706 INFO epoch # 5158 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0075-> 0.0075 -loss = 0.004567343090457143
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:36,728 INFO epoch # 5159 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0075-> 0.0075 -loss = 0.00458062146390148
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:36,750 INFO epoch # 5160 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0075-> 0.0075 -loss = 0.004619340174031095
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:36,750 INFO *** epoch 5160, rolling-avg-loss (window=10)= 0.004617701955930897
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:36,772 INFO epoch # 5161 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0075-> 0.0075 -loss = 0.004567662093904801
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:36,794 INFO epoch # 5162 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0075-> 0.0075 -loss = 0.00578486026279279
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:36,815 INFO epoch # 5163 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0075-> 0.0075 -loss = 0.005192351571167819
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:36,836 INFO epoch # 5164 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0075-> 0.0075 -loss = 0.004569015562083223
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:36,857 INFO epoch # 5165 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0075-> 0.0075 -loss = 0.004538099250567029
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:36,879 INFO epoch # 5166 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0075-> 0.0075 -loss = 0.0045604747165270965
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:36,900 INFO epoch # 5167 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0075-> 0.0075 -loss = 0.004544370127405273
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:36,922 INFO epoch # 5168 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0075-> 0.0075 -loss = 0.004548559365503024
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:36,944 INFO epoch # 5169 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0075-> 0.0075 -loss = 0.005415231701590528
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:36,966 INFO epoch # 5170 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0075-> 0.0075 -loss = 0.0045648575614904985
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:36,966 INFO *** epoch 5170, rolling-avg-loss (window=10)= 0.004828548221303209
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:36,988 INFO epoch # 5171 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0075-> 0.0075 -loss = 0.004541194776720658
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:37,009 INFO epoch # 5172 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0075-> 0.0075 -loss = 0.004553577196929837
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:37,031 INFO epoch # 5173 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0075-> 0.0075 -loss = 0.004546300611764309
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:37,052 INFO epoch # 5174 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0075-> 0.0075 -loss = 0.004596701259288238
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:37,073 INFO epoch # 5175 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0075-> 0.0075 -loss = 0.00462582580257731
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:37,094 INFO epoch # 5176 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0075-> 0.0074 -loss = 0.004546974054392194
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:37,116 INFO epoch # 5177 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0074-> 0.0074 -loss = 0.004532071421635919
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:37,138 INFO epoch # 5178 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0074-> 0.0074 -loss = 0.004525150153313007
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:37,159 INFO epoch # 5179 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0074-> 0.0074 -loss = 0.004555298919513007
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:37,181 INFO epoch # 5180 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0074-> 0.0074 -loss = 0.004544321561297693
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:37,181 INFO *** epoch 5180, rolling-avg-loss (window=10)= 0.004556741575743217
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:37,202 INFO epoch # 5181 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0074-> 0.0074 -loss = 0.004608043704138254
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:37,224 INFO epoch # 5182 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0074-> 0.0074 -loss = 0.00456406352805061
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:37,246 INFO epoch # 5183 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0074-> 0.0074 -loss = 0.004532678072791896
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:37,267 INFO epoch # 5184 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0074-> 0.0074 -loss = 0.004590284052937932
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:37,288 INFO epoch # 5185 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0074-> 0.0074 -loss = 0.004544378405626048
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:37,309 INFO epoch # 5186 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0074-> 0.0074 -loss = 0.006422909998946125
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:37,331 INFO epoch # 5187 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0074-> 0.0074 -loss = 0.0045234923645693925
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:37,352 INFO epoch # 5188 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0074-> 0.0074 -loss = 0.004541468902971246
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:37,374 INFO epoch # 5189 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0074-> 0.0074 -loss = 0.00453020328313869
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:37,396 INFO epoch # 5190 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0074-> 0.0074 -loss = 0.004558938265290635
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:37,396 INFO *** epoch 5190, rolling-avg-loss (window=10)= 0.0047416460578460825
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:37,419 INFO epoch # 5191 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0074-> 0.0074 -loss = 0.00451846380610732
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:37,441 INFO epoch # 5192 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0074-> 0.0074 -loss = 0.005259610026769224
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:37,462 INFO epoch # 5193 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0074-> 0.0074 -loss = 0.0045440410322044045
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:37,484 INFO epoch # 5194 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0074-> 0.0074 -loss = 0.005367895879317075
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:37,505 INFO epoch # 5195 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0074-> 0.0074 -loss = 0.00452223101024174
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:37,526 INFO epoch # 5196 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0074-> 0.0074 -loss = 0.004588356236126856
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:37,547 INFO epoch # 5197 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0074-> 0.0074 -loss = 0.004539603420198546
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:37,569 INFO epoch # 5198 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0074-> 0.0074 -loss = 0.0045096294634277
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:37,590 INFO epoch # 5199 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0074-> 0.0074 -loss = 0.004528696741544991
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:37,612 INFO epoch # 5200 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0074-> 0.0074 -loss = 0.005752898900027503
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:37,612 INFO *** epoch 5200, rolling-avg-loss (window=10)= 0.004813142651596536
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:37,635 INFO epoch # 5201 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0074-> 0.0074 -loss = 0.004763483070746588
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:37,657 INFO epoch # 5202 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0074-> 0.0074 -loss = 0.004516036889071984
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:37,678 INFO epoch # 5203 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0074-> 0.0074 -loss = 0.004633912133613194
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:37,699 INFO epoch # 5204 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0074-> 0.0074 -loss = 0.004537488250207389
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:37,721 INFO epoch # 5205 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0074-> 0.0074 -loss = 0.004524546251559514
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:37,743 INFO epoch # 5206 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0074-> 0.0074 -loss = 0.004562690488455701
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:37,764 INFO epoch # 5207 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0074-> 0.0074 -loss = 0.004533247598374146
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:37,786 INFO epoch # 5208 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0074-> 0.0074 -loss = 0.004552594862616388
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:37,808 INFO epoch # 5209 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0074-> 0.0073 -loss = 0.005355297130336112
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:37,830 INFO epoch # 5210 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0073-> 0.0073 -loss = 0.00451102725128294
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:37,830 INFO *** epoch 5210, rolling-avg-loss (window=10)= 0.004649032392626396
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:37,852 INFO epoch # 5211 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0073-> 0.0073 -loss = 0.004525472950263065
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:37,874 INFO epoch # 5212 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0073-> 0.0073 -loss = 0.004557673890303704
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:37,896 INFO epoch # 5213 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0073-> 0.0073 -loss = 0.004506766355916625
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:37,917 INFO epoch # 5214 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0073-> 0.0073 -loss = 0.005379581338274875
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:37,938 INFO epoch # 5215 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0073-> 0.0073 -loss = 0.0045091673118804465
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:37,959 INFO epoch # 5216 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0073-> 0.0073 -loss = 0.004499408739320643
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:37,980 INFO epoch # 5217 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0073-> 0.0073 -loss = 0.004508358971179405
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:38,002 INFO epoch # 5218 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0073-> 0.0073 -loss = 0.004556986310490174
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:38,023 INFO epoch # 5219 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0073-> 0.0073 -loss = 0.004646213636078755
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:38,045 INFO epoch # 5220 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0073-> 0.0073 -loss = 0.004508152043854352
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:38,045 INFO *** epoch 5220, rolling-avg-loss (window=10)= 0.004619778154756204
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:38,067 INFO epoch # 5221 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0073-> 0.0073 -loss = 0.0045369723411567975
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:38,089 INFO epoch # 5222 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0073-> 0.0073 -loss = 0.00456225704147073
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:38,111 INFO epoch # 5223 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0073-> 0.0073 -loss = 0.004611713819031138
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:38,133 INFO epoch # 5224 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0073-> 0.0073 -loss = 0.00451057766804297
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:38,154 INFO epoch # 5225 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0073-> 0.0073 -loss = 0.004541607202554587
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:38,175 INFO epoch # 5226 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0073-> 0.0073 -loss = 0.004671282622439321
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:38,197 INFO epoch # 5227 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0073-> 0.0072 -loss = 0.0046220049716794165
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:38,218 INFO epoch # 5228 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.004540244695817819
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:38,240 INFO epoch # 5229 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.004514508473221213
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:38,262 INFO epoch # 5230 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.0044933349163329694
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:38,262 INFO *** epoch 5230, rolling-avg-loss (window=10)= 0.004560450375174696
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:38,284 INFO epoch # 5231 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.005646988860462443
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:38,306 INFO epoch # 5232 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.004673970350268064
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:38,327 INFO epoch # 5233 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.004598456468556833
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:38,348 INFO epoch # 5234 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.004493942089538905
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:38,370 INFO epoch # 5235 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.0045752593423458165
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:38,391 INFO epoch # 5236 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.0045163468676037155
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:38,412 INFO epoch # 5237 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.0044945215740881395
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:38,434 INFO epoch # 5238 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.00449866750932415
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:38,455 INFO epoch # 5239 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.004492365821533895
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:38,477 INFO epoch # 5240 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.004513313031566213
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:38,477 INFO *** epoch 5240, rolling-avg-loss (window=10)= 0.004650383191528817
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:38,499 INFO epoch # 5241 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.004496408084378345
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:38,521 INFO epoch # 5242 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.004497696405451279
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:38,542 INFO epoch # 5243 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.004475687970625586
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:38,564 INFO epoch # 5244 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.005263444680167595
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:38,585 INFO epoch # 5245 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.004606924479048757
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:38,606 INFO epoch # 5246 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.004482349730096757
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:38,627 INFO epoch # 5247 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.00451933617296163
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:38,649 INFO epoch # 5248 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.004466543994567473
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:38,671 INFO epoch # 5249 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.0044824768647231394
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:38,693 INFO epoch # 5250 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.004947762040501402
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:38,693 INFO *** epoch 5250, rolling-avg-loss (window=10)= 0.004623863042252196
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:38,715 INFO epoch # 5251 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.004476164533116389
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:38,737 INFO epoch # 5252 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.004471499684768787
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:38,759 INFO epoch # 5253 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.004471176280276268
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:38,780 INFO epoch # 5254 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.0044723159862769535
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:38,801 INFO epoch # 5255 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.004484543987928191
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:38,822 INFO epoch # 5256 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.0044790272741010995
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:38,843 INFO epoch # 5257 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.004465548704501998
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:38,865 INFO epoch # 5258 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.004467213295356487
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:38,887 INFO epoch # 5259 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.004461925419036561
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:38,908 INFO epoch # 5260 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.0044921229309693445
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:38,908 INFO *** epoch 5260, rolling-avg-loss (window=10)= 0.0044741538096332075
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:38,930 INFO epoch # 5261 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.0044610846516661695
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:38,952 INFO epoch # 5262 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.004495443236010033
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:38,973 INFO epoch # 5263 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.004470338270039065
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:38,995 INFO epoch # 5264 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.004490083902965125
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:39,016 INFO epoch # 5265 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.004463791874513845
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:39,038 INFO epoch # 5266 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.004460961418772058
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:39,060 INFO epoch # 5267 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.004455624707588868
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:39,082 INFO epoch # 5268 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.004579264554195106
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:39,104 INFO epoch # 5269 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.004457762004676624
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:39,125 INFO epoch # 5270 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.005315840753610246
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:39,125 INFO *** epoch 5270, rolling-avg-loss (window=10)= 0.0045650195374037136
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:39,147 INFO epoch # 5271 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.004510735940129962
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:39,169 INFO epoch # 5272 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.004488064554607263
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:39,190 INFO epoch # 5273 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.004492833562835585
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:39,211 INFO epoch # 5274 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.004461765491214464
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:39,232 INFO epoch # 5275 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.004559028555377154
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:39,254 INFO epoch # 5276 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.004454936307411117
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:39,275 INFO epoch # 5277 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.0046158500936144264
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:39,297 INFO epoch # 5278 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.004505196378886467
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:39,319 INFO epoch # 5279 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.004523573334154207
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:39,341 INFO epoch # 5280 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.004457156459466205
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:39,341 INFO *** epoch 5280, rolling-avg-loss (window=10)= 0.004506914067769685
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:39,362 INFO epoch # 5281 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.004455868667719187
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:39,384 INFO epoch # 5282 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.004466902246349491
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:39,406 INFO epoch # 5283 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.004446666577678116
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:39,427 INFO epoch # 5284 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.004448249189408671
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:39,448 INFO epoch # 5285 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.004459882817172911
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:39,469 INFO epoch # 5286 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.005563637841987656
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:39,490 INFO epoch # 5287 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.004450373870895419
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:39,512 INFO epoch # 5288 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.004481615163967945
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:39,533 INFO epoch # 5289 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.004456578360986896
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:39,555 INFO epoch # 5290 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.004451913217053516
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:39,555 INFO *** epoch 5290, rolling-avg-loss (window=10)= 0.004568168795321981
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:39,576 INFO epoch # 5291 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.0044480474389274605
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:39,598 INFO epoch # 5292 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.005024025125749176
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:39,619 INFO epoch # 5293 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.0044973337953706505
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:39,641 INFO epoch # 5294 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.004500639177422272
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:39,662 INFO epoch # 5295 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.004465963031179854
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:39,683 INFO epoch # 5296 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.005549504849113873
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:39,704 INFO epoch # 5297 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.004491919937208877
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:39,726 INFO epoch # 5298 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.005281682811983046
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:39,748 INFO epoch # 5299 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.004446945182280615
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:39,770 INFO epoch # 5300 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.004472146096304641
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:39,770 INFO *** epoch 5300, rolling-avg-loss (window=10)= 0.004717820744554046
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:39,792 INFO epoch # 5301 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.00443018496298464
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:39,814 INFO epoch # 5302 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.004480034551306744
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:39,835 INFO epoch # 5303 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.004439304002517019
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:39,857 INFO epoch # 5304 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.004516781451457064
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:39,878 INFO epoch # 5305 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.004599242585754837
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:39,899 INFO epoch # 5306 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.004486592401008238
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:39,920 INFO epoch # 5307 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.004425991070547752
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:39,942 INFO epoch # 5308 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.004491661025895155
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:39,963 INFO epoch # 5309 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.004438877609572955
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:39,985 INFO epoch # 5310 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.00444089211850951
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:39,985 INFO *** epoch 5310, rolling-avg-loss (window=10)= 0.004474956177955391
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:40,006 INFO epoch # 5311 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.005019213855121052
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:40,028 INFO epoch # 5312 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.00453176584233006
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:40,049 INFO epoch # 5313 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.004481695459617185
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:40,071 INFO epoch # 5314 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.004429618796166324
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:40,092 INFO epoch # 5315 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.004425144963533967
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:40,113 INFO epoch # 5316 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.004443890968104824
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:40,134 INFO epoch # 5317 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.0044832385992776835
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:40,156 INFO epoch # 5318 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.004538478737231344
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:40,178 INFO epoch # 5319 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.004452905634025228
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:40,200 INFO epoch # 5320 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.004429469187016366
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:40,200 INFO *** epoch 5320, rolling-avg-loss (window=10)= 0.0045235422042424036
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:40,222 INFO epoch # 5321 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.004433094753039768
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:40,244 INFO epoch # 5322 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.004434325056536181
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:40,265 INFO epoch # 5323 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.0044463911162893055
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:40,286 INFO epoch # 5324 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.004479596178498468
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:40,307 INFO epoch # 5325 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.004436725303094136
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:40,329 INFO epoch # 5326 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0071 -loss = 0.004470502974982082
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:40,350 INFO epoch # 5327 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0071-> 0.0071 -loss = 0.004418048055413237
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:40,372 INFO epoch # 5328 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0071-> 0.0071 -loss = 0.00445874736760743
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:40,393 INFO epoch # 5329 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0071-> 0.0071 -loss = 0.004416862728248816
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:40,415 INFO epoch # 5330 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0071-> 0.0071 -loss = 0.004575437469611643
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:40,415 INFO *** epoch 5330, rolling-avg-loss (window=10)= 0.004456973100332107
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:40,437 INFO epoch # 5331 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0071-> 0.0071 -loss = 0.004457591823666007
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:40,459 INFO epoch # 5332 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0071-> 0.0071 -loss = 0.004433441583387321
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:40,481 INFO epoch # 5333 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0071-> 0.0071 -loss = 0.004426329989655642
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:40,502 INFO epoch # 5334 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0071-> 0.0071 -loss = 0.004454624102436355
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:40,524 INFO epoch # 5335 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0071-> 0.0071 -loss = 0.004459877714907634
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:40,545 INFO epoch # 5336 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0071-> 0.0071 -loss = 0.0045012560240138555
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:40,566 INFO epoch # 5337 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0071-> 0.0071 -loss = 0.004457821223695646
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:40,588 INFO epoch # 5338 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0071-> 0.0071 -loss = 0.0044742626923834905
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:40,609 INFO epoch # 5339 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0071-> 0.0071 -loss = 0.004420983093950781
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:40,631 INFO epoch # 5340 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0071-> 0.0071 -loss = 0.0044069755615510076
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:40,632 INFO *** epoch 5340, rolling-avg-loss (window=10)= 0.004449316380964774
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:40,654 INFO epoch # 5341 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0071-> 0.0071 -loss = 0.004730704595203861
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:40,676 INFO epoch # 5342 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0071-> 0.0071 -loss = 0.004420341287186602
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:40,698 INFO epoch # 5343 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0071-> 0.0071 -loss = 0.004431388033481198
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:40,719 INFO epoch # 5344 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0071-> 0.0071 -loss = 0.004414657764755248
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:40,740 INFO epoch # 5345 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0071-> 0.0071 -loss = 0.0044096450437791646
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:40,761 INFO epoch # 5346 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0071-> 0.0071 -loss = 0.004546404999018705
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:40,783 INFO epoch # 5347 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0071-> 0.0071 -loss = 0.004420572691742564
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:40,804 INFO epoch # 5348 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0071-> 0.0071 -loss = 0.004400112708026427
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:40,826 INFO epoch # 5349 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0071-> 0.0071 -loss = 0.004458849052753067
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:40,848 INFO epoch # 5350 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0071-> 0.0071 -loss = 0.004466733709705295
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:40,848 INFO *** epoch 5350, rolling-avg-loss (window=10)= 0.004469940988565213
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:40,870 INFO epoch # 5351 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0071-> 0.0071 -loss = 0.004401105286888196
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:40,892 INFO epoch # 5352 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0071-> 0.0071 -loss = 0.004405205654620659
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:40,914 INFO epoch # 5353 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0071-> 0.0071 -loss = 0.004404283536132425
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:40,935 INFO epoch # 5354 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0071-> 0.0071 -loss = 0.004412602278534905
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:40,956 INFO epoch # 5355 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0071-> 0.0071 -loss = 0.004508799413997622
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:40,977 INFO epoch # 5356 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0071-> 0.0071 -loss = 0.004424760400070227
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:40,998 INFO epoch # 5357 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0071-> 0.0071 -loss = 0.004391765801301517
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:41,020 INFO epoch # 5358 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0071-> 0.0071 -loss = 0.004427267049322836
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:41,042 INFO epoch # 5359 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0071-> 0.0071 -loss = 0.0044007255864926265
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:41,064 INFO epoch # 5360 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0071-> 0.0071 -loss = 0.004422496254846919
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:41,064 INFO *** epoch 5360, rolling-avg-loss (window=10)= 0.004419901126220793
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:41,086 INFO epoch # 5361 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0071-> 0.0071 -loss = 0.004462016655452317
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:41,108 INFO epoch # 5362 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0071-> 0.0071 -loss = 0.004398962755658431
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:41,129 INFO epoch # 5363 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0071-> 0.0071 -loss = 0.0043896281204069965
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:41,150 INFO epoch # 5364 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0071-> 0.0071 -loss = 0.004394470320221444
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:41,172 INFO epoch # 5365 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0071-> 0.0071 -loss = 0.004554296524474921
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:41,193 INFO epoch # 5366 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0071-> 0.0071 -loss = 0.004409177317938884
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:41,215 INFO epoch # 5367 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0071-> 0.0071 -loss = 0.004390000785861048
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:41,237 INFO epoch # 5368 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0071-> 0.0071 -loss = 0.0044494914491224336
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:41,259 INFO epoch # 5369 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0071-> 0.0071 -loss = 0.004393368779346929
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:41,281 INFO epoch # 5370 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0071-> 0.0071 -loss = 0.00443167332559824
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:41,281 INFO *** epoch 5370, rolling-avg-loss (window=10)= 0.004427308603408164
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:41,303 INFO epoch # 5371 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0071-> 0.0071 -loss = 0.004381578805350728
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:41,325 INFO epoch # 5372 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0071-> 0.0071 -loss = 0.005483252700287267
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:41,346 INFO epoch # 5373 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0071-> 0.0071 -loss = 0.00439802855362359
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:41,367 INFO epoch # 5374 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0071-> 0.0071 -loss = 0.004398425443469023
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:41,388 INFO epoch # 5375 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0071-> 0.0071 -loss = 0.004409526903145888
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:41,410 INFO epoch # 5376 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0071-> 0.0071 -loss = 0.004386473208796815
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:41,431 INFO epoch # 5377 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0071-> 0.0071 -loss = 0.004395339676193544
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:41,453 INFO epoch # 5378 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0071-> 0.0071 -loss = 0.004383912248158595
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:41,475 INFO epoch # 5379 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0071-> 0.0071 -loss = 0.004398826044052839
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:41,497 INFO epoch # 5380 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0071-> 0.0071 -loss = 0.004818656536372146
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:41,497 INFO *** epoch 5380, rolling-avg-loss (window=10)= 0.0045454020119450435
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:41,518 INFO epoch # 5381 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0071-> 0.0071 -loss = 0.004447231032827403
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:41,540 INFO epoch # 5382 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0071-> 0.007 -loss = 0.004413952576214797
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:41,561 INFO epoch # 5383 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.007-> 0.007 -loss = 0.004382910892672953
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:41,583 INFO epoch # 5384 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.007-> 0.007 -loss = 0.004415760689880699
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:41,604 INFO epoch # 5385 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.007-> 0.007 -loss = 0.004414634573549847
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:41,625 INFO epoch # 5386 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.007-> 0.007 -loss = 0.004387588094687089
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:41,647 INFO epoch # 5387 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.007-> 0.007 -loss = 0.004381540457870869
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:41,668 INFO epoch # 5388 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.007-> 0.007 -loss = 0.004384672305604909
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:41,690 INFO epoch # 5389 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.007-> 0.007 -loss = 0.004437949573912192
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:41,712 INFO epoch # 5390 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.007-> 0.007 -loss = 0.0043910598160437075
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:41,712 INFO *** epoch 5390, rolling-avg-loss (window=10)= 0.004405730001326447
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:41,734 INFO epoch # 5391 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.007-> 0.007 -loss = 0.0043767790721176425
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:41,757 INFO epoch # 5392 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.007-> 0.007 -loss = 0.004378110521429335
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:41,779 INFO epoch # 5393 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.007-> 0.007 -loss = 0.004401681415401981
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:41,800 INFO epoch # 5394 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.007-> 0.007 -loss = 0.004373204475996317
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:41,821 INFO epoch # 5395 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.007-> 0.007 -loss = 0.004416851255882648
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:41,842 INFO epoch # 5396 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.007-> 0.007 -loss = 0.004405962328746682
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:41,863 INFO epoch # 5397 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.007-> 0.007 -loss = 0.004374509554509132
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:41,885 INFO epoch # 5398 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.007-> 0.007 -loss = 0.004378679823275888
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:41,907 INFO epoch # 5399 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.007-> 0.007 -loss = 0.004417010028191726
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:41,929 INFO epoch # 5400 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.007-> 0.007 -loss = 0.0044030409826518735
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:41,929 INFO *** epoch 5400, rolling-avg-loss (window=10)= 0.004392582945820322
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:41,951 INFO epoch # 5401 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.007-> 0.007 -loss = 0.004380788836897409
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:41,973 INFO epoch # 5402 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.007-> 0.007 -loss = 0.004367689072751091
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:41,994 INFO epoch # 5403 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.007-> 0.007 -loss = 0.004403539463055495
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:42,015 INFO epoch # 5404 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.007-> 0.007 -loss = 0.004462952765607042
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:42,036 INFO epoch # 5405 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.007-> 0.007 -loss = 0.004387413673612173
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:42,058 INFO epoch # 5406 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.007-> 0.007 -loss = 0.004388920766359661
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:42,079 INFO epoch # 5407 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.007-> 0.007 -loss = 0.004367862849903759
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:42,100 INFO epoch # 5408 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.007-> 0.007 -loss = 0.00439013630602858
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:42,121 INFO epoch # 5409 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.007-> 0.007 -loss = 0.004405601736834797
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:42,143 INFO epoch # 5410 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.007-> 0.007 -loss = 0.004377145367470803
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:42,143 INFO *** epoch 5410, rolling-avg-loss (window=10)= 0.0043932050838520805
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:42,165 INFO epoch # 5411 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.007-> 0.007 -loss = 0.0043780688029073644
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:42,187 INFO epoch # 5412 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.007-> 0.007 -loss = 0.004367157967863022
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:42,209 INFO epoch # 5413 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.007-> 0.007 -loss = 0.004357343107585621
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:42,231 INFO epoch # 5414 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.007-> 0.007 -loss = 0.006139879857073538
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:42,252 INFO epoch # 5415 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.007-> 0.007 -loss = 0.004397226742185012
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:42,273 INFO epoch # 5416 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.007-> 0.007 -loss = 0.004360967248430825
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:42,294 INFO epoch # 5417 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.007-> 0.007 -loss = 0.004409782432048814
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:42,316 INFO epoch # 5418 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.007-> 0.007 -loss = 0.004396241103677312
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:42,337 INFO epoch # 5419 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.007-> 0.007 -loss = 0.004355431859039527
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:42,359 INFO epoch # 5420 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.007-> 0.007 -loss = 0.00440187870299269
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:42,359 INFO *** epoch 5420, rolling-avg-loss (window=10)= 0.0045563977823803725
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:42,381 INFO epoch # 5421 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.007-> 0.007 -loss = 0.004369445595330035
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:42,402 INFO epoch # 5422 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.007-> 0.007 -loss = 0.004377272235615237
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:42,424 INFO epoch # 5423 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.007-> 0.007 -loss = 0.005211657945437764
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:42,445 INFO epoch # 5424 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.007-> 0.007 -loss = 0.0043564476573010325
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:42,466 INFO epoch # 5425 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.007-> 0.007 -loss = 0.004402146563734277
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:42,487 INFO epoch # 5426 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.007-> 0.007 -loss = 0.004353748527137213
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:42,508 INFO epoch # 5427 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.007-> 0.007 -loss = 0.004383029487144086
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:42,530 INFO epoch # 5428 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.007-> 0.007 -loss = 0.004365021155535942
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:42,552 INFO epoch # 5429 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.007-> 0.007 -loss = 0.005098502275359351
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:42,573 INFO epoch # 5430 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.007-> 0.007 -loss = 0.004372201116893848
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:42,573 INFO *** epoch 5430, rolling-avg-loss (window=10)= 0.004528947255948879
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:42,595 INFO epoch # 5431 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.007-> 0.007 -loss = 0.004340142738328723
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:42,617 INFO epoch # 5432 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.007-> 0.007 -loss = 0.0043796014488179935
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:42,638 INFO epoch # 5433 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.007-> 0.007 -loss = 0.004709876458946383
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:42,659 INFO epoch # 5434 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.007-> 0.007 -loss = 0.004486877707677195
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:42,681 INFO epoch # 5435 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.007-> 0.007 -loss = 0.004349423743406078
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:42,702 INFO epoch # 5436 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.007-> 0.007 -loss = 0.004569297994748922
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:42,723 INFO epoch # 5437 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.007-> 0.007 -loss = 0.0043900840828428045
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:42,745 INFO epoch # 5438 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.007-> 0.007 -loss = 0.004351379104264197
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:42,767 INFO epoch # 5439 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.007-> 0.007 -loss = 0.004336403005254397
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:42,789 INFO epoch # 5440 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.007-> 0.007 -loss = 0.004343307369708782
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:42,789 INFO *** epoch 5440, rolling-avg-loss (window=10)= 0.004425639365399548
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:42,811 INFO epoch # 5441 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.007-> 0.007 -loss = 0.004336927369422483
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:42,833 INFO epoch # 5442 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.007-> 0.007 -loss = 0.0043589869146671845
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:42,854 INFO epoch # 5443 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.007-> 0.007 -loss = 0.004339457649621181
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:42,875 INFO epoch # 5444 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.007-> 0.007 -loss = 0.006090281738579506
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:42,896 INFO epoch # 5445 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.007-> 0.007 -loss = 0.004399791306241241
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:42,918 INFO epoch # 5446 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.007-> 0.007 -loss = 0.004341333666161518
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:42,939 INFO epoch # 5447 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.007-> 0.007 -loss = 0.004372515839349944
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:42,961 INFO epoch # 5448 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.007-> 0.007 -loss = 0.004401595278977766
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:42,982 INFO epoch # 5449 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.007-> 0.007 -loss = 0.004370490476503619
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:43,004 INFO epoch # 5450 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.007-> 0.007 -loss = 0.005384693082305603
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:43,004 INFO *** epoch 5450, rolling-avg-loss (window=10)= 0.004639607332183005
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:43,026 INFO epoch # 5451 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.007-> 0.007 -loss = 0.004349577415268868
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:43,048 INFO epoch # 5452 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.007-> 0.007 -loss = 0.004324688834458357
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:43,070 INFO epoch # 5453 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.007-> 0.007 -loss = 0.0053502076898439554
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:43,091 INFO epoch # 5454 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.007-> 0.007 -loss = 0.00434288752876455
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:43,112 INFO epoch # 5455 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.007-> 0.007 -loss = 0.004328410846028419
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:43,133 INFO epoch # 5456 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.007-> 0.007 -loss = 0.0043254822544440685
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:43,154 INFO epoch # 5457 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.007-> 0.007 -loss = 0.004376062164737959
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:43,176 INFO epoch # 5458 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.007-> 0.007 -loss = 0.004384389603728778
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:43,198 INFO epoch # 5459 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.007-> 0.007 -loss = 0.00439586346874421
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:43,220 INFO epoch # 5460 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.007-> 0.007 -loss = 0.004331626420025714
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:43,220 INFO *** epoch 5460, rolling-avg-loss (window=10)= 0.004450919622604488
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:43,242 INFO epoch # 5461 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.007-> 0.007 -loss = 0.004345104493040708
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:43,264 INFO epoch # 5462 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.007-> 0.007 -loss = 0.004341055839176988
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:43,286 INFO epoch # 5463 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.007-> 0.0069 -loss = 0.00435635384201305
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:43,307 INFO epoch # 5464 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0069-> 0.0069 -loss = 0.004316551342071762
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:43,328 INFO epoch # 5465 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0069-> 0.0069 -loss = 0.004366822617157595
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:43,349 INFO epoch # 5466 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0069-> 0.0069 -loss = 0.004347334239355405
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:43,370 INFO epoch # 5467 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0069-> 0.0069 -loss = 0.0043789791907329345
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:43,392 INFO epoch # 5468 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0069-> 0.0069 -loss = 0.004442920585461252
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:43,413 INFO epoch # 5469 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0069-> 0.0069 -loss = 0.0043233734477325925
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:43,435 INFO epoch # 5470 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0069-> 0.0069 -loss = 0.004319679683248978
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:43,435 INFO *** epoch 5470, rolling-avg-loss (window=10)= 0.0043538175279991265
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:43,457 INFO epoch # 5471 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0069-> 0.0069 -loss = 0.004318075623814366
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:43,479 INFO epoch # 5472 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0069-> 0.0069 -loss = 0.004329861034420901
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:43,501 INFO epoch # 5473 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0069-> 0.0069 -loss = 0.004352178195404122
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:43,522 INFO epoch # 5474 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0069-> 0.0069 -loss = 0.004311626729759155
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:43,543 INFO epoch # 5475 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0069-> 0.0069 -loss = 0.004316699005357805
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:43,564 INFO epoch # 5476 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0069-> 0.0069 -loss = 0.004332152393544675
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:43,586 INFO epoch # 5477 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0069-> 0.0069 -loss = 0.004319626603319193
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:43,608 INFO epoch # 5478 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0069-> 0.0069 -loss = 0.004325330493884394
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:43,630 INFO epoch # 5479 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0069-> 0.0069 -loss = 0.00431917597870779
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:43,652 INFO epoch # 5480 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0069-> 0.0069 -loss = 0.004343558959590155
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:43,652 INFO *** epoch 5480, rolling-avg-loss (window=10)= 0.004326828501780256
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:43,674 INFO epoch # 5481 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0069-> 0.0069 -loss = 0.004337169873906532
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:43,696 INFO epoch # 5482 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0069-> 0.0069 -loss = 0.00434635070450895
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:43,717 INFO epoch # 5483 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0069-> 0.0069 -loss = 0.004317577249821625
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:43,738 INFO epoch # 5484 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0069-> 0.0069 -loss = 0.00434372856580012
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:43,759 INFO epoch # 5485 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0069-> 0.0069 -loss = 0.0043076359143015
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:43,780 INFO epoch # 5486 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0069-> 0.0069 -loss = 0.0043286138879921054
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:43,802 INFO epoch # 5487 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0069-> 0.0069 -loss = 0.0043127240787725896
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:43,824 INFO epoch # 5488 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0069-> 0.0069 -loss = 0.004316245709560462
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:43,846 INFO epoch # 5489 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0069-> 0.0069 -loss = 0.004303615100980096
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:43,868 INFO epoch # 5490 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0069-> 0.0069 -loss = 0.00431869591557188
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:43,868 INFO *** epoch 5490, rolling-avg-loss (window=10)= 0.004323235700121586
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:43,890 INFO epoch # 5491 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0069-> 0.0069 -loss = 0.004309052576900285
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:43,911 INFO epoch # 5492 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0069-> 0.0069 -loss = 0.004303276803511835
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:43,932 INFO epoch # 5493 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0069-> 0.0069 -loss = 0.004314412846724736
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:43,954 INFO epoch # 5494 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0069-> 0.0069 -loss = 0.004350192753918236
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:43,975 INFO epoch # 5495 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0069-> 0.0069 -loss = 0.00532774665953184
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:43,996 INFO epoch # 5496 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0069-> 0.0069 -loss = 0.004345112432929454
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:44,018 INFO epoch # 5497 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0069-> 0.0069 -loss = 0.004392378526063112
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:44,039 INFO epoch # 5498 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0069-> 0.0069 -loss = 0.004297503062844044
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:44,061 INFO epoch # 5499 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0069-> 0.0069 -loss = 0.004305736465539667
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:44,083 INFO epoch # 5500 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0069-> 0.0069 -loss = 0.004317790633649565
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:44,083 INFO *** epoch 5500, rolling-avg-loss (window=10)= 0.004426320276161277
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:44,105 INFO epoch # 5501 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0069-> 0.0069 -loss = 0.004363845950138057
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:44,127 INFO epoch # 5502 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0069-> 0.0069 -loss = 0.004304711617805879
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:44,148 INFO epoch # 5503 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0069-> 0.0069 -loss = 0.004308623934775824
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:44,170 INFO epoch # 5504 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0069-> 0.0069 -loss = 0.004341729331827082
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:44,191 INFO epoch # 5505 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0069-> 0.0069 -loss = 0.0043022575409850106
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:44,212 INFO epoch # 5506 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0069-> 0.0069 -loss = 0.00431717168794421
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:44,234 INFO epoch # 5507 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0069-> 0.0069 -loss = 0.004286118662093941
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:44,256 INFO epoch # 5508 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0069-> 0.0069 -loss = 0.004289723750389385
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:44,278 INFO epoch # 5509 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0069-> 0.0069 -loss = 0.004323607859078038
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:44,300 INFO epoch # 5510 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0069-> 0.0069 -loss = 0.004298704267057474
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:44,300 INFO *** epoch 5510, rolling-avg-loss (window=10)= 0.00431364946020949
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:44,322 INFO epoch # 5511 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0069-> 0.0069 -loss = 0.004301154518543626
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:44,344 INFO epoch # 5512 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0069-> 0.0069 -loss = 0.004287059470698296
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:44,366 INFO epoch # 5513 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0069-> 0.0069 -loss = 0.004308628997023334
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:44,387 INFO epoch # 5514 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0069-> 0.0069 -loss = 0.0042897968351098825
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:44,408 INFO epoch # 5515 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0069-> 0.0069 -loss = 0.004838359092900646
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:44,429 INFO epoch # 5516 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0069-> 0.0069 -loss = 0.004311372502343147
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:44,451 INFO epoch # 5517 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0069-> 0.0069 -loss = 0.004336399773819721
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:44,473 INFO epoch # 5518 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0069-> 0.0068 -loss = 0.004728921509922657
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:44,494 INFO epoch # 5519 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0068-> 0.0068 -loss = 0.004293190389944357
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:44,516 INFO epoch # 5520 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0068-> 0.0068 -loss = 0.004293419473469839
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:44,516 INFO *** epoch 5520, rolling-avg-loss (window=10)= 0.0043988302563775505
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:44,539 INFO epoch # 5521 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0068-> 0.0068 -loss = 0.0043075267185486155
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:44,561 INFO epoch # 5522 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0068-> 0.0068 -loss = 0.0042890625472864485
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:44,582 INFO epoch # 5523 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0068-> 0.0068 -loss = 0.004306772822019411
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:44,603 INFO epoch # 5524 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0068-> 0.0068 -loss = 0.004276263819065207
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:44,624 INFO epoch # 5525 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0068-> 0.0068 -loss = 0.004289024287572829
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:44,645 INFO epoch # 5526 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0068-> 0.0068 -loss = 0.0043105507302243495
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:44,667 INFO epoch # 5527 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0068-> 0.0068 -loss = 0.004284740614821203
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:44,689 INFO epoch # 5528 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0068-> 0.0068 -loss = 0.004285757817342528
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:44,710 INFO epoch # 5529 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0068-> 0.0068 -loss = 0.0042950638744514436
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:44,732 INFO epoch # 5530 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0068-> 0.0068 -loss = 0.004285898278794775
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:44,732 INFO *** epoch 5530, rolling-avg-loss (window=10)= 0.004293066151012681
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:44,754 INFO epoch # 5531 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0068-> 0.0068 -loss = 0.00441020226207911
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:44,776 INFO epoch # 5532 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0068-> 0.0068 -loss = 0.004299965550671914
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:44,797 INFO epoch # 5533 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0068-> 0.0068 -loss = 0.0043120721657032846
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:44,819 INFO epoch # 5534 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0068-> 0.0068 -loss = 0.004320364240811614
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:44,840 INFO epoch # 5535 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0068-> 0.0068 -loss = 0.0043367576308810385
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:44,861 INFO epoch # 5536 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0068-> 0.0068 -loss = 0.004276754827515106
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:44,883 INFO epoch # 5537 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0068-> 0.0068 -loss = 0.004322490605773055
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:44,904 INFO epoch # 5538 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0068-> 0.0068 -loss = 0.004267641659225774
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:44,926 INFO epoch # 5539 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0068-> 0.0068 -loss = 0.005264119627099717
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:44,947 INFO epoch # 5540 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0068-> 0.0068 -loss = 0.004270814147275814
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:44,947 INFO *** epoch 5540, rolling-avg-loss (window=10)= 0.004408118271703643
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:44,969 INFO epoch # 5541 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0068-> 0.0068 -loss = 0.004299825577618321
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:44,991 INFO epoch # 5542 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0068-> 0.0068 -loss = 0.004421901639943826
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:45,012 INFO epoch # 5543 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0068-> 0.0068 -loss = 0.004276676994777517
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:45,034 INFO epoch # 5544 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0068-> 0.0068 -loss = 0.00437666666948644
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:45,055 INFO epoch # 5545 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0068-> 0.0068 -loss = 0.005381640582527325
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:45,076 INFO epoch # 5546 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0068-> 0.0068 -loss = 0.0048335319697798695
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:45,097 INFO epoch # 5547 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0068-> 0.0068 -loss = 0.0043010513654735405
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:45,119 INFO epoch # 5548 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0068-> 0.0068 -loss = 0.00426707140468352
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:45,141 INFO epoch # 5549 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0068-> 0.0068 -loss = 0.004280785113223828
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:45,163 INFO epoch # 5550 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0068-> 0.0068 -loss = 0.0042641999543775455
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:45,163 INFO *** epoch 5550, rolling-avg-loss (window=10)= 0.004470335127189173
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:45,185 INFO epoch # 5551 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0068-> 0.0068 -loss = 0.004334567144724133
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:45,207 INFO epoch # 5552 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0068-> 0.0068 -loss = 0.00426335904012376
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:45,228 INFO epoch # 5553 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0068-> 0.0068 -loss = 0.004266881278454093
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:45,250 INFO epoch # 5554 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0068-> 0.0068 -loss = 0.004290444089747325
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:45,271 INFO epoch # 5555 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0068-> 0.0068 -loss = 0.0042866785852311295
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:45,292 INFO epoch # 5556 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0068-> 0.0068 -loss = 0.00427146653055388
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:45,314 INFO epoch # 5557 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0068-> 0.0068 -loss = 0.004289892789529404
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:45,335 INFO epoch # 5558 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0068-> 0.0068 -loss = 0.004304071251681307
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:45,357 INFO epoch # 5559 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0068-> 0.0068 -loss = 0.004320936499425443
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:45,379 INFO epoch # 5560 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0068-> 0.0068 -loss = 0.004258121361999656
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:45,379 INFO *** epoch 5560, rolling-avg-loss (window=10)= 0.004288641857147013
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:45,401 INFO epoch # 5561 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0068-> 0.0068 -loss = 0.004304014324588934
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:45,422 INFO epoch # 5562 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0068-> 0.0068 -loss = 0.004273113060662581
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:45,444 INFO epoch # 5563 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0068-> 0.0068 -loss = 0.004390954592963681
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:45,465 INFO epoch # 5564 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0068-> 0.0068 -loss = 0.004252242933034722
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:45,486 INFO epoch # 5565 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0068-> 0.0068 -loss = 0.004265873652911978
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:45,507 INFO epoch # 5566 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0068-> 0.0068 -loss = 0.004295543518310296
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:45,529 INFO epoch # 5567 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0068-> 0.0068 -loss = 0.004278931939552422
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:45,551 INFO epoch # 5568 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0068-> 0.0068 -loss = 0.004288523965442437
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:45,573 INFO epoch # 5569 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0068-> 0.0068 -loss = 0.004283545500584296
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:45,595 INFO epoch # 5570 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0068-> 0.0068 -loss = 0.004272382870112779
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:45,595 INFO *** epoch 5570, rolling-avg-loss (window=10)= 0.004290512635816412
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:45,617 INFO epoch # 5571 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0068-> 0.0068 -loss = 0.004256518512192997
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:45,639 INFO epoch # 5572 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0068-> 0.0068 -loss = 0.004252830471159541
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:45,660 INFO epoch # 5573 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0068-> 0.0068 -loss = 0.004288716590963304
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:45,681 INFO epoch # 5574 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0068-> 0.0068 -loss = 0.00428782187464094
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:45,702 INFO epoch # 5575 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0068-> 0.0067 -loss = 0.004274118116882164
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:45,723 INFO epoch # 5576 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0067-> 0.0067 -loss = 0.00429687584801286
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:45,745 INFO epoch # 5577 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0067-> 0.0067 -loss = 0.00439246918358549
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:45,767 INFO epoch # 5578 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0067-> 0.0067 -loss = 0.004249891563631536
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:45,789 INFO epoch # 5579 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0067-> 0.0067 -loss = 0.004285482935301843
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:45,810 INFO epoch # 5580 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0067-> 0.0067 -loss = 0.004361008539490285
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:45,811 INFO *** epoch 5580, rolling-avg-loss (window=10)= 0.0042945733635860964
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:45,832 INFO epoch # 5581 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0067-> 0.0067 -loss = 0.004284724272110907
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:45,854 INFO epoch # 5582 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0067-> 0.0067 -loss = 0.00425424601053237
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:45,876 INFO epoch # 5583 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0067-> 0.0067 -loss = 0.005046127240348142
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:45,897 INFO epoch # 5584 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0067-> 0.0067 -loss = 0.0042972495102731045
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:45,918 INFO epoch # 5585 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0067-> 0.0067 -loss = 0.005355687742849113
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:45,939 INFO epoch # 5586 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0067-> 0.0067 -loss = 0.004244972457399854
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:45,961 INFO epoch # 5587 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0067-> 0.0067 -loss = 0.004345427609223407
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:45,983 INFO epoch # 5588 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0067-> 0.0067 -loss = 0.004256776300280762
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:46,005 INFO epoch # 5589 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0067-> 0.0067 -loss = 0.005226798257353948
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:46,027 INFO epoch # 5590 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0067-> 0.0067 -loss = 0.004353923784037761
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:46,027 INFO *** epoch 5590, rolling-avg-loss (window=10)= 0.004566593318440937
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:46,049 INFO epoch # 5591 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0067-> 0.0067 -loss = 0.0042858009965129895
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:46,070 INFO epoch # 5592 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0067-> 0.0067 -loss = 0.004240747537551215
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:46,092 INFO epoch # 5593 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0067-> 0.0067 -loss = 0.0042789228245965205
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:46,113 INFO epoch # 5594 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0067-> 0.0067 -loss = 0.004244497949912329
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:46,134 INFO epoch # 5595 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0067-> 0.0067 -loss = 0.00443363372960448
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:46,155 INFO epoch # 5596 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0067-> 0.0067 -loss = 0.004256711999005347
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:46,176 INFO epoch # 5597 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0067-> 0.0067 -loss = 0.005280683068122016
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:46,198 INFO epoch # 5598 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0067-> 0.0067 -loss = 0.0042740388271340635
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:46,219 INFO epoch # 5599 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0067-> 0.0067 -loss = 0.004240627746185055
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:46,241 INFO epoch # 5600 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0067-> 0.0067 -loss = 0.004238170206008363
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:46,241 INFO *** epoch 5600, rolling-avg-loss (window=10)= 0.004377383488463238
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:46,262 INFO epoch # 5601 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0067-> 0.0067 -loss = 0.004246350692483247
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:46,284 INFO epoch # 5602 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0067-> 0.0067 -loss = 0.004258378108715988
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:46,306 INFO epoch # 5603 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0067-> 0.0067 -loss = 0.0042611228445821325
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:46,327 INFO epoch # 5604 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0067-> 0.0067 -loss = 0.004383261441034847
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:46,348 INFO epoch # 5605 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0067-> 0.0067 -loss = 0.0042401511509524425
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:46,369 INFO epoch # 5606 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0067-> 0.0067 -loss = 0.004577892681481899
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:46,390 INFO epoch # 5607 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0067-> 0.0067 -loss = 0.004233722411299823
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:46,412 INFO epoch # 5608 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0067-> 0.0067 -loss = 0.004286871302610962
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:46,434 INFO epoch # 5609 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0067-> 0.0067 -loss = 0.00423769702683785
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:46,456 INFO epoch # 5610 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0067-> 0.0067 -loss = 0.0042462756882741814
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:46,457 INFO *** epoch 5610, rolling-avg-loss (window=10)= 0.004297172334827337
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:46,478 INFO epoch # 5611 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0067-> 0.0067 -loss = 0.004226517719871481
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:46,500 INFO epoch # 5612 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0067-> 0.0067 -loss = 0.00445367216343584
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:46,521 INFO epoch # 5613 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0067-> 0.0067 -loss = 0.004251159960404038
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:46,542 INFO epoch # 5614 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0067-> 0.0067 -loss = 0.0042383730369692785
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:46,564 INFO epoch # 5615 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0067-> 0.0067 -loss = 0.004250746580510167
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:46,585 INFO epoch # 5616 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0067-> 0.0067 -loss = 0.004256735633134667
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:46,606 INFO epoch # 5617 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0067-> 0.0067 -loss = 0.004229668387779384
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:46,630 INFO epoch # 5618 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0067-> 0.0067 -loss = 0.004280815022866591
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:46,652 INFO epoch # 5619 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0067-> 0.0067 -loss = 0.004313340457883896
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:46,674 INFO epoch # 5620 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0067-> 0.0067 -loss = 0.004220901287226297
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:46,674 INFO *** epoch 5620, rolling-avg-loss (window=10)= 0.0042721930250081645
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:46,696 INFO epoch # 5621 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0067-> 0.0067 -loss = 0.0042745974078570725
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:46,718 INFO epoch # 5622 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0067-> 0.0067 -loss = 0.004233154897519853
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:46,740 INFO epoch # 5623 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0067-> 0.0067 -loss = 0.004244341023877496
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:46,761 INFO epoch # 5624 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0067-> 0.0067 -loss = 0.004682853152189637
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:46,782 INFO epoch # 5625 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0067-> 0.0067 -loss = 0.004223690542858094
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:46,803 INFO epoch # 5626 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0067-> 0.0067 -loss = 0.004221328351377451
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:46,825 INFO epoch # 5627 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0067-> 0.0067 -loss = 0.004673795963753946
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:46,847 INFO epoch # 5628 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0067-> 0.0067 -loss = 0.004254594829035341
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:46,869 INFO epoch # 5629 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0067-> 0.0067 -loss = 0.004227059882396134
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:46,891 INFO epoch # 5630 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0067-> 0.0067 -loss = 0.004229823208333983
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:46,891 INFO *** epoch 5630, rolling-avg-loss (window=10)= 0.0043265239259199
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:46,913 INFO epoch # 5631 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0067-> 0.0067 -loss = 0.004218552999191161
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:46,935 INFO epoch # 5632 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0067-> 0.0067 -loss = 0.00425347895543382
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:46,956 INFO epoch # 5633 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0067-> 0.0067 -loss = 0.0042205710806229035
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:46,978 INFO epoch # 5634 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0067-> 0.0067 -loss = 0.004207111132927821
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:46,999 INFO epoch # 5635 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0067-> 0.0067 -loss = 0.004211557716189418
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:47,020 INFO epoch # 5636 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0067-> 0.0067 -loss = 0.0042408949902892346
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:47,042 INFO epoch # 5637 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0067-> 0.0067 -loss = 0.005049484319897601
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:47,063 INFO epoch # 5638 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0067-> 0.0067 -loss = 0.004296829629311105
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:47,085 INFO epoch # 5639 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0067-> 0.0067 -loss = 0.004223036268740543
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:47,107 INFO epoch # 5640 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0067-> 0.0067 -loss = 0.004311662401960348
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:47,107 INFO *** epoch 5640, rolling-avg-loss (window=10)= 0.004323317949456396
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:47,129 INFO epoch # 5641 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0067-> 0.0067 -loss = 0.004211341915834055
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:47,151 INFO epoch # 5642 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0067-> 0.0067 -loss = 0.004207975723147683
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:47,173 INFO epoch # 5643 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0067-> 0.0067 -loss = 0.0042262117995051085
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:47,194 INFO epoch # 5644 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0067-> 0.0067 -loss = 0.005030737802371732
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:47,215 INFO epoch # 5645 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0067-> 0.0066 -loss = 0.0042160029497608775
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:47,237 INFO epoch # 5646 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0066-> 0.0066 -loss = 0.004259803972672671
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:47,259 INFO epoch # 5647 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0066-> 0.0066 -loss = 0.005002243482522317
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:47,281 INFO epoch # 5648 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0066-> 0.0066 -loss = 0.004249090503435582
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:47,303 INFO epoch # 5649 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0066-> 0.0066 -loss = 0.004226664211273601
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:47,324 INFO epoch # 5650 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0066-> 0.0066 -loss = 0.004219798125632224
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:47,325 INFO *** epoch 5650, rolling-avg-loss (window=10)= 0.004384987048615585
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:47,347 INFO epoch # 5651 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0066-> 0.0066 -loss = 0.004198234518298705
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:47,368 INFO epoch # 5652 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0066-> 0.0066 -loss = 0.00420499672236474
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:47,390 INFO epoch # 5653 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0066-> 0.0066 -loss = 0.004197740598328892
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:47,411 INFO epoch # 5654 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0066-> 0.0066 -loss = 0.004197685680992436
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:47,432 INFO epoch # 5655 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0066-> 0.0066 -loss = 0.004202116328087868
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:47,453 INFO epoch # 5656 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0066-> 0.0066 -loss = 0.0042030889344459865
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:47,474 INFO epoch # 5657 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0066-> 0.0066 -loss = 0.004251625292454264
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:47,496 INFO epoch # 5658 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0066-> 0.0066 -loss = 0.004245511783665279
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:47,517 INFO epoch # 5659 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0066-> 0.0066 -loss = 0.004208296168144443
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:47,539 INFO epoch # 5660 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0066-> 0.0066 -loss = 0.004195320369035471
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:47,539 INFO *** epoch 5660, rolling-avg-loss (window=10)= 0.004210461639581808
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:47,561 INFO epoch # 5661 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0066-> 0.0066 -loss = 0.004203690657959669
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:47,583 INFO epoch # 5662 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0066-> 0.0066 -loss = 0.004192217353192973
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:47,605 INFO epoch # 5663 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0066-> 0.0066 -loss = 0.004263766595613561
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:47,626 INFO epoch # 5664 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0066-> 0.0066 -loss = 0.004216477824229514
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:47,647 INFO epoch # 5665 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0066-> 0.0066 -loss = 0.004218221521114174
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:47,668 INFO epoch # 5666 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0066-> 0.0066 -loss = 0.004237633429511334
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:47,690 INFO epoch # 5667 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0066-> 0.0066 -loss = 0.004213117690596846
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:47,711 INFO epoch # 5668 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0066-> 0.0066 -loss = 0.00423422070707602
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:47,734 INFO epoch # 5669 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0066-> 0.0066 -loss = 0.004205682866086136
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:47,755 INFO epoch # 5670 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0066-> 0.0066 -loss = 0.004219387308694422
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:47,755 INFO *** epoch 5670, rolling-avg-loss (window=10)= 0.004220441595407465
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:47,777 INFO epoch # 5671 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0066-> 0.0066 -loss = 0.00423314008548914
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:47,799 INFO epoch # 5672 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0066-> 0.0066 -loss = 0.005052954660641262
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:47,821 INFO epoch # 5673 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0066-> 0.0066 -loss = 0.004236173230310669
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:47,842 INFO epoch # 5674 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0066-> 0.0066 -loss = 0.0042130641732001095
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:47,863 INFO epoch # 5675 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0066-> 0.0066 -loss = 0.00419266810422414
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:47,884 INFO epoch # 5676 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0066-> 0.0066 -loss = 0.004192651898847544
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:47,906 INFO epoch # 5677 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0066-> 0.0066 -loss = 0.004190709525573766
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:47,928 INFO epoch # 5678 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0066-> 0.0066 -loss = 0.0045884162609581836
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:47,950 INFO epoch # 5679 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0066-> 0.0066 -loss = 0.004182822982329526
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:47,971 INFO epoch # 5680 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0066-> 0.0066 -loss = 0.004186546369055577
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:47,971 INFO *** epoch 5680, rolling-avg-loss (window=10)= 0.004326914729062992
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:47,993 INFO epoch # 5681 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0066-> 0.0066 -loss = 0.004188816881651292
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:48,015 INFO epoch # 5682 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0066-> 0.0066 -loss = 0.004209836552035995
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:48,037 INFO epoch # 5683 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0066-> 0.0066 -loss = 0.004247424933055299
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:48,058 INFO epoch # 5684 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0066-> 0.0066 -loss = 0.004359393280537915
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:48,079 INFO epoch # 5685 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0066-> 0.0066 -loss = 0.004191204838207341
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:48,100 INFO epoch # 5686 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0066-> 0.0066 -loss = 0.004359406031653634
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:48,122 INFO epoch # 5687 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0066-> 0.0066 -loss = 0.004192948636045912
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:48,144 INFO epoch # 5688 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0066-> 0.0066 -loss = 0.00419934453748283
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:48,165 INFO epoch # 5689 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0066-> 0.0066 -loss = 0.004361416409665253
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:48,187 INFO epoch # 5690 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0066-> 0.0066 -loss = 0.0041767335515032755
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:48,187 INFO *** epoch 5690, rolling-avg-loss (window=10)= 0.004248652565183875
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:48,209 INFO epoch # 5691 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0066-> 0.0066 -loss = 0.004186607695373823
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:48,231 INFO epoch # 5692 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0066-> 0.0066 -loss = 0.004172554181423038
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:48,253 INFO epoch # 5693 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0066-> 0.0066 -loss = 0.004181786367553286
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:48,274 INFO epoch # 5694 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0066-> 0.0066 -loss = 0.004203323818728677
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:48,295 INFO epoch # 5695 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0066-> 0.0066 -loss = 0.004197825752271456
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:48,316 INFO epoch # 5696 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0066-> 0.0066 -loss = 0.0041805428691077395
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:48,337 INFO epoch # 5697 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0066-> 0.0066 -loss = 0.004180029814961017
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:48,359 INFO epoch # 5698 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0066-> 0.0066 -loss = 0.004208667298371438
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:48,381 INFO epoch # 5699 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0066-> 0.0066 -loss = 0.004213099566186429
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:48,403 INFO epoch # 5700 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0066-> 0.0066 -loss = 0.004182540328656614
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:48,403 INFO *** epoch 5700, rolling-avg-loss (window=10)= 0.004190697769263352
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:48,425 INFO epoch # 5701 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0066-> 0.0066 -loss = 0.004186145797575591
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:48,447 INFO epoch # 5702 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0066-> 0.0066 -loss = 0.004198117785563227
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:48,468 INFO epoch # 5703 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0066-> 0.0065 -loss = 0.004211261901218677
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:48,490 INFO epoch # 5704 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0065-> 0.0065 -loss = 0.0042574075851007365
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:48,511 INFO epoch # 5705 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0065-> 0.0065 -loss = 0.004213359307868814
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:48,532 INFO epoch # 5706 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0065-> 0.0065 -loss = 0.004235798523950507
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:48,553 INFO epoch # 5707 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0065-> 0.0065 -loss = 0.004204720580673893
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:48,575 INFO epoch # 5708 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0065-> 0.0065 -loss = 0.004178315593890147
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:48,596 INFO epoch # 5709 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0065-> 0.0065 -loss = 0.004167897893239569
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:48,618 INFO epoch # 5710 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0065-> 0.0065 -loss = 0.004232236828102032
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:48,618 INFO *** epoch 5710, rolling-avg-loss (window=10)= 0.004208526179718319
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:48,640 INFO epoch # 5711 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0065-> 0.0065 -loss = 0.004162699293374317
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:48,662 INFO epoch # 5712 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0065-> 0.0065 -loss = 0.00423014428542956
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:48,684 INFO epoch # 5713 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0065-> 0.0065 -loss = 0.004168867431417311
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:48,705 INFO epoch # 5714 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0065-> 0.0065 -loss = 0.005908665239985567
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:48,726 INFO epoch # 5715 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0065-> 0.0065 -loss = 0.004168151488556759
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:48,747 INFO epoch # 5716 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0065-> 0.0065 -loss = 0.004165001459114137
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:48,769 INFO epoch # 5717 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0065-> 0.0065 -loss = 0.00513011682414799
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:48,791 INFO epoch # 5718 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0065-> 0.0065 -loss = 0.004243922749992635
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:48,812 INFO epoch # 5719 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0065-> 0.0065 -loss = 0.0042020021901407745
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:48,834 INFO epoch # 5720 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0065-> 0.0065 -loss = 0.004303435373003595
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:48,834 INFO *** epoch 5720, rolling-avg-loss (window=10)= 0.004468300633516264
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:48,856 INFO epoch # 5721 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0065-> 0.0065 -loss = 0.004159692908615398
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:48,879 INFO epoch # 5722 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0065-> 0.0065 -loss = 0.004155034941504709
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:48,900 INFO epoch # 5723 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0065-> 0.0065 -loss = 0.004163936659097089
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:48,921 INFO epoch # 5724 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0065-> 0.0065 -loss = 0.005324717825715197
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:48,943 INFO epoch # 5725 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0065-> 0.0065 -loss = 0.004166538108620443
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:48,964 INFO epoch # 5726 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0065-> 0.0065 -loss = 0.0042475878581171855
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:48,985 INFO epoch # 5727 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0065-> 0.0065 -loss = 0.0043324008056515595
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:49,006 INFO epoch # 5728 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0065-> 0.0065 -loss = 0.004150491940436041
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:49,028 INFO epoch # 5729 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0065-> 0.0065 -loss = 0.004166339157563925
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:49,050 INFO epoch # 5730 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0065-> 0.0065 -loss = 0.004178218149718305
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:49,050 INFO *** epoch 5730, rolling-avg-loss (window=10)= 0.004304495835503986
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:49,072 INFO epoch # 5731 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0065-> 0.0065 -loss = 0.004699064676970011
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:49,094 INFO epoch # 5732 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0065-> 0.0065 -loss = 0.004202292764603044
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:49,115 INFO epoch # 5733 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0065-> 0.0065 -loss = 0.004589105670675053
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:49,136 INFO epoch # 5734 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0065-> 0.0065 -loss = 0.00415746693215624
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:49,157 INFO epoch # 5735 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0065-> 0.0065 -loss = 0.0041570081793906866
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:49,178 INFO epoch # 5736 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0065-> 0.0065 -loss = 0.004930225890348083
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:49,200 INFO epoch # 5737 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0065-> 0.0065 -loss = 0.004181182657703175
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:49,221 INFO epoch # 5738 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0065-> 0.0065 -loss = 0.004195364181214245
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:49,243 INFO epoch # 5739 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0065-> 0.0064 -loss = 0.005224647575232666
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:49,265 INFO epoch # 5740 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0064-> 0.0064 -loss = 0.004150731743266078
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:49,265 INFO *** epoch 5740, rolling-avg-loss (window=10)= 0.004448709027155928
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:49,287 INFO epoch # 5741 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0064-> 0.0064 -loss = 0.004155831943535304
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:49,309 INFO epoch # 5742 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0064-> 0.0064 -loss = 0.00524806898101815
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:49,331 INFO epoch # 5743 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0064-> 0.0064 -loss = 0.004203143609629478
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:49,352 INFO epoch # 5744 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0064-> 0.0064 -loss = 0.004247975322869024
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:49,373 INFO epoch # 5745 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0064-> 0.0064 -loss = 0.004150111327362538
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:49,395 INFO epoch # 5746 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0064-> 0.0064 -loss = 0.004227402274409542
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:49,417 INFO epoch # 5747 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0064-> 0.0064 -loss = 0.004144017838370928
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:49,439 INFO epoch # 5748 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0064-> 0.0064 -loss = 0.00418203621484281
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:49,461 INFO epoch # 5749 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0064-> 0.0064 -loss = 0.004161848442890914
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:49,483 INFO epoch # 5750 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0064-> 0.0064 -loss = 0.0041845290343189845
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:49,483 INFO *** epoch 5750, rolling-avg-loss (window=10)= 0.004290496498924767
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:49,505 INFO epoch # 5751 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0064-> 0.0064 -loss = 0.00508253526459157
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:49,527 INFO epoch # 5752 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0064-> 0.0064 -loss = 0.004168396670138463
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:49,548 INFO epoch # 5753 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0064-> 0.0064 -loss = 0.004170327858446399
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:49,569 INFO epoch # 5754 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0064-> 0.0064 -loss = 0.004159139270996093
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:49,590 INFO epoch # 5755 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0064-> 0.0064 -loss = 0.004141830668231705
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:49,611 INFO epoch # 5756 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0064-> 0.0064 -loss = 0.004160457770922221
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:49,633 INFO epoch # 5757 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0064-> 0.0064 -loss = 0.004136270465096459
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:49,654 INFO epoch # 5758 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0064-> 0.0064 -loss = 0.004170137468463508
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:49,676 INFO epoch # 5759 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0064-> 0.0064 -loss = 0.004154320564339287
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:49,698 INFO epoch # 5760 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0064-> 0.0064 -loss = 0.004149618452174764
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:49,698 INFO *** epoch 5760, rolling-avg-loss (window=10)= 0.004249303445340047
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:49,720 INFO epoch # 5761 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0064-> 0.0064 -loss = 0.004137585762691742
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:49,742 INFO epoch # 5762 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0064-> 0.0064 -loss = 0.0041554267263563816
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:49,764 INFO epoch # 5763 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0064-> 0.0064 -loss = 0.004166582177276723
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:49,785 INFO epoch # 5764 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0064-> 0.0064 -loss = 0.004605045167409116
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:49,806 INFO epoch # 5765 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0064-> 0.0064 -loss = 0.004139151855270029
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:49,827 INFO epoch # 5766 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0064-> 0.0064 -loss = 0.00413806433971331
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:49,849 INFO epoch # 5767 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0064-> 0.0064 -loss = 0.004138143434829544
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:49,871 INFO epoch # 5768 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0064-> 0.0064 -loss = 0.00413572884099267
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:49,893 INFO epoch # 5769 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0064-> 0.0064 -loss = 0.004157556420977926
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:49,914 INFO epoch # 5770 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0064-> 0.0064 -loss = 0.004122646847463329
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:49,915 INFO *** epoch 5770, rolling-avg-loss (window=10)= 0.0041895931572980775
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:49,937 INFO epoch # 5771 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0064-> 0.0064 -loss = 0.004126145832287875
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:49,958 INFO epoch # 5772 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0064-> 0.0064 -loss = 0.004135642597248079
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:49,980 INFO epoch # 5773 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0064-> 0.0064 -loss = 0.004129540761823591
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:50,001 INFO epoch # 5774 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0064-> 0.0064 -loss = 0.004127953654460725
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:50,022 INFO epoch # 5775 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0064-> 0.0064 -loss = 0.004129619588638889
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:50,043 INFO epoch # 5776 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0064-> 0.0064 -loss = 0.004130788259317342
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:50,065 INFO epoch # 5777 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0064-> 0.0064 -loss = 0.004140758443099912
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:50,086 INFO epoch # 5778 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0064-> 0.0064 -loss = 0.004127544874791056
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:50,108 INFO epoch # 5779 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0064-> 0.0064 -loss = 0.0041929942217393545
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:50,130 INFO epoch # 5780 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0064-> 0.0064 -loss = 0.004155944095145969
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:50,130 INFO *** epoch 5780, rolling-avg-loss (window=10)= 0.004139693232855279
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:50,152 INFO epoch # 5781 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0064-> 0.0064 -loss = 0.0041567831231077434
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:50,174 INFO epoch # 5782 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0064-> 0.0064 -loss = 0.0041451511224295245
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:50,196 INFO epoch # 5783 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0064-> 0.0064 -loss = 0.0041215172150259605
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:50,217 INFO epoch # 5784 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0064-> 0.0064 -loss = 0.00411061389149836
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:50,238 INFO epoch # 5785 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0064-> 0.0064 -loss = 0.004126679407818301
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:50,260 INFO epoch # 5786 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0064-> 0.0064 -loss = 0.0046659124236612115
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:50,281 INFO epoch # 5787 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0064-> 0.0064 -loss = 0.004120806826449552
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:50,303 INFO epoch # 5788 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0064-> 0.0064 -loss = 0.004333594559284393
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:50,325 INFO epoch # 5789 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0064-> 0.0064 -loss = 0.004115797388294595
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:50,346 INFO epoch # 5790 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0064-> 0.0064 -loss = 0.0041353530577907804
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:50,347 INFO *** epoch 5790, rolling-avg-loss (window=10)= 0.004203220901536043
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:50,368 INFO epoch # 5791 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0064-> 0.0064 -loss = 0.004134550348680932
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:50,390 INFO epoch # 5792 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0064-> 0.0064 -loss = 0.004189353905530879
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:50,412 INFO epoch # 5793 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0064-> 0.0064 -loss = 0.004680735373767675
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:50,433 INFO epoch # 5794 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0064-> 0.0064 -loss = 0.004127484091441147
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:50,454 INFO epoch # 5795 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0064-> 0.0063 -loss = 0.005075474367913557
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:50,475 INFO epoch # 5796 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0063-> 0.0063 -loss = 0.004139900509471772
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:50,496 INFO epoch # 5797 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0063-> 0.0063 -loss = 0.004184769733910798
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:50,518 INFO epoch # 5798 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0063-> 0.0063 -loss = 0.0041426443212913
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:50,540 INFO epoch # 5799 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0063-> 0.0063 -loss = 0.004208224547255668
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:50,562 INFO epoch # 5800 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0063-> 0.0063 -loss = 0.004139365566516062
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:50,562 INFO *** epoch 5800, rolling-avg-loss (window=10)= 0.004302250276577979
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:50,584 INFO epoch # 5801 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0063-> 0.0063 -loss = 0.004118299235415179
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:50,606 INFO epoch # 5802 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0063-> 0.0063 -loss = 0.0041317239847558085
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:50,628 INFO epoch # 5803 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0063-> 0.0063 -loss = 0.004140797620493686
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:50,650 INFO epoch # 5804 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0063-> 0.0063 -loss = 0.004121676307477173
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:50,672 INFO epoch # 5805 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0063-> 0.0063 -loss = 0.0041183372031809995
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:50,693 INFO epoch # 5806 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0063-> 0.0062 -loss = 0.004148760292082443
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:50,715 INFO epoch # 5807 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0062-> 0.0062 -loss = 0.004131118477744167
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:50,737 INFO epoch # 5808 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0062-> 0.0062 -loss = 0.004166052784057683
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:50,759 INFO epoch # 5809 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0062-> 0.0062 -loss = 0.004112165739570628
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:50,781 INFO epoch # 5810 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0062-> 0.0062 -loss = 0.004169720546997269
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:50,781 INFO *** epoch 5810, rolling-avg-loss (window=10)= 0.004135865219177503
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:50,802 INFO epoch # 5811 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0062-> 0.0062 -loss = 0.004130058445298346
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:50,824 INFO epoch # 5812 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0062-> 0.0062 -loss = 0.004898069850241882
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:50,845 INFO epoch # 5813 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0062-> 0.0062 -loss = 0.005738962501709466
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:50,866 INFO epoch # 5814 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0062-> 0.0062 -loss = 0.004524057378148427
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:50,888 INFO epoch # 5815 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0062-> 0.0062 -loss = 0.004118279418435122
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:50,909 INFO epoch # 5816 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0062-> 0.0062 -loss = 0.004158404773988877
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:50,930 INFO epoch # 5817 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0062-> 0.0062 -loss = 0.004153575862801517
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:50,952 INFO epoch # 5818 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0062-> 0.0062 -loss = 0.004898641817817406
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:50,973 INFO epoch # 5819 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0062-> 0.0062 -loss = 0.0041110674901574384
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:50,995 INFO epoch # 5820 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0062-> 0.0062 -loss = 0.004117713215237018
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:50,995 INFO *** epoch 5820, rolling-avg-loss (window=10)= 0.00448488307538355
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:51,017 INFO epoch # 5821 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0062-> 0.0062 -loss = 0.0041230786500818795
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:51,039 INFO epoch # 5822 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0062-> 0.0062 -loss = 0.004111320235097082
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:51,060 INFO epoch # 5823 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0062-> 0.0062 -loss = 0.00411348808574985
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:51,081 INFO epoch # 5824 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0062-> 0.0062 -loss = 0.004110762120035361
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:51,103 INFO epoch # 5825 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0062-> 0.0062 -loss = 0.004196745867375284
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:51,124 INFO epoch # 5826 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0062-> 0.0062 -loss = 0.004141965568123851
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:51,145 INFO epoch # 5827 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0062-> 0.0062 -loss = 0.004122672837183927
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:51,167 INFO epoch # 5828 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0062-> 0.0061 -loss = 0.004132329337153351
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:51,189 INFO epoch # 5829 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0061-> 0.0061 -loss = 0.004109353532840032
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:51,211 INFO epoch # 5830 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0061-> 0.0061 -loss = 0.00410555218331865
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:51,211 INFO *** epoch 5830, rolling-avg-loss (window=10)= 0.004126726841695927
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:51,234 INFO epoch # 5831 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0061-> 0.0061 -loss = 0.004105769628949929
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:51,258 INFO epoch # 5832 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0061-> 0.0061 -loss = 0.004098806688489276
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:51,281 INFO epoch # 5833 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0061-> 0.0061 -loss = 0.004094847051419492
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:51,306 INFO epoch # 5834 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0061-> 0.0061 -loss = 0.004131333276745863
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:51,332 INFO epoch # 5835 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0061-> 0.0061 -loss = 0.004150259248490329
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:51,357 INFO epoch # 5836 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0061-> 0.0061 -loss = 0.004219363275296928
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:51,383 INFO epoch # 5837 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0061-> 0.0061 -loss = 0.004088033812877256
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:51,416 INFO epoch # 5838 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0061-> 0.0061 -loss = 0.004099193685760838
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:51,443 INFO epoch # 5839 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0061-> 0.0061 -loss = 0.004257417294866173
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:51,469 INFO epoch # 5840 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0061-> 0.0061 -loss = 0.004098524929759151
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:51,469 INFO *** epoch 5840, rolling-avg-loss (window=10)= 0.004134354889265524
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:51,494 INFO epoch # 5841 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0061-> 0.0061 -loss = 0.004095946575034759
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:51,518 INFO epoch # 5842 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0061-> 0.0061 -loss = 0.004113831815629965
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:51,540 INFO epoch # 5843 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0061-> 0.0061 -loss = 0.004166306169281597
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:51,562 INFO epoch # 5844 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0061-> 0.0061 -loss = 0.004090105807790678
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:51,584 INFO epoch # 5845 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0061-> 0.0061 -loss = 0.004118906677831546
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:51,606 INFO epoch # 5846 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0061-> 0.0061 -loss = 0.004083985992110684
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:51,627 INFO epoch # 5847 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0061-> 0.0061 -loss = 0.0040851323701645015
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:51,649 INFO epoch # 5848 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0061-> 0.0061 -loss = 0.004087663000973407
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:51,671 INFO epoch # 5849 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0061-> 0.0061 -loss = 0.004154299690526386
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:51,693 INFO epoch # 5850 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0061-> 0.0061 -loss = 0.004084678571416589
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:51,693 INFO *** epoch 5850, rolling-avg-loss (window=10)= 0.004108085667076012
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:51,715 INFO epoch # 5851 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0061-> 0.0061 -loss = 0.004169940031715669
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:51,736 INFO epoch # 5852 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0061-> 0.0061 -loss = 0.004110645931177714
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:51,757 INFO epoch # 5853 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0061-> 0.0061 -loss = 0.0041504419950797455
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:51,778 INFO epoch # 5854 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0061-> 0.0061 -loss = 0.004188000575595652
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:51,800 INFO epoch # 5855 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0061-> 0.0061 -loss = 0.004388458290122799
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:51,822 INFO epoch # 5856 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0061-> 0.0061 -loss = 0.004111148982701707
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:51,844 INFO epoch # 5857 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0061-> 0.0061 -loss = 0.004498743253861903
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:51,866 INFO epoch # 5858 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0061-> 0.0061 -loss = 0.004248767922035768
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:51,887 INFO epoch # 5859 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0061-> 0.0061 -loss = 0.004101766679013963
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:51,909 INFO epoch # 5860 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0061-> 0.0061 -loss = 0.00408749224152416
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:51,909 INFO *** epoch 5860, rolling-avg-loss (window=10)= 0.004205540590282908
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:51,930 INFO epoch # 5861 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0061-> 0.0061 -loss = 0.004078189811480115
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:51,951 INFO epoch # 5862 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0061-> 0.0061 -loss = 0.004099815938388929
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:51,972 INFO epoch # 5863 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0061-> 0.0061 -loss = 0.004088767900611856
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:51,994 INFO epoch # 5864 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0061-> 0.0061 -loss = 0.0040988758564708405
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:52,016 INFO epoch # 5865 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0061-> 0.0061 -loss = 0.004079822114363196
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:52,038 INFO epoch # 5866 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0061-> 0.0061 -loss = 0.004104441850358853
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:52,060 INFO epoch # 5867 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0061-> 0.0061 -loss = 0.004088852401764598
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:52,081 INFO epoch # 5868 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0061-> 0.0061 -loss = 0.004076921746673179
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:52,103 INFO epoch # 5869 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0061-> 0.0061 -loss = 0.004162656654443708
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:52,124 INFO epoch # 5870 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0061-> 0.0061 -loss = 0.004076268577591691
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:52,124 INFO *** epoch 5870, rolling-avg-loss (window=10)= 0.004095461285214696
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:52,146 INFO epoch # 5871 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0061-> 0.0061 -loss = 0.004070840872373083
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:52,167 INFO epoch # 5872 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0061-> 0.0061 -loss = 0.0040982801001518965
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:52,188 INFO epoch # 5873 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0061-> 0.0061 -loss = 0.004071838285199192
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:52,209 INFO epoch # 5874 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0061-> 0.0061 -loss = 0.004093645834473136
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:52,231 INFO epoch # 5875 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0061-> 0.0061 -loss = 0.004082827718775661
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:52,253 INFO epoch # 5876 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0061-> 0.0061 -loss = 0.004091913489901344
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:52,275 INFO epoch # 5877 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0061-> 0.0061 -loss = 0.0051253664705654955
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:52,297 INFO epoch # 5878 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0061-> 0.0061 -loss = 0.004079392907442525
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:52,319 INFO epoch # 5879 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0061-> 0.0061 -loss = 0.004073328748745553
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:52,340 INFO epoch # 5880 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0061-> 0.0061 -loss = 0.004065949127834756
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:52,340 INFO *** epoch 5880, rolling-avg-loss (window=10)= 0.0041853383555462646
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:52,361 INFO epoch # 5881 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0061-> 0.0061 -loss = 0.004070178863912588
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:52,383 INFO epoch # 5882 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0061-> 0.0061 -loss = 0.004120867849451315
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:52,404 INFO epoch # 5883 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0061-> 0.0061 -loss = 0.004480298901398783
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:52,425 INFO epoch # 5884 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0061-> 0.0061 -loss = 0.004073983493071864
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:52,447 INFO epoch # 5885 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0061-> 0.0061 -loss = 0.00408016851542925
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:52,469 INFO epoch # 5886 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0061-> 0.0061 -loss = 0.004093742245458998
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:52,491 INFO epoch # 5887 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0061-> 0.0061 -loss = 0.0041023822013812605
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:52,513 INFO epoch # 5888 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0061-> 0.0061 -loss = 0.00406971867869288
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:52,535 INFO epoch # 5889 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0061-> 0.0061 -loss = 0.004100134590771631
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:52,557 INFO epoch # 5890 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0061-> 0.0061 -loss = 0.004060260579535679
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:52,557 INFO *** epoch 5890, rolling-avg-loss (window=10)= 0.0041251735919104245
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:52,578 INFO epoch # 5891 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0061-> 0.0061 -loss = 0.004058544108829665
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:52,599 INFO epoch # 5892 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0061-> 0.0061 -loss = 0.004067516656505177
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:52,620 INFO epoch # 5893 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0061-> 0.0061 -loss = 0.0040701578745938605
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:52,641 INFO epoch # 5894 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0061-> 0.0061 -loss = 0.004121539745028713
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:52,663 INFO epoch # 5895 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0061-> 0.0061 -loss = 0.004071487130204332
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:52,685 INFO epoch # 5896 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0061-> 0.0061 -loss = 0.004084097760824079
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:52,707 INFO epoch # 5897 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0061-> 0.0061 -loss = 0.00407459947928146
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:52,729 INFO epoch # 5898 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0061-> 0.0061 -loss = 0.004080081862412044
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:52,751 INFO epoch # 5899 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0061-> 0.0061 -loss = 0.00416783776745433
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:52,772 INFO epoch # 5900 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0061-> 0.0061 -loss = 0.004091740593139548
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:52,772 INFO *** epoch 5900, rolling-avg-loss (window=10)= 0.00408876029782732
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:52,794 INFO epoch # 5901 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0061-> 0.0061 -loss = 0.00483091629575938
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:52,815 INFO epoch # 5902 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0061-> 0.006 -loss = 0.004085469965502853
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:52,836 INFO epoch # 5903 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.006-> 0.006 -loss = 0.004051187976529036
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:52,857 INFO epoch # 5904 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.006-> 0.006 -loss = 0.00415358106874919
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:52,879 INFO epoch # 5905 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.006-> 0.006 -loss = 0.004048378442803369
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:52,901 INFO epoch # 5906 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.006-> 0.006 -loss = 0.004057822385220788
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:52,923 INFO epoch # 5907 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.006-> 0.006 -loss = 0.004190222747638472
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:52,944 INFO epoch # 5908 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.006-> 0.006 -loss = 0.0040953276793516125
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:52,966 INFO epoch # 5909 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.006-> 0.006 -loss = 0.004472272939892719
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:52,987 INFO epoch # 5910 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.006-> 0.006 -loss = 0.00405167694134434
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:52,987 INFO *** epoch 5910, rolling-avg-loss (window=10)= 0.0042036856442791756
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:53,008 INFO epoch # 5911 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.006-> 0.006 -loss = 0.0040611963922856376
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:53,029 INFO epoch # 5912 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.006-> 0.006 -loss = 0.004047778300446225
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:53,050 INFO epoch # 5913 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.006-> 0.006 -loss = 0.004071678769832943
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:53,072 INFO epoch # 5914 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.006-> 0.006 -loss = 0.0040610245860079885
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:53,094 INFO epoch # 5915 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.006-> 0.006 -loss = 0.004099224313904415
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:53,116 INFO epoch # 5916 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.006-> 0.006 -loss = 0.0040844832747097826
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:53,137 INFO epoch # 5917 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.006-> 0.006 -loss = 0.0040673850489838514
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:53,159 INFO epoch # 5918 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.006-> 0.006 -loss = 0.0040725525714151445
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:53,181 INFO epoch # 5919 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.006-> 0.006 -loss = 0.004053684659083956
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:53,202 INFO epoch # 5920 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.006-> 0.006 -loss = 0.004058685879499535
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:53,202 INFO *** epoch 5920, rolling-avg-loss (window=10)= 0.004067769379616948
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:53,223 INFO epoch # 5921 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.006-> 0.006 -loss = 0.0042024114682135405
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:53,244 INFO epoch # 5922 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.006-> 0.006 -loss = 0.004132791429583449
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:53,266 INFO epoch # 5923 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.006-> 0.0059 -loss = 0.004105868178157834
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:53,287 INFO epoch # 5924 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0059-> 0.0059 -loss = 0.004141336887187208
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:53,309 INFO epoch # 5925 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0059-> 0.0059 -loss = 0.00408562526354217
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:53,330 INFO epoch # 5926 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0059-> 0.0059 -loss = 0.00408206840074854
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:53,352 INFO epoch # 5927 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0059-> 0.0059 -loss = 0.004046361249493202
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:53,373 INFO epoch # 5928 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0059-> 0.0059 -loss = 0.00406165270760539
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:53,395 INFO epoch # 5929 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0059-> 0.0059 -loss = 0.004047442739647522
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:53,417 INFO epoch # 5930 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0059-> 0.0059 -loss = 0.004072345634995145
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:53,417 INFO *** epoch 5930, rolling-avg-loss (window=10)= 0.0040977903959174
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:53,438 INFO epoch # 5931 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0059-> 0.0059 -loss = 0.004054091948091809
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:53,459 INFO epoch # 5932 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0059-> 0.0059 -loss = 0.004038332011077728
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:53,480 INFO epoch # 5933 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0059-> 0.0059 -loss = 0.004046584776915552
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:53,502 INFO epoch # 5934 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0059-> 0.0059 -loss = 0.0042073419062944595
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:53,523 INFO epoch # 5935 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0059-> 0.0059 -loss = 0.004042391006805701
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:53,545 INFO epoch # 5936 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0059-> 0.0059 -loss = 0.004059530934682698
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:53,567 INFO epoch # 5937 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0059-> 0.0059 -loss = 0.004044108435664384
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:53,589 INFO epoch # 5938 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0059-> 0.0059 -loss = 0.004120077581319492
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:53,610 INFO epoch # 5939 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0059-> 0.0059 -loss = 0.004129943750740495
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:53,632 INFO epoch # 5940 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0059-> 0.0059 -loss = 0.00403426012098862
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:53,632 INFO *** epoch 5940, rolling-avg-loss (window=10)= 0.004077666247258094
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:53,653 INFO epoch # 5941 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0059-> 0.0059 -loss = 0.004105410918782582
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:53,675 INFO epoch # 5942 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0059-> 0.0059 -loss = 0.004052311231134809
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:53,696 INFO epoch # 5943 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0059-> 0.0059 -loss = 0.004034933475850266
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:53,717 INFO epoch # 5944 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0059-> 0.0059 -loss = 0.004067769004905131
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:53,739 INFO epoch # 5945 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0059-> 0.0059 -loss = 0.004108816712687258
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:53,761 INFO epoch # 5946 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0059-> 0.0059 -loss = 0.0040461694243276725
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:53,783 INFO epoch # 5947 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0059-> 0.0059 -loss = 0.0040324517167391605
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:53,805 INFO epoch # 5948 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0059-> 0.0059 -loss = 0.0045417841010930715
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:53,827 INFO epoch # 5949 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0059-> 0.0059 -loss = 0.004047408376209205
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:53,848 INFO epoch # 5950 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0059-> 0.0059 -loss = 0.004041195392346708
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:53,848 INFO *** epoch 5950, rolling-avg-loss (window=10)= 0.004107825035407586
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:53,869 INFO epoch # 5951 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0059-> 0.0059 -loss = 0.004935069529892644
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:53,890 INFO epoch # 5952 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0059-> 0.0059 -loss = 0.004080128273926675
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:53,911 INFO epoch # 5953 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0059-> 0.0059 -loss = 0.0040619071642140625
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:53,932 INFO epoch # 5954 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0059-> 0.0059 -loss = 0.005596927691840392
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:53,954 INFO epoch # 5955 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0059-> 0.0059 -loss = 0.004037347720441176
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:53,976 INFO epoch # 5956 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0059-> 0.0059 -loss = 0.004030308780784253
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:53,998 INFO epoch # 5957 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0059-> 0.0059 -loss = 0.004138771264479146
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:54,020 INFO epoch # 5958 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0059-> 0.0059 -loss = 0.0040263446817334625
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:54,041 INFO epoch # 5959 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0059-> 0.0059 -loss = 0.0045634717753273435
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:54,063 INFO epoch # 5960 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0059-> 0.0059 -loss = 0.004064179271153989
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:54,063 INFO *** epoch 5960, rolling-avg-loss (window=10)= 0.004353445615379314
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:54,084 INFO epoch # 5961 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0059-> 0.0059 -loss = 0.004046028801894863
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:54,105 INFO epoch # 5962 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0059-> 0.0059 -loss = 0.004042981776365195
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:54,126 INFO epoch # 5963 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0059-> 0.0059 -loss = 0.004025614370220865
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:54,148 INFO epoch # 5964 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0059-> 0.0059 -loss = 0.004141411169257481
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:54,169 INFO epoch # 5965 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0059-> 0.0059 -loss = 0.004036334463307867
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:54,191 INFO epoch # 5966 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0059-> 0.0059 -loss = 0.004048387654620456
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:54,213 INFO epoch # 5967 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0059-> 0.0059 -loss = 0.004068706602993188
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:54,235 INFO epoch # 5968 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0059-> 0.0059 -loss = 0.00404693270320422
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:54,257 INFO epoch # 5969 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0059-> 0.0059 -loss = 0.004018423052002618
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:54,279 INFO epoch # 5970 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0059-> 0.0059 -loss = 0.004021943210318568
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:54,279 INFO *** epoch 5970, rolling-avg-loss (window=10)= 0.004049676380418532
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:54,300 INFO epoch # 5971 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0059-> 0.0059 -loss = 0.00402233280146902
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:54,321 INFO epoch # 5972 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0059-> 0.0059 -loss = 0.004021886958980758
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:54,342 INFO epoch # 5973 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0059-> 0.0059 -loss = 0.004572804440613254
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:54,364 INFO epoch # 5974 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0059-> 0.0059 -loss = 0.004131737114221323
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:54,385 INFO epoch # 5975 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0059-> 0.0059 -loss = 0.004621344794941251
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:54,407 INFO epoch # 5976 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0059-> 0.0059 -loss = 0.004019038739897951
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:54,428 INFO epoch # 5977 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0059-> 0.0059 -loss = 0.004023734702059301
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:54,450 INFO epoch # 5978 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0059-> 0.0059 -loss = 0.00403114680921135
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:54,472 INFO epoch # 5979 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0059-> 0.0059 -loss = 0.004034776135995344
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:54,493 INFO epoch # 5980 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0059-> 0.0059 -loss = 0.004027319571832777
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:54,494 INFO *** epoch 5980, rolling-avg-loss (window=10)= 0.0041506122069222325
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:54,515 INFO epoch # 5981 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0059-> 0.0059 -loss = 0.004078128712535545
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:54,536 INFO epoch # 5982 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0059-> 0.0059 -loss = 0.004022810899186879
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:54,557 INFO epoch # 5983 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0059-> 0.0059 -loss = 0.0040334871746381395
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:54,579 INFO epoch # 5984 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0059-> 0.0059 -loss = 0.0040090026068355655
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:54,600 INFO epoch # 5985 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0059-> 0.0059 -loss = 0.004029960206025862
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:54,622 INFO epoch # 5986 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0059-> 0.0059 -loss = 0.00404194084876508
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:54,644 INFO epoch # 5987 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0059-> 0.0059 -loss = 0.004039647918034461
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:54,666 INFO epoch # 5988 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0059-> 0.0059 -loss = 0.0040063447113425354
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:54,687 INFO epoch # 5989 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0059-> 0.0059 -loss = 0.004131274439714616
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:54,709 INFO epoch # 5990 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0059-> 0.0059 -loss = 0.004018400551103696
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:54,709 INFO *** epoch 5990, rolling-avg-loss (window=10)= 0.004041099806818238
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:54,730 INFO epoch # 5991 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0059-> 0.0059 -loss = 0.004073531778885808
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:54,752 INFO epoch # 5992 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0059-> 0.0059 -loss = 0.0040196928166551515
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:54,773 INFO epoch # 5993 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0059-> 0.0059 -loss = 0.004064234048200888
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:54,794 INFO epoch # 5994 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0059-> 0.0059 -loss = 0.0040324645342479926
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:54,816 INFO epoch # 5995 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0059-> 0.0059 -loss = 0.004011916959825612
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:54,837 INFO epoch # 5996 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0059-> 0.0059 -loss = 0.004022297878691461
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:54,859 INFO epoch # 5997 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0059-> 0.0059 -loss = 0.00402185578514036
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:54,881 INFO epoch # 5998 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0059-> 0.0059 -loss = 0.004100229908544861
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:54,902 INFO epoch # 5999 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0059-> 0.0058 -loss = 0.004023080043225491
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:54,924 INFO epoch # 6000 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0058-> 0.0058 -loss = 0.00400105243534199
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:54,924 INFO *** epoch 6000, rolling-avg-loss (window=10)= 0.004037035618875961
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:54,945 INFO epoch # 6001 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0058-> 0.0058 -loss = 0.004025761463708477
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:54,967 INFO epoch # 6002 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0058-> 0.0058 -loss = 0.004014380519947736
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:54,988 INFO epoch # 6003 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0058-> 0.0058 -loss = 0.004072049712704029
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:55,010 INFO epoch # 6004 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0058-> 0.0058 -loss = 0.004024061923701083
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:55,032 INFO epoch # 6005 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0058-> 0.0058 -loss = 0.005563369504670845
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:55,053 INFO epoch # 6006 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0058-> 0.0058 -loss = 0.004036289834402851
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:55,075 INFO epoch # 6007 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0058-> 0.0058 -loss = 0.0040689918387215585
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:55,097 INFO epoch # 6008 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0058-> 0.0058 -loss = 0.004012292584775423
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:55,118 INFO epoch # 6009 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0058-> 0.0058 -loss = 0.005031810573200346
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:55,139 INFO epoch # 6010 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0058-> 0.0058 -loss = 0.004098630271982984
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:55,139 INFO *** epoch 6010, rolling-avg-loss (window=10)= 0.004294763822781533
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:55,161 INFO epoch # 6011 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0058-> 0.0058 -loss = 0.0040652913057783735
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:55,182 INFO epoch # 6012 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0058-> 0.0058 -loss = 0.004035087423289951
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:55,203 INFO epoch # 6013 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0058-> 0.0058 -loss = 0.003995944055986911
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:55,224 INFO epoch # 6014 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0058-> 0.0058 -loss = 0.004770816598465899
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:55,246 INFO epoch # 6015 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0058-> 0.0058 -loss = 0.004009505206340691
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:55,268 INFO epoch # 6016 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0058-> 0.0058 -loss = 0.004188187944237143
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:55,290 INFO epoch # 6017 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0058-> 0.0058 -loss = 0.004049195253173821
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:55,312 INFO epoch # 6018 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0058-> 0.0058 -loss = 0.00402675917121087
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:55,334 INFO epoch # 6019 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0058-> 0.0058 -loss = 0.0039928780861373525
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:55,356 INFO epoch # 6020 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0058-> 0.0058 -loss = 0.0039950573391251964
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:55,356 INFO *** epoch 6020, rolling-avg-loss (window=10)= 0.0041128722383746204
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:55,377 INFO epoch # 6021 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0058-> 0.0058 -loss = 0.003997095070189971
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:55,398 INFO epoch # 6022 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0058-> 0.0058 -loss = 0.004048111175507074
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:55,419 INFO epoch # 6023 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0058-> 0.0058 -loss = 0.004085113887413172
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:55,440 INFO epoch # 6024 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0058-> 0.0058 -loss = 0.0039981951522349846
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:55,462 INFO epoch # 6025 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0058-> 0.0058 -loss = 0.003993581161012116
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:55,484 INFO epoch # 6026 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0058-> 0.0058 -loss = 0.004035980839034892
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:55,505 INFO epoch # 6027 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0058-> 0.0058 -loss = 0.00399988078061142
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:55,527 INFO epoch # 6028 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0058-> 0.0058 -loss = 0.0044074100551370066
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:55,550 INFO epoch # 6029 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0058-> 0.0058 -loss = 0.003997831654487527
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:55,572 INFO epoch # 6030 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0058-> 0.0057 -loss = 0.0040036762757154065
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:55,572 INFO *** epoch 6030, rolling-avg-loss (window=10)= 0.004056687605134357
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:55,593 INFO epoch # 6031 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0057-> 0.0057 -loss = 0.003988622835095157
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:55,615 INFO epoch # 6032 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0057-> 0.0057 -loss = 0.003994741848146077
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:55,636 INFO epoch # 6033 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0057-> 0.0057 -loss = 0.003989580451161601
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:55,657 INFO epoch # 6034 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0057-> 0.0057 -loss = 0.003993195245129755
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:55,679 INFO epoch # 6035 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0057-> 0.0057 -loss = 0.003993278081907192
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:55,701 INFO epoch # 6036 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0057-> 0.0057 -loss = 0.003997471241746098
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:55,723 INFO epoch # 6037 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0057-> 0.0057 -loss = 0.003987472219250776
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:55,745 INFO epoch # 6038 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0057-> 0.0057 -loss = 0.0040022456960286945
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:55,767 INFO epoch # 6039 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0057-> 0.0057 -loss = 0.004044023709866451
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:55,789 INFO epoch # 6040 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0057-> 0.0057 -loss = 0.004149563032115111
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:55,789 INFO *** epoch 6040, rolling-avg-loss (window=10)= 0.004014019436044691
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:55,810 INFO epoch # 6041 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0057-> 0.0057 -loss = 0.00400409980375116
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:55,831 INFO epoch # 6042 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0057-> 0.0057 -loss = 0.0039860247597971465
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:55,852 INFO epoch # 6043 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0057-> 0.0057 -loss = 0.004017627972643822
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:55,873 INFO epoch # 6044 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0057-> 0.0057 -loss = 0.004028450763144065
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:55,895 INFO epoch # 6045 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0057-> 0.0057 -loss = 0.004386592103401199
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:55,917 INFO epoch # 6046 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0057-> 0.0057 -loss = 0.004025259735499276
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:55,939 INFO epoch # 6047 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0057-> 0.0057 -loss = 0.004080112748852116
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:55,961 INFO epoch # 6048 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0057-> 0.0057 -loss = 0.003987037776823854
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:55,982 INFO epoch # 6049 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0057-> 0.0057 -loss = 0.003979445490585931
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:56,004 INFO epoch # 6050 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0057-> 0.0057 -loss = 0.0040050383904599585
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:56,004 INFO *** epoch 6050, rolling-avg-loss (window=10)= 0.004049968954495853
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:56,025 INFO epoch # 6051 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0057-> 0.0057 -loss = 0.0040292617322847946
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:56,046 INFO epoch # 6052 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0057-> 0.0057 -loss = 0.003985250250480021
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:56,067 INFO epoch # 6053 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0057-> 0.0057 -loss = 0.004025952446681913
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:56,089 INFO epoch # 6054 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0057-> 0.0057 -loss = 0.004007568454653665
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:56,111 INFO epoch # 6055 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0057-> 0.0057 -loss = 0.004056099167428329
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:56,133 INFO epoch # 6056 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0057-> 0.0057 -loss = 0.004013617533928482
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:56,154 INFO epoch # 6057 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0057-> 0.0057 -loss = 0.004108990586246364
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:56,176 INFO epoch # 6058 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0057-> 0.0057 -loss = 0.003985330055911618
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:56,198 INFO epoch # 6059 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0057-> 0.0057 -loss = 0.00398920465795527
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:56,219 INFO epoch # 6060 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0057-> 0.0056 -loss = 0.003979126684498624
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:56,219 INFO *** epoch 6060, rolling-avg-loss (window=10)= 0.004018040157006908
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:56,241 INFO epoch # 6061 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0056-> 0.0056 -loss = 0.004000883426670043
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:56,262 INFO epoch # 6062 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0056-> 0.0056 -loss = 0.004702593449110282
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:56,283 INFO epoch # 6063 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0056-> 0.0056 -loss = 0.004030503487228998
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:56,305 INFO epoch # 6064 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0056-> 0.0056 -loss = 0.003977329957706388
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:56,326 INFO epoch # 6065 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0056-> 0.0056 -loss = 0.003987760708696442
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:56,348 INFO epoch # 6066 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0056-> 0.0056 -loss = 0.004078057587321382
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:56,370 INFO epoch # 6067 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0056-> 0.0056 -loss = 0.00437982368930534
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:56,392 INFO epoch # 6068 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0056-> 0.0056 -loss = 0.003983224363764748
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:56,413 INFO epoch # 6069 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0056-> 0.0056 -loss = 0.003967733595800382
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:56,435 INFO epoch # 6070 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0056-> 0.0056 -loss = 0.0039851810925028985
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:56,435 INFO *** epoch 6070, rolling-avg-loss (window=10)= 0.00410930913581069
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:56,456 INFO epoch # 6071 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0056-> 0.0056 -loss = 0.003978085704147816
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:56,477 INFO epoch # 6072 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0056-> 0.0056 -loss = 0.0039648920437684865
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:56,498 INFO epoch # 6073 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0056-> 0.0056 -loss = 0.003992311440015328
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:56,519 INFO epoch # 6074 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0056-> 0.0056 -loss = 0.003990419641013432
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:56,541 INFO epoch # 6075 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0056-> 0.0056 -loss = 0.0039643757295380055
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:56,563 INFO epoch # 6076 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0056-> 0.0056 -loss = 0.003968147958403279
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:56,585 INFO epoch # 6077 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0056-> 0.0056 -loss = 0.00398637538546609
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:56,607 INFO epoch # 6078 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0056-> 0.0056 -loss = 0.004005208151284023
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:56,629 INFO epoch # 6079 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0056-> 0.0056 -loss = 0.003990375771536492
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:56,651 INFO epoch # 6080 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0056-> 0.0056 -loss = 0.0039658228615735425
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:56,651 INFO *** epoch 6080, rolling-avg-loss (window=10)= 0.00398060146867465
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:56,672 INFO epoch # 6081 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0056-> 0.0056 -loss = 0.005027158253142261
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:56,693 INFO epoch # 6082 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0056-> 0.0056 -loss = 0.0039878898478491465
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:56,714 INFO epoch # 6083 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0056-> 0.0056 -loss = 0.003972598190557619
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:56,737 INFO epoch # 6084 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0056-> 0.0056 -loss = 0.004039849880427937
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:56,759 INFO epoch # 6085 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0056-> 0.0056 -loss = 0.004019441663331236
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:56,781 INFO epoch # 6086 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0056-> 0.0056 -loss = 0.004048668388350052
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:56,803 INFO epoch # 6087 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0056-> 0.0056 -loss = 0.003966065806707775
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:56,825 INFO epoch # 6088 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0056-> 0.0056 -loss = 0.003964357873428526
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:56,846 INFO epoch # 6089 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0056-> 0.0056 -loss = 0.0040180955784308026
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:56,867 INFO epoch # 6090 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0056-> 0.0056 -loss = 0.003962168670113897
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:56,867 INFO *** epoch 6090, rolling-avg-loss (window=10)= 0.004100629415233925
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:56,889 INFO epoch # 6091 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0056-> 0.0056 -loss = 0.003972482364588359
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:56,910 INFO epoch # 6092 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0056-> 0.0056 -loss = 0.004844898876399384
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:56,931 INFO epoch # 6093 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0056-> 0.0056 -loss = 0.003968825261836173
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:56,952 INFO epoch # 6094 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0056-> 0.0056 -loss = 0.004092574903552304
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:56,973 INFO epoch # 6095 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0056-> 0.0056 -loss = 0.003956783113608253
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:56,995 INFO epoch # 6096 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0056-> 0.0056 -loss = 0.003961493986935238
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:57,016 INFO epoch # 6097 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0056-> 0.0056 -loss = 0.003955701267841505
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:57,038 INFO epoch # 6098 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0056-> 0.0056 -loss = 0.003975485191404005
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:57,060 INFO epoch # 6099 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0056-> 0.0056 -loss = 0.003956969021601253
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:57,082 INFO epoch # 6100 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0056-> 0.0056 -loss = 0.003996999157607206
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:57,082 INFO *** epoch 6100, rolling-avg-loss (window=10)= 0.004068221314537368
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:57,103 INFO epoch # 6101 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0056-> 0.0056 -loss = 0.00397618487750151
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:57,124 INFO epoch # 6102 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0056-> 0.0056 -loss = 0.004002821380709065
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:57,145 INFO epoch # 6103 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0056-> 0.0056 -loss = 0.003956233906137641
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:57,167 INFO epoch # 6104 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0056-> 0.0056 -loss = 0.0039534287725473405
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:57,188 INFO epoch # 6105 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0056-> 0.0056 -loss = 0.00395712326917419
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:57,210 INFO epoch # 6106 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0056-> 0.0056 -loss = 0.003987980226156651
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:57,231 INFO epoch # 6107 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0056-> 0.0056 -loss = 0.003949461052343395
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:57,254 INFO epoch # 6108 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0056-> 0.0056 -loss = 0.003953266381358844
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:57,276 INFO epoch # 6109 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0056-> 0.0056 -loss = 0.004378649080535979
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:57,297 INFO epoch # 6110 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0056-> 0.0056 -loss = 0.004009331451015896
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:57,297 INFO *** epoch 6110, rolling-avg-loss (window=10)= 0.004012448039748051
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:57,318 INFO epoch # 6111 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0056-> 0.0056 -loss = 0.00400346698006615
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:57,339 INFO epoch # 6112 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0056-> 0.0056 -loss = 0.0040415832427243
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:57,361 INFO epoch # 6113 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0056-> 0.0056 -loss = 0.004032592853036476
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:57,382 INFO epoch # 6114 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0056-> 0.0056 -loss = 0.00404410855480819
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:57,404 INFO epoch # 6115 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0056-> 0.0056 -loss = 0.004052435489029449
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:57,426 INFO epoch # 6116 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0056-> 0.0056 -loss = 0.003961119749874342
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:57,448 INFO epoch # 6117 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0056-> 0.0056 -loss = 0.004400805521072471
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:57,470 INFO epoch # 6118 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0056-> 0.0055 -loss = 0.003986629581959278
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:57,491 INFO epoch # 6119 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0055-> 0.0055 -loss = 0.003975681171141332
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:57,513 INFO epoch # 6120 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0055-> 0.0055 -loss = 0.004051873216667445
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:57,513 INFO *** epoch 6120, rolling-avg-loss (window=10)= 0.004055029636037944
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:57,534 INFO epoch # 6121 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0055-> 0.0055 -loss = 0.003981419025876676
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:57,555 INFO epoch # 6122 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0055-> 0.0055 -loss = 0.003952088538426324
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:57,576 INFO epoch # 6123 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0055-> 0.0055 -loss = 0.004000041204562876
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:57,597 INFO epoch # 6124 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0055-> 0.0055 -loss = 0.004047094846100663
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:57,619 INFO epoch # 6125 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0055-> 0.0055 -loss = 0.003972822119976627
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:57,641 INFO epoch # 6126 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0055-> 0.0055 -loss = 0.003961178426834522
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:57,663 INFO epoch # 6127 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0055-> 0.0055 -loss = 0.0039434070904462715
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:57,685 INFO epoch # 6128 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0055-> 0.0055 -loss = 0.003955647996008338
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:57,706 INFO epoch # 6129 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0055-> 0.0055 -loss = 0.003977038822995382
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:57,727 INFO epoch # 6130 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0055-> 0.0055 -loss = 0.0040296058878084295
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:57,728 INFO *** epoch 6130, rolling-avg-loss (window=10)= 0.003982034395903611
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:57,749 INFO epoch # 6131 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0055-> 0.0055 -loss = 0.003945475132240972
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:57,770 INFO epoch # 6132 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0055-> 0.0055 -loss = 0.003951959978621744
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:57,791 INFO epoch # 6133 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0055-> 0.0055 -loss = 0.003954020554374438
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:57,812 INFO epoch # 6134 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0055-> 0.0055 -loss = 0.003943694521694852
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:57,835 INFO epoch # 6135 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0055-> 0.0055 -loss = 0.003943725155295397
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:57,857 INFO epoch # 6136 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0055-> 0.0055 -loss = 0.0040178585186367854
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:57,879 INFO epoch # 6137 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0055-> 0.0055 -loss = 0.003960339046898298
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:57,900 INFO epoch # 6138 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0055-> 0.0055 -loss = 0.0039412464711858775
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:57,922 INFO epoch # 6139 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0055-> 0.0055 -loss = 0.004044692479510559
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:57,944 INFO epoch # 6140 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0055-> 0.0055 -loss = 0.003946219771023607
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:57,944 INFO *** epoch 6140, rolling-avg-loss (window=10)= 0.0039649231629482525
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:57,965 INFO epoch # 6141 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0055-> 0.0055 -loss = 0.003955492336899624
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:57,986 INFO epoch # 6142 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0055-> 0.0055 -loss = 0.004009416914414032
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:58,007 INFO epoch # 6143 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0055-> 0.0055 -loss = 0.0039441731405531755
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:58,028 INFO epoch # 6144 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0055-> 0.0055 -loss = 0.004274051225365838
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:58,050 INFO epoch # 6145 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0055-> 0.0055 -loss = 0.003951914739445783
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:58,072 INFO epoch # 6146 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0055-> 0.0055 -loss = 0.0043552980650929385
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:58,094 INFO epoch # 6147 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0055-> 0.0055 -loss = 0.003974458728407626
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:58,116 INFO epoch # 6148 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0055-> 0.0055 -loss = 0.004021758282760857
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:58,137 INFO epoch # 6149 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0055-> 0.0055 -loss = 0.003936793827961083
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:58,159 INFO epoch # 6150 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0055-> 0.0055 -loss = 0.004018949961391627
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:58,159 INFO *** epoch 6150, rolling-avg-loss (window=10)= 0.004044230722229258
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:58,184 INFO epoch # 6151 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0055-> 0.0055 -loss = 0.004024306228529895
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:58,205 INFO epoch # 6152 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0055-> 0.0055 -loss = 0.003941213841244462
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:58,226 INFO epoch # 6153 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0055-> 0.0055 -loss = 0.003990349575360597
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:58,248 INFO epoch # 6154 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0055-> 0.0055 -loss = 0.003949258802094846
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:58,270 INFO epoch # 6155 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0055-> 0.0055 -loss = 0.003966939108067891
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:58,291 INFO epoch # 6156 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0055-> 0.0055 -loss = 0.003932620400519227
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:58,313 INFO epoch # 6157 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0055-> 0.0055 -loss = 0.003949614805605961
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:58,335 INFO epoch # 6158 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0055-> 0.0055 -loss = 0.003943784114198934
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:58,356 INFO epoch # 6159 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0055-> 0.0055 -loss = 0.003933734962629387
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:58,378 INFO epoch # 6160 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0055-> 0.0055 -loss = 0.003950508218622417
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:58,378 INFO *** epoch 6160, rolling-avg-loss (window=10)= 0.003958233005687361
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:58,399 INFO epoch # 6161 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0055-> 0.0055 -loss = 0.00435062299038691
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:58,420 INFO epoch # 6162 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0055-> 0.0055 -loss = 0.00399415764331934
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:58,442 INFO epoch # 6163 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0055-> 0.0055 -loss = 0.003934976193704642
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:58,463 INFO epoch # 6164 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0055-> 0.0055 -loss = 0.00396383579391113
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:58,485 INFO epoch # 6165 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0055-> 0.0055 -loss = 0.004050799538163119
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:58,506 INFO epoch # 6166 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0055-> 0.0055 -loss = 0.003977638583819498
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:58,528 INFO epoch # 6167 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0055-> 0.0055 -loss = 0.003946960690882406
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:58,550 INFO epoch # 6168 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0055-> 0.0055 -loss = 0.0039677897489127645
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:58,572 INFO epoch # 6169 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0055-> 0.0055 -loss = 0.003998760334980034
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:58,594 INFO epoch # 6170 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0055-> 0.0055 -loss = 0.003975739688030444
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:58,594 INFO *** epoch 6170, rolling-avg-loss (window=10)= 0.004016128120611029
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:58,615 INFO epoch # 6171 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0055-> 0.0055 -loss = 0.003935135371648357
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:58,636 INFO epoch # 6172 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0055-> 0.0055 -loss = 0.003920828091395379
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:58,657 INFO epoch # 6173 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0055-> 0.0055 -loss = 0.003927558555005817
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:58,679 INFO epoch # 6174 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0055-> 0.0055 -loss = 0.004098910605534911
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:58,701 INFO epoch # 6175 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0055-> 0.0055 -loss = 0.003940894726838451
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:58,724 INFO epoch # 6176 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0055-> 0.0055 -loss = 0.003951066479203291
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:58,746 INFO epoch # 6177 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0055-> 0.0055 -loss = 0.003920076980648446
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:58,768 INFO epoch # 6178 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0055-> 0.0055 -loss = 0.003911631728442444
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:58,790 INFO epoch # 6179 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0055-> 0.0055 -loss = 0.003981321115134051
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:58,811 INFO epoch # 6180 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0055-> 0.0055 -loss = 0.003952460423533921
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:58,811 INFO *** epoch 6180, rolling-avg-loss (window=10)= 0.0039539884077385064
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:58,832 INFO epoch # 6181 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0055-> 0.0055 -loss = 0.004008760852229898
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:58,853 INFO epoch # 6182 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0055-> 0.0055 -loss = 0.003925214636183227
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:58,874 INFO epoch # 6183 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0055-> 0.0055 -loss = 0.003994368826170103
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:58,896 INFO epoch # 6184 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0055-> 0.0055 -loss = 0.00394166958903952
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:58,917 INFO epoch # 6185 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0055-> 0.0055 -loss = 0.003918831071132445
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:58,939 INFO epoch # 6186 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0055-> 0.0055 -loss = 0.003967521006416064
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:58,961 INFO epoch # 6187 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0055-> 0.0055 -loss = 0.0039414163347828435
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:58,983 INFO epoch # 6188 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0055-> 0.0055 -loss = 0.003918302823876729
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:59,005 INFO epoch # 6189 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0055-> 0.0054 -loss = 0.003943020263250219
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:59,026 INFO epoch # 6190 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0054-> 0.0054 -loss = 0.003910441138941678
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:59,027 INFO *** epoch 6190, rolling-avg-loss (window=10)= 0.003946954654202273
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:59,048 INFO epoch # 6191 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0054-> 0.0054 -loss = 0.003914633673957724
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:59,069 INFO epoch # 6192 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0054-> 0.0054 -loss = 0.003927900483176927
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:59,090 INFO epoch # 6193 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0054-> 0.0054 -loss = 0.004063561493239831
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:59,111 INFO epoch # 6194 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0054-> 0.0054 -loss = 0.003937816677535011
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:59,134 INFO epoch # 6195 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0054-> 0.0054 -loss = 0.003964599257415102
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:59,155 INFO epoch # 6196 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0054-> 0.0054 -loss = 0.00397281823643425
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:59,177 INFO epoch # 6197 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0054-> 0.0054 -loss = 0.003929706752387574
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:59,199 INFO epoch # 6198 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0054-> 0.0054 -loss = 0.003920956535694131
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:59,221 INFO epoch # 6199 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0054-> 0.0054 -loss = 0.003906791504505236
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:59,243 INFO epoch # 6200 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0054-> 0.0054 -loss = 0.004064310362991819
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:59,243 INFO *** epoch 6200, rolling-avg-loss (window=10)= 0.003960309497733761
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:59,265 INFO epoch # 6201 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0054-> 0.0054 -loss = 0.003980114732257789
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:59,286 INFO epoch # 6202 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0054-> 0.0054 -loss = 0.004044940773383132
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:59,307 INFO epoch # 6203 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0054-> 0.0054 -loss = 0.0039637749123357935
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:59,328 INFO epoch # 6204 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0054-> 0.0054 -loss = 0.003912912667146884
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:59,350 INFO epoch # 6205 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0054-> 0.0054 -loss = 0.00392630186615861
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:59,372 INFO epoch # 6206 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0054-> 0.0054 -loss = 0.00391387669606047
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:59,394 INFO epoch # 6207 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0054-> 0.0054 -loss = 0.004674435678680311
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:59,415 INFO epoch # 6208 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0054-> 0.0054 -loss = 0.003997622684437374
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:59,437 INFO epoch # 6209 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0054-> 0.0054 -loss = 0.003988129074059543
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:59,459 INFO epoch # 6210 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0054-> 0.0054 -loss = 0.003952812934585381
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:59,459 INFO *** epoch 6210, rolling-avg-loss (window=10)= 0.004035492201910529
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:59,480 INFO epoch # 6211 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0054-> 0.0054 -loss = 0.003912351216058596
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:59,501 INFO epoch # 6212 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0054-> 0.0054 -loss = 0.003903293460552959
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:59,522 INFO epoch # 6213 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0054-> 0.0054 -loss = 0.003987024501839187
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:59,544 INFO epoch # 6214 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0054-> 0.0054 -loss = 0.003909013038537523
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:59,566 INFO epoch # 6215 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0054-> 0.0054 -loss = 0.003925514984075562
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:59,588 INFO epoch # 6216 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0054-> 0.0054 -loss = 0.00391177149140276
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:59,610 INFO epoch # 6217 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0054-> 0.0054 -loss = 0.003942354665923631
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:59,632 INFO epoch # 6218 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0054-> 0.0054 -loss = 0.003906412794094649
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:59,653 INFO epoch # 6219 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0054-> 0.0054 -loss = 0.003913049520633649
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:59,675 INFO epoch # 6220 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0054-> 0.0054 -loss = 0.003951505307668413
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:59,675 INFO *** epoch 6220, rolling-avg-loss (window=10)= 0.003926229098078693
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:59,696 INFO epoch # 6221 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0054-> 0.0054 -loss = 0.003907957137926132
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:59,719 INFO epoch # 6222 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0054-> 0.0054 -loss = 0.003950628675738699
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:59,741 INFO epoch # 6223 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0054-> 0.0054 -loss = 0.003900609839547542
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:59,763 INFO epoch # 6224 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0054-> 0.0054 -loss = 0.003920937415387016
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:59,785 INFO epoch # 6225 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0054-> 0.0054 -loss = 0.0038979638302407693
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:59,807 INFO epoch # 6226 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0054-> 0.0054 -loss = 0.0039328737129835645
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:59,829 INFO epoch # 6227 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0054-> 0.0054 -loss = 0.0039040487672536983
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:59,851 INFO epoch # 6228 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0054-> 0.0054 -loss = 0.004082178364114952
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:59,872 INFO epoch # 6229 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0054-> 0.0054 -loss = 0.004067810274136718
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:59,894 INFO epoch # 6230 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0054-> 0.0054 -loss = 0.003913206979632378
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:55:59,894 INFO *** epoch 6230, rolling-avg-loss (window=10)= 0.003947821499696147
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:59,915 INFO epoch # 6231 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0054-> 0.0054 -loss = 0.003937617424526252
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:59,936 INFO epoch # 6232 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0054-> 0.0054 -loss = 0.003898048697919876
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:59,957 INFO epoch # 6233 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0054-> 0.0054 -loss = 0.003903324813109066
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:55:59,978 INFO epoch # 6234 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0054-> 0.0054 -loss = 0.0038997449410089757
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:00,000 INFO epoch # 6235 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0054-> 0.0054 -loss = 0.00393701165830862
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:00,022 INFO epoch # 6236 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0054-> 0.0053 -loss = 0.003898894537542219
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:00,044 INFO epoch # 6237 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0053-> 0.0053 -loss = 0.0039048568296493613
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:00,066 INFO epoch # 6238 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0053-> 0.0053 -loss = 0.003899620696756756
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:00,087 INFO epoch # 6239 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0053-> 0.0053 -loss = 0.003940139575206558
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:00,109 INFO epoch # 6240 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0053-> 0.0053 -loss = 0.003900665413311799
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:00,109 INFO *** epoch 6240, rolling-avg-loss (window=10)= 0.003911992458733948
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:00,130 INFO epoch # 6241 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0053-> 0.0053 -loss = 0.003905008375113539
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:00,151 INFO epoch # 6242 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0053-> 0.0053 -loss = 0.003928798376364284
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:00,172 INFO epoch # 6243 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0053-> 0.0053 -loss = 0.0038957532806307427
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:00,193 INFO epoch # 6244 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0053-> 0.0053 -loss = 0.003907035426891525
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:00,215 INFO epoch # 6245 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0053-> 0.0053 -loss = 0.0039035633963067085
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:00,237 INFO epoch # 6246 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0053-> 0.0053 -loss = 0.003903130776961916
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:00,259 INFO epoch # 6247 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0053-> 0.0053 -loss = 0.0038939325258979807
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:00,280 INFO epoch # 6248 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0053-> 0.0053 -loss = 0.00393127909865143
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:00,302 INFO epoch # 6249 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0053-> 0.0053 -loss = 0.0039001412951620296
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:00,323 INFO epoch # 6250 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0053-> 0.0053 -loss = 0.003908723485437804
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:00,323 INFO *** epoch 6250, rolling-avg-loss (window=10)= 0.003907736603741796
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:00,345 INFO epoch # 6251 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0053-> 0.0053 -loss = 0.0039249388664757134
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:00,366 INFO epoch # 6252 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0053-> 0.0053 -loss = 0.003988393838881166
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:00,387 INFO epoch # 6253 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0053-> 0.0053 -loss = 0.0038955711461312603
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:00,408 INFO epoch # 6254 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0053-> 0.0053 -loss = 0.0039032072199916
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:00,430 INFO epoch # 6255 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0053-> 0.0053 -loss = 0.0038886776610524976
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:00,451 INFO epoch # 6256 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0053-> 0.0053 -loss = 0.003884847395511315
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:00,473 INFO epoch # 6257 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0053-> 0.0053 -loss = 0.0038866611903358717
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:00,494 INFO epoch # 6258 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0053-> 0.0053 -loss = 0.0039059834598447196
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:00,516 INFO epoch # 6259 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0053-> 0.0053 -loss = 0.003947522797716374
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:00,537 INFO epoch # 6260 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0053-> 0.0053 -loss = 0.003888193326019973
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:00,537 INFO *** epoch 6260, rolling-avg-loss (window=10)= 0.003911399690196049
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:00,558 INFO epoch # 6261 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0053-> 0.0053 -loss = 0.003909918942554214
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:00,579 INFO epoch # 6262 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0053-> 0.0053 -loss = 0.003914937147783348
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:00,600 INFO epoch # 6263 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0053-> 0.0053 -loss = 0.003950188905946561
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:00,622 INFO epoch # 6264 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0053-> 0.0053 -loss = 0.003926451450752211
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:00,644 INFO epoch # 6265 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0053-> 0.0053 -loss = 0.003889605393851525
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:00,666 INFO epoch # 6266 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0053-> 0.0053 -loss = 0.0038821770240247133
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:00,688 INFO epoch # 6267 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0053-> 0.0053 -loss = 0.0039040451047185343
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:00,709 INFO epoch # 6268 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0053-> 0.0053 -loss = 0.003884010396177473
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:00,731 INFO epoch # 6269 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0053-> 0.0053 -loss = 0.003904094221070409
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:00,753 INFO epoch # 6270 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0053-> 0.0053 -loss = 0.003913489503247547
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:00,753 INFO *** epoch 6270, rolling-avg-loss (window=10)= 0.003907891809012654
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:00,775 INFO epoch # 6271 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0053-> 0.0053 -loss = 0.003942621191526996
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:00,796 INFO epoch # 6272 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0053-> 0.0053 -loss = 0.003944333033359726
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:00,817 INFO epoch # 6273 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0053-> 0.0053 -loss = 0.004042389626192744
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:00,838 INFO epoch # 6274 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0053-> 0.0053 -loss = 0.0039343897351500345
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:00,860 INFO epoch # 6275 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0053-> 0.0053 -loss = 0.003879798722664418
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:00,882 INFO epoch # 6276 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0053-> 0.0053 -loss = 0.004073405595590884
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:00,904 INFO epoch # 6277 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0053-> 0.0053 -loss = 0.0038870615644555073
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:00,926 INFO epoch # 6278 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0053-> 0.0053 -loss = 0.0038924482396396343
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:00,948 INFO epoch # 6279 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0053-> 0.0053 -loss = 0.003920254383046995
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:00,969 INFO epoch # 6280 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0053-> 0.0053 -loss = 0.0038837973597765085
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:00,969 INFO *** epoch 6280, rolling-avg-loss (window=10)= 0.003940049945140345
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:00,990 INFO epoch # 6281 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0053-> 0.0053 -loss = 0.0038740250333830772
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:01,012 INFO epoch # 6282 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0053-> 0.0053 -loss = 0.0038874540805409197
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:01,033 INFO epoch # 6283 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0053-> 0.0053 -loss = 0.0038982204077910865
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:01,054 INFO epoch # 6284 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0053-> 0.0053 -loss = 0.003916147745258058
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:01,076 INFO epoch # 6285 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0053-> 0.0053 -loss = 0.0038791581955592846
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:01,097 INFO epoch # 6286 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0053-> 0.0053 -loss = 0.0038764641303714598
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:01,119 INFO epoch # 6287 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0053-> 0.0053 -loss = 0.0038912005784368375
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:01,141 INFO epoch # 6288 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0053-> 0.0053 -loss = 0.003965259826145484
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:01,162 INFO epoch # 6289 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0053-> 0.0053 -loss = 0.0038819809715278097
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:01,184 INFO epoch # 6290 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0053-> 0.0053 -loss = 0.003875782607792644
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:01,184 INFO *** epoch 6290, rolling-avg-loss (window=10)= 0.003894569357680666
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:01,205 INFO epoch # 6291 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0053-> 0.0053 -loss = 0.00402712136565242
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:01,226 INFO epoch # 6292 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0053-> 0.0053 -loss = 0.0038720158827345585
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:01,248 INFO epoch # 6293 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0053-> 0.0053 -loss = 0.003896198208167334
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:01,269 INFO epoch # 6294 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0053-> 0.0053 -loss = 0.0038932948918954935
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:01,291 INFO epoch # 6295 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0053-> 0.0053 -loss = 0.00386985404202278
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:01,313 INFO epoch # 6296 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0053-> 0.0053 -loss = 0.0038785216984251747
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:01,335 INFO epoch # 6297 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0053-> 0.0053 -loss = 0.003885462549078511
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:01,357 INFO epoch # 6298 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0053-> 0.0053 -loss = 0.004280913484763005
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:01,379 INFO epoch # 6299 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0053-> 0.0053 -loss = 0.003983848466305062
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:01,401 INFO epoch # 6300 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0053-> 0.0053 -loss = 0.003938018603548699
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:01,401 INFO *** epoch 6300, rolling-avg-loss (window=10)= 0.003952524919259304
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:01,422 INFO epoch # 6301 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0053-> 0.0053 -loss = 0.0038707847297700937
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:01,443 INFO epoch # 6302 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0053-> 0.0053 -loss = 0.0038956897806201596
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:01,464 INFO epoch # 6303 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0053-> 0.0053 -loss = 0.00393993066791154
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:01,486 INFO epoch # 6304 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0053-> 0.0053 -loss = 0.004268768228939734
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:01,508 INFO epoch # 6305 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0053-> 0.0053 -loss = 0.004898219667666126
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:01,530 INFO epoch # 6306 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0053-> 0.0053 -loss = 0.004037424454509164
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:01,552 INFO epoch # 6307 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0053-> 0.0053 -loss = 0.0038744149323974852
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:01,573 INFO epoch # 6308 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0053-> 0.0053 -loss = 0.0038766901670896914
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:01,595 INFO epoch # 6309 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0053-> 0.0053 -loss = 0.0038617055033682846
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:01,616 INFO epoch # 6310 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0053-> 0.0053 -loss = 0.0039041651398292743
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:01,617 INFO *** epoch 6310, rolling-avg-loss (window=10)= 0.0040427793272101555
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:01,638 INFO epoch # 6311 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0053-> 0.0053 -loss = 0.003985692794230999
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:01,659 INFO epoch # 6312 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0053-> 0.0053 -loss = 0.003921660641935887
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:01,680 INFO epoch # 6313 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0053-> 0.0053 -loss = 0.003873132802254986
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:01,701 INFO epoch # 6314 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0053-> 0.0053 -loss = 0.0038913849530217703
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:01,723 INFO epoch # 6315 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0053-> 0.0053 -loss = 0.0038790189482824644
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:01,746 INFO epoch # 6316 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0053-> 0.0053 -loss = 0.004029984469525516
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:01,767 INFO epoch # 6317 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0053-> 0.0053 -loss = 0.0038550638701053686
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:01,789 INFO epoch # 6318 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0053-> 0.0053 -loss = 0.003910261624696432
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:01,811 INFO epoch # 6319 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0053-> 0.0053 -loss = 0.003856542444736988
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:01,832 INFO epoch # 6320 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0053-> 0.0053 -loss = 0.003861513818264939
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:01,832 INFO *** epoch 6320, rolling-avg-loss (window=10)= 0.003906425636705535
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:01,853 INFO epoch # 6321 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0053-> 0.0053 -loss = 0.003884569721776643
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:01,874 INFO epoch # 6322 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0053-> 0.0053 -loss = 0.0038654238487652037
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:01,895 INFO epoch # 6323 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0053-> 0.0053 -loss = 0.003864003198032151
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:01,917 INFO epoch # 6324 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0053-> 0.0053 -loss = 0.003943220841392758
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:01,938 INFO epoch # 6325 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0053-> 0.0053 -loss = 0.0038579331139771966
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:01,960 INFO epoch # 6326 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0053-> 0.0053 -loss = 0.003901260648490279
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:01,982 INFO epoch # 6327 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0053-> 0.0053 -loss = 0.003864388292640797
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:02,003 INFO epoch # 6328 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0053-> 0.0052 -loss = 0.0038595387359237066
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:02,025 INFO epoch # 6329 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0052-> 0.0052 -loss = 0.003859822168124083
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:02,047 INFO epoch # 6330 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0052-> 0.0052 -loss = 0.0038878888053659466
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:02,047 INFO *** epoch 6330, rolling-avg-loss (window=10)= 0.0038788049374488764
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:02,068 INFO epoch # 6331 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0052-> 0.0052 -loss = 0.004143043582189421
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:02,089 INFO epoch # 6332 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0052-> 0.0052 -loss = 0.004642134488676675
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:02,110 INFO epoch # 6333 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0052-> 0.0052 -loss = 0.003946259084841586
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:02,131 INFO epoch # 6334 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0052-> 0.0052 -loss = 0.00384809710431
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:02,153 INFO epoch # 6335 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0052-> 0.0052 -loss = 0.003937612987101602
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:02,175 INFO epoch # 6336 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0052-> 0.0052 -loss = 0.0038674486513627926
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:02,197 INFO epoch # 6337 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0052-> 0.0052 -loss = 0.003890079655320733
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:02,218 INFO epoch # 6338 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0052-> 0.0052 -loss = 0.0039641729126742575
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:02,241 INFO epoch # 6339 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0052-> 0.0052 -loss = 0.0038795835243945476
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:02,262 INFO epoch # 6340 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0052-> 0.0052 -loss = 0.00385195664694038
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:02,262 INFO *** epoch 6340, rolling-avg-loss (window=10)= 0.003997038863781199
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:02,286 INFO epoch # 6341 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0052-> 0.0052 -loss = 0.0038673736726195784
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:02,307 INFO epoch # 6342 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0052-> 0.0052 -loss = 0.003852658677715226
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:02,328 INFO epoch # 6343 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0052-> 0.0052 -loss = 0.003869626463711029
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:02,350 INFO epoch # 6344 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0052-> 0.0052 -loss = 0.003894956900694524
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:02,372 INFO epoch # 6345 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0052-> 0.0052 -loss = 0.0045956887624925
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:02,394 INFO epoch # 6346 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0052-> 0.0052 -loss = 0.0038850409709993983
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:02,416 INFO epoch # 6347 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0052-> 0.0052 -loss = 0.0038597994243900757
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:02,438 INFO epoch # 6348 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0052-> 0.0052 -loss = 0.0038581203789362917
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:02,460 INFO epoch # 6349 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0052-> 0.0052 -loss = 0.003929891763618798
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:02,481 INFO epoch # 6350 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0052-> 0.0052 -loss = 0.0038735927118977997
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:02,481 INFO *** epoch 6350, rolling-avg-loss (window=10)= 0.003948674972707522
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:02,503 INFO epoch # 6351 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0052-> 0.0052 -loss = 0.003853506275845575
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:02,524 INFO epoch # 6352 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0052-> 0.0052 -loss = 0.0038524758510902757
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:02,545 INFO epoch # 6353 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0052-> 0.0052 -loss = 0.0038545906381841633
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:02,567 INFO epoch # 6354 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0052-> 0.0052 -loss = 0.00384962662064936
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:02,589 INFO epoch # 6355 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0052-> 0.0052 -loss = 0.0038670385292789433
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:02,611 INFO epoch # 6356 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0052-> 0.0051 -loss = 0.0038600487578150933
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:02,632 INFO epoch # 6357 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0051-> 0.0051 -loss = 0.003873014349665027
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:02,654 INFO epoch # 6358 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0051-> 0.0051 -loss = 0.0038438222154582036
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:02,676 INFO epoch # 6359 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0051-> 0.0051 -loss = 0.0038586277391914336
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:02,698 INFO epoch # 6360 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0051-> 0.0051 -loss = 0.0038444103820438613
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:02,698 INFO *** epoch 6360, rolling-avg-loss (window=10)= 0.0038557161359221936
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:02,719 INFO epoch # 6361 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0051-> 0.0051 -loss = 0.0038912831296329387
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:02,741 INFO epoch # 6362 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0051-> 0.0051 -loss = 0.005273356377983873
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:02,762 INFO epoch # 6363 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0051-> 0.0051 -loss = 0.00386269513546722
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:02,784 INFO epoch # 6364 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0051-> 0.0051 -loss = 0.003879623919601727
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:02,805 INFO epoch # 6365 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0051-> 0.0051 -loss = 0.0038403946955440915
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:02,827 INFO epoch # 6366 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0051-> 0.0051 -loss = 0.003847250594844809
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:02,849 INFO epoch # 6367 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0051-> 0.0051 -loss = 0.003846476358376094
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:02,871 INFO epoch # 6368 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0051-> 0.0051 -loss = 0.003836714505268901
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:02,892 INFO epoch # 6369 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0051-> 0.0051 -loss = 0.0038654028867313173
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:02,913 INFO epoch # 6370 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0051-> 0.0051 -loss = 0.003944438658436411
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:02,914 INFO *** epoch 6370, rolling-avg-loss (window=10)= 0.004008763626188738
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:02,935 INFO epoch # 6371 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0051-> 0.0051 -loss = 0.00384298130938987
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:02,956 INFO epoch # 6372 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0051-> 0.0051 -loss = 0.00384839778598689
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:02,977 INFO epoch # 6373 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0051-> 0.0051 -loss = 0.0038453605520771816
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:02,998 INFO epoch # 6374 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0051-> 0.0051 -loss = 0.003844017963274382
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:03,020 INFO epoch # 6375 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0051-> 0.0051 -loss = 0.003861604956910014
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:03,042 INFO epoch # 6376 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0051-> 0.0051 -loss = 0.0038575449862037203
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:03,064 INFO epoch # 6377 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0051-> 0.0051 -loss = 0.003860580303808092
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:03,086 INFO epoch # 6378 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0051-> 0.0051 -loss = 0.0038405706254707184
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:03,107 INFO epoch # 6379 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0051-> 0.005 -loss = 0.0038601457617915003
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:03,129 INFO epoch # 6380 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.005-> 0.005 -loss = 0.0038699837041349383
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:03,129 INFO *** epoch 6380, rolling-avg-loss (window=10)= 0.0038531187949047306
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:03,150 INFO epoch # 6381 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.005-> 0.005 -loss = 0.004576215500492253
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:03,171 INFO epoch # 6382 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.005-> 0.005 -loss = 0.0038567436531593557
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:03,192 INFO epoch # 6383 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.005-> 0.005 -loss = 0.003889114955200057
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:03,213 INFO epoch # 6384 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.005-> 0.005 -loss = 0.0038426300925493706
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:03,236 INFO epoch # 6385 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.005-> 0.005 -loss = 0.003854431546642445
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:03,258 INFO epoch # 6386 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.005-> 0.005 -loss = 0.0038773911091993796
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:03,280 INFO epoch # 6387 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.005-> 0.005 -loss = 0.003866326907882467
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:03,301 INFO epoch # 6388 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.005-> 0.005 -loss = 0.003852908839689917
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:03,323 INFO epoch # 6389 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.005-> 0.005 -loss = 0.0038270449117590033
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:03,344 INFO epoch # 6390 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.005-> 0.005 -loss = 0.0038682910380885005
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:03,344 INFO *** epoch 6390, rolling-avg-loss (window=10)= 0.0039311098554662745
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:03,365 INFO epoch # 6391 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.005-> 0.005 -loss = 0.003886841403073049
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:03,387 INFO epoch # 6392 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.005-> 0.005 -loss = 0.0038443800258392002
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:03,408 INFO epoch # 6393 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.005-> 0.005 -loss = 0.003928567882212519
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:03,429 INFO epoch # 6394 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.005-> 0.005 -loss = 0.0038517842112923972
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:03,451 INFO epoch # 6395 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.005-> 0.005 -loss = 0.0038242912232817616
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:03,472 INFO epoch # 6396 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.005-> 0.005 -loss = 0.003978032485974836
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:03,494 INFO epoch # 6397 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.005-> 0.005 -loss = 0.0038880352421983844
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:03,516 INFO epoch # 6398 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.005-> 0.005 -loss = 0.003877898344399
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:03,538 INFO epoch # 6399 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.005-> 0.005 -loss = 0.003931122228095774
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:03,559 INFO epoch # 6400 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.005-> 0.005 -loss = 0.00385870945865463
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:03,559 INFO *** epoch 6400, rolling-avg-loss (window=10)= 0.003886966250502155
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:03,580 INFO epoch # 6401 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.005-> 0.005 -loss = 0.00384723653223773
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:03,602 INFO epoch # 6402 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.005-> 0.005 -loss = 0.0038356849890988087
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:03,623 INFO epoch # 6403 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.005-> 0.005 -loss = 0.003827325371275947
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:03,644 INFO epoch # 6404 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.005-> 0.005 -loss = 0.0038397204261855222
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:03,665 INFO epoch # 6405 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.005-> 0.005 -loss = 0.0038419492775574327
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:03,687 INFO epoch # 6406 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.005-> 0.005 -loss = 0.003825152919489483
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:03,709 INFO epoch # 6407 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.005-> 0.005 -loss = 0.0038767484043091827
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:03,731 INFO epoch # 6408 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.005-> 0.005 -loss = 0.0038809261450296617
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:03,753 INFO epoch # 6409 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.005-> 0.005 -loss = 0.0038706285968146403
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:03,774 INFO epoch # 6410 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.005-> 0.005 -loss = 0.004003349428785441
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:03,774 INFO *** epoch 6410, rolling-avg-loss (window=10)= 0.003864872209078385
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:03,796 INFO epoch # 6411 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.005-> 0.005 -loss = 0.003852405985526275
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:03,817 INFO epoch # 6412 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.005-> 0.005 -loss = 0.0044141150028735865
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:03,838 INFO epoch # 6413 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.005-> 0.005 -loss = 0.003819996003585402
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:03,859 INFO epoch # 6414 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.005-> 0.005 -loss = 0.0039086545884856605
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:03,881 INFO epoch # 6415 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.005-> 0.005 -loss = 0.003858199071146373
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:03,903 INFO epoch # 6416 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.005-> 0.005 -loss = 0.0038259258935795515
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:03,925 INFO epoch # 6417 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.005-> 0.005 -loss = 0.003927006962840096
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:03,946 INFO epoch # 6418 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.005-> 0.005 -loss = 0.0038218541212700075
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:03,968 INFO epoch # 6419 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.005-> 0.005 -loss = 0.0038307893119053915
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:03,990 INFO epoch # 6420 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.005-> 0.005 -loss = 0.00458948359664646
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:03,990 INFO *** epoch 6420, rolling-avg-loss (window=10)= 0.00398484305378588
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:04,011 INFO epoch # 6421 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.005-> 0.005 -loss = 0.0038678113769492484
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:04,032 INFO epoch # 6422 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.005-> 0.005 -loss = 0.003867342045850819
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:04,053 INFO epoch # 6423 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.005-> 0.005 -loss = 0.003982185443419439
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:04,075 INFO epoch # 6424 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.005-> 0.0049 -loss = 0.0038436189188360004
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:04,096 INFO epoch # 6425 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0049-> 0.0049 -loss = 0.0038173590946826153
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:04,118 INFO epoch # 6426 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0049-> 0.0049 -loss = 0.0038224634645303013
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:04,139 INFO epoch # 6427 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0049-> 0.0049 -loss = 0.003872729050272028
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:04,160 INFO epoch # 6428 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0049-> 0.0049 -loss = 0.003910279510819237
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:04,182 INFO epoch # 6429 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0049-> 0.0049 -loss = 0.0038468983839266002
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:04,204 INFO epoch # 6430 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0049-> 0.0049 -loss = 0.0038275140923360595
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:04,204 INFO *** epoch 6430, rolling-avg-loss (window=10)= 0.003865820138162235
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:04,225 INFO epoch # 6431 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0049-> 0.0049 -loss = 0.004559806986435433
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:04,247 INFO epoch # 6432 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0049-> 0.0049 -loss = 0.003871336606607656
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:04,268 INFO epoch # 6433 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0049-> 0.0049 -loss = 0.003816095327238145
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:04,290 INFO epoch # 6434 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0049-> 0.0049 -loss = 0.003816869778347609
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:04,312 INFO epoch # 6435 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0049-> 0.0049 -loss = 0.004387203075566504
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:04,334 INFO epoch # 6436 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0049-> 0.0049 -loss = 0.0038150110776768997
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:04,355 INFO epoch # 6437 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0049-> 0.0049 -loss = 0.0038671496067763655
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:04,377 INFO epoch # 6438 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0049-> 0.0049 -loss = 0.003814146519289352
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:04,399 INFO epoch # 6439 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0049-> 0.0049 -loss = 0.003804026907801017
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:04,420 INFO epoch # 6440 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0049-> 0.0049 -loss = 0.0038212957133509917
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:04,420 INFO *** epoch 6440, rolling-avg-loss (window=10)= 0.003957294159908998
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:04,441 INFO epoch # 6441 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0049-> 0.0049 -loss = 0.003807744538789848
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:04,463 INFO epoch # 6442 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0049-> 0.0049 -loss = 0.003815654078607622
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:04,484 INFO epoch # 6443 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0049-> 0.0049 -loss = 0.0038329978560796008
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:04,505 INFO epoch # 6444 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0049-> 0.0049 -loss = 0.0038454073492175667
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:04,527 INFO epoch # 6445 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0049-> 0.0049 -loss = 0.003866429568915919
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:04,549 INFO epoch # 6446 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0049-> 0.0049 -loss = 0.0038073376581451157
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:04,571 INFO epoch # 6447 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0049-> 0.0049 -loss = 0.003814480562141398
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:04,593 INFO epoch # 6448 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0049-> 0.0049 -loss = 0.0038943074841881753
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:04,615 INFO epoch # 6449 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0049-> 0.0049 -loss = 0.003806486040048185
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:04,637 INFO epoch # 6450 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0049-> 0.0049 -loss = 0.003866329402626434
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:04,637 INFO *** epoch 6450, rolling-avg-loss (window=10)= 0.0038357174538759865
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:04,658 INFO epoch # 6451 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0049-> 0.0049 -loss = 0.003822606744506629
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:04,679 INFO epoch # 6452 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0049-> 0.0049 -loss = 0.003805614799603063
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:04,700 INFO epoch # 6453 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0049-> 0.0049 -loss = 0.0038059736489231
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:04,722 INFO epoch # 6454 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0049-> 0.0049 -loss = 0.0038200754152057925
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:04,744 INFO epoch # 6455 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0049-> 0.0049 -loss = 0.0038105203666418674
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:04,766 INFO epoch # 6456 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0049-> 0.0049 -loss = 0.003806511540460633
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:04,788 INFO epoch # 6457 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0049-> 0.0049 -loss = 0.003809562786045717
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:04,809 INFO epoch # 6458 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0049-> 0.0049 -loss = 0.0038189839015103644
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:04,831 INFO epoch # 6459 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0049-> 0.0049 -loss = 0.0038009227328075212
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:04,852 INFO epoch # 6460 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0049-> 0.0049 -loss = 0.003833620849036379
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:04,852 INFO *** epoch 6460, rolling-avg-loss (window=10)= 0.0038134392784741067
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:04,874 INFO epoch # 6461 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0049-> 0.0049 -loss = 0.0038322708051055088
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:04,895 INFO epoch # 6462 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0049-> 0.0049 -loss = 0.003830561219729134
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:04,916 INFO epoch # 6463 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0049-> 0.0049 -loss = 0.0038879453677509446
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:04,937 INFO epoch # 6464 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0049-> 0.0049 -loss = 0.0038609227167398785
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:04,959 INFO epoch # 6465 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0049-> 0.0049 -loss = 0.0038353122254193295
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:04,981 INFO epoch # 6466 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0049-> 0.0049 -loss = 0.0038143165002111346
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:05,002 INFO epoch # 6467 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0049-> 0.0049 -loss = 0.003813736642769072
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:05,024 INFO epoch # 6468 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0049-> 0.0049 -loss = 0.0038011700698916684
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:05,046 INFO epoch # 6469 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0049-> 0.0049 -loss = 0.0038255547333392315
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:05,068 INFO epoch # 6470 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0049-> 0.0049 -loss = 0.00379731081193313
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:05,068 INFO *** epoch 6470, rolling-avg-loss (window=10)= 0.003829910109288903
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:05,089 INFO epoch # 6471 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0049-> 0.0049 -loss = 0.0037993809946783585
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:05,110 INFO epoch # 6472 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0049-> 0.0049 -loss = 0.0038172176009538816
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:05,131 INFO epoch # 6473 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0049-> 0.0049 -loss = 0.004795839483449527
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:05,152 INFO epoch # 6474 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0049-> 0.0049 -loss = 0.0038989765398582676
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:05,174 INFO epoch # 6475 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0049-> 0.0049 -loss = 0.0038215382155613042
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:05,196 INFO epoch # 6476 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0049-> 0.0049 -loss = 0.003965667308875709
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:05,218 INFO epoch # 6477 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0049-> 0.0049 -loss = 0.003819067045697011
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:05,240 INFO epoch # 6478 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0049-> 0.0049 -loss = 0.0038050827679398935
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:05,262 INFO epoch # 6479 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0049-> 0.0049 -loss = 0.0038032641732570482
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:05,284 INFO epoch # 6480 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0049-> 0.0049 -loss = 0.003926964009224321
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:05,284 INFO *** epoch 6480, rolling-avg-loss (window=10)= 0.003945299813949532
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:05,305 INFO epoch # 6481 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0049-> 0.0049 -loss = 0.0037925100441498216
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:05,326 INFO epoch # 6482 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0049-> 0.0049 -loss = 0.0038006895993021317
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:05,347 INFO epoch # 6483 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0049-> 0.0049 -loss = 0.004305637036850385
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:05,369 INFO epoch # 6484 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0049-> 0.0049 -loss = 0.004892052947070624
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:05,391 INFO epoch # 6485 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0049-> 0.0049 -loss = 0.0038169023109730915
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:05,412 INFO epoch # 6486 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0049-> 0.0049 -loss = 0.003813926665316103
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:05,434 INFO epoch # 6487 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0049-> 0.0049 -loss = 0.003818883784333593
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:05,456 INFO epoch # 6488 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0049-> 0.0049 -loss = 0.003847186450911977
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:05,478 INFO epoch # 6489 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0049-> 0.0049 -loss = 0.003827332501714409
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:05,499 INFO epoch # 6490 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0049-> 0.0049 -loss = 0.003805003151683195
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:05,499 INFO *** epoch 6490, rolling-avg-loss (window=10)= 0.0039720124492305334
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:05,520 INFO epoch # 6491 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0049-> 0.0049 -loss = 0.003837542077235412
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:05,541 INFO epoch # 6492 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0049-> 0.0048 -loss = 0.0038808686404081527
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:05,563 INFO epoch # 6493 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0048-> 0.0048 -loss = 0.0038033973523852183
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:05,584 INFO epoch # 6494 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0048-> 0.0048 -loss = 0.003928468458070711
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:05,606 INFO epoch # 6495 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0048-> 0.0048 -loss = 0.0038669207197017386
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:05,628 INFO epoch # 6496 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0048-> 0.0048 -loss = 0.0037934948531983537
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:05,650 INFO epoch # 6497 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0048-> 0.0048 -loss = 0.0037970795474393526
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:05,671 INFO epoch # 6498 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0048-> 0.0048 -loss = 0.0037981619771016994
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:05,693 INFO epoch # 6499 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0048-> 0.0048 -loss = 0.0038561549881706014
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:05,715 INFO epoch # 6500 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0048-> 0.0048 -loss = 0.0037968331580486847
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:05,715 INFO *** epoch 6500, rolling-avg-loss (window=10)= 0.0038358921771759922
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:05,736 INFO epoch # 6501 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0048-> 0.0048 -loss = 0.0037995690072420985
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:05,757 INFO epoch # 6502 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0048-> 0.0048 -loss = 0.004003603939054301
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:05,779 INFO epoch # 6503 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0048-> 0.0048 -loss = 0.0038177345722942846
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:05,800 INFO epoch # 6504 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0048-> 0.0048 -loss = 0.0038052441104809986
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:05,822 INFO epoch # 6505 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0048-> 0.0048 -loss = 0.0037870064243179513
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:05,844 INFO epoch # 6506 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0048-> 0.0048 -loss = 0.003809090849244967
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:05,866 INFO epoch # 6507 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0048-> 0.0048 -loss = 0.003864460783006507
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:05,888 INFO epoch # 6508 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0048-> 0.0048 -loss = 0.0038026581050871755
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:05,909 INFO epoch # 6509 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0048-> 0.0048 -loss = 0.0037879842002439545
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:05,930 INFO epoch # 6510 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0048-> 0.0048 -loss = 0.00451749112107791
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:05,930 INFO *** epoch 6510, rolling-avg-loss (window=10)= 0.003899484311205015
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:05,952 INFO epoch # 6511 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0048-> 0.0048 -loss = 0.0038073232790338807
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:05,973 INFO epoch # 6512 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0048-> 0.0048 -loss = 0.0038136508428578964
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:05,994 INFO epoch # 6513 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0048-> 0.0048 -loss = 0.003800967410825251
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:06,015 INFO epoch # 6514 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0048-> 0.0048 -loss = 0.0037849988702873816
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:06,037 INFO epoch # 6515 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0048-> 0.0048 -loss = 0.004475265643122839
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:06,059 INFO epoch # 6516 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0048-> 0.0048 -loss = 0.00379073672593222
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:06,081 INFO epoch # 6517 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0048-> 0.0048 -loss = 0.003780901691698091
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:06,102 INFO epoch # 6518 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0048-> 0.0048 -loss = 0.003851793018839089
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:06,124 INFO epoch # 6519 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0048-> 0.0048 -loss = 0.0038107680484245066
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:06,145 INFO epoch # 6520 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0048-> 0.0048 -loss = 0.004180395519142621
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:06,145 INFO *** epoch 6520, rolling-avg-loss (window=10)= 0.003909680105016378
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:06,167 INFO epoch # 6521 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0048-> 0.0048 -loss = 0.0037886399477429222
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:06,188 INFO epoch # 6522 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0048-> 0.0048 -loss = 0.0037805738274983014
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:06,209 INFO epoch # 6523 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0048-> 0.0048 -loss = 0.003793988676989102
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:06,230 INFO epoch # 6524 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0048-> 0.0048 -loss = 0.0038287468305497896
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:06,252 INFO epoch # 6525 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0048-> 0.0048 -loss = 0.0037799950632688706
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:06,274 INFO epoch # 6526 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0048-> 0.0048 -loss = 0.003863501588057261
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:06,296 INFO epoch # 6527 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0048-> 0.0048 -loss = 0.0037731792258455243
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:06,318 INFO epoch # 6528 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0048-> 0.0048 -loss = 0.003793391285398684
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:06,340 INFO epoch # 6529 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0048-> 0.0048 -loss = 0.003822404072707286
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:06,361 INFO epoch # 6530 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0048-> 0.0048 -loss = 0.0037873676428716863
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:06,361 INFO *** epoch 6530, rolling-avg-loss (window=10)= 0.003801178816092943
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:06,382 INFO epoch # 6531 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0048-> 0.0048 -loss = 0.005188995333810453
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:06,403 INFO epoch # 6532 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0048-> 0.0048 -loss = 0.0037787733808727353
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:06,424 INFO epoch # 6533 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0048-> 0.0048 -loss = 0.003785542237892514
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:06,446 INFO epoch # 6534 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0048-> 0.0048 -loss = 0.0037733458939328557
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:06,467 INFO epoch # 6535 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0048-> 0.0048 -loss = 0.00378460203683062
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:06,489 INFO epoch # 6536 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0048-> 0.0048 -loss = 0.0038072325005487073
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:06,510 INFO epoch # 6537 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0048-> 0.0048 -loss = 0.0037906287907389924
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:06,532 INFO epoch # 6538 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0048-> 0.0048 -loss = 0.003853703983622836
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:06,553 INFO epoch # 6539 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0048-> 0.0048 -loss = 0.004217997240630211
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:06,575 INFO epoch # 6540 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0048-> 0.0048 -loss = 0.0037718853400292573
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:06,575 INFO *** epoch 6540, rolling-avg-loss (window=10)= 0.003975270673890918
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:06,597 INFO epoch # 6541 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0048-> 0.0048 -loss = 0.004529130797891412
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:06,618 INFO epoch # 6542 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0048-> 0.0048 -loss = 0.003801501716225175
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:06,639 INFO epoch # 6543 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0048-> 0.0048 -loss = 0.0038527953438460827
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:06,660 INFO epoch # 6544 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0048-> 0.0048 -loss = 0.004489256137276243
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:06,682 INFO epoch # 6545 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0048-> 0.0048 -loss = 0.003789581593082403
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:06,703 INFO epoch # 6546 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0048-> 0.0048 -loss = 0.003848966943223786
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:06,725 INFO epoch # 6547 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0048-> 0.0048 -loss = 0.003981074006333074
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:06,747 INFO epoch # 6548 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0048-> 0.0048 -loss = 0.004525201931755873
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:06,769 INFO epoch # 6549 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0048-> 0.0048 -loss = 0.003795449405515683
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:06,791 INFO epoch # 6550 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0048-> 0.0048 -loss = 0.0037891563933953876
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:06,791 INFO *** epoch 6550, rolling-avg-loss (window=10)= 0.004040211426854512
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:06,812 INFO epoch # 6551 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0048-> 0.0048 -loss = 0.0037671776212846453
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:06,833 INFO epoch # 6552 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0048-> 0.0048 -loss = 0.004572487164296035
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:06,854 INFO epoch # 6553 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0048-> 0.0048 -loss = 0.004194381557681481
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:06,875 INFO epoch # 6554 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0048-> 0.0048 -loss = 0.003795714327679889
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:06,897 INFO epoch # 6555 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0048-> 0.0048 -loss = 0.0038124538768897764
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:06,919 INFO epoch # 6556 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0048-> 0.0048 -loss = 0.0038287186525849393
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:06,941 INFO epoch # 6557 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0048-> 0.0048 -loss = 0.0037634151203747024
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:06,963 INFO epoch # 6558 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0048-> 0.0048 -loss = 0.0038031346994102933
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:06,984 INFO epoch # 6559 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0048-> 0.0048 -loss = 0.0037729211999248946
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:07,006 INFO epoch # 6560 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0048-> 0.0048 -loss = 0.0037589417038361717
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:07,006 INFO *** epoch 6560, rolling-avg-loss (window=10)= 0.003906934592396283
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:07,027 INFO epoch # 6561 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0048-> 0.0048 -loss = 0.0037706900966441026
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:07,049 INFO epoch # 6562 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0048-> 0.0048 -loss = 0.003766150917726918
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:07,070 INFO epoch # 6563 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0048-> 0.0048 -loss = 0.0037748277973150834
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:07,091 INFO epoch # 6564 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0048-> 0.0048 -loss = 0.0037683497812395217
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:07,113 INFO epoch # 6565 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0048-> 0.0048 -loss = 0.003784163769978477
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:07,135 INFO epoch # 6566 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0048-> 0.0048 -loss = 0.004892625056527322
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:07,157 INFO epoch # 6567 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0048-> 0.0048 -loss = 0.003781996472753235
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:07,178 INFO epoch # 6568 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0048-> 0.0048 -loss = 0.0038108972730697133
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:07,200 INFO epoch # 6569 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0048-> 0.0048 -loss = 0.003764831089938525
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:07,221 INFO epoch # 6570 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0048-> 0.0048 -loss = 0.0038039548408050905
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:07,221 INFO *** epoch 6570, rolling-avg-loss (window=10)= 0.003891848709599799
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:07,244 INFO epoch # 6571 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0048-> 0.0047 -loss = 0.00384485544054769
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:07,265 INFO epoch # 6572 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0047-> 0.0047 -loss = 0.003764632413549407
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:07,286 INFO epoch # 6573 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0047-> 0.0047 -loss = 0.003754139291231695
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:07,308 INFO epoch # 6574 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0047-> 0.0047 -loss = 0.0037725458296336
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:07,329 INFO epoch # 6575 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0047-> 0.0047 -loss = 0.004037039894683403
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:07,351 INFO epoch # 6576 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0047-> 0.0047 -loss = 0.0038937836234254064
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:07,373 INFO epoch # 6577 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0047-> 0.0047 -loss = 0.004135036266234238
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:07,395 INFO epoch # 6578 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0047-> 0.0047 -loss = 0.0037835489893041085
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:07,416 INFO epoch # 6579 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0047-> 0.0047 -loss = 0.00380501166000613
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:07,438 INFO epoch # 6580 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0047-> 0.0047 -loss = 0.004422697609697934
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:07,438 INFO *** epoch 6580, rolling-avg-loss (window=10)= 0.003921329101831361
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:07,459 INFO epoch # 6581 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0047-> 0.0047 -loss = 0.00376289279483899
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:07,480 INFO epoch # 6582 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0047-> 0.0047 -loss = 0.00378034066852706
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:07,501 INFO epoch # 6583 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0047-> 0.0047 -loss = 0.003755638766961056
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:07,524 INFO epoch # 6584 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0047-> 0.0047 -loss = 0.003869960106385406
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:07,546 INFO epoch # 6585 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0047-> 0.0047 -loss = 0.0037552377298197825
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:07,568 INFO epoch # 6586 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0047-> 0.0047 -loss = 0.003756980515390751
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:07,590 INFO epoch # 6587 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0047-> 0.0047 -loss = 0.0037496275149351277
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:07,611 INFO epoch # 6588 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0047-> 0.0047 -loss = 0.0037838830839973525
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:07,633 INFO epoch # 6589 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0047-> 0.0047 -loss = 0.0037815370897078537
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:07,655 INFO epoch # 6590 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0047-> 0.0047 -loss = 0.0038107135060272412
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:07,655 INFO *** epoch 6590, rolling-avg-loss (window=10)= 0.003780681177659062
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:07,676 INFO epoch # 6591 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0047-> 0.0047 -loss = 0.0037728538027295144
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:07,697 INFO epoch # 6592 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0047-> 0.0047 -loss = 0.003763434164284263
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:07,718 INFO epoch # 6593 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0047-> 0.0047 -loss = 0.0037544512260865304
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:07,740 INFO epoch # 6594 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0047-> 0.0047 -loss = 0.003823010540145333
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:07,763 INFO epoch # 6595 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0047-> 0.0047 -loss = 0.0038980290191830136
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:07,784 INFO epoch # 6596 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0047-> 0.0047 -loss = 0.0037480515466086217
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:07,806 INFO epoch # 6597 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0047-> 0.0047 -loss = 0.003920277762517799
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:07,828 INFO epoch # 6598 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0047-> 0.0047 -loss = 0.0038194277540242183
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:07,850 INFO epoch # 6599 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0047-> 0.0047 -loss = 0.0037508554096348234
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:07,871 INFO epoch # 6600 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0047-> 0.0047 -loss = 0.0037579810750685283
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:07,871 INFO *** epoch 6600, rolling-avg-loss (window=10)= 0.0038008372300282643
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:07,892 INFO epoch # 6601 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0047-> 0.0047 -loss = 0.003833803328234353
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:07,913 INFO epoch # 6602 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0047-> 0.0047 -loss = 0.0037636659126292216
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:07,934 INFO epoch # 6603 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0047-> 0.0047 -loss = 0.003785853021327057
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:07,955 INFO epoch # 6604 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0047-> 0.0047 -loss = 0.0037726903728980687
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:07,977 INFO epoch # 6605 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0047-> 0.0047 -loss = 0.004017769006168237
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:07,998 INFO epoch # 6606 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0047-> 0.0047 -loss = 0.003759647977858549
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:08,020 INFO epoch # 6607 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0047-> 0.0046 -loss = 0.003751935522814165
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:08,042 INFO epoch # 6608 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0046-> 0.0046 -loss = 0.004750838734253193
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:08,064 INFO epoch # 6609 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0046-> 0.0046 -loss = 0.0037553943402599543
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:08,085 INFO epoch # 6610 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0046-> 0.0046 -loss = 0.0037524878625845304
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:08,085 INFO *** epoch 6610, rolling-avg-loss (window=10)= 0.0038944086079027327
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:08,107 INFO epoch # 6611 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0046-> 0.0046 -loss = 0.00376970719480596
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:08,128 INFO epoch # 6612 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0046-> 0.0046 -loss = 0.0038545771367353154
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:08,149 INFO epoch # 6613 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0046-> 0.0046 -loss = 0.004469553945455118
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:08,170 INFO epoch # 6614 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0046-> 0.0046 -loss = 0.003904677110767807
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:08,192 INFO epoch # 6615 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0046-> 0.0046 -loss = 0.004173251065367367
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:08,213 INFO epoch # 6616 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0046-> 0.0046 -loss = 0.003761627263884293
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:08,236 INFO epoch # 6617 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0046-> 0.0046 -loss = 0.003750887374735612
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:08,258 INFO epoch # 6618 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0046-> 0.0046 -loss = 0.003802939820161555
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:08,279 INFO epoch # 6619 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0046-> 0.0046 -loss = 0.0038120355166029185
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:08,300 INFO epoch # 6620 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0046-> 0.0046 -loss = 0.0037520976593441446
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:08,301 INFO *** epoch 6620, rolling-avg-loss (window=10)= 0.003905135408786009
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:08,322 INFO epoch # 6621 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0046-> 0.0046 -loss = 0.0037574241032416467
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:08,343 INFO epoch # 6622 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0046-> 0.0046 -loss = 0.0037538015503741917
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:08,364 INFO epoch # 6623 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0046-> 0.0046 -loss = 0.003739694883734046
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:08,385 INFO epoch # 6624 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0046-> 0.0046 -loss = 0.0037479637285287026
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:08,407 INFO epoch # 6625 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0046-> 0.0046 -loss = 0.003738380385129858
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:08,429 INFO epoch # 6626 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0046-> 0.0046 -loss = 0.00377322554049897
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:08,451 INFO epoch # 6627 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0046-> 0.0046 -loss = 0.004212503989947436
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:08,473 INFO epoch # 6628 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0046-> 0.0046 -loss = 0.0038041340794734424
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:08,495 INFO epoch # 6629 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0046-> 0.0046 -loss = 0.0038416958832385717
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:08,516 INFO epoch # 6630 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0046-> 0.0046 -loss = 0.0037393492502815207
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:08,516 INFO *** epoch 6630, rolling-avg-loss (window=10)= 0.0038108173394448388
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:08,537 INFO epoch # 6631 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0046-> 0.0046 -loss = 0.0037463729622686515
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:08,558 INFO epoch # 6632 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0046-> 0.0046 -loss = 0.003745510235603433
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:08,579 INFO epoch # 6633 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0046-> 0.0046 -loss = 0.0037466317080543377
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:08,601 INFO epoch # 6634 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0046-> 0.0046 -loss = 0.003734557327334187
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:08,623 INFO epoch # 6635 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0046-> 0.0046 -loss = 0.003755775687750429
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:08,644 INFO epoch # 6636 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0046-> 0.0046 -loss = 0.0037601151852868497
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:08,666 INFO epoch # 6637 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0046-> 0.0046 -loss = 0.003735202095413115
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:08,688 INFO epoch # 6638 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0046-> 0.0046 -loss = 0.0037508268251258414
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:08,709 INFO epoch # 6639 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0046-> 0.0046 -loss = 0.0037576889608317288
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:08,731 INFO epoch # 6640 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0046-> 0.0046 -loss = 0.0038545143015653593
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:08,731 INFO *** epoch 6640, rolling-avg-loss (window=10)= 0.003758719528923393
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:08,753 INFO epoch # 6641 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0046-> 0.0046 -loss = 0.0037339265782065922
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:08,775 INFO epoch # 6642 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0046-> 0.0046 -loss = 0.003735140147000493
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:08,796 INFO epoch # 6643 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0046-> 0.0046 -loss = 0.004034460192997358
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:08,817 INFO epoch # 6644 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0046-> 0.0046 -loss = 0.003811228111771925
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:08,839 INFO epoch # 6645 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0046-> 0.0046 -loss = 0.003922130294085946
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:08,861 INFO epoch # 6646 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0046-> 0.0046 -loss = 0.0037300272952052183
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:08,883 INFO epoch # 6647 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0046-> 0.0046 -loss = 0.003795239612372825
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:08,904 INFO epoch # 6648 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0046-> 0.0046 -loss = 0.0037326642213884043
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:08,926 INFO epoch # 6649 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0046-> 0.0046 -loss = 0.003751244061277248
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:08,947 INFO epoch # 6650 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0046-> 0.0046 -loss = 0.0037666569514840376
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:08,947 INFO *** epoch 6650, rolling-avg-loss (window=10)= 0.0038012717465790045
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:08,968 INFO epoch # 6651 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0046-> 0.0046 -loss = 0.0037324178410926834
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:08,989 INFO epoch # 6652 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0046-> 0.0046 -loss = 0.0038686134948875406
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:09,010 INFO epoch # 6653 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0046-> 0.0046 -loss = 0.0037464440374606056
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:09,032 INFO epoch # 6654 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0046-> 0.0046 -loss = 0.003784903941777884
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:09,054 INFO epoch # 6655 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0046-> 0.0046 -loss = 0.0050915081446873955
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:09,076 INFO epoch # 6656 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0046-> 0.0046 -loss = 0.0037445394300448243
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:09,097 INFO epoch # 6657 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0046-> 0.0045 -loss = 0.004486316775000887
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:09,119 INFO epoch # 6658 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0045-> 0.0045 -loss = 0.0037255995330269798
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:09,141 INFO epoch # 6659 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0045-> 0.0045 -loss = 0.00372640412660985
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:09,162 INFO epoch # 6660 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0045-> 0.0045 -loss = 0.003726747141627129
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:09,162 INFO *** epoch 6660, rolling-avg-loss (window=10)= 0.003963349446621578
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:09,184 INFO epoch # 6661 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0045-> 0.0045 -loss = 0.003808188124821754
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:09,205 INFO epoch # 6662 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0045-> 0.0045 -loss = 0.0037370630125224125
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:09,226 INFO epoch # 6663 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0045-> 0.0045 -loss = 0.003774961905037344
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:09,248 INFO epoch # 6664 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0045-> 0.0045 -loss = 0.0037524735871556913
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:09,269 INFO epoch # 6665 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0045-> 0.0045 -loss = 0.003737747629202204
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:09,291 INFO epoch # 6666 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0045-> 0.0045 -loss = 0.003741515309229726
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:09,313 INFO epoch # 6667 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0045-> 0.0045 -loss = 0.003733021826519689
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:09,335 INFO epoch # 6668 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0045-> 0.0045 -loss = 0.003853838421491673
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:09,357 INFO epoch # 6669 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0045-> 0.0045 -loss = 0.0037486070759769063
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:09,378 INFO epoch # 6670 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0045-> 0.0045 -loss = 0.003728332821992808
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:09,379 INFO *** epoch 6670, rolling-avg-loss (window=10)= 0.003761574971395021
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:09,400 INFO epoch # 6671 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0045-> 0.0045 -loss = 0.0037291747803465114
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:09,421 INFO epoch # 6672 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0045-> 0.0045 -loss = 0.0037501383440030622
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:09,442 INFO epoch # 6673 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0045-> 0.0045 -loss = 0.004412748320646642
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:09,464 INFO epoch # 6674 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0045-> 0.0045 -loss = 0.0037343298663472524
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:09,485 INFO epoch # 6675 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0045-> 0.0045 -loss = 0.003740695569831587
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:09,507 INFO epoch # 6676 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0045-> 0.0045 -loss = 0.00375107473701064
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:09,529 INFO epoch # 6677 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0045-> 0.0045 -loss = 0.0037846561699552694
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:09,551 INFO epoch # 6678 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0045-> 0.0045 -loss = 0.0037238315690046875
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:09,573 INFO epoch # 6679 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0045-> 0.0045 -loss = 0.004386193895697943
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:09,595 INFO epoch # 6680 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0045-> 0.0045 -loss = 0.003842573840302066
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:09,595 INFO *** epoch 6680, rolling-avg-loss (window=10)= 0.003885541709314566
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:09,617 INFO epoch # 6681 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0045-> 0.0045 -loss = 0.003724741196492687
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:09,639 INFO epoch # 6682 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0045-> 0.0045 -loss = 0.0037563494151982013
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:09,660 INFO epoch # 6683 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0045-> 0.0045 -loss = 0.0037325303819670808
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:09,681 INFO epoch # 6684 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0045-> 0.0045 -loss = 0.0037231864025670802
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:09,703 INFO epoch # 6685 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0045-> 0.0045 -loss = 0.003719361175171798
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:09,725 INFO epoch # 6686 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0045-> 0.0045 -loss = 0.0037204074551482336
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:09,748 INFO epoch # 6687 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0045-> 0.0045 -loss = 0.003746254084035172
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:09,770 INFO epoch # 6688 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0045-> 0.0045 -loss = 0.003725307169588632
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:09,792 INFO epoch # 6689 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0045-> 0.0045 -loss = 0.0037216694063317846
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:09,813 INFO epoch # 6690 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0045-> 0.0045 -loss = 0.0038264361364781507
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:09,813 INFO *** epoch 6690, rolling-avg-loss (window=10)= 0.003739624282297882
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:09,834 INFO epoch # 6691 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0045-> 0.0045 -loss = 0.0037425175523821963
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:09,856 INFO epoch # 6692 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0045-> 0.0045 -loss = 0.003722996058058925
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:09,877 INFO epoch # 6693 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0045-> 0.0045 -loss = 0.004528036468400387
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:09,898 INFO epoch # 6694 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0045-> 0.0045 -loss = 0.0037621829451381927
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:09,920 INFO epoch # 6695 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0045-> 0.0045 -loss = 0.003748982333490858
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:09,942 INFO epoch # 6696 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0045-> 0.0044 -loss = 0.003733632611329085
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:09,964 INFO epoch # 6697 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0044-> 0.0044 -loss = 0.0037294180001481436
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:09,985 INFO epoch # 6698 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0044-> 0.0044 -loss = 0.003789065063756425
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:10,007 INFO epoch # 6699 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0044-> 0.0044 -loss = 0.0037476115403478616
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:10,029 INFO epoch # 6700 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0044-> 0.0044 -loss = 0.003804360048889066
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:10,029 INFO *** epoch 6700, rolling-avg-loss (window=10)= 0.003830880262194114
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:10,050 INFO epoch # 6701 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0044-> 0.0044 -loss = 0.003708003282554273
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:10,071 INFO epoch # 6702 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0044-> 0.0044 -loss = 0.003712583817105042
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:10,092 INFO epoch # 6703 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0044-> 0.0044 -loss = 0.004133710695896298
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:10,114 INFO epoch # 6704 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0044-> 0.0044 -loss = 0.0037245864605210954
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:10,136 INFO epoch # 6705 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0044-> 0.0044 -loss = 0.003746084186786902
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:10,158 INFO epoch # 6706 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0044-> 0.0044 -loss = 0.0037354085479819332
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:10,179 INFO epoch # 6707 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0044-> 0.0044 -loss = 0.0037329683955249493
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:10,201 INFO epoch # 6708 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0044-> 0.0044 -loss = 0.004218520838549011
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:10,223 INFO epoch # 6709 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0044-> 0.0044 -loss = 0.0037741591841040645
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:10,245 INFO epoch # 6710 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0044-> 0.0044 -loss = 0.0037450865311257076
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:10,245 INFO *** epoch 6710, rolling-avg-loss (window=10)= 0.0038231111940149275
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:10,266 INFO epoch # 6711 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0044-> 0.0044 -loss = 0.00374667413689167
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:10,287 INFO epoch # 6712 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0044-> 0.0044 -loss = 0.003744110656043631
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:10,308 INFO epoch # 6713 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0044-> 0.0044 -loss = 0.004096538366866298
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:10,330 INFO epoch # 6714 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0044-> 0.0044 -loss = 0.003865775582198694
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:10,352 INFO epoch # 6715 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0044-> 0.0044 -loss = 0.0037528089069382986
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:10,374 INFO epoch # 6716 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0044-> 0.0044 -loss = 0.0037286207098077284
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:10,396 INFO epoch # 6717 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0044-> 0.0044 -loss = 0.0037367824397733784
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:10,418 INFO epoch # 6718 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0044-> 0.0044 -loss = 0.003706879323999601
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:10,439 INFO epoch # 6719 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0044-> 0.0044 -loss = 0.003736468913302815
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:10,461 INFO epoch # 6720 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0044-> 0.0044 -loss = 0.0037351444461819483
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:10,461 INFO *** epoch 6720, rolling-avg-loss (window=10)= 0.0037849803482004063
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:10,482 INFO epoch # 6721 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0044-> 0.0044 -loss = 0.00372382588830078
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:10,503 INFO epoch # 6722 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0044-> 0.0044 -loss = 0.003710256789418054
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:10,524 INFO epoch # 6723 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0044-> 0.0044 -loss = 0.0041981564745583455
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:10,546 INFO epoch # 6724 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0044-> 0.0044 -loss = 0.0037163355846132617
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:10,567 INFO epoch # 6725 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0044-> 0.0044 -loss = 0.003707544838107424
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:10,590 INFO epoch # 6726 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0044-> 0.0044 -loss = 0.0037037028546365036
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:10,612 INFO epoch # 6727 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0044-> 0.0044 -loss = 0.0037151678106965846
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:10,634 INFO epoch # 6728 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0044-> 0.0044 -loss = 0.0037036384101156727
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:10,656 INFO epoch # 6729 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0044-> 0.0044 -loss = 0.0037151465730858035
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:10,677 INFO epoch # 6730 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0044-> 0.0044 -loss = 0.003719202108186437
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:10,677 INFO *** epoch 6730, rolling-avg-loss (window=10)= 0.0037612977331718867
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:10,698 INFO epoch # 6731 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0044-> 0.0044 -loss = 0.003723210962562007
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:10,719 INFO epoch # 6732 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0044-> 0.0044 -loss = 0.003741347753930313
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:10,741 INFO epoch # 6733 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0044-> 0.0044 -loss = 0.0044385028841134044
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:10,762 INFO epoch # 6734 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0044-> 0.0044 -loss = 0.0038465969664684962
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:10,784 INFO epoch # 6735 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0044-> 0.0044 -loss = 0.0044135862262919545
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:10,806 INFO epoch # 6736 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0044-> 0.0044 -loss = 0.0037024837474746164
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:10,828 INFO epoch # 6737 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0044-> 0.0044 -loss = 0.003714008977112826
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:10,850 INFO epoch # 6738 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0044-> 0.0044 -loss = 0.0037075010368425865
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:10,871 INFO epoch # 6739 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0044-> 0.0044 -loss = 0.003706791166223411
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:10,892 INFO epoch # 6740 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0044-> 0.0044 -loss = 0.003704331994867971
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:10,892 INFO *** epoch 6740, rolling-avg-loss (window=10)= 0.0038698361715887586
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:10,914 INFO epoch # 6741 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0044-> 0.0044 -loss = 0.0037188463156780927
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:10,935 INFO epoch # 6742 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0044-> 0.0044 -loss = 0.003750867899725563
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:10,956 INFO epoch # 6743 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0044-> 0.0044 -loss = 0.0037559735674221884
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:10,977 INFO epoch # 6744 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0044-> 0.0044 -loss = 0.0037697355037380476
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:10,999 INFO epoch # 6745 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0044-> 0.0044 -loss = 0.003695964694088616
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:11,021 INFO epoch # 6746 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0044-> 0.0044 -loss = 0.003743901850612019
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:11,043 INFO epoch # 6747 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0044-> 0.0044 -loss = 0.0036939207893738057
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:11,065 INFO epoch # 6748 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0044-> 0.0044 -loss = 0.0037160761157792876
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:11,087 INFO epoch # 6749 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0044-> 0.0044 -loss = 0.003726640724380559
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:11,108 INFO epoch # 6750 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0044-> 0.0044 -loss = 0.004096647251571994
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:11,108 INFO *** epoch 6750, rolling-avg-loss (window=10)= 0.0037668574712370175
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:11,129 INFO epoch # 6751 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0044-> 0.0044 -loss = 0.003694777933333171
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:11,150 INFO epoch # 6752 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0044-> 0.0044 -loss = 0.0037087683158461004
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:11,172 INFO epoch # 6753 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0044-> 0.0044 -loss = 0.003705260429342161
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:11,193 INFO epoch # 6754 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0044-> 0.0044 -loss = 0.0037054854810776305
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:11,215 INFO epoch # 6755 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0044-> 0.0044 -loss = 0.004101248062397644
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:11,237 INFO epoch # 6756 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0044-> 0.0044 -loss = 0.004400408903165953
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:11,259 INFO epoch # 6757 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0044-> 0.0044 -loss = 0.0037182912819844205
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:11,281 INFO epoch # 6758 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0044-> 0.0043 -loss = 0.0036952254613424884
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:11,303 INFO epoch # 6759 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.0037287650848156773
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:11,325 INFO epoch # 6760 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.003754190867766738
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:11,325 INFO *** epoch 6760, rolling-avg-loss (window=10)= 0.0038212421821071985
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:11,346 INFO epoch # 6761 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.003715808883498539
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:11,367 INFO epoch # 6762 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.0036918000550940633
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:11,388 INFO epoch # 6763 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.003716802764301974
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:11,409 INFO epoch # 6764 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.0036920450402249116
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:11,431 INFO epoch # 6765 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.003722600451510516
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:11,453 INFO epoch # 6766 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.0037289870724634966
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:11,475 INFO epoch # 6767 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.0036912462637701537
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:11,497 INFO epoch # 6768 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.0036877017087135755
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:11,519 INFO epoch # 6769 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.00376421508644853
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:11,540 INFO epoch # 6770 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.003704969320097007
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:11,540 INFO *** epoch 6770, rolling-avg-loss (window=10)= 0.0037116176646122766
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:11,561 INFO epoch # 6771 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.00369891501031816
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:11,582 INFO epoch # 6772 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.003785391065321164
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:11,603 INFO epoch # 6773 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.0038599106128458516
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:11,625 INFO epoch # 6774 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.003721393662999617
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:11,647 INFO epoch # 6775 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.0036881481182717835
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:11,669 INFO epoch # 6776 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.003701062618802098
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:11,691 INFO epoch # 6777 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.003711016775923781
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:11,713 INFO epoch # 6778 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.0036994856664023246
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:11,734 INFO epoch # 6779 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.003698865185469913
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:11,757 INFO epoch # 6780 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.0037122195044503314
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:11,757 INFO *** epoch 6780, rolling-avg-loss (window=10)= 0.0037276408220805026
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:11,778 INFO epoch # 6781 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.0037305524365365272
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:11,799 INFO epoch # 6782 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.0037748060385638382
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:11,820 INFO epoch # 6783 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.003681608672650327
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:11,841 INFO epoch # 6784 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.0037087306427565636
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:11,863 INFO epoch # 6785 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.003686075132463884
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:11,885 INFO epoch # 6786 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.00382382307361695
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:11,907 INFO epoch # 6787 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.0037183289750828408
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:11,929 INFO epoch # 6788 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.0036848245154033066
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:11,951 INFO epoch # 6789 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.003690542002004804
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:11,972 INFO epoch # 6790 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.0037024053835921222
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:11,972 INFO *** epoch 6790, rolling-avg-loss (window=10)= 0.003720169687267116
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:11,994 INFO epoch # 6791 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.0037055989450891502
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:12,015 INFO epoch # 6792 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.003703247685734823
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:12,036 INFO epoch # 6793 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.003691649664688157
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:12,058 INFO epoch # 6794 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.0037235987656458747
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:12,080 INFO epoch # 6795 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.0041650490329629974
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:12,101 INFO epoch # 6796 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.003683469993120525
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:12,123 INFO epoch # 6797 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.003688115893965005
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:12,145 INFO epoch # 6798 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.0036782695697183954
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:12,167 INFO epoch # 6799 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.004400696851007524
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:12,189 INFO epoch # 6800 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.003705506431288086
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:12,189 INFO *** epoch 6800, rolling-avg-loss (window=10)= 0.003814520283322054
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:12,210 INFO epoch # 6801 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.0036783637306143646
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:12,231 INFO epoch # 6802 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.0037936760254524415
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:12,252 INFO epoch # 6803 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.0043867049516848056
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:12,274 INFO epoch # 6804 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.003682973162540293
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:12,296 INFO epoch # 6805 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.0036871943339065183
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:12,317 INFO epoch # 6806 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.004339833511039615
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:12,339 INFO epoch # 6807 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.0037090788737259572
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:12,361 INFO epoch # 6808 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.003677571883144992
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:12,382 INFO epoch # 6809 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.00372872475963959
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:12,404 INFO epoch # 6810 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.0037632715620929957
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:12,404 INFO *** epoch 6810, rolling-avg-loss (window=10)= 0.003844739279384157
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:12,425 INFO epoch # 6811 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.003697562862726045
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:12,446 INFO epoch # 6812 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.0036725706954712223
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:12,467 INFO epoch # 6813 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.0036716646454806323
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:12,488 INFO epoch # 6814 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.004434551568920142
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:12,510 INFO epoch # 6815 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.003683076067318325
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:12,531 INFO epoch # 6816 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.003672144107213171
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:12,553 INFO epoch # 6817 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.0037027346734248567
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:12,575 INFO epoch # 6818 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.00469457313647581
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:12,597 INFO epoch # 6819 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.003674909381516045
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:12,618 INFO epoch # 6820 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.00449508856763714
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:12,618 INFO *** epoch 6820, rolling-avg-loss (window=10)= 0.003939887570618339
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:12,640 INFO epoch # 6821 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.0037645477677870076
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:12,661 INFO epoch # 6822 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.003671319188470079
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:12,682 INFO epoch # 6823 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.0036694997029371734
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:12,703 INFO epoch # 6824 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.004404855129905627
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:12,725 INFO epoch # 6825 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.0037652608552889433
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:12,747 INFO epoch # 6826 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.003674119595416414
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:12,769 INFO epoch # 6827 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.0037157672995817848
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:12,791 INFO epoch # 6828 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.0037167579894230585
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:12,813 INFO epoch # 6829 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.0036733526203533984
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:12,835 INFO epoch # 6830 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.0036913415460730903
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:12,835 INFO *** epoch 6830, rolling-avg-loss (window=10)= 0.003774682169523658
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:12,856 INFO epoch # 6831 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.0036709128762595356
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:12,877 INFO epoch # 6832 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.0037473928477993468
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:12,898 INFO epoch # 6833 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.003702531375893159
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:12,919 INFO epoch # 6834 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0042 -loss = 0.0037169412134971935
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:12,941 INFO epoch # 6835 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0042-> 0.0042 -loss = 0.0037223630506559857
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:12,963 INFO epoch # 6836 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0042-> 0.0042 -loss = 0.0036664642479991016
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:12,985 INFO epoch # 6837 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0042-> 0.0042 -loss = 0.0036962444664823124
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:13,007 INFO epoch # 6838 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0042-> 0.0042 -loss = 0.003665220704533567
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:13,029 INFO epoch # 6839 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0042-> 0.0042 -loss = 0.003688846161821857
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:13,050 INFO epoch # 6840 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0042-> 0.0042 -loss = 0.003700221504914225
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:13,050 INFO *** epoch 6840, rolling-avg-loss (window=10)= 0.0036977138449856284
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:13,071 INFO epoch # 6841 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0042-> 0.0042 -loss = 0.0036922288172718254
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:13,093 INFO epoch # 6842 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0042-> 0.0042 -loss = 0.0036856182441624696
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:13,114 INFO epoch # 6843 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0042-> 0.0042 -loss = 0.004043343756165996
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:13,135 INFO epoch # 6844 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0042-> 0.0042 -loss = 0.003755997142434353
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:13,157 INFO epoch # 6845 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0042-> 0.0042 -loss = 0.003667910061267321
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:13,178 INFO epoch # 6846 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0042-> 0.0042 -loss = 0.0036895645080221584
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:13,200 INFO epoch # 6847 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0042-> 0.0042 -loss = 0.004136904149163456
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:13,222 INFO epoch # 6848 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0042-> 0.0042 -loss = 0.0037426010821945965
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:13,244 INFO epoch # 6849 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0042-> 0.0042 -loss = 0.0037240705414660624
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:13,266 INFO epoch # 6850 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0042-> 0.0042 -loss = 0.0036794721800106345
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:13,266 INFO *** epoch 6850, rolling-avg-loss (window=10)= 0.003781771048215887
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:13,287 INFO epoch # 6851 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0042-> 0.0042 -loss = 0.003722769275555038
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:13,308 INFO epoch # 6852 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0042-> 0.0042 -loss = 0.0036771193090316956
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:13,329 INFO epoch # 6853 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0042-> 0.0042 -loss = 0.0036960126299163676
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:13,351 INFO epoch # 6854 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0042-> 0.0042 -loss = 0.003663731019514671
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:13,373 INFO epoch # 6855 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0042-> 0.0042 -loss = 0.0038066895367592224
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:13,395 INFO epoch # 6856 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0042-> 0.0042 -loss = 0.003667126762593398
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:13,417 INFO epoch # 6857 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0042-> 0.0042 -loss = 0.003661433384877455
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:13,439 INFO epoch # 6858 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0042-> 0.0042 -loss = 0.003672730848848005
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:13,461 INFO epoch # 6859 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0042-> 0.0042 -loss = 0.003745904897186847
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:13,483 INFO epoch # 6860 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0042-> 0.0042 -loss = 0.0036789827863685787
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:13,483 INFO *** epoch 6860, rolling-avg-loss (window=10)= 0.0036992500450651277
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:13,504 INFO epoch # 6861 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0042-> 0.0042 -loss = 0.003680314466691925
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:13,526 INFO epoch # 6862 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0042-> 0.0042 -loss = 0.003665546276351961
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:13,547 INFO epoch # 6863 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0042-> 0.0042 -loss = 0.003682300779473735
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:13,568 INFO epoch # 6864 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0042-> 0.0042 -loss = 0.003683899444695271
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:13,590 INFO epoch # 6865 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0042-> 0.0042 -loss = 0.0036609061171475332
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:13,612 INFO epoch # 6866 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0042-> 0.0042 -loss = 0.003798353238380514
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:13,633 INFO epoch # 6867 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0042-> 0.0042 -loss = 0.003661088076114538
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:13,655 INFO epoch # 6868 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0042-> 0.0042 -loss = 0.003655708979749761
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:13,677 INFO epoch # 6869 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0042-> 0.0042 -loss = 0.003653964525938136
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:13,698 INFO epoch # 6870 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0042-> 0.0042 -loss = 0.0037836517021787586
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:13,699 INFO *** epoch 6870, rolling-avg-loss (window=10)= 0.0036925733606722132
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:13,720 INFO epoch # 6871 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0042-> 0.0042 -loss = 0.0037698194682889152
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:13,742 INFO epoch # 6872 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0042-> 0.0042 -loss = 0.0036708449842990376
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:13,763 INFO epoch # 6873 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0042-> 0.0042 -loss = 0.0036842903318756726
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:13,785 INFO epoch # 6874 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0042-> 0.0042 -loss = 0.003762260737858014
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:13,807 INFO epoch # 6875 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0042-> 0.0042 -loss = 0.003664686933007033
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:13,829 INFO epoch # 6876 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0042-> 0.0042 -loss = 0.003685281762955128
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:13,850 INFO epoch # 6877 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0042-> 0.0042 -loss = 0.0036635116575780557
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:13,872 INFO epoch # 6878 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0042-> 0.0042 -loss = 0.003659886630885012
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:13,894 INFO epoch # 6879 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0042-> 0.0042 -loss = 0.003659874693767051
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:13,915 INFO epoch # 6880 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0042-> 0.0041 -loss = 0.003656252840301022
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:13,915 INFO *** epoch 6880, rolling-avg-loss (window=10)= 0.0036876710040814943
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:13,936 INFO epoch # 6881 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0041-> 0.0041 -loss = 0.003664244071842404
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:13,957 INFO epoch # 6882 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0041-> 0.0041 -loss = 0.003687894234644773
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:13,978 INFO epoch # 6883 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0041-> 0.0041 -loss = 0.0036848462359557743
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:14,000 INFO epoch # 6884 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0041-> 0.0041 -loss = 0.0036563088424372836
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:14,022 INFO epoch # 6885 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0041-> 0.0041 -loss = 0.0036678473561551073
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:14,044 INFO epoch # 6886 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0041-> 0.0041 -loss = 0.003671771835797699
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:14,066 INFO epoch # 6887 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0041-> 0.0041 -loss = 0.0036572711333064944
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:14,087 INFO epoch # 6888 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0041-> 0.0041 -loss = 0.003665744659883785
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:14,109 INFO epoch # 6889 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0041-> 0.0041 -loss = 0.0036456213256315095
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:14,131 INFO epoch # 6890 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0041-> 0.0041 -loss = 0.0037198110221652314
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:14,131 INFO *** epoch 6890, rolling-avg-loss (window=10)= 0.003672136071782006
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:14,152 INFO epoch # 6891 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0041-> 0.0041 -loss = 0.0036485697828538832
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:14,173 INFO epoch # 6892 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0041-> 0.0041 -loss = 0.0036591443231372978
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:14,194 INFO epoch # 6893 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0041-> 0.0041 -loss = 0.003695098148455145
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:14,215 INFO epoch # 6894 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0041-> 0.0041 -loss = 0.003688653395329311
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:14,238 INFO epoch # 6895 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0041-> 0.0041 -loss = 0.0037171062504057772
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:14,261 INFO epoch # 6896 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0041-> 0.0041 -loss = 0.003682252366161265
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:14,283 INFO epoch # 6897 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0041-> 0.0041 -loss = 0.0036487438001131522
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:14,304 INFO epoch # 6898 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0041-> 0.0041 -loss = 0.0036623248452087864
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:14,326 INFO epoch # 6899 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0041-> 0.0041 -loss = 0.003674624502309598
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:14,347 INFO epoch # 6900 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0041-> 0.0041 -loss = 0.0036899268243359984
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:14,348 INFO *** epoch 6900, rolling-avg-loss (window=10)= 0.0036766444238310212
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:14,369 INFO epoch # 6901 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0041-> 0.0041 -loss = 0.0036706647424580297
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:14,390 INFO epoch # 6902 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0041-> 0.0041 -loss = 0.0037858683326703613
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:14,411 INFO epoch # 6903 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0041-> 0.0041 -loss = 0.0036543802552841953
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:14,432 INFO epoch # 6904 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0041-> 0.0041 -loss = 0.0036966439638490556
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:14,454 INFO epoch # 6905 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0041-> 0.0041 -loss = 0.0036678523811133346
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:14,476 INFO epoch # 6906 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0041-> 0.0041 -loss = 0.003647777988589951
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:14,498 INFO epoch # 6907 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0041-> 0.0041 -loss = 0.00404010372585617
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:14,519 INFO epoch # 6908 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0041-> 0.0041 -loss = 0.0037498115502785367
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:14,541 INFO epoch # 6909 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0041-> 0.0041 -loss = 0.0036507983877527295
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:14,562 INFO epoch # 6910 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0041-> 0.0041 -loss = 0.004045584174491523
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:14,562 INFO *** epoch 6910, rolling-avg-loss (window=10)= 0.0037609485502343885
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:14,583 INFO epoch # 6911 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0041-> 0.004 -loss = 0.004500606555666309
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:14,604 INFO epoch # 6912 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.004-> 0.004 -loss = 0.0037117586834938265
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:14,626 INFO epoch # 6913 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.004-> 0.004 -loss = 0.0036564620768331224
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:14,647 INFO epoch # 6914 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.004-> 0.004 -loss = 0.0036483740659605246
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:14,668 INFO epoch # 6915 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.004-> 0.004 -loss = 0.0036561931046890095
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:14,690 INFO epoch # 6916 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.004-> 0.004 -loss = 0.0036747943468071753
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:14,712 INFO epoch # 6917 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.004-> 0.004 -loss = 0.0037020037225374836
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:14,734 INFO epoch # 6918 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.004-> 0.004 -loss = 0.003659201476693852
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:14,756 INFO epoch # 6919 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.004-> 0.004 -loss = 0.0037125406934137573
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:14,778 INFO epoch # 6920 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.004-> 0.004 -loss = 0.0036633921226894017
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:14,778 INFO *** epoch 6920, rolling-avg-loss (window=10)= 0.0037585326848784462
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:14,799 INFO epoch # 6921 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.004-> 0.004 -loss = 0.004079588336026063
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:14,820 INFO epoch # 6922 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.004-> 0.004 -loss = 0.003649978277280752
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:14,841 INFO epoch # 6923 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.004-> 0.004 -loss = 0.0037333755481085973
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:14,863 INFO epoch # 6924 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.004-> 0.004 -loss = 0.0043935747034993256
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:14,884 INFO epoch # 6925 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.004-> 0.004 -loss = 0.0036657550281233853
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:14,906 INFO epoch # 6926 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.004-> 0.004 -loss = 0.003695877818245208
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:14,928 INFO epoch # 6927 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.004-> 0.004 -loss = 0.0037081419286550954
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:14,950 INFO epoch # 6928 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.004-> 0.004 -loss = 0.0036445754949454567
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:14,972 INFO epoch # 6929 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.004-> 0.004 -loss = 0.0036435249139685766
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:14,994 INFO epoch # 6930 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.004-> 0.004 -loss = 0.003648815622455004
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:14,994 INFO *** epoch 6930, rolling-avg-loss (window=10)= 0.003786320767130746
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:15,016 INFO epoch # 6931 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.004-> 0.004 -loss = 0.0036625805751100415
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:15,037 INFO epoch # 6932 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.004-> 0.004 -loss = 0.0036797598804696463
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:15,058 INFO epoch # 6933 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.004-> 0.004 -loss = 0.0036461832132772543
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:15,079 INFO epoch # 6934 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.004-> 0.004 -loss = 0.0036381914096637047
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:15,101 INFO epoch # 6935 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.004-> 0.004 -loss = 0.0036426434089662507
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:15,123 INFO epoch # 6936 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.004-> 0.004 -loss = 0.0036448380815272685
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:15,145 INFO epoch # 6937 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.004-> 0.004 -loss = 0.004433692549355328
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:15,167 INFO epoch # 6938 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.004-> 0.004 -loss = 0.003714723008670262
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:15,188 INFO epoch # 6939 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.004-> 0.004 -loss = 0.0036467561913013924
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:15,210 INFO epoch # 6940 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.004-> 0.004 -loss = 0.003650072378150071
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:15,210 INFO *** epoch 6940, rolling-avg-loss (window=10)= 0.003735944069649122
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:15,231 INFO epoch # 6941 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.004-> 0.004 -loss = 0.003645205069005897
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:15,252 INFO epoch # 6942 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.004-> 0.004 -loss = 0.0036361383554321947
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:15,273 INFO epoch # 6943 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.004-> 0.004 -loss = 0.0036606426619982813
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:15,295 INFO epoch # 6944 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.004-> 0.004 -loss = 0.003704084652781603
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:15,316 INFO epoch # 6945 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.004-> 0.004 -loss = 0.003635299706729711
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:15,338 INFO epoch # 6946 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.004-> 0.004 -loss = 0.0036505941843643086
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:15,360 INFO epoch # 6947 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.004-> 0.004 -loss = 0.0036383896076586097
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:15,381 INFO epoch # 6948 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.004-> 0.004 -loss = 0.003629661991226385
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:15,402 INFO epoch # 6949 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.004-> 0.004 -loss = 0.003736314670277352
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:15,424 INFO epoch # 6950 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.004-> 0.004 -loss = 0.003709850931954861
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:15,424 INFO *** epoch 6950, rolling-avg-loss (window=10)= 0.0036646181831429202
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:15,445 INFO epoch # 6951 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.004-> 0.004 -loss = 0.0036418440176930744
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:15,466 INFO epoch # 6952 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.004-> 0.004 -loss = 0.0036590564686775906
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:15,487 INFO epoch # 6953 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.004-> 0.004 -loss = 0.0036604663682737737
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:15,508 INFO epoch # 6954 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.004-> 0.004 -loss = 0.0036435082265597885
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:15,530 INFO epoch # 6955 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.004-> 0.004 -loss = 0.003688243839860661
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:15,552 INFO epoch # 6956 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.004-> 0.004 -loss = 0.0036311410331109073
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:15,574 INFO epoch # 6957 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.004-> 0.004 -loss = 0.004614049119481933
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:15,596 INFO epoch # 6958 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.004-> 0.004 -loss = 0.003672560560517013
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:15,618 INFO epoch # 6959 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.004-> 0.004 -loss = 0.0036663721048171283
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:15,639 INFO epoch # 6960 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.004-> 0.004 -loss = 0.0036579802344931522
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:15,639 INFO *** epoch 6960, rolling-avg-loss (window=10)= 0.003753522197348502
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:15,660 INFO epoch # 6961 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.004-> 0.004 -loss = 0.0036336161028884817
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:15,682 INFO epoch # 6962 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.004-> 0.004 -loss = 0.0036573106972355163
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:15,703 INFO epoch # 6963 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.004-> 0.004 -loss = 0.0036402008172444766
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:15,724 INFO epoch # 6964 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.004-> 0.004 -loss = 0.003687670876388438
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:15,746 INFO epoch # 6965 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.004-> 0.004 -loss = 0.003629815329986741
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:15,769 INFO epoch # 6966 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.004-> 0.004 -loss = 0.0036989944892411586
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:15,790 INFO epoch # 6967 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.004-> 0.004 -loss = 0.004022669214464258
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:15,812 INFO epoch # 6968 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.004-> 0.004 -loss = 0.0036595698602468474
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:15,834 INFO epoch # 6969 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.004-> 0.004 -loss = 0.003630323142715497
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:15,856 INFO epoch # 6970 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.004-> 0.0039 -loss = 0.0036354324356580037
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:15,856 INFO *** epoch 6970, rolling-avg-loss (window=10)= 0.003689560296606942
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:15,877 INFO epoch # 6971 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0039-> 0.0039 -loss = 0.0036976201909055817
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:15,898 INFO epoch # 6972 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0039-> 0.0039 -loss = 0.0036706668906845152
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:15,919 INFO epoch # 6973 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0039-> 0.0039 -loss = 0.0036326861554698553
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:15,941 INFO epoch # 6974 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0039-> 0.0039 -loss = 0.003641972096374957
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:15,962 INFO epoch # 6975 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0039-> 0.0039 -loss = 0.003758798924536677
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:15,984 INFO epoch # 6976 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0039-> 0.0039 -loss = 0.0036359784498927183
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:16,006 INFO epoch # 6977 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0039-> 0.0039 -loss = 0.0036297672140790382
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:16,028 INFO epoch # 6978 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0039-> 0.0039 -loss = 0.0036405302980710985
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:16,050 INFO epoch # 6979 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0039-> 0.0039 -loss = 0.003724856065673521
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:16,072 INFO epoch # 6980 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0039-> 0.0039 -loss = 0.003640989732957678
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:16,072 INFO *** epoch 6980, rolling-avg-loss (window=10)= 0.003667386601864564
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:16,093 INFO epoch # 6981 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0039-> 0.0039 -loss = 0.0036485429636741173
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:16,115 INFO epoch # 6982 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0039-> 0.0039 -loss = 0.0036405249156814534
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:16,136 INFO epoch # 6983 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0039-> 0.0039 -loss = 0.0036545565326377982
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:16,157 INFO epoch # 6984 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0039-> 0.0039 -loss = 0.0036253442831366556
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:16,179 INFO epoch # 6985 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0039-> 0.0039 -loss = 0.0036245608698664
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:16,201 INFO epoch # 6986 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0039-> 0.0039 -loss = 0.003670806541776983
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:16,222 INFO epoch # 6987 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0039-> 0.0039 -loss = 0.003662291486762115
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:16,245 INFO epoch # 6988 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0039-> 0.0039 -loss = 0.0037380967050921754
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:16,266 INFO epoch # 6989 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0039-> 0.0039 -loss = 0.003648784877441358
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:16,288 INFO epoch # 6990 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0039-> 0.0039 -loss = 0.004030953597975895
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:16,288 INFO *** epoch 6990, rolling-avg-loss (window=10)= 0.003694446277404495
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:16,309 INFO epoch # 6991 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0039-> 0.0039 -loss = 0.003627929512731498
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:16,330 INFO epoch # 6992 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0039-> 0.0039 -loss = 0.003633004218499991
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:16,351 INFO epoch # 6993 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0039-> 0.0039 -loss = 0.0036190267201163806
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:16,373 INFO epoch # 6994 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0039-> 0.0039 -loss = 0.0036365762434797944
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:16,394 INFO epoch # 6995 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0039-> 0.0039 -loss = 0.003664244517494808
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:16,416 INFO epoch # 6996 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0039-> 0.0039 -loss = 0.003654697165984544
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:16,439 INFO epoch # 6997 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0039-> 0.0039 -loss = 0.0036284910329413833
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:16,461 INFO epoch # 6998 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0039-> 0.0039 -loss = 0.0036365913638292113
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:16,483 INFO epoch # 6999 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0039-> 0.0039 -loss = 0.003636316659139993
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:16,504 INFO epoch # 7000 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0039-> 0.0039 -loss = 0.0036394680946614244
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:16,504 INFO *** epoch 7000, rolling-avg-loss (window=10)= 0.003637634552887903
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:16,526 INFO epoch # 7001 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0039-> 0.0039 -loss = 0.003619341310695745
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:16,547 INFO epoch # 7002 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0039-> 0.0039 -loss = 0.0036756349281859
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:16,568 INFO epoch # 7003 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0039-> 0.0039 -loss = 0.0036430228856261238
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:16,590 INFO epoch # 7004 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0039-> 0.0038 -loss = 0.0036292183522164123
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:16,612 INFO epoch # 7005 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0038-> 0.0038 -loss = 0.0036561231718224008
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:16,634 INFO epoch # 7006 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0038-> 0.0038 -loss = 0.00369412292366178
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:16,656 INFO epoch # 7007 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0038-> 0.0038 -loss = 0.0036249600125302095
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:16,677 INFO epoch # 7008 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0038-> 0.0038 -loss = 0.003681886567392212
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:16,699 INFO epoch # 7009 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0038-> 0.0038 -loss = 0.003628663300332846
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:16,720 INFO epoch # 7010 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0038-> 0.0038 -loss = 0.0036195823104208102
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:16,721 INFO *** epoch 7010, rolling-avg-loss (window=10)= 0.003647255576288444
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:16,742 INFO epoch # 7011 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0038-> 0.0038 -loss = 0.0036292840331952902
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:16,764 INFO epoch # 7012 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0038-> 0.0038 -loss = 0.0036781867866011453
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:16,785 INFO epoch # 7013 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0038-> 0.0038 -loss = 0.0036482908199104713
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:16,807 INFO epoch # 7014 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0038-> 0.0038 -loss = 0.003651708624602179
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:16,828 INFO epoch # 7015 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0038-> 0.0038 -loss = 0.0036197170920786448
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:16,850 INFO epoch # 7016 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0038-> 0.0038 -loss = 0.0036154463687125826
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:16,872 INFO epoch # 7017 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0038-> 0.0038 -loss = 0.0036187533787597204
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:16,894 INFO epoch # 7018 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0038-> 0.0038 -loss = 0.003631315319580608
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:16,915 INFO epoch # 7019 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0038-> 0.0038 -loss = 0.0036516338568617357
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:16,936 INFO epoch # 7020 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0038-> 0.0038 -loss = 0.0036284776688262355
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:16,937 INFO *** epoch 7020, rolling-avg-loss (window=10)= 0.003637281394912861
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:16,958 INFO epoch # 7021 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0038-> 0.0038 -loss = 0.0036336448138172273
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:16,979 INFO epoch # 7022 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0038-> 0.0038 -loss = 0.0036243849262973526
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:17,000 INFO epoch # 7023 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0038-> 0.0038 -loss = 0.0036069378784304718
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:17,022 INFO epoch # 7024 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0038-> 0.0038 -loss = 0.0036486398239503615
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:17,044 INFO epoch # 7025 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0038-> 0.0038 -loss = 0.0036164218317935592
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:17,066 INFO epoch # 7026 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0038-> 0.0038 -loss = 0.0036161237376290956
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:17,087 INFO epoch # 7027 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0038-> 0.0038 -loss = 0.0036113381993345683
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:17,109 INFO epoch # 7028 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0038-> 0.0038 -loss = 0.003625257256317127
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:17,131 INFO epoch # 7029 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0038-> 0.0038 -loss = 0.0036098701875744155
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:17,152 INFO epoch # 7030 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0038-> 0.0038 -loss = 0.003656824645076995
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:17,152 INFO *** epoch 7030, rolling-avg-loss (window=10)= 0.0036249443300221174
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:17,173 INFO epoch # 7031 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0038-> 0.0038 -loss = 0.003627482992669684
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:17,194 INFO epoch # 7032 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0038-> 0.0038 -loss = 0.0036286728482082253
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:17,215 INFO epoch # 7033 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0038-> 0.0038 -loss = 0.0036181050818413496
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:17,237 INFO epoch # 7034 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0038-> 0.0038 -loss = 0.0036422006087377667
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:17,259 INFO epoch # 7035 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0038-> 0.0038 -loss = 0.0036103076172366855
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:17,281 INFO epoch # 7036 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0038-> 0.0038 -loss = 0.0036191921735735377
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:17,303 INFO epoch # 7037 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0038-> 0.0038 -loss = 0.0036073973333259346
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:17,325 INFO epoch # 7038 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0038-> 0.0038 -loss = 0.003643184978500358
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:17,347 INFO epoch # 7039 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0038-> 0.0038 -loss = 0.003619884253566852
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:17,368 INFO epoch # 7040 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0038-> 0.0038 -loss = 0.0036202047285769368
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:17,368 INFO *** epoch 7040, rolling-avg-loss (window=10)= 0.003623663261623733
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:17,390 INFO epoch # 7041 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0038-> 0.0038 -loss = 0.0036119476089879754
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:17,411 INFO epoch # 7042 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0038-> 0.0038 -loss = 0.003614160501456354
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:17,432 INFO epoch # 7043 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0038-> 0.0038 -loss = 0.0037176363612161367
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:17,453 INFO epoch # 7044 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0038-> 0.0038 -loss = 0.0036341193535918137
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:17,475 INFO epoch # 7045 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0038-> 0.0037 -loss = 0.0036240454101061914
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:17,496 INFO epoch # 7046 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0037-> 0.0037 -loss = 0.0036267176965338876
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:17,518 INFO epoch # 7047 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0037-> 0.0037 -loss = 0.003700636586472683
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:17,540 INFO epoch # 7048 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0037-> 0.0037 -loss = 0.0036950769481336465
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:17,562 INFO epoch # 7049 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0037-> 0.0037 -loss = 0.00399679192196345
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:17,583 INFO epoch # 7050 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0037-> 0.0037 -loss = 0.0036170967869111337
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:17,583 INFO *** epoch 7050, rolling-avg-loss (window=10)= 0.003683822917537327
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:17,604 INFO epoch # 7051 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0037-> 0.0037 -loss = 0.0036080379177292343
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:17,625 INFO epoch # 7052 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0037-> 0.0037 -loss = 0.0036157687318336684
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:17,646 INFO epoch # 7053 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0037-> 0.0037 -loss = 0.0036434797821129905
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:17,668 INFO epoch # 7054 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0037-> 0.0037 -loss = 0.00365535606033518
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:17,689 INFO epoch # 7055 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0037-> 0.0037 -loss = 0.0036087416419832152
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:17,711 INFO epoch # 7056 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0037-> 0.0037 -loss = 0.0036049692735105054
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:17,733 INFO epoch # 7057 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0037-> 0.0037 -loss = 0.003605117070947017
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:17,755 INFO epoch # 7058 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0037-> 0.0037 -loss = 0.0036552835827023955
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:17,777 INFO epoch # 7059 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0037-> 0.0037 -loss = 0.003604841718697571
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:17,799 INFO epoch # 7060 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0037-> 0.0037 -loss = 0.003631190911619342
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:17,799 INFO *** epoch 7060, rolling-avg-loss (window=10)= 0.003623278669147112
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:17,820 INFO epoch # 7061 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0037-> 0.0037 -loss = 0.0036306308957136935
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:17,841 INFO epoch # 7062 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0037-> 0.0037 -loss = 0.0036659136594607844
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:17,862 INFO epoch # 7063 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0037-> 0.0037 -loss = 0.003690137429657625
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:17,884 INFO epoch # 7064 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0037-> 0.0037 -loss = 0.003685458705149358
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:17,906 INFO epoch # 7065 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0037-> 0.0037 -loss = 0.0036555223359755473
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:17,927 INFO epoch # 7066 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0037-> 0.0037 -loss = 0.0036665377774625085
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:17,949 INFO epoch # 7067 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0037-> 0.0037 -loss = 0.003651325620012358
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:17,971 INFO epoch # 7068 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0037-> 0.0037 -loss = 0.003626084806455765
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:17,992 INFO epoch # 7069 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0037-> 0.0037 -loss = 0.0035972328023490263
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:18,014 INFO epoch # 7070 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0037-> 0.0037 -loss = 0.0036215901982359355
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:18,014 INFO *** epoch 7070, rolling-avg-loss (window=10)= 0.0036490434230472602
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:18,035 INFO epoch # 7071 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0037-> 0.0037 -loss = 0.003611668784287758
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:18,056 INFO epoch # 7072 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0037-> 0.0037 -loss = 0.003621900723373983
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:18,077 INFO epoch # 7073 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0037-> 0.0037 -loss = 0.0036618113899749005
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:18,098 INFO epoch # 7074 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0037-> 0.0037 -loss = 0.0035988146673844312
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:18,120 INFO epoch # 7075 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0037-> 0.0037 -loss = 0.0036451947280511376
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:18,142 INFO epoch # 7076 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0037-> 0.0037 -loss = 0.00361155106111255
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:18,164 INFO epoch # 7077 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0037-> 0.0037 -loss = 0.004366648337963852
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:18,185 INFO epoch # 7078 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0037-> 0.0037 -loss = 0.004376445546768082
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:18,207 INFO epoch # 7079 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0037-> 0.0037 -loss = 0.003604940284276381
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:18,228 INFO epoch # 7080 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0037-> 0.0037 -loss = 0.003650629174444475
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:18,228 INFO *** epoch 7080, rolling-avg-loss (window=10)= 0.003774960469763755
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:18,250 INFO epoch # 7081 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0037-> 0.0037 -loss = 0.003619886299929931
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:18,271 INFO epoch # 7082 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0037-> 0.0037 -loss = 0.0035996410415464197
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:18,292 INFO epoch # 7083 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0037-> 0.0037 -loss = 0.0036313662631073385
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:18,314 INFO epoch # 7084 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0037-> 0.0037 -loss = 0.0036852646098850528
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:18,336 INFO epoch # 7085 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0037-> 0.0037 -loss = 0.003671934195153881
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:18,358 INFO epoch # 7086 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0037-> 0.0037 -loss = 0.0036119064297963632
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:18,380 INFO epoch # 7087 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0037-> 0.0037 -loss = 0.0036003133327540127
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:18,402 INFO epoch # 7088 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0037-> 0.0037 -loss = 0.003676471459584718
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:18,424 INFO epoch # 7089 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0037-> 0.0037 -loss = 0.0036019348863192135
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:18,445 INFO epoch # 7090 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0037-> 0.0037 -loss = 0.0037307502589101205
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:18,445 INFO *** epoch 7090, rolling-avg-loss (window=10)= 0.003642946877698705
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:18,467 INFO epoch # 7091 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0037-> 0.0036 -loss = 0.004359605596619076
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:18,488 INFO epoch # 7092 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0036-> 0.0036 -loss = 0.0035904957776438096
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:18,509 INFO epoch # 7093 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0036-> 0.0036 -loss = 0.0036152303273411235
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:18,530 INFO epoch # 7094 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0036-> 0.0036 -loss = 0.003592204980122915
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:18,552 INFO epoch # 7095 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0036-> 0.0036 -loss = 0.0036038491689396324
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:18,573 INFO epoch # 7096 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0036-> 0.0036 -loss = 0.003609357383538736
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:18,595 INFO epoch # 7097 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0036-> 0.0036 -loss = 0.003594335739762755
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:18,617 INFO epoch # 7098 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0036-> 0.0036 -loss = 0.003588058527384419
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:18,639 INFO epoch # 7099 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0036-> 0.0036 -loss = 0.0036436936488826177
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:18,661 INFO epoch # 7100 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0036-> 0.0036 -loss = 0.0036317910771686
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:18,661 INFO *** epoch 7100, rolling-avg-loss (window=10)= 0.0036828622227403685
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:18,682 INFO epoch # 7101 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0036-> 0.0036 -loss = 0.0036101848745602183
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:18,703 INFO epoch # 7102 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0036-> 0.0036 -loss = 0.003601702371270221
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:18,724 INFO epoch # 7103 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0036-> 0.0036 -loss = 0.003980457264333381
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:18,746 INFO epoch # 7104 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0036-> 0.0036 -loss = 0.0035916232936870074
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:18,768 INFO epoch # 7105 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0036-> 0.0036 -loss = 0.0035922134693464614
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:18,790 INFO epoch # 7106 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0036-> 0.0036 -loss = 0.003617541855419404
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:18,812 INFO epoch # 7107 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0036-> 0.0036 -loss = 0.003604617599194171
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:18,834 INFO epoch # 7108 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0036-> 0.0036 -loss = 0.0036191620492900256
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:18,855 INFO epoch # 7109 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0036-> 0.0036 -loss = 0.0036107220457779476
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:18,877 INFO epoch # 7110 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0036-> 0.0036 -loss = 0.0036493404240900418
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:18,877 INFO *** epoch 7110, rolling-avg-loss (window=10)= 0.0036477565246968878
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:18,898 INFO epoch # 7111 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0036-> 0.0036 -loss = 0.0036281624052207917
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:18,919 INFO epoch # 7112 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0036-> 0.0036 -loss = 0.00486138000178471
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:18,941 INFO epoch # 7113 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0036-> 0.0036 -loss = 0.003597776620154036
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:18,962 INFO epoch # 7114 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0036-> 0.0036 -loss = 0.003588671459510806
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:18,983 INFO epoch # 7115 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0036-> 0.0036 -loss = 0.0035913956735385
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:19,005 INFO epoch # 7116 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0036-> 0.0036 -loss = 0.0036301501568232197
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:19,027 INFO epoch # 7117 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0036-> 0.0036 -loss = 0.003587363055885362
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:19,049 INFO epoch # 7118 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0036-> 0.0036 -loss = 0.0035884231256204657
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:19,070 INFO epoch # 7119 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0036-> 0.0036 -loss = 0.0036559593509082333
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:19,092 INFO epoch # 7120 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0036-> 0.0036 -loss = 0.003598375216824934
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:19,092 INFO *** epoch 7120, rolling-avg-loss (window=10)= 0.0037327657066271057
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:19,113 INFO epoch # 7121 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0036-> 0.0036 -loss = 0.0036134584224782884
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:19,134 INFO epoch # 7122 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0036-> 0.0036 -loss = 0.003599172827307484
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:19,155 INFO epoch # 7123 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0036-> 0.0036 -loss = 0.0036270946429795003
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:19,176 INFO epoch # 7124 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0036-> 0.0036 -loss = 0.0036353648301883368
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:19,198 INFO epoch # 7125 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0036-> 0.0036 -loss = 0.0036834167985944077
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:19,220 INFO epoch # 7126 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0036-> 0.0036 -loss = 0.004433762545886566
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:19,242 INFO epoch # 7127 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0036-> 0.0036 -loss = 0.003595085029701295
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:19,264 INFO epoch # 7128 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0036-> 0.0036 -loss = 0.004054501016071299
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:19,285 INFO epoch # 7129 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0036-> 0.0036 -loss = 0.003593280434870394
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:19,307 INFO epoch # 7130 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0036-> 0.0036 -loss = 0.003694062934300746
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:19,307 INFO *** epoch 7130, rolling-avg-loss (window=10)= 0.0037529199482378315
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:19,328 INFO epoch # 7131 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0036-> 0.0036 -loss = 0.0035964312537544174
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:19,349 INFO epoch # 7132 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0036-> 0.0036 -loss = 0.0036112263496761443
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:19,370 INFO epoch # 7133 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0036-> 0.0036 -loss = 0.0035908941499656066
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:19,391 INFO epoch # 7134 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0036-> 0.0036 -loss = 0.003583447487471858
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:19,413 INFO epoch # 7135 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0036-> 0.0036 -loss = 0.0036200956365064485
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:19,435 INFO epoch # 7136 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0036-> 0.0036 -loss = 0.0036410731972864596
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:19,457 INFO epoch # 7137 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0036-> 0.0036 -loss = 0.003583639193493582
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:19,478 INFO epoch # 7138 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0036-> 0.0036 -loss = 0.003632216921687359
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:19,500 INFO epoch # 7139 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0036-> 0.0036 -loss = 0.004529958410785184
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:19,523 INFO epoch # 7140 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0036-> 0.0036 -loss = 0.003622876960434951
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:19,523 INFO *** epoch 7140, rolling-avg-loss (window=10)= 0.0037011859561062012
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:19,544 INFO epoch # 7141 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0036-> 0.0036 -loss = 0.0035782316263066605
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:19,565 INFO epoch # 7142 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0036-> 0.0036 -loss = 0.003580215622605465
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:19,587 INFO epoch # 7143 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0036-> 0.0036 -loss = 0.0035793158267551917
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:19,609 INFO epoch # 7144 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0036-> 0.0036 -loss = 0.004251622976880753
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:19,631 INFO epoch # 7145 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0036-> 0.0036 -loss = 0.003666136094579997
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:19,653 INFO epoch # 7146 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0036-> 0.0036 -loss = 0.0036618079020627192
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:19,675 INFO epoch # 7147 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0036-> 0.0036 -loss = 0.0035918522680731257
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:19,697 INFO epoch # 7148 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0036-> 0.0036 -loss = 0.0035903497619074187
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:19,718 INFO epoch # 7149 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0036-> 0.0036 -loss = 0.003591607268390362
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:19,740 INFO epoch # 7150 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0036-> 0.0036 -loss = 0.0035845228640027926
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:19,740 INFO *** epoch 7150, rolling-avg-loss (window=10)= 0.0036675662211564488
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:19,762 INFO epoch # 7151 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0036-> 0.0036 -loss = 0.0036182542835376807
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:19,783 INFO epoch # 7152 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0036-> 0.0036 -loss = 0.003576328444069077
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:19,804 INFO epoch # 7153 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0036-> 0.0036 -loss = 0.0036022781150677474
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:19,825 INFO epoch # 7154 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0036-> 0.0036 -loss = 0.0035819187005472486
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:19,847 INFO epoch # 7155 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0036-> 0.0036 -loss = 0.0036021589457959635
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:19,869 INFO epoch # 7156 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0036-> 0.0036 -loss = 0.003594281331061211
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:19,891 INFO epoch # 7157 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0036-> 0.0036 -loss = 0.003581588947781711
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:19,913 INFO epoch # 7158 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0036-> 0.0036 -loss = 0.003589915047996328
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:19,935 INFO epoch # 7159 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0036-> 0.0036 -loss = 0.003595130295252602
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:19,956 INFO epoch # 7160 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0036-> 0.0036 -loss = 0.003591508852878178
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:19,956 INFO *** epoch 7160, rolling-avg-loss (window=10)= 0.003593336296398775
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:19,977 INFO epoch # 7161 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0036-> 0.0036 -loss = 0.0035870661686203675
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:19,998 INFO epoch # 7162 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0036-> 0.0036 -loss = 0.003694519100463367
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:20,019 INFO epoch # 7163 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0036-> 0.0035 -loss = 0.0036107917994741
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:20,041 INFO epoch # 7164 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0035-> 0.0035 -loss = 0.0035705876171050477
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:20,063 INFO epoch # 7165 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0035-> 0.0035 -loss = 0.0035715362569135323
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:20,084 INFO epoch # 7166 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0035-> 0.0035 -loss = 0.0036391233534232015
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:20,106 INFO epoch # 7167 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0035-> 0.0035 -loss = 0.0036129110822002986
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:20,128 INFO epoch # 7168 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0035-> 0.0035 -loss = 0.003573489821064868
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:20,150 INFO epoch # 7169 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0035-> 0.0035 -loss = 0.005083176291009295
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:20,171 INFO epoch # 7170 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0035-> 0.0035 -loss = 0.003578993958853971
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:20,171 INFO *** epoch 7170, rolling-avg-loss (window=10)= 0.0037522195449128048
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:20,193 INFO epoch # 7171 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0035-> 0.0035 -loss = 0.0036057223096577218
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:20,214 INFO epoch # 7172 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0035-> 0.0035 -loss = 0.003581746332201874
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:20,235 INFO epoch # 7173 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0035-> 0.0035 -loss = 0.004854661494391621
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:20,256 INFO epoch # 7174 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0035-> 0.0035 -loss = 0.003577231162125827
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:20,278 INFO epoch # 7175 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0035-> 0.0035 -loss = 0.0035833728361467365
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:20,300 INFO epoch # 7176 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0035-> 0.0035 -loss = 0.003638455552390951
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:20,322 INFO epoch # 7177 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0035-> 0.0035 -loss = 0.00358571280776232
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:20,344 INFO epoch # 7178 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0035-> 0.0035 -loss = 0.003565611503290711
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:20,365 INFO epoch # 7179 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0035-> 0.0035 -loss = 0.004673587651268463
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:20,387 INFO epoch # 7180 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0035-> 0.0035 -loss = 0.003594114979932783
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:20,387 INFO *** epoch 7180, rolling-avg-loss (window=10)= 0.003826021662916901
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:20,409 INFO epoch # 7181 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0035-> 0.0035 -loss = 0.003578812169507728
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:20,430 INFO epoch # 7182 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0035-> 0.0035 -loss = 0.0035855474834534107
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:20,451 INFO epoch # 7183 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0035-> 0.0035 -loss = 0.0036616475699702278
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:20,472 INFO epoch # 7184 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0035-> 0.0035 -loss = 0.0035680758214766684
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:20,494 INFO epoch # 7185 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0035-> 0.0035 -loss = 0.0035775374908553204
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:20,516 INFO epoch # 7186 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0035-> 0.0035 -loss = 0.0035908841418859083
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:20,538 INFO epoch # 7187 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0035-> 0.0035 -loss = 0.003569286690435547
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:20,560 INFO epoch # 7188 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0035-> 0.0035 -loss = 0.003567684798326809
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:20,582 INFO epoch # 7189 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0035-> 0.0034 -loss = 0.003571491346519906
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:20,603 INFO epoch # 7190 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0034-> 0.0034 -loss = 0.003585427797588636
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:20,604 INFO *** epoch 7190, rolling-avg-loss (window=10)= 0.003585639531002016
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:20,625 INFO epoch # 7191 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0034-> 0.0034 -loss = 0.0035920782802350004
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:20,646 INFO epoch # 7192 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0034-> 0.0034 -loss = 0.0035688120233317022
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:20,668 INFO epoch # 7193 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0034-> 0.0034 -loss = 0.0036096850690228166
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:20,689 INFO epoch # 7194 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0034-> 0.0034 -loss = 0.0036020486822962994
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:20,711 INFO epoch # 7195 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0034-> 0.0034 -loss = 0.0035989058451377787
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:20,733 INFO epoch # 7196 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0034-> 0.0034 -loss = 0.003572705561055045
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:20,756 INFO epoch # 7197 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0034-> 0.0034 -loss = 0.004278235799574759
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:20,777 INFO epoch # 7198 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0034-> 0.0034 -loss = 0.00362931480503903
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:20,799 INFO epoch # 7199 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0034-> 0.0034 -loss = 0.0035698311066880706
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:20,821 INFO epoch # 7200 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0034-> 0.0034 -loss = 0.003570025339286076
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:20,821 INFO *** epoch 7200, rolling-avg-loss (window=10)= 0.0036591642511666577
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:20,843 INFO epoch # 7201 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0034-> 0.0034 -loss = 0.0035871812360710464
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:20,864 INFO epoch # 7202 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0034-> 0.0034 -loss = 0.0035635968361020787
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:20,885 INFO epoch # 7203 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0034-> 0.0034 -loss = 0.003581976756322547
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:20,906 INFO epoch # 7204 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0034-> 0.0034 -loss = 0.003612251961385482
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:20,928 INFO epoch # 7205 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0034-> 0.0034 -loss = 0.003568094027286861
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:20,950 INFO epoch # 7206 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0034-> 0.0034 -loss = 0.003694817170071474
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:20,972 INFO epoch # 7207 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0034-> 0.0034 -loss = 0.003587247418181505
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:20,994 INFO epoch # 7208 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0034-> 0.0034 -loss = 0.003572807332602679
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:21,016 INFO epoch # 7209 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0034-> 0.0034 -loss = 0.0036044412681803806
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:21,037 INFO epoch # 7210 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0034-> 0.0034 -loss = 0.0035694857979251537
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:21,037 INFO *** epoch 7210, rolling-avg-loss (window=10)= 0.003594189980412921
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:21,059 INFO epoch # 7211 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0034-> 0.0034 -loss = 0.0048181758565988275
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:21,080 INFO epoch # 7212 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0034-> 0.0034 -loss = 0.0036035776774951955
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:21,101 INFO epoch # 7213 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0034-> 0.0034 -loss = 0.0042687876793934265
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:21,123 INFO epoch # 7214 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0034-> 0.0034 -loss = 0.003653691627732769
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:21,145 INFO epoch # 7215 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0034-> 0.0034 -loss = 0.0035835536300510284
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:21,167 INFO epoch # 7216 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0034-> 0.0034 -loss = 0.0035621649844870262
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:21,189 INFO epoch # 7217 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0034-> 0.0034 -loss = 0.00356481247672491
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:21,211 INFO epoch # 7218 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0034-> 0.0034 -loss = 0.003568607635315857
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:21,232 INFO epoch # 7219 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0034-> 0.0034 -loss = 0.0035656943255162332
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:21,254 INFO epoch # 7220 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0034-> 0.0034 -loss = 0.003578725507395575
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:21,254 INFO *** epoch 7220, rolling-avg-loss (window=10)= 0.003776779140071085
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:21,276 INFO epoch # 7221 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0034-> 0.0034 -loss = 0.003582196865863807
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:21,297 INFO epoch # 7222 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0034-> 0.0034 -loss = 0.0035723158025575685
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:21,318 INFO epoch # 7223 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0034-> 0.0034 -loss = 0.0035819053100567544
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:21,339 INFO epoch # 7224 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0034-> 0.0034 -loss = 0.003576789778890088
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:21,361 INFO epoch # 7225 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0034-> 0.0034 -loss = 0.003566935816706973
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:21,384 INFO epoch # 7226 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0034-> 0.0034 -loss = 0.0035813863923976896
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:21,409 INFO epoch # 7227 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0034-> 0.0033 -loss = 0.003986674377301824
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:21,434 INFO epoch # 7228 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0033-> 0.0033 -loss = 0.0035605200127974967
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:21,457 INFO epoch # 7229 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0033-> 0.0033 -loss = 0.003581609858883894
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:21,479 INFO epoch # 7230 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0033-> 0.0033 -loss = 0.0036932582006556913
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:21,479 INFO *** epoch 7230, rolling-avg-loss (window=10)= 0.003628359241611179
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:21,500 INFO epoch # 7231 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0033-> 0.0033 -loss = 0.003620221363235032
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:21,521 INFO epoch # 7232 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0033-> 0.0033 -loss = 0.0037243760179990204
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:21,542 INFO epoch # 7233 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0033-> 0.0033 -loss = 0.004089465110155288
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:21,564 INFO epoch # 7234 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0033-> 0.0033 -loss = 0.0035874939621862723
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:21,586 INFO epoch # 7235 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0033-> 0.0033 -loss = 0.0036140857646387303
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:21,608 INFO epoch # 7236 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0033-> 0.0033 -loss = 0.0035582222199082025
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:21,630 INFO epoch # 7237 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0033-> 0.0033 -loss = 0.003580534858883766
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:21,652 INFO epoch # 7238 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0033-> 0.0033 -loss = 0.0035727863250940572
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:21,673 INFO epoch # 7239 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0033-> 0.0033 -loss = 0.00357162326326943
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:21,694 INFO epoch # 7240 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0033-> 0.0033 -loss = 0.003586835224268725
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:21,694 INFO *** epoch 7240, rolling-avg-loss (window=10)= 0.0036505644109638526
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:21,716 INFO epoch # 7241 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0033-> 0.0033 -loss = 0.0035745347804549965
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:21,737 INFO epoch # 7242 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0033-> 0.0033 -loss = 0.0035620295766420895
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:21,759 INFO epoch # 7243 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0033-> 0.0033 -loss = 0.0035690045979208662
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:21,782 INFO epoch # 7244 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0033-> 0.0033 -loss = 0.0035710360480152303
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:21,805 INFO epoch # 7245 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0033-> 0.0033 -loss = 0.0035719703810173087
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:21,827 INFO epoch # 7246 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0033-> 0.0033 -loss = 0.003555958673132409
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:21,849 INFO epoch # 7247 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0033-> 0.0033 -loss = 0.0035802672755380627
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:21,871 INFO epoch # 7248 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0033-> 0.0033 -loss = 0.004501905617871671
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:21,896 INFO epoch # 7249 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0033-> 0.0033 -loss = 0.0035660388457472436
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:21,920 INFO epoch # 7250 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0033-> 0.0033 -loss = 0.003578994133931701
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:21,920 INFO *** epoch 7250, rolling-avg-loss (window=10)= 0.003663173993027158
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:21,945 INFO epoch # 7251 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0033-> 0.0033 -loss = 0.0035846224263877957
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:21,968 INFO epoch # 7252 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0033-> 0.0033 -loss = 0.0035495474544404715
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:21,990 INFO epoch # 7253 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0033-> 0.0033 -loss = 0.0035551292676245794
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:22,013 INFO epoch # 7254 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0033-> 0.0033 -loss = 0.0035563200144679286
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:22,035 INFO epoch # 7255 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0033-> 0.0033 -loss = 0.0035661720885400428
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:22,058 INFO epoch # 7256 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0033-> 0.0033 -loss = 0.003557601949069067
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:22,080 INFO epoch # 7257 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0033-> 0.0033 -loss = 0.0035517430678737583
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:22,101 INFO epoch # 7258 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0033-> 0.0033 -loss = 0.00424684759855154
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:22,123 INFO epoch # 7259 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0033-> 0.0033 -loss = 0.003557436030860117
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:22,144 INFO epoch # 7260 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0033-> 0.0033 -loss = 0.0035876753863703925
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:22,144 INFO *** epoch 7260, rolling-avg-loss (window=10)= 0.0036313095284185694
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:22,165 INFO epoch # 7261 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0033-> 0.0033 -loss = 0.0035473166335577844
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:22,187 INFO epoch # 7262 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0033-> 0.0033 -loss = 0.0035564814970712177
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:22,209 INFO epoch # 7263 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0033-> 0.0033 -loss = 0.0035695304304681486
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:22,231 INFO epoch # 7264 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0033-> 0.0033 -loss = 0.0035588574019129737
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:22,255 INFO epoch # 7265 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0033-> 0.0033 -loss = 0.003553820963134058
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:22,282 INFO epoch # 7266 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0033-> 0.0033 -loss = 0.0035967099784102174
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:22,304 INFO epoch # 7267 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0033-> 0.0033 -loss = 0.003552779506208026
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:22,326 INFO epoch # 7268 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0033-> 0.0033 -loss = 0.00354909892030264
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:22,347 INFO epoch # 7269 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0033-> 0.0033 -loss = 0.0035796322063106345
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:22,368 INFO epoch # 7270 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0033-> 0.0033 -loss = 0.004004749827799969
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:22,368 INFO *** epoch 7270, rolling-avg-loss (window=10)= 0.003606897736517567
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:22,390 INFO epoch # 7271 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0033-> 0.0033 -loss = 0.0035886295463569695
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:22,411 INFO epoch # 7272 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0033-> 0.0033 -loss = 0.003589444109820761
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:22,433 INFO epoch # 7273 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0033-> 0.0033 -loss = 0.0035603968899522442
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:22,455 INFO epoch # 7274 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0033-> 0.0033 -loss = 0.003569176953533315
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:22,477 INFO epoch # 7275 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0033-> 0.0033 -loss = 0.0036435451274883235
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:22,500 INFO epoch # 7276 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0033-> 0.0033 -loss = 0.0035542083824111614
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:22,522 INFO epoch # 7277 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0033-> 0.0033 -loss = 0.0035475009317451622
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:22,543 INFO epoch # 7278 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0033-> 0.0033 -loss = 0.0036124491180089535
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:22,564 INFO epoch # 7279 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0033-> 0.0033 -loss = 0.003551181020156946
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:22,586 INFO epoch # 7280 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0033-> 0.0033 -loss = 0.003557524142706825
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:22,586 INFO *** epoch 7280, rolling-avg-loss (window=10)= 0.003577405622218066
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:22,608 INFO epoch # 7281 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0033-> 0.0033 -loss = 0.0035602824009401957
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:22,631 INFO epoch # 7282 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0033-> 0.0033 -loss = 0.0035461785291772685
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:22,653 INFO epoch # 7283 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0033-> 0.0033 -loss = 0.004334133285738062
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:22,675 INFO epoch # 7284 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0033-> 0.0033 -loss = 0.0035410937016422395
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:22,697 INFO epoch # 7285 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0033-> 0.0033 -loss = 0.0035489313863763527
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:22,719 INFO epoch # 7286 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0033-> 0.0033 -loss = 0.0035529313954612007
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:22,741 INFO epoch # 7287 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0033-> 0.0033 -loss = 0.0035776343229372287
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:22,762 INFO epoch # 7288 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0033-> 0.0033 -loss = 0.0035589471353887348
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:22,783 INFO epoch # 7289 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0033-> 0.0033 -loss = 0.003540388294368313
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:22,804 INFO epoch # 7290 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0033-> 0.0033 -loss = 0.003548882360519201
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:22,804 INFO *** epoch 7290, rolling-avg-loss (window=10)= 0.0036309402812548797
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:22,826 INFO epoch # 7291 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0033-> 0.0033 -loss = 0.003541564270562958
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:22,848 INFO epoch # 7292 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0033-> 0.0033 -loss = 0.0035764288004429545
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:22,870 INFO epoch # 7293 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0033-> 0.0033 -loss = 0.0035489295642037177
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:22,891 INFO epoch # 7294 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0033-> 0.0033 -loss = 0.0035909116431867005
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:22,913 INFO epoch # 7295 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0033-> 0.0033 -loss = 0.0035441841255305917
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:22,935 INFO epoch # 7296 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0033-> 0.0033 -loss = 0.0035573329751059646
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:22,956 INFO epoch # 7297 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0033-> 0.0033 -loss = 0.0035523316746548517
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:22,977 INFO epoch # 7298 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0033-> 0.0033 -loss = 0.0035404167419983423
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:22,998 INFO epoch # 7299 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0033-> 0.0033 -loss = 0.0035485151602188125
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:23,019 INFO epoch # 7300 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0033-> 0.0033 -loss = 0.0036199677670083474
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:23,020 INFO *** epoch 7300, rolling-avg-loss (window=10)= 0.003562058272291324
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:23,041 INFO epoch # 7301 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0033-> 0.0033 -loss = 0.0036358763245516457
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:23,063 INFO epoch # 7302 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0033-> 0.0033 -loss = 0.003539119604283769
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:23,085 INFO epoch # 7303 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0033-> 0.0033 -loss = 0.003956802843276819
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:23,107 INFO epoch # 7304 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0033-> 0.0033 -loss = 0.003565156913282408
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:23,129 INFO epoch # 7305 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0033-> 0.0033 -loss = 0.0035829399566864595
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:23,151 INFO epoch # 7306 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0033-> 0.0033 -loss = 0.004228054755003541
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:23,173 INFO epoch # 7307 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0033-> 0.0033 -loss = 0.0035374013700675278
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:23,195 INFO epoch # 7308 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0033-> 0.0033 -loss = 0.0035365775484024198
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:23,216 INFO epoch # 7309 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0033-> 0.0033 -loss = 0.0035699686104635475
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:23,238 INFO epoch # 7310 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0033-> 0.0033 -loss = 0.0035447017708065687
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:23,238 INFO *** epoch 7310, rolling-avg-loss (window=10)= 0.0036696599696824706
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:23,261 INFO epoch # 7311 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0033-> 0.0033 -loss = 0.0036269937936594943
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:23,283 INFO epoch # 7312 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0033-> 0.0033 -loss = 0.0037183264876148314
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:23,304 INFO epoch # 7313 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0033-> 0.0033 -loss = 0.003568353289665538
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:23,326 INFO epoch # 7314 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0033-> 0.0033 -loss = 0.0035367566829336283
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:23,348 INFO epoch # 7315 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0033-> 0.0033 -loss = 0.00425512047331722
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:23,370 INFO epoch # 7316 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0033-> 0.0033 -loss = 0.003561044266461977
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:23,392 INFO epoch # 7317 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0033-> 0.0033 -loss = 0.0035454431490506977
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:23,413 INFO epoch # 7318 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0033-> 0.0033 -loss = 0.0035347099210412125
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:23,434 INFO epoch # 7319 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0033-> 0.0033 -loss = 0.004224995381264307
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:23,455 INFO epoch # 7320 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0033-> 0.0033 -loss = 0.004241847874254745
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:23,455 INFO *** epoch 7320, rolling-avg-loss (window=10)= 0.003781359131926365
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:23,477 INFO epoch # 7321 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0033-> 0.0033 -loss = 0.0035623532603494823
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:23,498 INFO epoch # 7322 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0033-> 0.0033 -loss = 0.003589683477912331
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:23,520 INFO epoch # 7323 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0033-> 0.0033 -loss = 0.0036381190602696734
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:23,541 INFO epoch # 7324 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0033-> 0.0033 -loss = 0.0035355913987586973
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:23,563 INFO epoch # 7325 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0033-> 0.0033 -loss = 0.0036144623127256637
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:23,585 INFO epoch # 7326 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0033-> 0.0033 -loss = 0.0035720666382985655
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:23,607 INFO epoch # 7327 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0033-> 0.0033 -loss = 0.004265395356924273
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:23,629 INFO epoch # 7328 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0033-> 0.0033 -loss = 0.0035485153885019827
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:23,651 INFO epoch # 7329 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0033-> 0.0032 -loss = 0.0035379632827243768
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:23,672 INFO epoch # 7330 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0032-> 0.0032 -loss = 0.0035419861978880363
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:23,672 INFO *** epoch 7330, rolling-avg-loss (window=10)= 0.003640613637435308
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:23,693 INFO epoch # 7331 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0032-> 0.0032 -loss = 0.003569264132238459
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:23,715 INFO epoch # 7332 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0032-> 0.0032 -loss = 0.0035486395863699727
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:23,736 INFO epoch # 7333 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0032-> 0.0032 -loss = 0.003540397331562417
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:23,759 INFO epoch # 7334 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0032-> 0.0032 -loss = 0.003538190305334865
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:23,780 INFO epoch # 7335 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0032-> 0.0032 -loss = 0.0036433498025871813
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:23,802 INFO epoch # 7336 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0032-> 0.0032 -loss = 0.003534497936925618
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:23,823 INFO epoch # 7337 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0032-> 0.0032 -loss = 0.0036010379481012933
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:23,844 INFO epoch # 7338 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0032-> 0.0032 -loss = 0.0035334887693352357
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:23,865 INFO epoch # 7339 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0032-> 0.0032 -loss = 0.003545105226294254
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:23,886 INFO epoch # 7340 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0032-> 0.0032 -loss = 0.0035601886766016833
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:23,887 INFO *** epoch 7340, rolling-avg-loss (window=10)= 0.003561415971535098
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:23,908 INFO epoch # 7341 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0032-> 0.0032 -loss = 0.003560357232345268
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:23,929 INFO epoch # 7342 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0032-> 0.0032 -loss = 0.0036568804334820015
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:23,951 INFO epoch # 7343 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0032-> 0.0032 -loss = 0.0035382086116442224
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:23,973 INFO epoch # 7344 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0032-> 0.0032 -loss = 0.0035968986467196373
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:23,995 INFO epoch # 7345 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0032-> 0.0032 -loss = 0.0035882144038623665
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:24,017 INFO epoch # 7346 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0032-> 0.0032 -loss = 0.003912357762601459
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:24,039 INFO epoch # 7347 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0032-> 0.0032 -loss = 0.003528948868279258
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:24,060 INFO epoch # 7348 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0032-> 0.0032 -loss = 0.003531465426021896
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:24,081 INFO epoch # 7349 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0032-> 0.0032 -loss = 0.003545061188560794
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:24,102 INFO epoch # 7350 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0032-> 0.0032 -loss = 0.003531648914758989
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:24,102 INFO *** epoch 7350, rolling-avg-loss (window=10)= 0.0035990041488275894
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:24,124 INFO epoch # 7351 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0032-> 0.0032 -loss = 0.0035501150905474788
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:24,145 INFO epoch # 7352 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0032-> 0.0032 -loss = 0.0035488414996507345
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:24,166 INFO epoch # 7353 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0032-> 0.0032 -loss = 0.003932997097763291
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:24,188 INFO epoch # 7354 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0032-> 0.0032 -loss = 0.0035372276324778795
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:24,209 INFO epoch # 7355 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0032-> 0.0032 -loss = 0.004014182239188813
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:24,232 INFO epoch # 7356 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0032-> 0.0032 -loss = 0.003535992071192595
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:24,253 INFO epoch # 7357 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0032-> 0.0032 -loss = 0.0035424616744421655
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:24,275 INFO epoch # 7358 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0032-> 0.0032 -loss = 0.0035311984793224838
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:24,296 INFO epoch # 7359 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0032-> 0.0032 -loss = 0.0035265619662823156
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:24,317 INFO epoch # 7360 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0032-> 0.0032 -loss = 0.0035416675673332065
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:24,317 INFO *** epoch 7360, rolling-avg-loss (window=10)= 0.0036261245318200963
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:24,338 INFO epoch # 7361 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0032-> 0.0032 -loss = 0.00352742196082545
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:24,360 INFO epoch # 7362 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0032-> 0.0032 -loss = 0.003536101616191445
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:24,381 INFO epoch # 7363 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0032-> 0.0032 -loss = 0.003647727403404133
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:24,403 INFO epoch # 7364 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0032-> 0.0032 -loss = 0.0035351257247384638
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:24,425 INFO epoch # 7365 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0032-> 0.0032 -loss = 0.003542073907738086
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:24,447 INFO epoch # 7366 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0032-> 0.0032 -loss = 0.00352254686958986
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:24,468 INFO epoch # 7367 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0032-> 0.0032 -loss = 0.003521415255136162
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:24,490 INFO epoch # 7368 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0032-> 0.0032 -loss = 0.0035239078188169515
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:24,511 INFO epoch # 7369 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0032-> 0.0032 -loss = 0.0039921076477185125
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:24,532 INFO epoch # 7370 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0032-> 0.0032 -loss = 0.004737253962048271
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:24,532 INFO *** epoch 7370, rolling-avg-loss (window=10)= 0.0037085682166207333
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:24,553 INFO epoch # 7371 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0032-> 0.0032 -loss = 0.0035473012658258085
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:24,575 INFO epoch # 7372 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0032-> 0.0032 -loss = 0.0035347475813978235
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:24,597 INFO epoch # 7373 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0032-> 0.0032 -loss = 0.004372604044874606
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:24,619 INFO epoch # 7374 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0032-> 0.0032 -loss = 0.0035241377236161497
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:24,641 INFO epoch # 7375 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0032-> 0.0032 -loss = 0.003570811076770042
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:24,663 INFO epoch # 7376 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0032-> 0.0032 -loss = 0.0036193689429637743
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:24,684 INFO epoch # 7377 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0032-> 0.0032 -loss = 0.0035304167640788364
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:24,705 INFO epoch # 7378 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0032-> 0.0032 -loss = 0.004462421906282543
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:24,726 INFO epoch # 7379 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0032-> 0.0032 -loss = 0.0035240421952948964
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:24,748 INFO epoch # 7380 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0032-> 0.0032 -loss = 0.004194074876977538
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:24,748 INFO *** epoch 7380, rolling-avg-loss (window=10)= 0.0037879926378082017
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:24,770 INFO epoch # 7381 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0032-> 0.0032 -loss = 0.0035411989601925598
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:24,792 INFO epoch # 7382 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0032-> 0.0032 -loss = 0.0035255439706816105
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:24,814 INFO epoch # 7383 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0032-> 0.0032 -loss = 0.0036500163296295796
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:24,836 INFO epoch # 7384 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0032-> 0.0032 -loss = 0.0035597046717157355
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:24,858 INFO epoch # 7385 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0032-> 0.0032 -loss = 0.0035351671003809315
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:24,880 INFO epoch # 7386 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0032-> 0.0032 -loss = 0.0035458289794405573
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:24,901 INFO epoch # 7387 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0032-> 0.0032 -loss = 0.003523690659676504
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:24,922 INFO epoch # 7388 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0032-> 0.0032 -loss = 0.0035248854728706647
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:24,943 INFO epoch # 7389 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0032-> 0.0031 -loss = 0.0036222965445631417
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:24,964 INFO epoch # 7390 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.0036118895368417725
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:24,964 INFO *** epoch 7390, rolling-avg-loss (window=10)= 0.0035640222225993058
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:24,985 INFO epoch # 7391 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.0036402295663719997
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:25,008 INFO epoch # 7392 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.0035773488189079217
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:25,030 INFO epoch # 7393 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.003974400307924952
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:25,052 INFO epoch # 7394 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.0035506541480572196
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:25,074 INFO epoch # 7395 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.0035168152203368663
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:25,096 INFO epoch # 7396 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.003956829910748638
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:25,117 INFO epoch # 7397 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.004257429283825331
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:25,138 INFO epoch # 7398 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.003525649076436821
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:25,159 INFO epoch # 7399 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.003526880627759965
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:25,180 INFO epoch # 7400 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.0035304308112245053
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:25,180 INFO *** epoch 7400, rolling-avg-loss (window=10)= 0.003705666777159422
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:25,201 INFO epoch # 7401 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.0035254227805125993
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:25,223 INFO epoch # 7402 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.0035338624056748813
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:25,245 INFO epoch # 7403 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.0035252114248578437
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:25,267 INFO epoch # 7404 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.003528084625941119
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:25,289 INFO epoch # 7405 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.0035247675186838023
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:25,311 INFO epoch # 7406 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.0035183791196686798
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:25,333 INFO epoch # 7407 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.0035230429220973747
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:25,354 INFO epoch # 7408 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.0035157443435309688
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:25,376 INFO epoch # 7409 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.003549846953319502
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:25,397 INFO epoch # 7410 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.0035174389922758564
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:25,397 INFO *** epoch 7410, rolling-avg-loss (window=10)= 0.0035261801086562627
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:25,419 INFO epoch # 7411 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.0035283447459732997
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:25,441 INFO epoch # 7412 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.003520515545460512
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:25,463 INFO epoch # 7413 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.0035413032601354644
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:25,484 INFO epoch # 7414 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.0036078254652238684
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:25,506 INFO epoch # 7415 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.00425093941976229
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:25,528 INFO epoch # 7416 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.0035127770379403955
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:25,549 INFO epoch # 7417 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.0035846698920067865
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:25,570 INFO epoch # 7418 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.0035110232192892
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:25,591 INFO epoch # 7419 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.004185489133305964
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:25,613 INFO epoch # 7420 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.0035145693755112006
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:25,613 INFO *** epoch 7420, rolling-avg-loss (window=10)= 0.0036757457094608982
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:25,634 INFO epoch # 7421 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.003516038926136389
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:25,656 INFO epoch # 7422 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.003543151231497177
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:25,678 INFO epoch # 7423 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.003518461054227373
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:25,700 INFO epoch # 7424 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.003535886717145331
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:25,722 INFO epoch # 7425 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.003576712626454537
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:25,744 INFO epoch # 7426 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.003534249977747095
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:25,765 INFO epoch # 7427 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.0039497722555097425
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:25,787 INFO epoch # 7428 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.0035735984274651855
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:25,808 INFO epoch # 7429 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.003527113160089357
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:25,829 INFO epoch # 7430 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.0036099247881793417
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:25,829 INFO *** epoch 7430, rolling-avg-loss (window=10)= 0.003588490916445153
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:25,850 INFO epoch # 7431 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.0035091770846520376
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:25,872 INFO epoch # 7432 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.003520149901305558
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:25,894 INFO epoch # 7433 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.0035095501316391164
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:25,916 INFO epoch # 7434 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.003571945625481021
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:25,938 INFO epoch # 7435 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.00374294983157597
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:25,960 INFO epoch # 7436 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.003518286826874828
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:25,981 INFO epoch # 7437 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.004247396458595176
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:26,002 INFO epoch # 7438 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.0035154164779669372
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:26,023 INFO epoch # 7439 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.0035850556578225223
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:26,045 INFO epoch # 7440 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.003522038563460228
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:26,045 INFO *** epoch 7440, rolling-avg-loss (window=10)= 0.0036241966559373397
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:26,066 INFO epoch # 7441 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.0035092601938231383
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:26,088 INFO epoch # 7442 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.00392129458123236
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:26,110 INFO epoch # 7443 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.0035153470671502873
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:26,132 INFO epoch # 7444 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.003542732050846098
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:26,154 INFO epoch # 7445 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.0035049007735779014
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:26,176 INFO epoch # 7446 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.0035110705393890385
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:26,198 INFO epoch # 7447 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.0035141993375873426
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:26,220 INFO epoch # 7448 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.003516143414344697
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:26,241 INFO epoch # 7449 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.003512403088279825
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:26,263 INFO epoch # 7450 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.003528145412929007
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:26,263 INFO *** epoch 7450, rolling-avg-loss (window=10)= 0.0035575496459159693
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:26,285 INFO epoch # 7451 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.0035282351564092096
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:26,307 INFO epoch # 7452 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.00357701151551737
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:26,328 INFO epoch # 7453 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.003508003808747162
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:26,350 INFO epoch # 7454 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.004705620698587154
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:26,372 INFO epoch # 7455 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.0035056151364187826
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:26,394 INFO epoch # 7456 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.003504133978367463
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:26,415 INFO epoch # 7457 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.0035556615930545377
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:26,436 INFO epoch # 7458 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.0035070501926384168
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:26,457 INFO epoch # 7459 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.003535326590281329
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:26,478 INFO epoch # 7460 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.003508643654640764
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:26,478 INFO *** epoch 7460, rolling-avg-loss (window=10)= 0.003643530232466219
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:26,499 INFO epoch # 7461 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.0035252952238806756
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:26,521 INFO epoch # 7462 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.0035607908030215185
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:26,544 INFO epoch # 7463 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.003525766540406039
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:26,565 INFO epoch # 7464 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.003517478895446402
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:26,588 INFO epoch # 7465 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.0035679996835824568
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:26,610 INFO epoch # 7466 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.003513286283123307
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:26,632 INFO epoch # 7467 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.003 -loss = 0.003513286825182149
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:26,653 INFO epoch # 7468 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.003-> 0.003 -loss = 0.003574565358576365
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:26,674 INFO epoch # 7469 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.003-> 0.003 -loss = 0.003504867127048783
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:26,695 INFO epoch # 7470 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.003-> 0.003 -loss = 0.004144460534007521
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:26,695 INFO *** epoch 7470, rolling-avg-loss (window=10)= 0.0035947797274275216
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:26,716 INFO epoch # 7471 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.003-> 0.003 -loss = 0.003517480734444689
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:26,738 INFO epoch # 7472 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.003-> 0.003 -loss = 0.0035191606748412596
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:26,760 INFO epoch # 7473 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.003-> 0.003 -loss = 0.0035455258166621206
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:26,782 INFO epoch # 7474 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.003-> 0.003 -loss = 0.0035093800597678637
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:26,804 INFO epoch # 7475 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.003-> 0.003 -loss = 0.003512357807267108
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:26,826 INFO epoch # 7476 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.003-> 0.003 -loss = 0.003688635350044933
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:26,847 INFO epoch # 7477 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.003-> 0.003 -loss = 0.0035451412295515183
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:26,868 INFO epoch # 7478 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.003-> 0.003 -loss = 0.003505296435832861
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:26,889 INFO epoch # 7479 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.003-> 0.003 -loss = 0.003520827673128224
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:26,910 INFO epoch # 7480 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.003-> 0.003 -loss = 0.0035845864294969942
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:26,910 INFO *** epoch 7480, rolling-avg-loss (window=10)= 0.003544839221103757
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:26,931 INFO epoch # 7481 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.003-> 0.003 -loss = 0.003505324858451786
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:26,953 INFO epoch # 7482 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.003-> 0.003 -loss = 0.0035021045932808192
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:26,975 INFO epoch # 7483 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.003-> 0.003 -loss = 0.0035145855445080088
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:26,997 INFO epoch # 7484 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.003-> 0.003 -loss = 0.0035026697723878897
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:27,019 INFO epoch # 7485 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.003-> 0.003 -loss = 0.0035586262838478433
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:27,041 INFO epoch # 7486 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.003-> 0.003 -loss = 0.004683028309045767
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:27,062 INFO epoch # 7487 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.003-> 0.003 -loss = 0.003519032788972254
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:27,083 INFO epoch # 7488 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.003-> 0.003 -loss = 0.0035000619773200015
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:27,104 INFO epoch # 7489 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.003-> 0.003 -loss = 0.0035041840637859423
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:27,125 INFO epoch # 7490 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.003-> 0.003 -loss = 0.0035113316644128645
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:27,125 INFO *** epoch 7490, rolling-avg-loss (window=10)= 0.0036300949856013175
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:27,147 INFO epoch # 7491 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.003-> 0.003 -loss = 0.003500995690046693
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:27,168 INFO epoch # 7492 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.003-> 0.003 -loss = 0.0035162977874279022
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:27,190 INFO epoch # 7493 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.003-> 0.003 -loss = 0.0035228998567617964
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:27,211 INFO epoch # 7494 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.003-> 0.003 -loss = 0.003526694393258367
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:27,233 INFO epoch # 7495 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.003-> 0.003 -loss = 0.0034977458126377314
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:27,255 INFO epoch # 7496 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.003-> 0.003 -loss = 0.0035395174636505544
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:27,277 INFO epoch # 7497 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.003-> 0.003 -loss = 0.003503377807646757
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:27,298 INFO epoch # 7498 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.003-> 0.003 -loss = 0.0035654822386277374
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:27,319 INFO epoch # 7499 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.003-> 0.003 -loss = 0.00354277842961892
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:27,340 INFO epoch # 7500 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.003-> 0.003 -loss = 0.0034988264374078426
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:27,340 INFO *** epoch 7500, rolling-avg-loss (window=10)= 0.00352146159170843
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:27,362 INFO epoch # 7501 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.003-> 0.003 -loss = 0.0035158167866029544
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:27,384 INFO epoch # 7502 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.003-> 0.003 -loss = 0.0035289774950797437
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:27,405 INFO epoch # 7503 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.003-> 0.003 -loss = 0.0035405134894972434
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:27,427 INFO epoch # 7504 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.003-> 0.003 -loss = 0.003492728824767255
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:27,449 INFO epoch # 7505 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.003-> 0.003 -loss = 0.003609041244999389
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:27,471 INFO epoch # 7506 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.003-> 0.003 -loss = 0.0035014625000258093
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:27,492 INFO epoch # 7507 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.003-> 0.003 -loss = 0.0035293257042212645
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:27,514 INFO epoch # 7508 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.003-> 0.003 -loss = 0.0035031409006478498
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:27,535 INFO epoch # 7509 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.003-> 0.003 -loss = 0.0041254347288486315
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:27,556 INFO epoch # 7510 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.003-> 0.003 -loss = 0.003521352064126404
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:27,556 INFO *** epoch 7510, rolling-avg-loss (window=10)= 0.0035867793738816544
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:27,578 INFO epoch # 7511 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.003-> 0.003 -loss = 0.0034947964923048858
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:27,600 INFO epoch # 7512 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.003-> 0.003 -loss = 0.003536371643349412
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:27,622 INFO epoch # 7513 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.003-> 0.003 -loss = 0.0035300569488754263
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:27,644 INFO epoch # 7514 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.003-> 0.003 -loss = 0.003618276585257263
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:27,665 INFO epoch # 7515 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.003-> 0.003 -loss = 0.003556977988409926
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:27,687 INFO epoch # 7516 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.003-> 0.003 -loss = 0.0035066044983977918
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:27,708 INFO epoch # 7517 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.003-> 0.003 -loss = 0.0035367461041460047
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:27,730 INFO epoch # 7518 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.003-> 0.003 -loss = 0.003490380060611642
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:27,751 INFO epoch # 7519 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.003-> 0.003 -loss = 0.0034950445933645824
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:27,772 INFO epoch # 7520 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.003-> 0.003 -loss = 0.0034908393763544154
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:27,772 INFO *** epoch 7520, rolling-avg-loss (window=10)= 0.003525609429107135
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:27,794 INFO epoch # 7521 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.003-> 0.003 -loss = 0.0035290438408992486
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:27,816 INFO epoch # 7522 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.003-> 0.003 -loss = 0.0034950545013998635
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:27,838 INFO epoch # 7523 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.003-> 0.003 -loss = 0.0035153847911715275
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:27,860 INFO epoch # 7524 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.003-> 0.003 -loss = 0.0035737615489779273
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:27,882 INFO epoch # 7525 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.003-> 0.003 -loss = 0.0035457940603009774
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:27,903 INFO epoch # 7526 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.003-> 0.003 -loss = 0.003515101139782928
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:27,924 INFO epoch # 7527 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.003-> 0.003 -loss = 0.0035482076309563126
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:27,946 INFO epoch # 7528 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.003-> 0.003 -loss = 0.003536908648129611
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:27,967 INFO epoch # 7529 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.003-> 0.0029 -loss = 0.004684626379457768
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:27,988 INFO epoch # 7530 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0029-> 0.0029 -loss = 0.0035376841706238338
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:27,988 INFO *** epoch 7530, rolling-avg-loss (window=10)= 0.00364815667117
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:28,010 INFO epoch # 7531 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0029-> 0.0029 -loss = 0.004136272331379587
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:28,032 INFO epoch # 7532 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0029-> 0.0029 -loss = 0.003524998310240335
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:28,053 INFO epoch # 7533 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0029-> 0.0029 -loss = 0.0034855590620281873
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:28,075 INFO epoch # 7534 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0029-> 0.0029 -loss = 0.003925261515178136
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:28,097 INFO epoch # 7535 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0029-> 0.0029 -loss = 0.004141923155657423
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:28,119 INFO epoch # 7536 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0029-> 0.0029 -loss = 0.003509863797262369
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:28,140 INFO epoch # 7537 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0029-> 0.0029 -loss = 0.004166716396866832
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:28,161 INFO epoch # 7538 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0029-> 0.0029 -loss = 0.0035141925400239415
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:28,182 INFO epoch # 7539 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0029-> 0.0029 -loss = 0.0034937001355501707
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:28,203 INFO epoch # 7540 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0029-> 0.0029 -loss = 0.003533074816004955
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:28,203 INFO *** epoch 7540, rolling-avg-loss (window=10)= 0.0037431562060191935
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:28,225 INFO epoch # 7541 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0029-> 0.0029 -loss = 0.0035212076400057413
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:28,247 INFO epoch # 7542 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0029-> 0.0029 -loss = 0.0034935620224132435
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:28,269 INFO epoch # 7543 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0029-> 0.0029 -loss = 0.0034840575776797778
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:28,291 INFO epoch # 7544 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0029-> 0.0029 -loss = 0.003493303031063988
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:28,313 INFO epoch # 7545 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0029-> 0.0029 -loss = 0.003565328594049788
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:28,335 INFO epoch # 7546 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0029-> 0.0029 -loss = 0.0034848612526729994
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:28,357 INFO epoch # 7547 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0029-> 0.0029 -loss = 0.003510166608975851
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:28,378 INFO epoch # 7548 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0029-> 0.0029 -loss = 0.0035146553882441367
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:28,399 INFO epoch # 7549 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0029-> 0.0029 -loss = 0.003488973366074788
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:28,421 INFO epoch # 7550 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0029-> 0.0029 -loss = 0.0035181212497263914
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:28,421 INFO *** epoch 7550, rolling-avg-loss (window=10)= 0.0035074236730906704
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:28,443 INFO epoch # 7551 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0029-> 0.0029 -loss = 0.003504618947772542
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:28,464 INFO epoch # 7552 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0029-> 0.0029 -loss = 0.003500402084682719
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:28,486 INFO epoch # 7553 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0029-> 0.0029 -loss = 0.0035224842686147895
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:28,508 INFO epoch # 7554 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0029-> 0.0029 -loss = 0.003484928903162654
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:28,530 INFO epoch # 7555 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0029-> 0.0029 -loss = 0.003552763437255635
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:28,552 INFO epoch # 7556 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0029-> 0.0029 -loss = 0.003513095827656798
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:28,574 INFO epoch # 7557 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0029-> 0.0029 -loss = 0.00356045664557314
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:28,596 INFO epoch # 7558 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0029-> 0.0029 -loss = 0.003504237217384798
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:28,618 INFO epoch # 7559 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0029-> 0.0029 -loss = 0.0038642959716526093
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:28,639 INFO epoch # 7560 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0029-> 0.0029 -loss = 0.003525513258864521
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:28,639 INFO *** epoch 7560, rolling-avg-loss (window=10)= 0.0035532796562620208
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:28,661 INFO epoch # 7561 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0029-> 0.0029 -loss = 0.0034914504321932327
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:28,683 INFO epoch # 7562 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0029-> 0.0029 -loss = 0.0035301336538395844
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:28,704 INFO epoch # 7563 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0029-> 0.0029 -loss = 0.0035011739873880288
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:28,726 INFO epoch # 7564 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0029-> 0.0029 -loss = 0.003479183123090479
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:28,749 INFO epoch # 7565 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0029-> 0.0029 -loss = 0.0034945599854836473
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:28,771 INFO epoch # 7566 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0029-> 0.0029 -loss = 0.0034851607006203267
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:28,792 INFO epoch # 7567 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0029-> 0.0029 -loss = 0.0034974926293216413
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:28,814 INFO epoch # 7568 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0029-> 0.0029 -loss = 0.003537341855917475
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:28,835 INFO epoch # 7569 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0029-> 0.0029 -loss = 0.003507175804770668
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:28,856 INFO epoch # 7570 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0029-> 0.0029 -loss = 0.003496835587611713
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:28,856 INFO *** epoch 7570, rolling-avg-loss (window=10)= 0.00350205077602368
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:28,877 INFO epoch # 7571 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0029-> 0.0029 -loss = 0.003490080991468858
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:28,899 INFO epoch # 7572 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0029-> 0.0029 -loss = 0.0046642091911053285
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:28,921 INFO epoch # 7573 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0029-> 0.0029 -loss = 0.003499341594761063
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:28,942 INFO epoch # 7574 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0029-> 0.0029 -loss = 0.0035052258435825934
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:28,964 INFO epoch # 7575 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0029-> 0.0029 -loss = 0.0038526093139807926
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:28,986 INFO epoch # 7576 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0029-> 0.0029 -loss = 0.003530533464072505
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:29,008 INFO epoch # 7577 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0029-> 0.0029 -loss = 0.004211732612020569
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:29,029 INFO epoch # 7578 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0029-> 0.0029 -loss = 0.003492216700578865
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:29,050 INFO epoch # 7579 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0029-> 0.0029 -loss = 0.004119036342672189
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:29,073 INFO epoch # 7580 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0029-> 0.0029 -loss = 0.0034824621870939154
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:29,073 INFO *** epoch 7580, rolling-avg-loss (window=10)= 0.003784744824133668
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:29,096 INFO epoch # 7581 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0029-> 0.0029 -loss = 0.0034962357676704414
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:29,118 INFO epoch # 7582 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0029-> 0.0029 -loss = 0.003486124465780449
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:29,140 INFO epoch # 7583 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0029-> 0.0029 -loss = 0.0034860108635257347
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:29,161 INFO epoch # 7584 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0029-> 0.0029 -loss = 0.0034813196089089615
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:29,183 INFO epoch # 7585 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0029-> 0.0029 -loss = 0.003473406315606553
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:29,205 INFO epoch # 7586 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0029-> 0.0029 -loss = 0.003521096681652125
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:29,226 INFO epoch # 7587 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0029-> 0.0029 -loss = 0.0034768591153806483
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:29,248 INFO epoch # 7588 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0029-> 0.0029 -loss = 0.0034756655632008915
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:29,269 INFO epoch # 7589 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0029-> 0.0029 -loss = 0.003492630852633738
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:29,291 INFO epoch # 7590 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0029-> 0.0029 -loss = 0.003478168627680134
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:29,291 INFO *** epoch 7590, rolling-avg-loss (window=10)= 0.0034867517862039676
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:29,313 INFO epoch # 7591 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0029-> 0.0029 -loss = 0.003506199107505381
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:29,334 INFO epoch # 7592 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0029-> 0.0029 -loss = 0.004433060899827979
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:29,356 INFO epoch # 7593 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0029-> 0.0029 -loss = 0.0034815189319488127
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:29,378 INFO epoch # 7594 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0029-> 0.0029 -loss = 0.0034992710516235093
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:29,400 INFO epoch # 7595 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0029-> 0.0029 -loss = 0.0034770148668030743
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:29,422 INFO epoch # 7596 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0029-> 0.0028 -loss = 0.003557830903446302
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:29,444 INFO epoch # 7597 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.0034779440920829074
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:29,465 INFO epoch # 7598 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.0034916124741357635
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:29,486 INFO epoch # 7599 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.003475885708212445
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:29,507 INFO epoch # 7600 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.0034730768338704365
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:29,507 INFO *** epoch 7600, rolling-avg-loss (window=10)= 0.003587341486945661
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:29,528 INFO epoch # 7601 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.0035491007984091993
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:29,550 INFO epoch # 7602 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.003485039538645651
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:29,572 INFO epoch # 7603 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.0034719067516562063
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:29,594 INFO epoch # 7604 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.003479229359072633
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:29,616 INFO epoch # 7605 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.003472872293968976
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:29,638 INFO epoch # 7606 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.003475418790912954
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:29,659 INFO epoch # 7607 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.0034788292286975775
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:29,680 INFO epoch # 7608 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.0034731490713966195
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:29,701 INFO epoch # 7609 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.0038673178751196247
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:29,723 INFO epoch # 7610 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.00349390801784466
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:29,723 INFO *** epoch 7610, rolling-avg-loss (window=10)= 0.0035246771725724103
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:29,745 INFO epoch # 7611 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.0034761834886012366
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:29,767 INFO epoch # 7612 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.0035263831614429364
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:29,789 INFO epoch # 7613 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.0034765632399285096
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:29,810 INFO epoch # 7614 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.003470761120752286
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:29,832 INFO epoch # 7615 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.0034727905499494227
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:29,854 INFO epoch # 7616 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.003491667488560779
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:29,876 INFO epoch # 7617 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.003482979445834644
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:29,897 INFO epoch # 7618 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.003470291039775475
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:29,918 INFO epoch # 7619 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.0034736998177322675
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:29,939 INFO epoch # 7620 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.0034703759606600215
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:29,939 INFO *** epoch 7620, rolling-avg-loss (window=10)= 0.0034811695313237577
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:29,960 INFO epoch # 7621 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.0035370978112041485
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:29,982 INFO epoch # 7622 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.0035968609427072806
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:30,003 INFO epoch # 7623 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.004152672427153448
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:30,025 INFO epoch # 7624 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.003478238987554505
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:30,047 INFO epoch # 7625 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.003471379983238876
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:30,069 INFO epoch # 7626 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.003539271853696846
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:30,091 INFO epoch # 7627 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.0034761568904286833
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:30,112 INFO epoch # 7628 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.003482039277514559
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:30,134 INFO epoch # 7629 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.0034649674364573
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:30,155 INFO epoch # 7630 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.003468679056823021
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:30,155 INFO *** epoch 7630, rolling-avg-loss (window=10)= 0.0035667364666778665
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:30,176 INFO epoch # 7631 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.0034908940906461794
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:30,198 INFO epoch # 7632 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.0035082584854535526
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:30,219 INFO epoch # 7633 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.0034669697470235405
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:30,241 INFO epoch # 7634 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.003557174064553692
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:30,263 INFO epoch # 7635 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.003850801558655803
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:30,285 INFO epoch # 7636 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.004628856124327285
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:30,306 INFO epoch # 7637 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.0034940327359436196
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:30,327 INFO epoch # 7638 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.003479730438812112
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:30,348 INFO epoch # 7639 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.003502096000374877
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:30,370 INFO epoch # 7640 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.004088269519343157
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:30,370 INFO *** epoch 7640, rolling-avg-loss (window=10)= 0.003706708276513382
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:30,391 INFO epoch # 7641 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.0034675014917411318
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:30,413 INFO epoch # 7642 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.0034945100014738273
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:30,435 INFO epoch # 7643 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.0034752774135995423
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:30,456 INFO epoch # 7644 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.003483710483124014
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:30,478 INFO epoch # 7645 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.003484156122794957
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:30,500 INFO epoch # 7646 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.0035486410042722127
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:30,521 INFO epoch # 7647 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.00389817681752902
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:30,542 INFO epoch # 7648 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.0035068245670117904
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:30,564 INFO epoch # 7649 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.003487190244413796
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:30,585 INFO epoch # 7650 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.0034684492948144907
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:30,585 INFO *** epoch 7650, rolling-avg-loss (window=10)= 0.003531443744077478
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:30,606 INFO epoch # 7651 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.0034678431793508935
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:30,628 INFO epoch # 7652 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.0035159513827238698
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:30,651 INFO epoch # 7653 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.003495092868433858
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:30,673 INFO epoch # 7654 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.0035004941000806866
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:30,694 INFO epoch # 7655 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.0034670115519475075
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:30,716 INFO epoch # 7656 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.0034667986883505364
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:30,738 INFO epoch # 7657 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.004371254273792147
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:30,759 INFO epoch # 7658 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.0034814886003005086
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:30,780 INFO epoch # 7659 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.0035325623975950293
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:30,802 INFO epoch # 7660 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.003492095342153334
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:30,802 INFO *** epoch 7660, rolling-avg-loss (window=10)= 0.003579059238472837
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:30,823 INFO epoch # 7661 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.0034635524589248234
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:30,845 INFO epoch # 7662 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.0034851006039389176
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:30,867 INFO epoch # 7663 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.003471352063570521
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:30,889 INFO epoch # 7664 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.003461904408140981
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:30,911 INFO epoch # 7665 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.0034703380551945884
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:30,933 INFO epoch # 7666 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.003518356694257818
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:30,955 INFO epoch # 7667 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.0038659293195451028
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:30,976 INFO epoch # 7668 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.0034677150251809508
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:30,997 INFO epoch # 7669 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.003496862671454437
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:31,018 INFO epoch # 7670 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.003460546939550113
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:31,018 INFO *** epoch 7670, rolling-avg-loss (window=10)= 0.0035161658239758254
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:31,040 INFO epoch # 7671 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.003496097962852218
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:31,062 INFO epoch # 7672 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.0035519106168067083
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:31,084 INFO epoch # 7673 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.004393212581817352
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:31,106 INFO epoch # 7674 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.0034961423098138766
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:31,128 INFO epoch # 7675 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.003916955378372222
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:31,150 INFO epoch # 7676 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.0038960511392360786
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:31,171 INFO epoch # 7677 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.003498900397971738
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:31,192 INFO epoch # 7678 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.003539755406563927
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:31,213 INFO epoch # 7679 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.0034626672977537964
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:31,234 INFO epoch # 7680 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.003462339144789439
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:31,234 INFO *** epoch 7680, rolling-avg-loss (window=10)= 0.0036714032235977355
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:31,257 INFO epoch # 7681 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.0034603068838805484
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:31,279 INFO epoch # 7682 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.0039016719019855373
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:31,301 INFO epoch # 7683 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.0034820151176973013
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:31,323 INFO epoch # 7684 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.0034677848516366794
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:31,345 INFO epoch # 7685 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.003485458570139599
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:31,367 INFO epoch # 7686 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.0034686048438743455
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:31,388 INFO epoch # 7687 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.0035345006381248822
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:31,410 INFO epoch # 7688 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.0035116757317155134
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:31,431 INFO epoch # 7689 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.004147889787418535
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:31,453 INFO epoch # 7690 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.003493914828140987
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:31,453 INFO *** epoch 7690, rolling-avg-loss (window=10)= 0.003595382315461393
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:31,475 INFO epoch # 7691 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.0036295712652645307
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:31,497 INFO epoch # 7692 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.0034597574222061667
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:31,520 INFO epoch # 7693 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.0034687795832724078
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:31,542 INFO epoch # 7694 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.0034804286533471895
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:31,564 INFO epoch # 7695 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.0034949154760397505
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:31,586 INFO epoch # 7696 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.0034829736505344044
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:31,607 INFO epoch # 7697 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.004162495345553907
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:31,628 INFO epoch # 7698 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.003502879060761188
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:31,649 INFO epoch # 7699 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.0034703937390077044
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:31,670 INFO epoch # 7700 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.003458007372501015
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:31,670 INFO *** epoch 7700, rolling-avg-loss (window=10)= 0.0035610201568488263
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:31,692 INFO epoch # 7701 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.0035009759976674104
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:31,713 INFO epoch # 7702 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.00346681336122856
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:31,735 INFO epoch # 7703 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.003462897320787306
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:31,757 INFO epoch # 7704 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.0035037404186368803
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:31,780 INFO epoch # 7705 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.003461680913460441
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:31,801 INFO epoch # 7706 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.003462574186414713
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:31,823 INFO epoch # 7707 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.003509910851789755
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:31,844 INFO epoch # 7708 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.003465428728304687
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:31,865 INFO epoch # 7709 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.003474290379017475
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:31,886 INFO epoch # 7710 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.0034741492818284314
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:31,886 INFO *** epoch 7710, rolling-avg-loss (window=10)= 0.003478246143913566
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:31,908 INFO epoch # 7711 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.0034536490338723524
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:31,930 INFO epoch # 7712 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.0034804216847987846
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:31,951 INFO epoch # 7713 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.003621848210968892
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:31,973 INFO epoch # 7714 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.004604833187840995
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:31,995 INFO epoch # 7715 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.003535212221322581
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:32,017 INFO epoch # 7716 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.0034873904469350236
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:32,039 INFO epoch # 7717 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.0035022975171159487
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:32,060 INFO epoch # 7718 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.0034570949364933767
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:32,081 INFO epoch # 7719 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.003471768139206688
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:32,102 INFO epoch # 7720 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.0034673954087338643
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:32,102 INFO *** epoch 7720, rolling-avg-loss (window=10)= 0.003608191078728851
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:32,124 INFO epoch # 7721 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.0034566360445751343
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:32,145 INFO epoch # 7722 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0027 -loss = 0.003532359260134399
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:32,167 INFO epoch # 7723 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0027-> 0.0027 -loss = 0.0034685211703617824
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:32,189 INFO epoch # 7724 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0027-> 0.0027 -loss = 0.0034863748951465823
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:32,211 INFO epoch # 7725 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0027-> 0.0027 -loss = 0.0034537046176410513
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:32,233 INFO epoch # 7726 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0027-> 0.0027 -loss = 0.0034595464130688924
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:32,256 INFO epoch # 7727 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0027-> 0.0027 -loss = 0.0034626934793777764
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:32,277 INFO epoch # 7728 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0027-> 0.0027 -loss = 0.0034576359894344932
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:32,298 INFO epoch # 7729 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0027-> 0.0027 -loss = 0.0035006517537112813
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:32,320 INFO epoch # 7730 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0027-> 0.0027 -loss = 0.0035759462871283176
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:32,320 INFO *** epoch 7730, rolling-avg-loss (window=10)= 0.003485406991057971
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:32,341 INFO epoch # 7731 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0027-> 0.0027 -loss = 0.003455179260527075
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:32,363 INFO epoch # 7732 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0027-> 0.0027 -loss = 0.0038291294968075817
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:32,385 INFO epoch # 7733 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0027-> 0.0027 -loss = 0.0034675753395276843
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:32,407 INFO epoch # 7734 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0027-> 0.0027 -loss = 0.0035510312363840058
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:32,429 INFO epoch # 7735 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0027-> 0.0027 -loss = 0.0035040962720813695
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:32,451 INFO epoch # 7736 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0027-> 0.0027 -loss = 0.0034632339502422838
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:32,473 INFO epoch # 7737 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0027-> 0.0027 -loss = 0.0034613862771948334
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:32,494 INFO epoch # 7738 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0027-> 0.0027 -loss = 0.004190632978861686
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:32,515 INFO epoch # 7739 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0027-> 0.0027 -loss = 0.003560961382390815
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:32,536 INFO epoch # 7740 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0027-> 0.0027 -loss = 0.003454872445217916
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:32,536 INFO *** epoch 7740, rolling-avg-loss (window=10)= 0.003593809863923525
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:32,558 INFO epoch # 7741 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0027-> 0.0027 -loss = 0.003467127322437591
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:32,580 INFO epoch # 7742 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0027-> 0.0027 -loss = 0.0034462781882211857
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:32,602 INFO epoch # 7743 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0027-> 0.0027 -loss = 0.0034479917339922395
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:32,624 INFO epoch # 7744 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0027-> 0.0027 -loss = 0.0034508109083617455
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:32,646 INFO epoch # 7745 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0027-> 0.0027 -loss = 0.003494794302241644
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:32,668 INFO epoch # 7746 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0027-> 0.0027 -loss = 0.003476785212114919
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:32,689 INFO epoch # 7747 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0027-> 0.0027 -loss = 0.0034693311417868244
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:32,711 INFO epoch # 7748 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0027-> 0.0027 -loss = 0.003459801564531517
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:32,732 INFO epoch # 7749 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0027-> 0.0027 -loss = 0.0034547747200122103
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:32,753 INFO epoch # 7750 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0027-> 0.0027 -loss = 0.0034584878740133718
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:32,753 INFO *** epoch 7750, rolling-avg-loss (window=10)= 0.0034626182967713247
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:32,775 INFO epoch # 7751 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0027-> 0.0027 -loss = 0.0034462458888810943
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:32,797 INFO epoch # 7752 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0027-> 0.0027 -loss = 0.0034496202824811917
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:32,819 INFO epoch # 7753 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0027-> 0.0027 -loss = 0.003457011447608238
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:32,841 INFO epoch # 7754 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0027-> 0.0027 -loss = 0.0034611498640515492
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:32,862 INFO epoch # 7755 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0027-> 0.0027 -loss = 0.0035004279470740585
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:32,884 INFO epoch # 7756 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0027-> 0.0027 -loss = 0.004148229141719639
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:32,905 INFO epoch # 7757 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0027-> 0.0027 -loss = 0.003447981513090781
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:32,927 INFO epoch # 7758 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0027-> 0.0027 -loss = 0.003448790066613583
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:32,948 INFO epoch # 7759 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0027-> 0.0027 -loss = 0.003476478566881269
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:32,969 INFO epoch # 7760 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0027-> 0.0027 -loss = 0.003556306548489374
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:32,969 INFO *** epoch 7760, rolling-avg-loss (window=10)= 0.0035392241266890777
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:32,990 INFO epoch # 7761 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0027-> 0.0027 -loss = 0.00344598696256071
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:33,012 INFO epoch # 7762 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0027-> 0.0027 -loss = 0.0034857375831052195
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:33,034 INFO epoch # 7763 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0027-> 0.0027 -loss = 0.00345292128258734
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:33,056 INFO epoch # 7764 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0027-> 0.0027 -loss = 0.0034516781070124125
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:33,078 INFO epoch # 7765 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0027-> 0.0027 -loss = 0.0034587337722769007
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:33,100 INFO epoch # 7766 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0027-> 0.0027 -loss = 0.003446798331424361
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:33,121 INFO epoch # 7767 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0027-> 0.0027 -loss = 0.00344415802101139
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:33,142 INFO epoch # 7768 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0027-> 0.0027 -loss = 0.0034624313011590857
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:33,163 INFO epoch # 7769 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0027-> 0.0027 -loss = 0.0034855259336836752
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:33,184 INFO epoch # 7770 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0027-> 0.0027 -loss = 0.0034732659814835642
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:33,184 INFO *** epoch 7770, rolling-avg-loss (window=10)= 0.003460723727630466
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:33,206 INFO epoch # 7771 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0027-> 0.0027 -loss = 0.0034409611844239407
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:33,227 INFO epoch # 7772 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0027-> 0.0027 -loss = 0.0034424388968545827
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:33,250 INFO epoch # 7773 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0027-> 0.0027 -loss = 0.0034808122863978497
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:33,272 INFO epoch # 7774 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0027-> 0.0027 -loss = 0.003513878288686101
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:33,294 INFO epoch # 7775 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0027-> 0.0027 -loss = 0.0034557775707071414
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:33,316 INFO epoch # 7776 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0027-> 0.0027 -loss = 0.0034848157683882164
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:33,337 INFO epoch # 7777 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0027-> 0.0027 -loss = 0.005251556694929604
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:33,358 INFO epoch # 7778 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0027-> 0.0027 -loss = 0.004078585052411654
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:33,379 INFO epoch # 7779 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0027-> 0.0027 -loss = 0.0034689219428400975
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:33,400 INFO epoch # 7780 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0027-> 0.0027 -loss = 0.0034500387228035834
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:33,400 INFO *** epoch 7780, rolling-avg-loss (window=10)= 0.003706778640844277
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:33,421 INFO epoch # 7781 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0027-> 0.0027 -loss = 0.003448808700341033
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:33,443 INFO epoch # 7782 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0027-> 0.0026 -loss = 0.0034423194929331657
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:33,465 INFO epoch # 7783 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0026-> 0.0026 -loss = 0.0034540865362941986
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:33,487 INFO epoch # 7784 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0026-> 0.0026 -loss = 0.003439995754888514
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:33,509 INFO epoch # 7785 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0026-> 0.0026 -loss = 0.0034662104026210727
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:33,531 INFO epoch # 7786 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0026-> 0.0026 -loss = 0.0034406889872116153
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:33,552 INFO epoch # 7787 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0026-> 0.0026 -loss = 0.0034565076130093075
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:33,573 INFO epoch # 7788 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0026-> 0.0026 -loss = 0.0034376405683360645
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:33,594 INFO epoch # 7789 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0026-> 0.0026 -loss = 0.0034581523414090043
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:33,615 INFO epoch # 7790 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0026-> 0.0026 -loss = 0.003447367973421933
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:33,615 INFO *** epoch 7790, rolling-avg-loss (window=10)= 0.0034491778370465908
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:33,636 INFO epoch # 7791 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0026-> 0.0026 -loss = 0.0034421670807205373
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:33,658 INFO epoch # 7792 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0026-> 0.0026 -loss = 0.0034862040520238224
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:33,680 INFO epoch # 7793 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0026-> 0.0026 -loss = 0.0034446609133738093
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:33,701 INFO epoch # 7794 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0026-> 0.0026 -loss = 0.0034356940295765526
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:33,723 INFO epoch # 7795 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0026-> 0.0026 -loss = 0.0035056564956903458
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:33,746 INFO epoch # 7796 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0026-> 0.0026 -loss = 0.0035176056317141047
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:33,767 INFO epoch # 7797 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0026-> 0.0026 -loss = 0.0034375646823718853
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:33,788 INFO epoch # 7798 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0026-> 0.0026 -loss = 0.003447260860411916
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:33,809 INFO epoch # 7799 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0026-> 0.0026 -loss = 0.00345449887754512
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:33,831 INFO epoch # 7800 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0026-> 0.0026 -loss = 0.0034610399097800837
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:33,831 INFO *** epoch 7800, rolling-avg-loss (window=10)= 0.0034632352533208177
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:33,852 INFO epoch # 7801 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0026-> 0.0026 -loss = 0.003485529618046712
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:33,874 INFO epoch # 7802 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0026-> 0.0026 -loss = 0.0034520215922384523
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:33,896 INFO epoch # 7803 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0026-> 0.0026 -loss = 0.003492999445370515
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:33,918 INFO epoch # 7804 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0026-> 0.0026 -loss = 0.0034401331695335102
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:33,940 INFO epoch # 7805 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0026-> 0.0026 -loss = 0.003515688595143729
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:33,962 INFO epoch # 7806 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0026-> 0.0026 -loss = 0.00355610778387927
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:33,983 INFO epoch # 7807 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0026-> 0.0026 -loss = 0.003479051951217116
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:34,004 INFO epoch # 7808 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0026-> 0.0026 -loss = 0.0034739499969873577
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:34,026 INFO epoch # 7809 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0026-> 0.0026 -loss = 0.0034488485816837056
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:34,047 INFO epoch # 7810 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0026-> 0.0026 -loss = 0.0035499782188708195
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:34,047 INFO *** epoch 7810, rolling-avg-loss (window=10)= 0.0034894308952971185
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:34,068 INFO epoch # 7811 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0026-> 0.0026 -loss = 0.003441111792199081
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:34,089 INFO epoch # 7812 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0026-> 0.0026 -loss = 0.0034425737540004775
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:34,111 INFO epoch # 7813 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0026-> 0.0026 -loss = 0.003448515668424079
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:34,133 INFO epoch # 7814 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0026-> 0.0026 -loss = 0.003433699549532321
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:34,155 INFO epoch # 7815 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0026-> 0.0026 -loss = 0.003459511071923771
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:34,177 INFO epoch # 7816 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0026-> 0.0026 -loss = 0.0034619889065652387
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:34,198 INFO epoch # 7817 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0026-> 0.0026 -loss = 0.003450455620622961
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:34,219 INFO epoch # 7818 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0026-> 0.0026 -loss = 0.0034423956203681882
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:34,241 INFO epoch # 7819 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0026-> 0.0026 -loss = 0.0034883883972725016
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:34,263 INFO epoch # 7820 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0026-> 0.0026 -loss = 0.003515636134579836
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:34,263 INFO *** epoch 7820, rolling-avg-loss (window=10)= 0.0034584276515488453
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:34,285 INFO epoch # 7821 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0026-> 0.0026 -loss = 0.0034872476226155413
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:34,307 INFO epoch # 7822 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0026-> 0.0026 -loss = 0.003487394839794433
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:34,329 INFO epoch # 7823 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0026-> 0.0026 -loss = 0.0035472619092615787
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:34,350 INFO epoch # 7824 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0026-> 0.0026 -loss = 0.0034546746292107855
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:34,372 INFO epoch # 7825 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0026-> 0.0026 -loss = 0.0034554068834040663
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:34,394 INFO epoch # 7826 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0026-> 0.0026 -loss = 0.0034379363896732684
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:34,415 INFO epoch # 7827 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0026-> 0.0026 -loss = 0.0035360282781766728
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:34,436 INFO epoch # 7828 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0026-> 0.0026 -loss = 0.003446229632572795
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:34,457 INFO epoch # 7829 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0026-> 0.0026 -loss = 0.0034525584369475837
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:34,478 INFO epoch # 7830 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0026-> 0.0026 -loss = 0.0034367713788014953
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:34,479 INFO *** epoch 7830, rolling-avg-loss (window=10)= 0.003474151000045822
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:34,500 INFO epoch # 7831 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0026-> 0.0026 -loss = 0.0034303495467611356
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:34,522 INFO epoch # 7832 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0026-> 0.0026 -loss = 0.003456819287748658
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:34,543 INFO epoch # 7833 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0026-> 0.0026 -loss = 0.003431327621001401
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:34,566 INFO epoch # 7834 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0026-> 0.0026 -loss = 0.0034511940102675
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:34,588 INFO epoch # 7835 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0026-> 0.0026 -loss = 0.003450285466897185
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:34,610 INFO epoch # 7836 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0026-> 0.0026 -loss = 0.0034935559842779185
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:34,631 INFO epoch # 7837 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0026-> 0.0026 -loss = 0.0034262133083302615
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:34,653 INFO epoch # 7838 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0026-> 0.0026 -loss = 0.0034306695770283113
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:34,674 INFO epoch # 7839 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0026-> 0.0026 -loss = 0.0034316371211389196
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:34,695 INFO epoch # 7840 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0026-> 0.0026 -loss = 0.0034325759652347188
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:34,695 INFO *** epoch 7840, rolling-avg-loss (window=10)= 0.003443462788868601
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:34,716 INFO epoch # 7841 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0026-> 0.0026 -loss = 0.0034378884702164214
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:34,739 INFO epoch # 7842 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0026-> 0.0026 -loss = 0.0036549454816849902
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:34,761 INFO epoch # 7843 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0026-> 0.0026 -loss = 0.003538832608683151
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:34,783 INFO epoch # 7844 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0026-> 0.0026 -loss = 0.0034591406238178024
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:34,805 INFO epoch # 7845 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0026-> 0.0026 -loss = 0.0034549440342743765
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:34,827 INFO epoch # 7846 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0026-> 0.0026 -loss = 0.003451689587564033
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:34,848 INFO epoch # 7847 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0026-> 0.0026 -loss = 0.003679092186757771
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:34,870 INFO epoch # 7848 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0026-> 0.0025 -loss = 0.003521869368341868
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:34,892 INFO epoch # 7849 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.0034534902060840977
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:34,914 INFO epoch # 7850 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.0034488022902223747
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:34,914 INFO *** epoch 7850, rolling-avg-loss (window=10)= 0.0035100694857646887
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:34,936 INFO epoch # 7851 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.0034285809142602375
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:34,959 INFO epoch # 7852 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.0034516038049332565
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:34,981 INFO epoch # 7853 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.0034331873512201128
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:35,003 INFO epoch # 7854 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.0034418233244650764
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:35,025 INFO epoch # 7855 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.003433156353821687
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:35,047 INFO epoch # 7856 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.0034394787708151853
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:35,068 INFO epoch # 7857 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.0034693580309976824
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:35,089 INFO epoch # 7858 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.0036058804107597098
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:35,110 INFO epoch # 7859 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.003431357081808528
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:35,131 INFO epoch # 7860 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.00343560317196534
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:35,131 INFO *** epoch 7860, rolling-avg-loss (window=10)= 0.0034570029215046814
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:35,153 INFO epoch # 7861 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.003432328864619194
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:35,174 INFO epoch # 7862 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.0034295675750399823
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:35,196 INFO epoch # 7863 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.0034798268561644363
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:35,218 INFO epoch # 7864 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.0034243180125486106
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:35,240 INFO epoch # 7865 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.0034295204595764517
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:35,263 INFO epoch # 7866 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.00347012027305027
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:35,284 INFO epoch # 7867 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.0034660723831621
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:35,305 INFO epoch # 7868 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.00342922428080783
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:35,326 INFO epoch # 7869 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.0034253387843818928
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:35,347 INFO epoch # 7870 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.0034215998907711764
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:35,348 INFO *** epoch 7870, rolling-avg-loss (window=10)= 0.0034407917380121942
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:35,369 INFO epoch # 7871 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.0034433380624250276
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:35,391 INFO epoch # 7872 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.0035565450198191684
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:35,413 INFO epoch # 7873 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.003489536182314623
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:35,435 INFO epoch # 7874 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.003471730564342579
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:35,457 INFO epoch # 7875 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.0035039698814216536
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:35,479 INFO epoch # 7876 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.003479111190245021
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:35,501 INFO epoch # 7877 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.003422015769956488
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:35,522 INFO epoch # 7878 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.0034207990204322414
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:35,544 INFO epoch # 7879 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.003515572930155031
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:35,565 INFO epoch # 7880 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.0034270085370735615
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:35,565 INFO *** epoch 7880, rolling-avg-loss (window=10)= 0.0034729627158185394
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:35,586 INFO epoch # 7881 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.003534825752467441
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:35,608 INFO epoch # 7882 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.0034624388408701634
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:35,629 INFO epoch # 7883 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.003444566673351801
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:35,651 INFO epoch # 7884 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.0034462802614143584
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:35,673 INFO epoch # 7885 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.003445572652708506
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:35,695 INFO epoch # 7886 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.003429237323871348
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:35,716 INFO epoch # 7887 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.003420447104872437
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:35,737 INFO epoch # 7888 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.0034285087749594823
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:35,760 INFO epoch # 7889 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.003423723056585004
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:35,781 INFO epoch # 7890 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.0034393837049719878
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:35,781 INFO *** epoch 7890, rolling-avg-loss (window=10)= 0.003447498414607253
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:35,802 INFO epoch # 7891 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.003431843555517844
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:35,824 INFO epoch # 7892 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.0034395876700727968
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:35,846 INFO epoch # 7893 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.0034444069697201485
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:35,868 INFO epoch # 7894 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.003429742640037148
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:35,890 INFO epoch # 7895 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.0035128186118527083
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:35,912 INFO epoch # 7896 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.003446001641350449
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:35,933 INFO epoch # 7897 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.0034345899748586817
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:35,954 INFO epoch # 7898 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.0034774473588186083
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:35,975 INFO epoch # 7899 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.0034362799488008022
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:35,997 INFO epoch # 7900 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.003513784998176561
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:35,997 INFO *** epoch 7900, rolling-avg-loss (window=10)= 0.0034566503369205747
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:36,019 INFO epoch # 7901 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.0034227142978124903
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:36,041 INFO epoch # 7902 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.0034183539946752717
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:36,063 INFO epoch # 7903 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.0034583095848574885
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:36,084 INFO epoch # 7904 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.0034338010163992294
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:36,106 INFO epoch # 7905 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.003442200841163867
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:36,128 INFO epoch # 7906 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.0041302144945802866
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:36,149 INFO epoch # 7907 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.003441607164859306
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:36,170 INFO epoch # 7908 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.004327270682551898
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:36,191 INFO epoch # 7909 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.003470553430815926
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:36,212 INFO epoch # 7910 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.003425703675020486
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:36,213 INFO *** epoch 7910, rolling-avg-loss (window=10)= 0.003597072918273625
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:36,234 INFO epoch # 7911 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.0034280974732610048
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:36,256 INFO epoch # 7912 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.003818142172349326
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:36,278 INFO epoch # 7913 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.003416235298573156
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:36,300 INFO epoch # 7914 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.003437408041463641
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:36,322 INFO epoch # 7915 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.0034261074142705183
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:36,344 INFO epoch # 7916 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.0034382363792246906
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:36,365 INFO epoch # 7917 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.003443636844167486
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:36,387 INFO epoch # 7918 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.00341558262516628
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:36,408 INFO epoch # 7919 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.003923873084204388
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:36,429 INFO epoch # 7920 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.0034826977953343885
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:36,429 INFO *** epoch 7920, rolling-avg-loss (window=10)= 0.003523001712801488
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:36,450 INFO epoch # 7921 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.00344050308012811
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:36,472 INFO epoch # 7922 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.003416560335608665
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:36,493 INFO epoch # 7923 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.00345064981138421
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:36,515 INFO epoch # 7924 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.0034581167183205253
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:36,537 INFO epoch # 7925 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.003436401326325722
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:36,559 INFO epoch # 7926 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.0034757036873998004
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:36,580 INFO epoch # 7927 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.003419622178626014
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:36,601 INFO epoch # 7928 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.0041127132208202966
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:36,623 INFO epoch # 7929 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.0034520417812018422
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:36,644 INFO epoch # 7930 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.003421185516344849
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:36,644 INFO *** epoch 7930, rolling-avg-loss (window=10)= 0.0035083497656160033
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:36,665 INFO epoch # 7931 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.0035135119205733645
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:36,687 INFO epoch # 7932 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.0034174227657786105
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:36,708 INFO epoch # 7933 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.003559157527888601
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:36,729 INFO epoch # 7934 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.0036848724348601536
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:36,751 INFO epoch # 7935 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.003437799277890008
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:36,773 INFO epoch # 7936 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.0034810585684681428
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:36,795 INFO epoch # 7937 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.0034665514763219107
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:36,816 INFO epoch # 7938 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.003522009793414327
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:36,837 INFO epoch # 7939 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.0034258267769473605
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:36,858 INFO epoch # 7940 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0024 -loss = 0.003424841517698951
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:36,858 INFO *** epoch 7940, rolling-avg-loss (window=10)= 0.003493305205984143
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:36,880 INFO epoch # 7941 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.0034147666174249025
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:36,901 INFO epoch # 7942 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.0034136469666918856
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:36,923 INFO epoch # 7943 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.0037753489468741463
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:36,945 INFO epoch # 7944 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.003424781676585553
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:36,967 INFO epoch # 7945 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.003468095483185607
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:36,989 INFO epoch # 7946 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.0034265057283846545
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:37,011 INFO epoch # 7947 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.003426826131544658
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:37,032 INFO epoch # 7948 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.0034569374884085846
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:37,053 INFO epoch # 7949 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.0035531156199795078
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:37,075 INFO epoch # 7950 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.0034178532550868113
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:37,075 INFO *** epoch 7950, rolling-avg-loss (window=10)= 0.003477787791416631
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:37,096 INFO epoch # 7951 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.0034693821289693005
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:37,118 INFO epoch # 7952 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.0036613466600101674
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:37,139 INFO epoch # 7953 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.003416002773519722
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:37,161 INFO epoch # 7954 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.003430764974837075
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:37,183 INFO epoch # 7955 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.0034317306481170817
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:37,205 INFO epoch # 7956 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.0035336540549906204
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:37,226 INFO epoch # 7957 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.003416848037886666
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:37,248 INFO epoch # 7958 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.004110809013582184
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:37,269 INFO epoch # 7959 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.0034256343606102746
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:37,291 INFO epoch # 7960 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.0034218817145301728
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:37,291 INFO *** epoch 7960, rolling-avg-loss (window=10)= 0.0035318054367053263
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:37,312 INFO epoch # 7961 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.0034093935983037227
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:37,335 INFO epoch # 7962 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.003502408624626696
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:37,357 INFO epoch # 7963 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.003408939307064429
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:37,379 INFO epoch # 7964 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.0034929327812278643
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:37,401 INFO epoch # 7965 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.0034301705582038267
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:37,423 INFO epoch # 7966 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.0035097575673717074
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:37,444 INFO epoch # 7967 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.003444427151407581
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:37,465 INFO epoch # 7968 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.0034149892489949707
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:37,486 INFO epoch # 7969 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.0035886149325961014
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:37,508 INFO epoch # 7970 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.003407926037652942
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:37,508 INFO *** epoch 7970, rolling-avg-loss (window=10)= 0.0034609559807449843
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:37,529 INFO epoch # 7971 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.003407241495551716
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:37,551 INFO epoch # 7972 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.004143599619055749
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:37,573 INFO epoch # 7973 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.0040422379825031385
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:37,595 INFO epoch # 7974 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.003484857748844661
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:37,617 INFO epoch # 7975 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.0034558925344754243
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:37,639 INFO epoch # 7976 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.00346656164219894
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:37,661 INFO epoch # 7977 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.003550046905729687
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:37,682 INFO epoch # 7978 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.0034367103762633633
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:37,703 INFO epoch # 7979 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.003408149971619423
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:37,725 INFO epoch # 7980 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.0034804552560672164
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:37,725 INFO *** epoch 7980, rolling-avg-loss (window=10)= 0.003587575353230932
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:37,746 INFO epoch # 7981 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.0034316220226173755
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:37,768 INFO epoch # 7982 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.004112055841687834
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:37,790 INFO epoch # 7983 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.0034069241883116774
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:37,812 INFO epoch # 7984 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.0034215093292004894
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:37,834 INFO epoch # 7985 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.0034119135616492713
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:37,856 INFO epoch # 7986 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.0034097386023859144
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:37,877 INFO epoch # 7987 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.003419861168367788
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:37,899 INFO epoch # 7988 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.0034028349136860925
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:37,920 INFO epoch # 7989 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.004090805324267421
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:37,941 INFO epoch # 7990 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.003427689933232614
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:37,941 INFO *** epoch 7990, rolling-avg-loss (window=10)= 0.003553495488540648
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:37,963 INFO epoch # 7991 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.0034190228652732912
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:37,984 INFO epoch # 7992 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.0034059026093018474
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:38,005 INFO epoch # 7993 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.00452719112035993
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:38,027 INFO epoch # 7994 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.0034291990432393504
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:38,049 INFO epoch # 7995 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.0034536599005150492
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:38,071 INFO epoch # 7996 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.0034269287771167
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:38,093 INFO epoch # 7997 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.0034699036805250216
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:38,114 INFO epoch # 7998 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.0034370099601801485
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:38,135 INFO epoch # 7999 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.003409738726077194
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:38,156 INFO epoch # 8000 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.003447916569712106
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:38,156 INFO *** epoch 8000, rolling-avg-loss (window=10)= 0.0035426473252300637
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:38,178 INFO epoch # 8001 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.0034028332870548184
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:38,199 INFO epoch # 8002 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.003440777462856204
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:38,221 INFO epoch # 8003 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.0034601833240230917
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:38,243 INFO epoch # 8004 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.00342560479293752
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:38,265 INFO epoch # 8005 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.003450672040344216
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:38,287 INFO epoch # 8006 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.004300772873648384
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:38,309 INFO epoch # 8007 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.003425622590839339
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:38,330 INFO epoch # 8008 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.0035169087605027016
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:38,351 INFO epoch # 8009 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.0034572412732813973
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:38,372 INFO epoch # 8010 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.0034103791886082035
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:38,373 INFO *** epoch 8010, rolling-avg-loss (window=10)= 0.0035290995594095876
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:38,395 INFO epoch # 8011 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.003419768501771614
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:38,416 INFO epoch # 8012 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.00341669964382163
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:38,438 INFO epoch # 8013 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.0034329438694840064
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:38,460 INFO epoch # 8014 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.003782888335081225
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:38,482 INFO epoch # 8015 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.003405806057344307
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:38,504 INFO epoch # 8016 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.003453768957115244
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:38,525 INFO epoch # 8017 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.00341954741270456
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:38,546 INFO epoch # 8018 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.0034282291253475705
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:38,568 INFO epoch # 8019 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.0034532515765022254
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:38,590 INFO epoch # 8020 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.003407658425203408
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:38,590 INFO *** epoch 8020, rolling-avg-loss (window=10)= 0.003462056190437579
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:38,612 INFO epoch # 8021 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0023 -loss = 0.0034434473573128344
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:38,634 INFO epoch # 8022 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.004061902098328574
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:38,655 INFO epoch # 8023 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.003400215811780072
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:38,677 INFO epoch # 8024 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.0034553942091406498
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:38,699 INFO epoch # 8025 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.0036305685625848128
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:38,721 INFO epoch # 8026 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.0034141178693971597
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:38,743 INFO epoch # 8027 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.003407636517295032
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:38,764 INFO epoch # 8028 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.00452462411203669
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:38,785 INFO epoch # 8029 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.0033968220341193955
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:38,806 INFO epoch # 8030 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.0033977142738876864
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:38,806 INFO *** epoch 8030, rolling-avg-loss (window=10)= 0.0036132442845882907
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:38,828 INFO epoch # 8031 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.003449183562224789
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:38,849 INFO epoch # 8032 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.0034440570898368605
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:38,871 INFO epoch # 8033 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.0034190322394351824
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:38,892 INFO epoch # 8034 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.0034118683161068475
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:38,914 INFO epoch # 8035 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.0034202540678052173
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:38,936 INFO epoch # 8036 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.0034194418349215994
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:38,957 INFO epoch # 8037 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.003421463097765809
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:38,978 INFO epoch # 8038 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.0033983662310674845
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:38,999 INFO epoch # 8039 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.003469783236141666
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:39,020 INFO epoch # 8040 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.003467132743480761
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:39,021 INFO *** epoch 8040, rolling-avg-loss (window=10)= 0.0034320582418786217
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:39,042 INFO epoch # 8041 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.003395375018953928
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:39,064 INFO epoch # 8042 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.004130243071813311
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:39,085 INFO epoch # 8043 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.003476751653579413
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:39,107 INFO epoch # 8044 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.003398643235414056
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:39,129 INFO epoch # 8045 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.003403545342735015
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:39,151 INFO epoch # 8046 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.0033998827611867455
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:39,172 INFO epoch # 8047 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.003469812963885488
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:39,194 INFO epoch # 8048 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.0034125766260331147
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:39,215 INFO epoch # 8049 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.0034358839475316927
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:39,236 INFO epoch # 8050 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.00339939098830655
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:39,236 INFO *** epoch 8050, rolling-avg-loss (window=10)= 0.0034922105609439314
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:39,258 INFO epoch # 8051 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.0033948918353416957
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:39,280 INFO epoch # 8052 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.003456127176832524
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:39,301 INFO epoch # 8053 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.0034162126321461983
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:39,323 INFO epoch # 8054 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.003415115677853464
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:39,345 INFO epoch # 8055 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.0034134615498260246
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:39,367 INFO epoch # 8056 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.004111575796741818
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:39,388 INFO epoch # 8057 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.003397313767891319
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:39,409 INFO epoch # 8058 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.0034205694082629634
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:39,431 INFO epoch # 8059 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.003394057511286519
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:39,452 INFO epoch # 8060 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.003392834926216892
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:39,452 INFO *** epoch 8060, rolling-avg-loss (window=10)= 0.0034812160282399417
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:39,473 INFO epoch # 8061 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.003430771479543182
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:39,494 INFO epoch # 8062 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.0034889192174887285
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:39,516 INFO epoch # 8063 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.003393940442492749
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:39,538 INFO epoch # 8064 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.003394469540580758
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:39,560 INFO epoch # 8065 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.004087054916453781
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:39,581 INFO epoch # 8066 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.003442837668444554
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:39,603 INFO epoch # 8067 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.003414918333874084
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:39,624 INFO epoch # 8068 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.00339774953226879
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:39,645 INFO epoch # 8069 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.0034240607365063624
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:39,666 INFO epoch # 8070 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.0034504229079175275
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:39,667 INFO *** epoch 8070, rolling-avg-loss (window=10)= 0.0034925144775570516
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:39,688 INFO epoch # 8071 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.003408649901757599
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:39,710 INFO epoch # 8072 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.003397058626433136
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:39,732 INFO epoch # 8073 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.0033952015182876494
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:39,754 INFO epoch # 8074 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.003410102188354358
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:39,776 INFO epoch # 8075 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.003397098598725279
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:39,798 INFO epoch # 8076 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.003431518161960412
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:39,819 INFO epoch # 8077 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.0033890589611473843
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:39,840 INFO epoch # 8078 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.0035009340972464997
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:39,861 INFO epoch # 8079 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.003468382408755133
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:39,883 INFO epoch # 8080 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.0034159748729507555
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:39,883 INFO *** epoch 8080, rolling-avg-loss (window=10)= 0.0034213979335618204
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:39,904 INFO epoch # 8081 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.0034097827892765054
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:39,925 INFO epoch # 8082 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.0034034957898256835
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:39,947 INFO epoch # 8083 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.0045237540234666085
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:39,969 INFO epoch # 8084 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.0034325145488764974
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:39,991 INFO epoch # 8085 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.0034604260326887015
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:40,013 INFO epoch # 8086 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.0038424450140155386
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:40,034 INFO epoch # 8087 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.003421235445784987
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:40,056 INFO epoch # 8088 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.003388105263638863
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:40,077 INFO epoch # 8089 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.0034127162653021514
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:40,098 INFO epoch # 8090 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.003405707535421243
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:40,098 INFO *** epoch 8090, rolling-avg-loss (window=10)= 0.003570018270829678
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:40,119 INFO epoch # 8091 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.003393287070139195
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:40,141 INFO epoch # 8092 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.00348541465245944
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:40,163 INFO epoch # 8093 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.003396829784833244
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:40,185 INFO epoch # 8094 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.0034107332012354163
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:40,207 INFO epoch # 8095 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.004283156609744765
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:40,230 INFO epoch # 8096 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.0033900131502377917
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:40,252 INFO epoch # 8097 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.003397211408810108
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:40,273 INFO epoch # 8098 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.003417322811401391
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:40,295 INFO epoch # 8099 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.0034102031031579827
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:40,316 INFO epoch # 8100 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.003419525064600748
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:40,316 INFO *** epoch 8100, rolling-avg-loss (window=10)= 0.003500369685662008
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:40,337 INFO epoch # 8101 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.003389633830920502
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:40,359 INFO epoch # 8102 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.003401997124456102
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:40,381 INFO epoch # 8103 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.003462728429440176
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:40,403 INFO epoch # 8104 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.0035329843376530334
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:40,425 INFO epoch # 8105 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.0034105932063539512
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:40,447 INFO epoch # 8106 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.0033942193585971836
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:40,468 INFO epoch # 8107 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.003383704789030162
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:40,490 INFO epoch # 8108 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.0034052943519782275
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:40,511 INFO epoch # 8109 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.0034666765423025936
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:40,532 INFO epoch # 8110 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.003390254252735758
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:40,532 INFO *** epoch 8110, rolling-avg-loss (window=10)= 0.003423808622346769
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:40,553 INFO epoch # 8111 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.003406947616895195
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:40,575 INFO epoch # 8112 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.0033983689536398742
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:40,597 INFO epoch # 8113 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.003412063309951918
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:40,619 INFO epoch # 8114 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.003387972629752767
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:40,641 INFO epoch # 8115 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.0033905536902238964
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:40,663 INFO epoch # 8116 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.00346597575389751
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:40,684 INFO epoch # 8117 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.003460101503151236
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:40,705 INFO epoch # 8118 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0022 -loss = 0.0034882396130342386
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:40,726 INFO epoch # 8119 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0022-> 0.0022 -loss = 0.003424599477511947
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:40,748 INFO epoch # 8120 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0022-> 0.0022 -loss = 0.003479076269286452
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:40,748 INFO *** epoch 8120, rolling-avg-loss (window=10)= 0.0034313898817345035
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:40,770 INFO epoch # 8121 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0022-> 0.0022 -loss = 0.0033946555749935214
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:40,792 INFO epoch # 8122 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0022-> 0.0022 -loss = 0.0034256623484907323
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:40,814 INFO epoch # 8123 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0022-> 0.0022 -loss = 0.0034066694879584247
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:40,836 INFO epoch # 8124 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0022-> 0.0022 -loss = 0.003381898320185428
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:40,858 INFO epoch # 8125 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0022-> 0.0022 -loss = 0.0034026765442831675
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:40,880 INFO epoch # 8126 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0022-> 0.0022 -loss = 0.0034042476308968617
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:40,901 INFO epoch # 8127 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0022-> 0.0022 -loss = 0.0034033710307994625
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:40,922 INFO epoch # 8128 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0022-> 0.0022 -loss = 0.003408804916034569
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:40,943 INFO epoch # 8129 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0022-> 0.0022 -loss = 0.003407624180908897
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:40,965 INFO epoch # 8130 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0022-> 0.0022 -loss = 0.0033867523434309987
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:40,965 INFO *** epoch 8130, rolling-avg-loss (window=10)= 0.0034022362377982064
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:40,986 INFO epoch # 8131 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0022-> 0.0022 -loss = 0.0033980279013121617
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:41,008 INFO epoch # 8132 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0022-> 0.0022 -loss = 0.00339812535821693
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:41,030 INFO epoch # 8133 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0022-> 0.0022 -loss = 0.004077638197486522
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:41,052 INFO epoch # 8134 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0022-> 0.0022 -loss = 0.0033928030243259855
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:41,073 INFO epoch # 8135 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0022-> 0.0022 -loss = 0.0033939771992663736
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:41,095 INFO epoch # 8136 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0022-> 0.0022 -loss = 0.003796083017732599
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:41,116 INFO epoch # 8137 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0022-> 0.0022 -loss = 0.0034354529962001834
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:41,138 INFO epoch # 8138 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0022-> 0.0022 -loss = 0.004495497103562229
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:41,159 INFO epoch # 8139 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0022-> 0.0022 -loss = 0.003386925991435419
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:41,180 INFO epoch # 8140 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0022-> 0.0022 -loss = 0.003393727130969637
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:41,180 INFO *** epoch 8140, rolling-avg-loss (window=10)= 0.003616825792050804
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:41,202 INFO epoch # 8141 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0022-> 0.0022 -loss = 0.0038766874349676073
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:41,223 INFO epoch # 8142 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0022-> 0.0022 -loss = 0.0035106904706481146
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:41,246 INFO epoch # 8143 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0022-> 0.0022 -loss = 0.003384442225069506
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:41,268 INFO epoch # 8144 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0022-> 0.0022 -loss = 0.0033849427236418705
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:41,290 INFO epoch # 8145 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0022-> 0.0022 -loss = 0.0033846080932562472
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:41,312 INFO epoch # 8146 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0022-> 0.0022 -loss = 0.0034048053530568723
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:41,333 INFO epoch # 8147 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0022-> 0.0022 -loss = 0.0033838865983852884
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:41,354 INFO epoch # 8148 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0022-> 0.0022 -loss = 0.0033905410282386583
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:41,375 INFO epoch # 8149 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0022-> 0.0022 -loss = 0.0033884646682054154
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:41,397 INFO epoch # 8150 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0022-> 0.0022 -loss = 0.0034033860447379993
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:41,397 INFO *** epoch 8150, rolling-avg-loss (window=10)= 0.003451245464020758
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:41,418 INFO epoch # 8151 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0022-> 0.0022 -loss = 0.00342568588348513
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:41,440 INFO epoch # 8152 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0022-> 0.0022 -loss = 0.003387678963918006
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:41,462 INFO epoch # 8153 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0022-> 0.0022 -loss = 0.0034658271842999966
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:41,483 INFO epoch # 8154 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0022-> 0.0022 -loss = 0.003407983404031256
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:41,505 INFO epoch # 8155 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0022-> 0.0022 -loss = 0.003399486775379046
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:41,526 INFO epoch # 8156 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0022-> 0.0022 -loss = 0.0034264365895069204
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:41,547 INFO epoch # 8157 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0022-> 0.0022 -loss = 0.0033778685969991784
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:41,569 INFO epoch # 8158 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0022-> 0.0022 -loss = 0.003404757995667751
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:41,590 INFO epoch # 8159 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0022-> 0.0022 -loss = 0.0033891741795741837
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:41,611 INFO epoch # 8160 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0022-> 0.0022 -loss = 0.0033800919463828905
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:41,611 INFO *** epoch 8160, rolling-avg-loss (window=10)= 0.003406499151924436
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:41,632 INFO epoch # 8161 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0022-> 0.0022 -loss = 0.004077327231243544
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:41,654 INFO epoch # 8162 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0022-> 0.0022 -loss = 0.0033782559460178163
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:41,676 INFO epoch # 8163 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0022-> 0.0022 -loss = 0.003391332644241629
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:41,698 INFO epoch # 8164 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0022-> 0.0022 -loss = 0.0034527957623140537
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:41,720 INFO epoch # 8165 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0022-> 0.0022 -loss = 0.0034013701533694984
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:41,742 INFO epoch # 8166 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0022-> 0.0022 -loss = 0.0033770185132198094
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:41,764 INFO epoch # 8167 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0022-> 0.0022 -loss = 0.003383038070751354
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:41,785 INFO epoch # 8168 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0022-> 0.0022 -loss = 0.0034167163830716163
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:41,806 INFO epoch # 8169 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0022-> 0.0022 -loss = 0.0033836142383734114
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:41,827 INFO epoch # 8170 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0022-> 0.0022 -loss = 0.003409032364288578
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:41,827 INFO *** epoch 8170, rolling-avg-loss (window=10)= 0.003467050130689131
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:41,849 INFO epoch # 8171 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0022-> 0.0022 -loss = 0.003391691706383426
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:41,870 INFO epoch # 8172 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0022-> 0.0022 -loss = 0.003384507674127235
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:41,891 INFO epoch # 8173 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0022-> 0.0022 -loss = 0.0034053227172989864
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:41,913 INFO epoch # 8174 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0022-> 0.0022 -loss = 0.003387344491784461
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:41,935 INFO epoch # 8175 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0022-> 0.0022 -loss = 0.0035631962446132093
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:41,957 INFO epoch # 8176 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0022-> 0.0022 -loss = 0.003427110028496827
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:41,978 INFO epoch # 8177 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0022-> 0.0022 -loss = 0.003383969416972832
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:41,999 INFO epoch # 8178 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0022-> 0.0022 -loss = 0.0034044068033836083
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:42,021 INFO epoch # 8179 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0022-> 0.0022 -loss = 0.003385429659829242
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:42,042 INFO epoch # 8180 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0022-> 0.0022 -loss = 0.003440815018620924
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:42,042 INFO *** epoch 8180, rolling-avg-loss (window=10)= 0.003417379376151075
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:42,063 INFO epoch # 8181 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0022-> 0.0022 -loss = 0.003383006894182472
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:42,085 INFO epoch # 8182 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0022-> 0.0022 -loss = 0.0033740310491339187
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:42,107 INFO epoch # 8183 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0022-> 0.0022 -loss = 0.003378793129741098
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:42,129 INFO epoch # 8184 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0022-> 0.0022 -loss = 0.0033819610143837053
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:42,150 INFO epoch # 8185 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0022-> 0.0022 -loss = 0.003375490035068651
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:42,173 INFO epoch # 8186 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0022-> 0.0022 -loss = 0.003390849393326789
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:42,194 INFO epoch # 8187 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0022-> 0.0022 -loss = 0.0033756059574443498
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:42,215 INFO epoch # 8188 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0022-> 0.0022 -loss = 0.0033805884331741254
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:42,236 INFO epoch # 8189 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0022-> 0.0022 -loss = 0.003436268546465726
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:42,259 INFO epoch # 8190 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0022-> 0.0022 -loss = 0.0034000997147813905
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:42,259 INFO *** epoch 8190, rolling-avg-loss (window=10)= 0.0033876694167702228
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:42,281 INFO epoch # 8191 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0022-> 0.0022 -loss = 0.003409527222174802
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:42,303 INFO epoch # 8192 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0022-> 0.0022 -loss = 0.003425340504691121
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:42,325 INFO epoch # 8193 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0022-> 0.0021 -loss = 0.004056429013871821
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:42,347 INFO epoch # 8194 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.003390117448361707
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:42,369 INFO epoch # 8195 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.0033956795141421026
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:42,391 INFO epoch # 8196 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.0034086640507666743
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:42,412 INFO epoch # 8197 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.003481954777271312
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:42,434 INFO epoch # 8198 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.0033938771193788853
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:42,455 INFO epoch # 8199 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.003389408804650884
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:42,476 INFO epoch # 8200 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.0033743728445188026
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:42,476 INFO *** epoch 8200, rolling-avg-loss (window=10)= 0.0034725371299828113
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:42,497 INFO epoch # 8201 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.003517263634421397
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:42,519 INFO epoch # 8202 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.003438968192313041
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:42,541 INFO epoch # 8203 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.0033912547369254753
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:42,563 INFO epoch # 8204 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.0033839115603768732
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:42,585 INFO epoch # 8205 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.003426111014050548
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:42,607 INFO epoch # 8206 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.0033690111615669593
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:42,629 INFO epoch # 8207 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.003370649390035396
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:42,650 INFO epoch # 8208 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.0033702945465847733
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:42,671 INFO epoch # 8209 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.003378472303666058
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:42,692 INFO epoch # 8210 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.0033771819089452038
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:42,692 INFO *** epoch 8210, rolling-avg-loss (window=10)= 0.0034023118448885726
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:42,714 INFO epoch # 8211 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.003377244009243441
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:42,735 INFO epoch # 8212 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.003377224390533229
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:42,757 INFO epoch # 8213 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.0037474159189514467
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:42,779 INFO epoch # 8214 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.0033785509931476554
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:42,801 INFO epoch # 8215 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.004269006912181794
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:42,823 INFO epoch # 8216 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.003382669883649214
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:42,844 INFO epoch # 8217 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.003388013000403589
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:42,865 INFO epoch # 8218 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.003371417408743582
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:42,886 INFO epoch # 8219 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.003396892294404097
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:42,907 INFO epoch # 8220 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.003369949452462606
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:42,907 INFO *** epoch 8220, rolling-avg-loss (window=10)= 0.0035058384263720655
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:42,929 INFO epoch # 8221 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.0033912245326064294
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:42,950 INFO epoch # 8222 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.003995833207227406
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:42,972 INFO epoch # 8223 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.003412113825106644
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:42,993 INFO epoch # 8224 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.003373241671397409
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:43,015 INFO epoch # 8225 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.0033704754869177123
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:43,037 INFO epoch # 8226 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.0034447338066456723
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:43,058 INFO epoch # 8227 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.003376602347998414
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:43,080 INFO epoch # 8228 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.004010890110293985
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:43,101 INFO epoch # 8229 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.003439365937083494
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:43,122 INFO epoch # 8230 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.004029855190310627
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:43,122 INFO *** epoch 8230, rolling-avg-loss (window=10)= 0.0035844336115587795
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:43,143 INFO epoch # 8231 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.003378848343345453
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:43,165 INFO epoch # 8232 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.0033958382841774437
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:43,187 INFO epoch # 8233 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.0033761374606910977
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:43,209 INFO epoch # 8234 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.003782563413551543
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:43,231 INFO epoch # 8235 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.003400690657144878
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:43,254 INFO epoch # 8236 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.0034042127399516176
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:43,275 INFO epoch # 8237 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.0033790183060773415
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:43,296 INFO epoch # 8238 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.003386190401215572
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:43,317 INFO epoch # 8239 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.0033643942408616567
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:43,338 INFO epoch # 8240 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.003370433887539548
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:43,338 INFO *** epoch 8240, rolling-avg-loss (window=10)= 0.003423832773455615
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:43,360 INFO epoch # 8241 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.003478207039734116
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:43,382 INFO epoch # 8242 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.003438275614826125
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:43,404 INFO epoch # 8243 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.0033852753522296553
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:43,426 INFO epoch # 8244 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.0034026148832708714
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:43,448 INFO epoch # 8245 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.0033792756712500704
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:43,470 INFO epoch # 8246 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.003379415975359734
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:43,492 INFO epoch # 8247 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.0034158506805397337
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:43,514 INFO epoch # 8248 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.0033658686361377477
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:43,535 INFO epoch # 8249 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.0033768751700335997
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:43,556 INFO epoch # 8250 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.003378878830517351
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:43,556 INFO *** epoch 8250, rolling-avg-loss (window=10)= 0.0034000537853899004
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:43,578 INFO epoch # 8251 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.003368205570950522
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:43,599 INFO epoch # 8252 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.0034028550408038427
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:43,621 INFO epoch # 8253 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.0033775585106923245
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:43,643 INFO epoch # 8254 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.003373867082700599
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:43,665 INFO epoch # 8255 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.0033811135954238125
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:43,687 INFO epoch # 8256 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.0033762492948881118
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:43,708 INFO epoch # 8257 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.0034063476141454885
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:43,729 INFO epoch # 8258 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.0033893078589244396
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:43,750 INFO epoch # 8259 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.003400996874916018
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:43,772 INFO epoch # 8260 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.003393577377210022
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:43,772 INFO *** epoch 8260, rolling-avg-loss (window=10)= 0.003387007882065518
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:43,793 INFO epoch # 8261 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.002 -loss = 0.003367573639479815
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:43,815 INFO epoch # 8262 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.0033722121333994437
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:43,837 INFO epoch # 8263 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.003377217747583927
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:43,859 INFO epoch # 8264 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.0033881767321872758
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:43,881 INFO epoch # 8265 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.0033822864206740633
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:43,903 INFO epoch # 8266 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.0033840881351352436
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:43,924 INFO epoch # 8267 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.003380969356840069
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:43,945 INFO epoch # 8268 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.0034046236196445534
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:43,967 INFO epoch # 8269 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.0033705122796163778
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:43,988 INFO epoch # 8270 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.0033900931011885405
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:43,988 INFO *** epoch 8270, rolling-avg-loss (window=10)= 0.003381775316574931
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:44,009 INFO epoch # 8271 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.0033920311652764212
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:44,031 INFO epoch # 8272 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.00338302423733694
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:44,053 INFO epoch # 8273 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.003380452546480228
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:44,074 INFO epoch # 8274 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.0033650857549218927
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:44,096 INFO epoch # 8275 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.0033747671941455337
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:44,118 INFO epoch # 8276 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.0033766925198506215
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:44,140 INFO epoch # 8277 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.0034529801159806084
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:44,161 INFO epoch # 8278 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.003408858523471281
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:44,182 INFO epoch # 8279 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.003436488711486163
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:44,203 INFO epoch # 8280 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.0033640155770626734
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:44,203 INFO *** epoch 8280, rolling-avg-loss (window=10)= 0.0033934396346012364
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:44,224 INFO epoch # 8281 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.0033611639669288707
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:44,248 INFO epoch # 8282 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.0033633502443990437
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:44,270 INFO epoch # 8283 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.003411498251807643
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:44,292 INFO epoch # 8284 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.0033726893616403686
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:44,314 INFO epoch # 8285 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.003359827175927421
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:44,336 INFO epoch # 8286 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.003372609790403658
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:44,357 INFO epoch # 8287 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.003406828316656174
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:44,378 INFO epoch # 8288 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.003586430015275255
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:44,399 INFO epoch # 8289 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.003387835552530305
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:44,420 INFO epoch # 8290 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.0033962172074097907
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:44,420 INFO *** epoch 8290, rolling-avg-loss (window=10)= 0.003401844988297853
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:44,442 INFO epoch # 8291 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.0033615727443248034
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:44,464 INFO epoch # 8292 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.003372637977008708
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:44,486 INFO epoch # 8293 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.0033853236982395174
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:44,508 INFO epoch # 8294 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.0034086412360920804
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:44,529 INFO epoch # 8295 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.0034678196425375063
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:44,551 INFO epoch # 8296 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.003375414489710238
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:44,572 INFO epoch # 8297 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.0033932162205019267
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:44,593 INFO epoch # 8298 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.004089578652383352
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:44,614 INFO epoch # 8299 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.0033676941702651675
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:44,635 INFO epoch # 8300 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.003378585174687032
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:44,635 INFO *** epoch 8300, rolling-avg-loss (window=10)= 0.003460048400575033
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:44,657 INFO epoch # 8301 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.0034589721835800447
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:44,678 INFO epoch # 8302 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.0033886575229189475
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:44,700 INFO epoch # 8303 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.003424500661822094
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:44,722 INFO epoch # 8304 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.0033999772276729345
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:44,744 INFO epoch # 8305 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.003402619535336271
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:44,766 INFO epoch # 8306 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.0034337252254772466
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:44,787 INFO epoch # 8307 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.0033663104359220597
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:44,808 INFO epoch # 8308 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.0034032352814392652
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:44,830 INFO epoch # 8309 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.003380855887371581
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:44,859 INFO epoch # 8310 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.003429341046285117
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:44,859 INFO *** epoch 8310, rolling-avg-loss (window=10)= 0.003408819500782556
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:44,882 INFO epoch # 8311 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.003390753042367578
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:44,904 INFO epoch # 8312 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.0033718122485879576
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:44,926 INFO epoch # 8313 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.0033945470713661052
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:44,948 INFO epoch # 8314 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.0033587242378416704
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:44,969 INFO epoch # 8315 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.0034275830857950496
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:44,991 INFO epoch # 8316 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.00335452303056627
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:45,012 INFO epoch # 8317 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.004130458513827762
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:45,033 INFO epoch # 8318 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.003385109520422702
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:45,055 INFO epoch # 8319 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.003361453906109091
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:45,076 INFO epoch # 8320 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.0033644998284216854
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:45,076 INFO *** epoch 8320, rolling-avg-loss (window=10)= 0.003453946448530587
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:45,098 INFO epoch # 8321 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.003365559926351125
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:45,120 INFO epoch # 8322 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.0033988697978202254
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:45,142 INFO epoch # 8323 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.0033675630093057407
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:45,163 INFO epoch # 8324 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.0033731861221895088
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:45,185 INFO epoch # 8325 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.0033974115121964132
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:45,207 INFO epoch # 8326 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.0033743768617569003
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:45,228 INFO epoch # 8327 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.0034018153237411752
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:45,250 INFO epoch # 8328 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.0033861371193779632
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:45,272 INFO epoch # 8329 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.004011878932033142
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:45,294 INFO epoch # 8330 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.0033745794571586885
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:45,294 INFO *** epoch 8330, rolling-avg-loss (window=10)= 0.003445137806193088
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:45,316 INFO epoch # 8331 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.0033784950101107825
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:45,338 INFO epoch # 8332 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.0033661285297057475
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:45,360 INFO epoch # 8333 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.003355322291099583
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:45,382 INFO epoch # 8334 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.0033571200274309376
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:45,404 INFO epoch # 8335 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.003364162782418134
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:45,427 INFO epoch # 8336 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.0033807265190262115
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:45,449 INFO epoch # 8337 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.003385456006071763
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:45,470 INFO epoch # 8338 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.0019 -loss = 0.0033725911443980294
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:45,491 INFO epoch # 8339 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0019 -loss = 0.0033741956340236356
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:45,513 INFO epoch # 8340 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0019 -loss = 0.0033619380792515585
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:45,513 INFO *** epoch 8340, rolling-avg-loss (window=10)= 0.0033696136023536384
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:45,535 INFO epoch # 8341 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0019 -loss = 0.003352558574079012
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:45,557 INFO epoch # 8342 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0019 -loss = 0.004241645472575328
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:45,579 INFO epoch # 8343 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0019 -loss = 0.0033715485706125037
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:45,601 INFO epoch # 8344 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0019 -loss = 0.003366349645148148
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:45,623 INFO epoch # 8345 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0019 -loss = 0.003364496966241859
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:45,645 INFO epoch # 8346 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0019 -loss = 0.003374317686393624
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:45,666 INFO epoch # 8347 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0019 -loss = 0.0033541112070452073
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:45,687 INFO epoch # 8348 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0019 -loss = 0.0033695751499180915
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:45,708 INFO epoch # 8349 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0019 -loss = 0.0035507546926965006
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:45,730 INFO epoch # 8350 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0019 -loss = 0.0033644118357187835
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:45,730 INFO *** epoch 8350, rolling-avg-loss (window=10)= 0.003470976980042906
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:45,752 INFO epoch # 8351 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0019 -loss = 0.0033828891105258663
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:45,775 INFO epoch # 8352 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0019 -loss = 0.0033643534734437708
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:45,797 INFO epoch # 8353 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0019 -loss = 0.0033613497553233174
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:45,819 INFO epoch # 8354 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0019 -loss = 0.0033828278592409333
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:45,841 INFO epoch # 8355 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0019 -loss = 0.003356487106429995
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:45,862 INFO epoch # 8356 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0019 -loss = 0.0033623529907345073
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:45,884 INFO epoch # 8357 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0019 -loss = 0.0033966705104830908
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:45,905 INFO epoch # 8358 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0019 -loss = 0.003351768996253668
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:45,926 INFO epoch # 8359 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0019 -loss = 0.0033727342779457103
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:45,947 INFO epoch # 8360 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0019 -loss = 0.0033780470375859295
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:45,947 INFO *** epoch 8360, rolling-avg-loss (window=10)= 0.003370948111796679
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:45,969 INFO epoch # 8361 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0019 -loss = 0.003367322779922688
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:45,991 INFO epoch # 8362 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0019 -loss = 0.003374456608980836
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:46,012 INFO epoch # 8363 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0019 -loss = 0.0034011218394880416
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:46,035 INFO epoch # 8364 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0019 -loss = 0.0033643414490143186
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:46,057 INFO epoch # 8365 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0019 -loss = 0.0033557296883373056
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:46,078 INFO epoch # 8366 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0019 -loss = 0.003351835341163678
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:46,100 INFO epoch # 8367 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0019 -loss = 0.003354097370902309
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:46,121 INFO epoch # 8368 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0019 -loss = 0.003369105345882417
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:46,142 INFO epoch # 8369 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0019 -loss = 0.0033701667762215948
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:46,163 INFO epoch # 8370 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0019 -loss = 0.003354090164975787
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:46,163 INFO *** epoch 8370, rolling-avg-loss (window=10)= 0.0033662267364888976
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:46,185 INFO epoch # 8371 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0019 -loss = 0.003370090924363467
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:46,206 INFO epoch # 8372 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0019 -loss = 0.0033708700375427725
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:46,228 INFO epoch # 8373 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0019 -loss = 0.003357299560775573
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:46,251 INFO epoch # 8374 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0019 -loss = 0.0033859275154100033
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:46,273 INFO epoch # 8375 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0019 -loss = 0.0034392413344903616
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:46,295 INFO epoch # 8376 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0019 -loss = 0.004024221349027357
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:46,316 INFO epoch # 8377 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0019 -loss = 0.003410249435546575
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:46,337 INFO epoch # 8378 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0019 -loss = 0.003389013472769875
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:46,358 INFO epoch # 8379 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0019 -loss = 0.0034905468337456114
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:46,380 INFO epoch # 8380 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0019 -loss = 0.0034191678832939942
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:46,380 INFO *** epoch 8380, rolling-avg-loss (window=10)= 0.003465662834696559
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:46,402 INFO epoch # 8381 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0019 -loss = 0.0033749822450772626
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:46,424 INFO epoch # 8382 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0019 -loss = 0.00339018209160713
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:46,446 INFO epoch # 8383 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0019 -loss = 0.003450115651503438
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:46,468 INFO epoch # 8384 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0019 -loss = 0.0033625149426370626
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:46,490 INFO epoch # 8385 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0019 -loss = 0.003379265706826118
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:46,512 INFO epoch # 8386 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0019 -loss = 0.0033690260388539173
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:46,533 INFO epoch # 8387 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0019 -loss = 0.0033623516483203275
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:46,555 INFO epoch # 8388 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0019 -loss = 0.003390039766600239
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:46,576 INFO epoch # 8389 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0019 -loss = 0.0033557335882505868
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:46,599 INFO epoch # 8390 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0019 -loss = 0.0033681031218293356
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:46,599 INFO *** epoch 8390, rolling-avg-loss (window=10)= 0.0033802314801505418
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:46,621 INFO epoch # 8391 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0019 -loss = 0.0033838867511803983
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:46,643 INFO epoch # 8392 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0019 -loss = 0.004099224566289195
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:46,665 INFO epoch # 8393 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0019 -loss = 0.0033459216615483456
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:46,687 INFO epoch # 8394 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0019 -loss = 0.0033649646493358887
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:46,709 INFO epoch # 8395 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0019 -loss = 0.003403676194466243
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:46,731 INFO epoch # 8396 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0019 -loss = 0.003730230080691399
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:46,753 INFO epoch # 8397 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0019 -loss = 0.004144266411458375
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:46,774 INFO epoch # 8398 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0019 -loss = 0.0033738591118890326
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:46,796 INFO epoch # 8399 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0019 -loss = 0.0034103388807125157
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:46,817 INFO epoch # 8400 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0019 -loss = 0.003344420201756293
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:46,817 INFO *** epoch 8400, rolling-avg-loss (window=10)= 0.0035600788509327686
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:46,839 INFO epoch # 8401 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0019 -loss = 0.003393925375348772
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:46,861 INFO epoch # 8402 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0019 -loss = 0.003414034139495925
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:46,883 INFO epoch # 8403 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0019 -loss = 0.003366451839610818
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:46,905 INFO epoch # 8404 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0019 -loss = 0.003376516692696896
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:46,927 INFO epoch # 8405 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0019 -loss = 0.0034062634849760798
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:46,948 INFO epoch # 8406 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0019 -loss = 0.004001534643975901
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:46,969 INFO epoch # 8407 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0019 -loss = 0.0033534011263327557
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:46,991 INFO epoch # 8408 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0019 -loss = 0.003372211738678743
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:47,012 INFO epoch # 8409 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0019 -loss = 0.0033503378836030606
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:47,033 INFO epoch # 8410 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0019 -loss = 0.00334572707197367
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:47,033 INFO *** epoch 8410, rolling-avg-loss (window=10)= 0.003438040399669262
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:47,055 INFO epoch # 8411 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0018 -loss = 0.003396605192392599
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:47,077 INFO epoch # 8412 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.0033736860350472853
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:47,099 INFO epoch # 8413 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.0033608847707000677
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:47,121 INFO epoch # 8414 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.0033581373372726375
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:47,143 INFO epoch # 8415 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.0033430901412430103
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:47,165 INFO epoch # 8416 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.0033540465619807946
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:47,186 INFO epoch # 8417 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.0033501418629384716
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:47,207 INFO epoch # 8418 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.003348226810885535
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:47,228 INFO epoch # 8419 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.0033692178922137828
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:47,250 INFO epoch # 8420 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.0034812454805432935
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:47,250 INFO *** epoch 8420, rolling-avg-loss (window=10)= 0.003373528208521748
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:47,272 INFO epoch # 8421 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.0033597848641875316
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:47,294 INFO epoch # 8422 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.00343361117211316
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:47,316 INFO epoch # 8423 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.0033437640868214658
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:47,338 INFO epoch # 8424 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.0033664831389614847
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:47,360 INFO epoch # 8425 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.003345078795973677
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:47,381 INFO epoch # 8426 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.003347618084262649
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:47,403 INFO epoch # 8427 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.003361540791047446
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:47,424 INFO epoch # 8428 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.0033478006425866624
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:47,445 INFO epoch # 8429 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.003383348042916623
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:47,467 INFO epoch # 8430 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.0033639421017142013
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:47,467 INFO *** epoch 8430, rolling-avg-loss (window=10)= 0.00336529717205849
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:47,488 INFO epoch # 8431 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.0033418919801988523
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:47,510 INFO epoch # 8432 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.003339442099331791
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:47,532 INFO epoch # 8433 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.003354353028043988
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:47,554 INFO epoch # 8434 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.0033562985445314553
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:47,576 INFO epoch # 8435 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.0033510779021526105
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:47,598 INFO epoch # 8436 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.0033491669864815776
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:47,619 INFO epoch # 8437 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.0033544209491083166
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:47,640 INFO epoch # 8438 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.0033412712114113674
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:47,661 INFO epoch # 8439 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.0033551638607605128
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:47,683 INFO epoch # 8440 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.0034403856402605015
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:47,683 INFO *** epoch 8440, rolling-avg-loss (window=10)= 0.0033583472202280973
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:47,705 INFO epoch # 8441 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.0033446182969782967
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:47,726 INFO epoch # 8442 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.0033469262125436217
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:47,748 INFO epoch # 8443 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.0033479381909273798
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:47,770 INFO epoch # 8444 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.0033462849951320095
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:47,792 INFO epoch # 8445 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.0036007229355163872
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:47,814 INFO epoch # 8446 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.0033663517406239407
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:47,835 INFO epoch # 8447 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.0034124789181078086
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:47,856 INFO epoch # 8448 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.0033468185256424476
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:47,877 INFO epoch # 8449 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.003366322545844014
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:47,899 INFO epoch # 8450 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.0033530743148730835
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:47,899 INFO *** epoch 8450, rolling-avg-loss (window=10)= 0.003383153667618899
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:47,921 INFO epoch # 8451 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.003349016385982395
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:47,943 INFO epoch # 8452 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.003383552188097383
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:47,965 INFO epoch # 8453 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.0033655732686384
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:47,987 INFO epoch # 8454 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.003418184594011109
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:48,009 INFO epoch # 8455 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.0033374372042089817
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:48,030 INFO epoch # 8456 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.003345411363625317
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:48,052 INFO epoch # 8457 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.0033568627268323326
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:48,073 INFO epoch # 8458 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.0033902821905940073
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:48,094 INFO epoch # 8459 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.0033383887139279977
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:48,115 INFO epoch # 8460 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.003349756379975588
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:48,115 INFO *** epoch 8460, rolling-avg-loss (window=10)= 0.003363446501589351
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:48,137 INFO epoch # 8461 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.003997601748778834
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:48,159 INFO epoch # 8462 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.0033510266348457662
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:48,181 INFO epoch # 8463 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.003405570009817893
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:48,203 INFO epoch # 8464 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.0033957146679313155
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:48,225 INFO epoch # 8465 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.0033769635228964034
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:48,247 INFO epoch # 8466 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.003342288496241963
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:48,268 INFO epoch # 8467 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.0033525323733556434
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:48,289 INFO epoch # 8468 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.0033630397610977525
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:48,310 INFO epoch # 8469 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.003369308954461303
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:48,332 INFO epoch # 8470 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.003354494978339062
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:48,332 INFO *** epoch 8470, rolling-avg-loss (window=10)= 0.0034308541147765937
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:48,354 INFO epoch # 8471 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.0033423995337216184
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:48,375 INFO epoch # 8472 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.0033410136275051627
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:48,397 INFO epoch # 8473 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.00334677150749485
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:48,418 INFO epoch # 8474 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.0033823433241195744
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:48,440 INFO epoch # 8475 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.0033583931899556774
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:48,461 INFO epoch # 8476 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.003362493694112345
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:48,482 INFO epoch # 8477 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.0033353874068779987
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:48,503 INFO epoch # 8478 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.0033894426669576205
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:48,525 INFO epoch # 8479 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.0033412228476663586
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:48,548 INFO epoch # 8480 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.0033552196073287632
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:48,548 INFO *** epoch 8480, rolling-avg-loss (window=10)= 0.003355468740573997
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:48,570 INFO epoch # 8481 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.004438978106009017
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:48,592 INFO epoch # 8482 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.0033364271957907476
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:48,614 INFO epoch # 8483 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.004084524112840882
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:48,636 INFO epoch # 8484 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.00337531619152287
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:48,658 INFO epoch # 8485 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.0033636800362728536
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:48,679 INFO epoch # 8486 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.003366705510416068
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:48,700 INFO epoch # 8487 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.0033486916290712543
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:48,722 INFO epoch # 8488 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.0033631128189881565
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:48,743 INFO epoch # 8489 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.0034120743584935553
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:48,765 INFO epoch # 8490 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.0033775310057535535
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:48,765 INFO *** epoch 8490, rolling-avg-loss (window=10)= 0.003546704096515896
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:48,787 INFO epoch # 8491 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.003364606895047473
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:48,809 INFO epoch # 8492 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.0033821850756794447
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:48,831 INFO epoch # 8493 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.00400221146264812
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:48,853 INFO epoch # 8494 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.003369281068444252
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:48,875 INFO epoch # 8495 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.0033529024049130385
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:48,896 INFO epoch # 8496 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.0034454736833140487
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:48,917 INFO epoch # 8497 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.0033622545288380934
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:48,938 INFO epoch # 8498 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.003359719337822753
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:48,959 INFO epoch # 8499 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0017 -loss = 0.0033479448893558583
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:48,980 INFO epoch # 8500 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.003965658541346784
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:48,981 INFO *** epoch 8500, rolling-avg-loss (window=10)= 0.0034952237887409866
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:49,002 INFO epoch # 8501 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.003358258291882521
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:49,024 INFO epoch # 8502 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.0033676747007120866
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:49,046 INFO epoch # 8503 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.003344464550536941
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:49,068 INFO epoch # 8504 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.0033511422716401285
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:49,090 INFO epoch # 8505 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.00333498085183237
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:49,111 INFO epoch # 8506 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.003350697368659894
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:49,132 INFO epoch # 8507 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.004045214114739792
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:49,153 INFO epoch # 8508 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.0033415893294659327
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:49,174 INFO epoch # 8509 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.0033388885312888306
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:49,196 INFO epoch # 8510 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.0033450315795562346
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:49,196 INFO *** epoch 8510, rolling-avg-loss (window=10)= 0.003417794159031473
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:49,217 INFO epoch # 8511 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.003352854697368457
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:49,239 INFO epoch # 8512 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.003341344363434473
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:49,261 INFO epoch # 8513 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.003334605982672656
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:49,283 INFO epoch # 8514 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.0033549340205354383
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:49,305 INFO epoch # 8515 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.0033534405374666676
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:49,327 INFO epoch # 8516 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.0034582319522087346
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:49,348 INFO epoch # 8517 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.003356178574904334
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:49,369 INFO epoch # 8518 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.0033387208304702654
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:49,390 INFO epoch # 8519 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.003414443988731364
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:49,411 INFO epoch # 8520 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.0033337894310534466
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:49,411 INFO *** epoch 8520, rolling-avg-loss (window=10)= 0.0033638544378845835
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:49,433 INFO epoch # 8521 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.003331441985665151
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:49,455 INFO epoch # 8522 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.003336400760417746
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:49,477 INFO epoch # 8523 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.0033652930105745327
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:49,498 INFO epoch # 8524 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.0033605931321289972
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:49,520 INFO epoch # 8525 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.003343394408148015
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:49,542 INFO epoch # 8526 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.003453651219388121
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:49,563 INFO epoch # 8527 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.003413285243368591
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:49,584 INFO epoch # 8528 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.00334093791207124
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:49,606 INFO epoch # 8529 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.0033339544279442634
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:49,628 INFO epoch # 8530 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.003730569740582723
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:49,628 INFO *** epoch 8530, rolling-avg-loss (window=10)= 0.003400952184028938
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:49,650 INFO epoch # 8531 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.0033344586818202515
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:49,672 INFO epoch # 8532 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.003341379670018796
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:49,693 INFO epoch # 8533 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.0033356680696670082
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:49,715 INFO epoch # 8534 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.003342067653647973
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:49,737 INFO epoch # 8535 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.003345165998325683
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:49,760 INFO epoch # 8536 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.0033337649792883894
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:49,782 INFO epoch # 8537 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.003376055817170709
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:49,804 INFO epoch # 8538 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.0034264035002706805
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:49,825 INFO epoch # 8539 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.0033392414006812032
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:49,847 INFO epoch # 8540 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.003350318907905603
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:49,847 INFO *** epoch 8540, rolling-avg-loss (window=10)= 0.0033524524678796297
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:49,869 INFO epoch # 8541 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.003331969784994726
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:49,891 INFO epoch # 8542 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.003360130458531785
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:49,913 INFO epoch # 8543 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.0037705245113102137
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:49,935 INFO epoch # 8544 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.0033665358096186537
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:49,957 INFO epoch # 8545 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.0033372815005350276
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:49,978 INFO epoch # 8546 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.0033498869197501335
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:49,999 INFO epoch # 8547 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.003344761487824144
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:50,020 INFO epoch # 8548 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.0033537845920363907
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:50,042 INFO epoch # 8549 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.0033504438479212695
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:50,063 INFO epoch # 8550 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.003341106154039153
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:50,064 INFO *** epoch 8550, rolling-avg-loss (window=10)= 0.0033906425066561495
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:50,085 INFO epoch # 8551 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.0033363240991093335
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:50,107 INFO epoch # 8552 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.0034328235196880996
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:50,129 INFO epoch # 8553 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.003349649645315367
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:50,151 INFO epoch # 8554 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.004094148342119297
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:50,173 INFO epoch # 8555 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.0033696390864861314
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:50,195 INFO epoch # 8556 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.003350604099978227
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:50,216 INFO epoch # 8557 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.003330813541651878
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:50,237 INFO epoch # 8558 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.0033351375423080754
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:50,259 INFO epoch # 8559 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.0033406337588530732
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:50,281 INFO epoch # 8560 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.003376439382918761
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:50,281 INFO *** epoch 8560, rolling-avg-loss (window=10)= 0.0034316213018428243
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:50,303 INFO epoch # 8561 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.0033455252860221663
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:50,325 INFO epoch # 8562 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.0033310888793494087
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:50,347 INFO epoch # 8563 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.003393714585399721
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:50,369 INFO epoch # 8564 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.003441127751102613
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:50,391 INFO epoch # 8565 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.0033851942089313525
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:50,412 INFO epoch # 8566 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.0033608123540034285
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:50,433 INFO epoch # 8567 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.0033736156237864634
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:50,455 INFO epoch # 8568 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.003335534202051349
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:50,476 INFO epoch # 8569 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.0033473367166152457
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:50,497 INFO epoch # 8570 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.0033418253597119474
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:50,497 INFO *** epoch 8570, rolling-avg-loss (window=10)= 0.0033655774966973697
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:50,519 INFO epoch # 8571 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.0033289698885710095
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:50,541 INFO epoch # 8572 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.0033252743050979916
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:50,563 INFO epoch # 8573 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.0033329660254821647
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:50,585 INFO epoch # 8574 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.003351747864144272
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:50,607 INFO epoch # 8575 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.004025204375466274
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:50,629 INFO epoch # 8576 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.0033578551974642323
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:50,650 INFO epoch # 8577 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.003331850321046659
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:50,671 INFO epoch # 8578 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.003409505578019889
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:50,692 INFO epoch # 8579 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.003350441373186186
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:50,713 INFO epoch # 8580 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.003358285835929564
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:50,713 INFO *** epoch 8580, rolling-avg-loss (window=10)= 0.003417210076440824
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:50,735 INFO epoch # 8581 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.004035168463815353
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:50,757 INFO epoch # 8582 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.0033327046749036526
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:50,779 INFO epoch # 8583 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.003421863970288541
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:50,801 INFO epoch # 8584 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.0033691706939862343
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:50,823 INFO epoch # 8585 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.003324944576888811
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:50,844 INFO epoch # 8586 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.003338996973070607
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:50,865 INFO epoch # 8587 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.003329025448692846
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:50,886 INFO epoch # 8588 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.0033345911106152926
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:50,908 INFO epoch # 8589 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.003325494864839129
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:50,929 INFO epoch # 8590 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.0033979567006099387
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:50,929 INFO *** epoch 8590, rolling-avg-loss (window=10)= 0.0034209917477710404
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:50,951 INFO epoch # 8591 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.0034621498107298976
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:50,972 INFO epoch # 8592 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.0033443651045672596
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:50,994 INFO epoch # 8593 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.0033360120924044168
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:51,015 INFO epoch # 8594 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0016 -loss = 0.003362190645930241
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:51,037 INFO epoch # 8595 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.0033235518098990724
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:51,059 INFO epoch # 8596 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.0033339596830046503
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:51,080 INFO epoch # 8597 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.003370434375028708
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:51,101 INFO epoch # 8598 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.0033446850648033433
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:51,122 INFO epoch # 8599 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.0033275558143941453
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:51,143 INFO epoch # 8600 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.003405625849154603
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:51,144 INFO *** epoch 8600, rolling-avg-loss (window=10)= 0.003361053024991634
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:51,165 INFO epoch # 8601 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.0033279654999205377
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:51,187 INFO epoch # 8602 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.0034094999809894944
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:51,208 INFO epoch # 8603 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.0033297715199296363
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:51,230 INFO epoch # 8604 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.0033255455500693643
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:51,253 INFO epoch # 8605 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.0033609151041673613
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:51,275 INFO epoch # 8606 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.003353653388330713
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:51,296 INFO epoch # 8607 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.003356781153343036
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:51,318 INFO epoch # 8608 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.003337221396577661
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:51,339 INFO epoch # 8609 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.0034520936987973982
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:51,361 INFO epoch # 8610 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.0033266132022617967
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:51,361 INFO *** epoch 8610, rolling-avg-loss (window=10)= 0.0033580060494387
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:51,383 INFO epoch # 8611 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.00333729727572063
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:51,404 INFO epoch # 8612 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.0033329621710436186
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:51,426 INFO epoch # 8613 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.0033397442293789936
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:51,448 INFO epoch # 8614 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.003343308032526693
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:51,469 INFO epoch # 8615 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.003322402842968586
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:51,491 INFO epoch # 8616 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.00420823414788174
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:51,512 INFO epoch # 8617 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.0033806781875682645
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:51,533 INFO epoch # 8618 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.0034351813337707426
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:51,554 INFO epoch # 8619 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.0033291812833340373
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:51,575 INFO epoch # 8620 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.0033351168858644087
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:51,576 INFO *** epoch 8620, rolling-avg-loss (window=10)= 0.0034364106390057715
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:51,598 INFO epoch # 8621 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.003341012589771708
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:51,620 INFO epoch # 8622 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.0033387568892067065
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:51,642 INFO epoch # 8623 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.00332388968217856
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:51,664 INFO epoch # 8624 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.003363169056683546
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:51,685 INFO epoch # 8625 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.003352370326865639
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:51,707 INFO epoch # 8626 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.0033232726500500576
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:51,728 INFO epoch # 8627 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.0033624493480601814
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:51,750 INFO epoch # 8628 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.0033449666798333055
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:51,772 INFO epoch # 8629 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.0036840056700384594
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:51,793 INFO epoch # 8630 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.0033299299739155686
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:51,794 INFO *** epoch 8630, rolling-avg-loss (window=10)= 0.003376382286660373
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:51,815 INFO epoch # 8631 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.0033489074194221757
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:51,837 INFO epoch # 8632 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.003325921874420601
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:51,859 INFO epoch # 8633 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.003325826525724551
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:51,881 INFO epoch # 8634 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.0033242349163629115
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:51,903 INFO epoch # 8635 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.0033340229911118513
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:51,924 INFO epoch # 8636 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.0033290039382336545
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:51,946 INFO epoch # 8637 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.0033437362144468352
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:51,967 INFO epoch # 8638 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.0038254704741120804
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:51,988 INFO epoch # 8639 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.003373446325895202
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:52,009 INFO epoch # 8640 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.0033327020519209327
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:52,009 INFO *** epoch 8640, rolling-avg-loss (window=10)= 0.0033863272731650797
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:52,031 INFO epoch # 8641 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.0033568729286344023
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:52,053 INFO epoch # 8642 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.003336786128784297
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:52,074 INFO epoch # 8643 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.003332792632136261
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:52,096 INFO epoch # 8644 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.0033301341190963285
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:52,118 INFO epoch # 8645 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.003354418291564798
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:52,139 INFO epoch # 8646 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.003379713254616945
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:52,160 INFO epoch # 8647 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.003343545482493937
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:52,181 INFO epoch # 8648 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.003351284805830801
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:52,202 INFO epoch # 8649 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.0033286853449681075
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:52,224 INFO epoch # 8650 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.0033449369730078615
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:52,224 INFO *** epoch 8650, rolling-avg-loss (window=10)= 0.003345916996113374
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:52,246 INFO epoch # 8651 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.0033357096353938687
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:52,268 INFO epoch # 8652 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.0033278656769653026
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:52,290 INFO epoch # 8653 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.0033226295745407697
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:52,312 INFO epoch # 8654 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.003335884935950162
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:52,334 INFO epoch # 8655 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.0033254683567065513
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:52,356 INFO epoch # 8656 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.0033373896148987114
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:52,377 INFO epoch # 8657 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.0033180509954036097
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:52,398 INFO epoch # 8658 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.0033189103505719686
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:52,419 INFO epoch # 8659 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.0033214004597539315
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:52,441 INFO epoch # 8660 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.004380250725262158
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:52,441 INFO *** epoch 8660, rolling-avg-loss (window=10)= 0.003432356032544703
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:52,463 INFO epoch # 8661 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.003321688725009153
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:52,484 INFO epoch # 8662 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.0033447187379351817
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:52,505 INFO epoch # 8663 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.003977849934017286
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:52,527 INFO epoch # 8664 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.0033220530776816304
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:52,549 INFO epoch # 8665 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.003327961461764062
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:52,571 INFO epoch # 8666 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.003332610170218686
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:52,592 INFO epoch # 8667 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.003336062938615214
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:52,613 INFO epoch # 8668 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.00338581566393259
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:52,634 INFO epoch # 8669 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.003390425352336024
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:52,655 INFO epoch # 8670 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.0033439599519624608
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:52,655 INFO *** epoch 8670, rolling-avg-loss (window=10)= 0.003408314601347229
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:52,690 INFO epoch # 8671 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.0033400078591512283
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:52,713 INFO epoch # 8672 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.0033781789334170753
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:52,735 INFO epoch # 8673 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.003437666888203239
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:52,757 INFO epoch # 8674 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.0033182171609951183
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:52,779 INFO epoch # 8675 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.0033254607342314557
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:52,801 INFO epoch # 8676 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.0033178485500684474
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:52,822 INFO epoch # 8677 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.0033369711454724893
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:52,843 INFO epoch # 8678 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.003338272044857149
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:52,864 INFO epoch # 8679 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0015 -loss = 0.003348538462887518
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:52,886 INFO epoch # 8680 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.003318018204481632
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:52,886 INFO *** epoch 8680, rolling-avg-loss (window=10)= 0.0033459179983765354
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:52,908 INFO epoch # 8681 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.0033225764400413027
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:52,930 INFO epoch # 8682 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.0033994913846981945
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:52,952 INFO epoch # 8683 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.0033121958233550686
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:52,973 INFO epoch # 8684 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.0033154670845760847
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:52,995 INFO epoch # 8685 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.0033448037784182816
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:53,016 INFO epoch # 8686 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.003354171158207464
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:53,037 INFO epoch # 8687 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.0033343990944558755
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:53,058 INFO epoch # 8688 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.003358823771122843
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:53,080 INFO epoch # 8689 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.003343524915180751
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:53,102 INFO epoch # 8690 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.0035520045366865816
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:53,102 INFO *** epoch 8690, rolling-avg-loss (window=10)= 0.003363745798674245
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:53,124 INFO epoch # 8691 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.0033651672156338464
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:53,146 INFO epoch # 8692 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.0033304162952845218
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:53,168 INFO epoch # 8693 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.0033162300223921193
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:53,189 INFO epoch # 8694 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.0033968939915212104
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:53,211 INFO epoch # 8695 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.003313012173748575
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:53,232 INFO epoch # 8696 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.003980198582212324
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:53,255 INFO epoch # 8697 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.0033245993918171735
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:53,276 INFO epoch # 8698 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.003396788337340695
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:53,298 INFO epoch # 8699 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.003322115602713893
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:53,320 INFO epoch # 8700 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.0033579713308427017
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:53,320 INFO *** epoch 8700, rolling-avg-loss (window=10)= 0.003410339294350706
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:53,342 INFO epoch # 8701 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.0034282480646652402
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:53,364 INFO epoch # 8702 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.0033862154859889415
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:53,386 INFO epoch # 8703 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.003322034954180708
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:53,408 INFO epoch # 8704 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.0044302084688752075
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:53,429 INFO epoch # 8705 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.0033282490585406777
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:53,450 INFO epoch # 8706 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.003668360113806557
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:53,471 INFO epoch # 8707 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.0033531208582644467
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:53,492 INFO epoch # 8708 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.003332687235342746
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:53,514 INFO epoch # 8709 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.0033247002593270736
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:53,535 INFO epoch # 8710 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.003321666838019155
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:53,535 INFO *** epoch 8710, rolling-avg-loss (window=10)= 0.003489549133701075
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:53,557 INFO epoch # 8711 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.003339415156005998
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:53,579 INFO epoch # 8712 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.003322807177937648
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:53,601 INFO epoch # 8713 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.003343426520586945
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:53,623 INFO epoch # 8714 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.0033241795408684993
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:53,644 INFO epoch # 8715 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.0033458523512308602
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:53,666 INFO epoch # 8716 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.0033210088276973693
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:53,687 INFO epoch # 8717 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.003330259645736078
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:53,708 INFO epoch # 8718 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.0033492149977973895
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:53,729 INFO epoch # 8719 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.003333884897074313
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:53,751 INFO epoch # 8720 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.004409601428960741
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:53,752 INFO *** epoch 8720, rolling-avg-loss (window=10)= 0.003441965054389584
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:53,773 INFO epoch # 8721 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.0033129810844911844
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:53,795 INFO epoch # 8722 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.0033135159847006435
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:53,817 INFO epoch # 8723 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.0033311272418359295
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:53,839 INFO epoch # 8724 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.0033098931412496313
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:53,860 INFO epoch # 8725 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.0033158383921545465
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:53,881 INFO epoch # 8726 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.003348868519424286
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:53,902 INFO epoch # 8727 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.004225836481055012
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:53,923 INFO epoch # 8728 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.0033587865509616677
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:53,945 INFO epoch # 8729 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.0033137239533971297
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:53,966 INFO epoch # 8730 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.0033247799810851575
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:53,966 INFO *** epoch 8730, rolling-avg-loss (window=10)= 0.0034155351330355187
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:53,988 INFO epoch # 8731 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.0033178645635416615
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:54,009 INFO epoch # 8732 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.0033215799603567575
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:54,031 INFO epoch # 8733 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.0033212689977517584
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:54,053 INFO epoch # 8734 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.003330504603582085
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:54,075 INFO epoch # 8735 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.0033640648380242055
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:54,096 INFO epoch # 8736 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.0033849661158456
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:54,117 INFO epoch # 8737 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.0033159811200675904
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:54,138 INFO epoch # 8738 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.003318787968964898
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:54,160 INFO epoch # 8739 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.004236262202539365
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:54,181 INFO epoch # 8740 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.0033194122988788877
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:54,182 INFO *** epoch 8740, rolling-avg-loss (window=10)= 0.0034230692669552807
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:54,204 INFO epoch # 8741 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.0033443471729697194
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:54,225 INFO epoch # 8742 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.0034018165497400332
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:54,248 INFO epoch # 8743 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.0034022918407572433
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:54,270 INFO epoch # 8744 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.003347419129568152
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:54,292 INFO epoch # 8745 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.003311454614959075
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:54,313 INFO epoch # 8746 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.0033653267437330214
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:54,334 INFO epoch # 8747 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.003309477097900526
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:54,355 INFO epoch # 8748 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.0033133147917396855
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:54,377 INFO epoch # 8749 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.004350963143224362
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:54,399 INFO epoch # 8750 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.0033113114195657545
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:54,399 INFO *** epoch 8750, rolling-avg-loss (window=10)= 0.0034457722504157573
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:54,421 INFO epoch # 8751 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.003390545082766039
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:54,443 INFO epoch # 8752 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.0033331370732412324
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:54,465 INFO epoch # 8753 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.003321596304886043
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:54,487 INFO epoch # 8754 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.003959751710681303
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:54,508 INFO epoch # 8755 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.0033226116856894805
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:54,529 INFO epoch # 8756 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.0033200478319486137
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:54,551 INFO epoch # 8757 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.0033355795803799992
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:54,572 INFO epoch # 8758 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.0033181436019731336
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:54,593 INFO epoch # 8759 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.003690417636789789
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:54,615 INFO epoch # 8760 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.0033568259259482147
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:54,616 INFO *** epoch 8760, rolling-avg-loss (window=10)= 0.003434865643430385
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:54,638 INFO epoch # 8761 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.003311593113721756
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:54,660 INFO epoch # 8762 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.00341144114099734
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:54,682 INFO epoch # 8763 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.0033294912600467796
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:54,704 INFO epoch # 8764 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.00331664270197507
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:54,725 INFO epoch # 8765 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.003360652463925362
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:54,747 INFO epoch # 8766 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.0033313956773781683
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:54,769 INFO epoch # 8767 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.0035101101393593126
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:54,790 INFO epoch # 8768 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.0033322412627967424
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:54,811 INFO epoch # 8769 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0014 -loss = 0.003382941284144181
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:54,833 INFO epoch # 8770 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.0033282953318121145
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:54,833 INFO *** epoch 8770, rolling-avg-loss (window=10)= 0.0033614804376156824
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:54,855 INFO epoch # 8771 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.003383324084097694
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:54,877 INFO epoch # 8772 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.003357319862516306
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:54,899 INFO epoch # 8773 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.003315220923468587
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:54,920 INFO epoch # 8774 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.003319512836242211
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:54,941 INFO epoch # 8775 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.0033931020534510026
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:54,963 INFO epoch # 8776 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.0035255037546448875
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:54,984 INFO epoch # 8777 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.0033241947521673865
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:55,005 INFO epoch # 8778 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.0033737903513610945
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:55,026 INFO epoch # 8779 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.003401913380912447
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:55,048 INFO epoch # 8780 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.003682860613480443
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:55,048 INFO *** epoch 8780, rolling-avg-loss (window=10)= 0.003407674261234206
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:55,070 INFO epoch # 8781 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.0033195220657944446
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:55,092 INFO epoch # 8782 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.003305244894363568
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:55,114 INFO epoch # 8783 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.0033039047889360518
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:55,136 INFO epoch # 8784 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.0033182434035552433
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:55,157 INFO epoch # 8785 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.0037782253148179734
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:55,178 INFO epoch # 8786 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.003307410421257373
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:55,199 INFO epoch # 8787 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.003381478672963567
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:55,220 INFO epoch # 8788 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.0033804085014708107
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:55,242 INFO epoch # 8789 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.0033113661584138754
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:55,265 INFO epoch # 8790 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.003302469653363005
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:55,265 INFO *** epoch 8790, rolling-avg-loss (window=10)= 0.0033708273874935913
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:55,287 INFO epoch # 8791 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.00331600059325865
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:55,309 INFO epoch # 8792 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.003340370838486706
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:55,331 INFO epoch # 8793 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.003314936129754642
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:55,352 INFO epoch # 8794 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.0033056084685085807
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:55,374 INFO epoch # 8795 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.0033186217642651172
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:55,395 INFO epoch # 8796 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.0033665253704384668
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:55,416 INFO epoch # 8797 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.003317696022349992
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:55,437 INFO epoch # 8798 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.003976254140070523
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:55,459 INFO epoch # 8799 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.004044892815727508
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:55,481 INFO epoch # 8800 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.003333419979753671
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:55,481 INFO *** epoch 8800, rolling-avg-loss (window=10)= 0.0034634326122613855
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:55,503 INFO epoch # 8801 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.003964937835917226
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:55,525 INFO epoch # 8802 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.003373309562448412
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:55,547 INFO epoch # 8803 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.0033075566179832094
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:55,569 INFO epoch # 8804 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.003301832808574545
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:55,591 INFO epoch # 8805 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.0033370839682902442
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:55,612 INFO epoch # 8806 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.003303072116068506
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:55,633 INFO epoch # 8807 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.0033408750641683582
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:55,654 INFO epoch # 8808 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.003310476927254058
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:55,676 INFO epoch # 8809 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.003341857608575083
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:55,698 INFO epoch # 8810 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.0033502913574920967
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:55,698 INFO *** epoch 8810, rolling-avg-loss (window=10)= 0.0033931293866771737
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:55,720 INFO epoch # 8811 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.0033092004587160773
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:55,742 INFO epoch # 8812 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.003307166194645106
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:55,764 INFO epoch # 8813 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.0033945283266803017
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:55,785 INFO epoch # 8814 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.0033385162514605327
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:55,807 INFO epoch # 8815 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.003934393727831775
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:55,828 INFO epoch # 8816 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.0033030885397238308
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:55,849 INFO epoch # 8817 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.0033009004064297187
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:55,870 INFO epoch # 8818 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.0035184685948479455
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:55,892 INFO epoch # 8819 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.0033635344698268455
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:55,914 INFO epoch # 8820 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.003524703293805942
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:55,914 INFO *** epoch 8820, rolling-avg-loss (window=10)= 0.0034294500263968076
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:55,936 INFO epoch # 8821 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.0033090512820308504
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:55,957 INFO epoch # 8822 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.003322127362480387
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:55,979 INFO epoch # 8823 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.0036772455741811427
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:56,001 INFO epoch # 8824 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.0033002685058818315
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:56,022 INFO epoch # 8825 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.0033075448336603586
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:56,044 INFO epoch # 8826 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.0033546488084539305
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:56,065 INFO epoch # 8827 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.003303526673335
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:56,086 INFO epoch # 8828 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.0033558437553438125
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:56,108 INFO epoch # 8829 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.0033750376678653993
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:56,130 INFO epoch # 8830 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.003309573974547675
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:56,131 INFO *** epoch 8830, rolling-avg-loss (window=10)= 0.0033614868437780387
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:56,153 INFO epoch # 8831 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.003331200139655266
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:56,175 INFO epoch # 8832 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.0033133652059404994
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:56,197 INFO epoch # 8833 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.003403594786504982
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:56,219 INFO epoch # 8834 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.0033801189665609854
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:56,240 INFO epoch # 8835 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.0033098818985308753
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:56,262 INFO epoch # 8836 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.0033176303277286934
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:56,284 INFO epoch # 8837 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.003304883734017494
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:56,305 INFO epoch # 8838 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.0033048740624508355
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:56,327 INFO epoch # 8839 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.0033141815274575492
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:56,349 INFO epoch # 8840 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.0033077148782467702
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:56,349 INFO *** epoch 8840, rolling-avg-loss (window=10)= 0.003328744552709395
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:56,371 INFO epoch # 8841 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.0033013285383276525
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:56,393 INFO epoch # 8842 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.0033926010655704886
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:56,415 INFO epoch # 8843 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.0037371937069110572
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:56,436 INFO epoch # 8844 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.003927199533791281
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:56,458 INFO epoch # 8845 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.0033007419929163007
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:56,480 INFO epoch # 8846 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.003298207442412604
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:56,501 INFO epoch # 8847 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.00329584888561385
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:56,522 INFO epoch # 8848 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.00329926547328796
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:56,543 INFO epoch # 8849 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.0033028487259798567
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:56,565 INFO epoch # 8850 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.00332012542639859
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:56,565 INFO *** epoch 8850, rolling-avg-loss (window=10)= 0.0034175360791209642
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:56,587 INFO epoch # 8851 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.0032994912608046434
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:56,609 INFO epoch # 8852 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.0032998756855704414
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:56,631 INFO epoch # 8853 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.0033399734038539464
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:56,652 INFO epoch # 8854 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.0034059070649163914
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:56,673 INFO epoch # 8855 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.0033459243013567175
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:56,695 INFO epoch # 8856 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.0033430331413910608
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:56,716 INFO epoch # 8857 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.0033057330356314196
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:56,737 INFO epoch # 8858 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.0033139345123345265
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:56,759 INFO epoch # 8859 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.0033258476432820316
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:56,781 INFO epoch # 8860 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.003301363583886996
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:56,781 INFO *** epoch 8860, rolling-avg-loss (window=10)= 0.0033281083633028173
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:56,803 INFO epoch # 8861 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.0033609185625209648
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:56,825 INFO epoch # 8862 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.004358682010206394
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:56,847 INFO epoch # 8863 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.0033114874077000422
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:56,869 INFO epoch # 8864 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.0033489735742477933
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:56,891 INFO epoch # 8865 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.003307168411993189
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:56,912 INFO epoch # 8866 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.00338433039632946
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:56,933 INFO epoch # 8867 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.0033403090164938476
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:56,954 INFO epoch # 8868 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.003326492488668009
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:56,975 INFO epoch # 8869 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.0033243623438465875
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:56,997 INFO epoch # 8870 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.0034760895196086494
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:56,997 INFO *** epoch 8870, rolling-avg-loss (window=10)= 0.0034538813731614937
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:57,020 INFO epoch # 8871 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.0037626703233399894
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:57,041 INFO epoch # 8872 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.003301349003777432
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:57,063 INFO epoch # 8873 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.0033215430930795264
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:57,085 INFO epoch # 8874 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.0033149152386613423
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:57,106 INFO epoch # 8875 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.0033349238765367772
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:57,127 INFO epoch # 8876 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.00331595567149634
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:57,148 INFO epoch # 8877 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.003306498721940443
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:57,170 INFO epoch # 8878 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.0033451109848101623
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:57,191 INFO epoch # 8879 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.0033431060346629238
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:57,213 INFO epoch # 8880 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0013 -loss = 0.003305072896182537
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:57,213 INFO *** epoch 8880, rolling-avg-loss (window=10)= 0.0033651145844487474
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:57,235 INFO epoch # 8881 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.003313747731226613
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:57,258 INFO epoch # 8882 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.003305265861854423
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:57,280 INFO epoch # 8883 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.0033230511735382606
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:57,302 INFO epoch # 8884 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.0033066728174162563
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:57,323 INFO epoch # 8885 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.003296634608432214
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:57,344 INFO epoch # 8886 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.003301365983134019
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:57,366 INFO epoch # 8887 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.003307790368126007
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:57,387 INFO epoch # 8888 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.003309347310278099
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:57,408 INFO epoch # 8889 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.003326908543385798
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:57,430 INFO epoch # 8890 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.0032977616497191775
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:57,430 INFO *** epoch 8890, rolling-avg-loss (window=10)= 0.0033088546047110867
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:57,452 INFO epoch # 8891 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.0035113905960315606
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:57,474 INFO epoch # 8892 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.003292991458238248
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:57,496 INFO epoch # 8893 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.003388421934687358
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:57,518 INFO epoch # 8894 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.0033233379617740866
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:57,539 INFO epoch # 8895 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.003300496924566687
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:57,560 INFO epoch # 8896 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.0033878170524985762
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:57,581 INFO epoch # 8897 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.003303965316263202
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:57,603 INFO epoch # 8898 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.003298296077446139
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:57,624 INFO epoch # 8899 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.0033599727175896987
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:57,646 INFO epoch # 8900 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.003375066564331064
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:57,646 INFO *** epoch 8900, rolling-avg-loss (window=10)= 0.003354175660342662
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:57,668 INFO epoch # 8901 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.0033368632621204597
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:57,689 INFO epoch # 8902 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.0032980124142341083
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:57,711 INFO epoch # 8903 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.003299236940620176
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:57,733 INFO epoch # 8904 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.0033121879387181252
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:57,754 INFO epoch # 8905 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.003300677722108958
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:57,776 INFO epoch # 8906 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.0033111694292529137
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:57,798 INFO epoch # 8907 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.0032958545803012385
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:57,819 INFO epoch # 8908 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.0033387262974429177
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:57,840 INFO epoch # 8909 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.003296730186775676
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:57,862 INFO epoch # 8910 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.003312170891149435
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:57,862 INFO *** epoch 8910, rolling-avg-loss (window=10)= 0.003310162966272401
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:57,884 INFO epoch # 8911 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.003296659983789141
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:57,906 INFO epoch # 8912 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.00332102602624218
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:57,927 INFO epoch # 8913 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.0033367964715580456
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:57,949 INFO epoch # 8914 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.003306083484858391
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:57,970 INFO epoch # 8915 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.003293785845016828
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:57,992 INFO epoch # 8916 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.003318107803352177
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:58,013 INFO epoch # 8917 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.0033025681468643597
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:58,034 INFO epoch # 8918 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.0033681848926789826
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:58,055 INFO epoch # 8919 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.003298387906397693
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:58,077 INFO epoch # 8920 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.003299691735264787
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:58,077 INFO *** epoch 8920, rolling-avg-loss (window=10)= 0.0033141292296022585
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:58,099 INFO epoch # 8921 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.0035182476894988213
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:58,120 INFO epoch # 8922 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.0032976598586174077
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:58,142 INFO epoch # 8923 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.003321089089695306
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:58,163 INFO epoch # 8924 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.003344436379848048
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:58,185 INFO epoch # 8925 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.0033588825517654186
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:58,206 INFO epoch # 8926 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.003338591186548001
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:58,227 INFO epoch # 8927 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.003393130782569642
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:58,249 INFO epoch # 8928 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.0033227542335225735
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:58,271 INFO epoch # 8929 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.0033417342565371655
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:58,293 INFO epoch # 8930 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.0032992936075970647
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:58,293 INFO *** epoch 8930, rolling-avg-loss (window=10)= 0.0033535819636199447
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:58,315 INFO epoch # 8931 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.0033162297722810763
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:58,336 INFO epoch # 8932 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.0033185750062330044
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:58,358 INFO epoch # 8933 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.003384218727660482
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:58,380 INFO epoch # 8934 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.0033202481072294177
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:58,401 INFO epoch # 8935 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.0033089380431192694
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:58,423 INFO epoch # 8936 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.00417389984249894
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:58,444 INFO epoch # 8937 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.0033230059007109958
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:58,465 INFO epoch # 8938 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.0032969210760711576
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:58,487 INFO epoch # 8939 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.003903618121512409
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:58,509 INFO epoch # 8940 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.0032940061537374277
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:58,509 INFO *** epoch 8940, rolling-avg-loss (window=10)= 0.003463966075105418
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:58,532 INFO epoch # 8941 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.003295871088084823
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:58,554 INFO epoch # 8942 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.003309049747258541
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:58,576 INFO epoch # 8943 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.0033239743515878217
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:58,598 INFO epoch # 8944 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.003316633135000302
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:58,619 INFO epoch # 8945 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.0033039121626643464
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:58,641 INFO epoch # 8946 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.0032983141873046407
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:58,662 INFO epoch # 8947 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.0033348306860716548
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:58,683 INFO epoch # 8948 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.00331067373190308
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:58,704 INFO epoch # 8949 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.003365497371305537
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:58,726 INFO epoch # 8950 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.0033808945254349965
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:58,726 INFO *** epoch 8950, rolling-avg-loss (window=10)= 0.0033239650986615745
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:58,749 INFO epoch # 8951 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.0033444745367887663
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:58,771 INFO epoch # 8952 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.003292213128588628
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:58,793 INFO epoch # 8953 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.0033069080227505765
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:58,815 INFO epoch # 8954 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.003349377004269627
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:58,837 INFO epoch # 8955 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.0032888295806969836
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:58,858 INFO epoch # 8956 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.0032961197994154645
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:58,879 INFO epoch # 8957 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.0033865458444779506
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:58,900 INFO epoch # 8958 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.004352431383267685
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:58,922 INFO epoch # 8959 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.003313004866868141
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:58,943 INFO epoch # 8960 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.003291368465852429
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:58,944 INFO *** epoch 8960, rolling-avg-loss (window=10)= 0.003422127263297625
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:58,965 INFO epoch # 8961 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.00330668381502619
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:58,987 INFO epoch # 8962 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.003305250976154639
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:59,009 INFO epoch # 8963 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.0033126104672192014
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:59,031 INFO epoch # 8964 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.0033009588014465407
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:59,052 INFO epoch # 8965 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.003342688331485988
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:59,074 INFO epoch # 8966 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0012 -loss = 0.003375149701241753
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:59,095 INFO epoch # 8967 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.003297678274975624
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:59,116 INFO epoch # 8968 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.003335853381031484
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:59,137 INFO epoch # 8969 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.0033025656375684775
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:59,159 INFO epoch # 8970 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.003321363270515576
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:59,159 INFO *** epoch 8970, rolling-avg-loss (window=10)= 0.0033200802656665473
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:59,181 INFO epoch # 8971 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.0033542123219376663
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:59,203 INFO epoch # 8972 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.0033264929352299077
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:59,225 INFO epoch # 8973 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.003295133600659028
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:59,248 INFO epoch # 8974 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.0033035922460840084
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:59,269 INFO epoch # 8975 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.0033180210875798366
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:59,291 INFO epoch # 8976 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.0032919736768235452
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:59,312 INFO epoch # 8977 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.0032922411683102837
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:59,333 INFO epoch # 8978 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.003371927689840959
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:59,354 INFO epoch # 8979 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.003355081158588291
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:59,376 INFO epoch # 8980 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.0033343252198392292
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:59,376 INFO *** epoch 8980, rolling-avg-loss (window=10)= 0.0033243001104892754
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:59,398 INFO epoch # 8981 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.00394830143704894
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:59,420 INFO epoch # 8982 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.003717371346283471
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:59,442 INFO epoch # 8983 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.003307689057692187
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:59,463 INFO epoch # 8984 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.0033392956956959097
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:59,484 INFO epoch # 8985 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.0032876346340344753
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:59,505 INFO epoch # 8986 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.0033096408096753294
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:59,526 INFO epoch # 8987 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.0033301299863524036
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:59,547 INFO epoch # 8988 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.004316893061513838
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:59,569 INFO epoch # 8989 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.0033201450169144664
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:59,591 INFO epoch # 8990 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.0033795326089602895
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:59,591 INFO *** epoch 8990, rolling-avg-loss (window=10)= 0.003525663365417131
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:59,613 INFO epoch # 8991 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.0032875255606086284
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:59,635 INFO epoch # 8992 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.0033824134816313745
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:59,657 INFO epoch # 8993 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.0033710808102114243
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:59,678 INFO epoch # 8994 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.003304023651253374
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:59,700 INFO epoch # 8995 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.0039692673317404115
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:59,721 INFO epoch # 8996 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.0032884410106817086
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:59,742 INFO epoch # 8997 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.003325017134557129
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:59,764 INFO epoch # 8998 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.003293052264780272
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:59,785 INFO epoch # 8999 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.003925091805285774
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:59,807 INFO epoch # 9000 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.003296653243523906
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:56:59,807 INFO *** epoch 9000, rolling-avg-loss (window=10)= 0.0034442566294274
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:59,829 INFO epoch # 9001 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.0033080874827646767
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:59,851 INFO epoch # 9002 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.0032941498175205197
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:59,873 INFO epoch # 9003 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.0033681039367365884
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:59,895 INFO epoch # 9004 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.0032915451483859215
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:59,916 INFO epoch # 9005 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.003358233312610537
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:59,937 INFO epoch # 9006 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.003381450324013713
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:59,958 INFO epoch # 9007 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.003951036302169086
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:56:59,979 INFO epoch # 9008 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.0033623028593865456
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:00,000 INFO epoch # 9009 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.003327683578390861
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:00,022 INFO epoch # 9010 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.0033292465086560696
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:57:00,022 INFO *** epoch 9010, rolling-avg-loss (window=10)= 0.003397183927063452
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:00,045 INFO epoch # 9011 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.0033489119086880237
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:00,067 INFO epoch # 9012 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.003293898142146645
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:00,089 INFO epoch # 9013 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.003286647276581789
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:00,110 INFO epoch # 9014 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.003300324642623309
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:00,132 INFO epoch # 9015 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.003287283424015186
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:00,153 INFO epoch # 9016 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.0033250688666157657
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:00,174 INFO epoch # 9017 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.0032975521298794774
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:00,195 INFO epoch # 9018 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.003302737390185939
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:00,216 INFO epoch # 9019 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.003315495179776917
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:00,238 INFO epoch # 9020 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.0032946756145975087
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:57:00,238 INFO *** epoch 9020, rolling-avg-loss (window=10)= 0.003305259457511056
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:00,261 INFO epoch # 9021 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.0032896335524128517
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:00,283 INFO epoch # 9022 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.00399589054450189
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:00,305 INFO epoch # 9023 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.0032871982352844498
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:00,327 INFO epoch # 9024 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.0033436167450417997
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:00,348 INFO epoch # 9025 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.004022042215183319
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:00,370 INFO epoch # 9026 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.0032918764100031694
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:00,391 INFO epoch # 9027 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.0032873269065021304
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:00,412 INFO epoch # 9028 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.0033076230065489653
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:00,433 INFO epoch # 9029 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.0039727662688164855
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:00,455 INFO epoch # 9030 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.003294889005701407
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:57:00,455 INFO *** epoch 9030, rolling-avg-loss (window=10)= 0.0035092862889996466
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:00,477 INFO epoch # 9031 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.0032947662202786887
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:00,498 INFO epoch # 9032 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.0033083417747548083
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:00,520 INFO epoch # 9033 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.0033028520592779387
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:00,541 INFO epoch # 9034 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.0034043018113152357
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:00,563 INFO epoch # 9035 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.0032836053483151773
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:00,584 INFO epoch # 9036 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.0033249408425035654
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:00,605 INFO epoch # 9037 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.0032943287087618955
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:00,626 INFO epoch # 9038 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.003955079540901352
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:00,648 INFO epoch # 9039 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.0032887684856177657
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:00,670 INFO epoch # 9040 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.0033186756018039887
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:57:00,670 INFO *** epoch 9040, rolling-avg-loss (window=10)= 0.0033775660393530415
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:00,692 INFO epoch # 9041 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.003307049218165048
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:00,713 INFO epoch # 9042 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.0032867646696104202
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:00,735 INFO epoch # 9043 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.0033855247138490085
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:00,757 INFO epoch # 9044 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.003331420688482467
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:00,779 INFO epoch # 9045 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.0033834797504823655
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:00,800 INFO epoch # 9046 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.0034122233719244832
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:00,821 INFO epoch # 9047 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.00329933277953387
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:00,842 INFO epoch # 9048 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.0033018030335369986
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:00,864 INFO epoch # 9049 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.0032963450576062314
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:00,885 INFO epoch # 9050 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.0044428843411878916
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:57:00,886 INFO *** epoch 9050, rolling-avg-loss (window=10)= 0.0034446827624378786
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:00,907 INFO epoch # 9051 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.0033816771283454727
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:00,929 INFO epoch # 9052 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.003286781578026421
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:00,951 INFO epoch # 9053 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.003279430776274239
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:00,973 INFO epoch # 9054 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.003290740381089563
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:00,994 INFO epoch # 9055 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.0032800881579078123
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:01,016 INFO epoch # 9056 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.003724871835402155
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:01,037 INFO epoch # 9057 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.00329415420856094
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:01,058 INFO epoch # 9058 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.003286036002464243
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:01,079 INFO epoch # 9059 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.0032814270962262526
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:01,101 INFO epoch # 9060 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.0033443009724578587
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:57:01,101 INFO *** epoch 9060, rolling-avg-loss (window=10)= 0.0033449508136754957
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:01,123 INFO epoch # 9061 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.003296196753581171
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:01,145 INFO epoch # 9062 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.003342194819197175
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:01,167 INFO epoch # 9063 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.0032812579338497017
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:01,188 INFO epoch # 9064 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.0036393088103068294
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:01,210 INFO epoch # 9065 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.003285778202553047
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:01,231 INFO epoch # 9066 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.0037316415246095858
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:01,253 INFO epoch # 9067 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.0032804211195980315
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:01,274 INFO epoch # 9068 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.003297826058769715
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:01,296 INFO epoch # 9069 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.003288077023171354
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:01,317 INFO epoch # 9070 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.0034126723739973386
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:57:01,318 INFO *** epoch 9070, rolling-avg-loss (window=10)= 0.0033855374619633947
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:01,339 INFO epoch # 9071 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.003302503801023704
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:01,361 INFO epoch # 9072 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.003286198885689373
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:01,383 INFO epoch # 9073 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.0034180088387074647
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:01,404 INFO epoch # 9074 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.0032834097246450256
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:01,426 INFO epoch # 9075 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.003291198738224921
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:01,448 INFO epoch # 9076 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.003294855447165901
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:01,469 INFO epoch # 9077 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.0033367506712238537
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:01,490 INFO epoch # 9078 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.0033296215551672503
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:01,512 INFO epoch # 9079 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.0033154277352878125
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:01,534 INFO epoch # 9080 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.003285844410129357
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:57:01,534 INFO *** epoch 9080, rolling-avg-loss (window=10)= 0.003314381980726466
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:01,556 INFO epoch # 9081 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.003300561477772135
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:01,578 INFO epoch # 9082 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.0032810743778100004
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:01,600 INFO epoch # 9083 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.003331313386297552
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:01,622 INFO epoch # 9084 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.0032849228264240082
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:01,644 INFO epoch # 9085 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.003963278735682252
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:01,665 INFO epoch # 9086 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.0033630543512117583
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:01,686 INFO epoch # 9087 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.0034046648379444377
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:01,707 INFO epoch # 9088 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.0032897454784688307
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:01,729 INFO epoch # 9089 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.003321040749142412
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:01,751 INFO epoch # 9090 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.0032898151666813646
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:57:01,752 INFO *** epoch 9090, rolling-avg-loss (window=10)= 0.003382947138743475
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:01,774 INFO epoch # 9091 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.003396233936655335
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:01,796 INFO epoch # 9092 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.0034475518059480237
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:01,818 INFO epoch # 9093 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.0032951505318123964
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:01,839 INFO epoch # 9094 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.003285043723280978
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:01,861 INFO epoch # 9095 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.003312953498607385
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:01,882 INFO epoch # 9096 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.003287755289420602
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:01,903 INFO epoch # 9097 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0011 -loss = 0.0032916397885855986
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:01,925 INFO epoch # 9098 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.0032780784567876253
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:01,946 INFO epoch # 9099 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.003341779036418302
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:01,968 INFO epoch # 9100 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.003360015152793494
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:57:01,968 INFO *** epoch 9100, rolling-avg-loss (window=10)= 0.003329620122030974
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:01,990 INFO epoch # 9101 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.003288106065156171
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:02,012 INFO epoch # 9102 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.003306272805275512
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:02,034 INFO epoch # 9103 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.003284421769421897
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:02,055 INFO epoch # 9104 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.00330319535714807
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:02,077 INFO epoch # 9105 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.003286745695731952
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:02,098 INFO epoch # 9106 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.0033146080540973344
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:02,119 INFO epoch # 9107 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.003291494827863062
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:02,140 INFO epoch # 9108 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.003324517256260151
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:02,161 INFO epoch # 9109 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.003283205874140549
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:02,183 INFO epoch # 9110 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.003315881418529898
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:57:02,183 INFO *** epoch 9110, rolling-avg-loss (window=10)= 0.0032998449123624596
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:02,205 INFO epoch # 9111 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.0033024090189428534
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:02,226 INFO epoch # 9112 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.0033094558220909676
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:02,248 INFO epoch # 9113 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.0032916054069573875
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:02,270 INFO epoch # 9114 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.0036726782955156523
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:02,292 INFO epoch # 9115 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.003332085334477597
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:02,313 INFO epoch # 9116 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.0033972366945818067
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:02,334 INFO epoch # 9117 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.0033024330650732736
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:02,355 INFO epoch # 9118 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.0032985565358103486
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:02,376 INFO epoch # 9119 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.003282324018982763
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:02,398 INFO epoch # 9120 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.0032808749319883646
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:57:02,398 INFO *** epoch 9120, rolling-avg-loss (window=10)= 0.0033469659124421014
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:02,420 INFO epoch # 9121 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.0032875170263650944
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:02,442 INFO epoch # 9122 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.0032988391285471153
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:02,463 INFO epoch # 9123 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.0032770568559499225
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:02,485 INFO epoch # 9124 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.0033650019995548064
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:02,506 INFO epoch # 9125 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.0033032109568011947
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:02,527 INFO epoch # 9126 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.003318734739877982
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:02,548 INFO epoch # 9127 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.0033840355899883434
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:02,569 INFO epoch # 9128 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.0032886976277950453
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:02,591 INFO epoch # 9129 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.0033199161443917546
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:02,613 INFO epoch # 9130 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.0032848340433702106
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:57:02,613 INFO *** epoch 9130, rolling-avg-loss (window=10)= 0.003312784411264147
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:02,635 INFO epoch # 9131 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.0032785037028588704
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:02,656 INFO epoch # 9132 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.0032900239602895454
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:02,678 INFO epoch # 9133 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.0033046536500478396
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:02,700 INFO epoch # 9134 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.0032791423582239076
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:02,721 INFO epoch # 9135 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.0033300473169219913
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:02,743 INFO epoch # 9136 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.0032800051267258823
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:02,764 INFO epoch # 9137 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.003350000375576201
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:02,785 INFO epoch # 9138 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.0032936981097009266
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:02,807 INFO epoch # 9139 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.0032991602092806716
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:02,829 INFO epoch # 9140 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.0032813167617860017
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:57:02,829 INFO *** epoch 9140, rolling-avg-loss (window=10)= 0.003298655157141184
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:02,851 INFO epoch # 9141 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.0032905353200476384
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:02,873 INFO epoch # 9142 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.0033062551519833505
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:02,895 INFO epoch # 9143 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.0033384127436875133
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:02,917 INFO epoch # 9144 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.0032817141682244255
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:02,938 INFO epoch # 9145 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.003318251760902058
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:02,959 INFO epoch # 9146 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.003309279592031089
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:02,980 INFO epoch # 9147 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.0032936116949713323
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:03,001 INFO epoch # 9148 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.0033064451436075615
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:03,023 INFO epoch # 9149 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.0032971926975733368
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:03,045 INFO epoch # 9150 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.0033247613200728665
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:57:03,045 INFO *** epoch 9150, rolling-avg-loss (window=10)= 0.003306645959310117
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:03,067 INFO epoch # 9151 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.003925883658666862
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:03,089 INFO epoch # 9152 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.00339268864809128
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:03,111 INFO epoch # 9153 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.0032859916227607755
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:03,132 INFO epoch # 9154 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.003347017304804467
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:03,154 INFO epoch # 9155 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.0032757735066297755
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:03,175 INFO epoch # 9156 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.0032786906504043145
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:03,196 INFO epoch # 9157 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.0032851551350177033
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:03,217 INFO epoch # 9158 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.003278031919762725
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:03,239 INFO epoch # 9159 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.0032759513460405287
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:03,262 INFO epoch # 9160 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.0033383192239853088
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:57:03,262 INFO *** epoch 9160, rolling-avg-loss (window=10)= 0.0033683503016163742
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:03,284 INFO epoch # 9161 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.0032769050962997426
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:03,305 INFO epoch # 9162 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.003365816601217375
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:03,327 INFO epoch # 9163 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.003754234225198161
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:03,349 INFO epoch # 9164 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.0033044379288185155
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:03,371 INFO epoch # 9165 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.0032740759061198332
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:03,392 INFO epoch # 9166 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.0033188001143571455
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:03,413 INFO epoch # 9167 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.003885090916810441
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:03,434 INFO epoch # 9168 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.0033063535929613863
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:03,455 INFO epoch # 9169 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.0033913138577190693
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:03,477 INFO epoch # 9170 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.0033688526946207276
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:57:03,477 INFO *** epoch 9170, rolling-avg-loss (window=10)= 0.00342458809341224
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:03,499 INFO epoch # 9171 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.0033253741457883734
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:03,521 INFO epoch # 9172 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.004299480962799862
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:03,542 INFO epoch # 9173 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.0033073933145715273
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:03,564 INFO epoch # 9174 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.0033113985155068804
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:03,585 INFO epoch # 9175 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.003352458681547432
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:03,607 INFO epoch # 9176 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.003274444231919915
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:03,628 INFO epoch # 9177 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.003321262964163907
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:03,649 INFO epoch # 9178 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.0032760996036813594
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:03,670 INFO epoch # 9179 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.003299099897958513
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:03,692 INFO epoch # 9180 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.003290487651611329
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:57:03,692 INFO *** epoch 9180, rolling-avg-loss (window=10)= 0.0034057499969549097
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:03,714 INFO epoch # 9181 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.0033132515072793467
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:03,735 INFO epoch # 9182 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.003275103767919063
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:03,757 INFO epoch # 9183 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.003305326674308162
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:03,779 INFO epoch # 9184 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.004138830090596457
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:03,801 INFO epoch # 9185 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.003290733933681622
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:03,822 INFO epoch # 9186 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.0032934873142949073
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:03,843 INFO epoch # 9187 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.0032845416235431912
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:03,864 INFO epoch # 9188 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.0032835781858011615
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:03,886 INFO epoch # 9189 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.003299297375633614
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:03,908 INFO epoch # 9190 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.0032758136567281326
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:57:03,908 INFO *** epoch 9190, rolling-avg-loss (window=10)= 0.003375996412978566
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:03,930 INFO epoch # 9191 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.00414400302543072
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:03,952 INFO epoch # 9192 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.004313800627642195
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:03,973 INFO epoch # 9193 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.0032979078896460123
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:03,994 INFO epoch # 9194 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.0032816505117807537
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:04,016 INFO epoch # 9195 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.003282905822743487
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:04,037 INFO epoch # 9196 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.0032820711148815462
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:04,059 INFO epoch # 9197 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.003323511227790732
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:04,080 INFO epoch # 9198 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.003285270409833174
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:04,102 INFO epoch # 9199 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.0033647769432718633
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:04,124 INFO epoch # 9200 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.0032857847600098467
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:57:04,124 INFO *** epoch 9200, rolling-avg-loss (window=10)= 0.003486168233303033
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:04,146 INFO epoch # 9201 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.0033056951888283947
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:04,168 INFO epoch # 9202 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.0033381855573679786
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:04,190 INFO epoch # 9203 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.0033150387498608325
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:04,212 INFO epoch # 9204 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.0032902339207794284
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:04,233 INFO epoch # 9205 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.003288706630883098
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:04,256 INFO epoch # 9206 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.0032951361608866137
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:04,277 INFO epoch # 9207 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.003286816387117142
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:04,298 INFO epoch # 9208 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.0033690038726490457
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:04,320 INFO epoch # 9209 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.0033339109158987412
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:04,342 INFO epoch # 9210 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.0032833081577336998
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:57:04,342 INFO *** epoch 9210, rolling-avg-loss (window=10)= 0.0033106035542004976
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:04,364 INFO epoch # 9211 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.003301462862509652
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:04,386 INFO epoch # 9212 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.003344807437315467
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:04,407 INFO epoch # 9213 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.0032910929821809987
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:04,429 INFO epoch # 9214 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.003293253719675704
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:04,451 INFO epoch # 9215 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.0032738569807406748
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:04,472 INFO epoch # 9216 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.0032870747172637493
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:04,493 INFO epoch # 9217 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.0033365597710144357
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:04,514 INFO epoch # 9218 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.003273368432019197
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:04,535 INFO epoch # 9219 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.003294572689810593
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:04,557 INFO epoch # 9220 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.0032721167835916276
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:57:04,557 INFO *** epoch 9220, rolling-avg-loss (window=10)= 0.0032968166376122097
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:04,579 INFO epoch # 9221 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.003288737256298191
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:04,601 INFO epoch # 9222 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.0033035034084605286
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:04,623 INFO epoch # 9223 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.0033463203690189403
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:04,646 INFO epoch # 9224 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.003277633437392069
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:04,668 INFO epoch # 9225 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.0032964306183203007
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:04,691 INFO epoch # 9226 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.0033150491490232525
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:04,713 INFO epoch # 9227 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.0032889870462895487
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:04,734 INFO epoch # 9228 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.0032927492502494715
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:04,756 INFO epoch # 9229 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.003373441153598833
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:04,778 INFO epoch # 9230 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.003286325320004835
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:57:04,779 INFO *** epoch 9230, rolling-avg-loss (window=10)= 0.003306917700865597
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:04,801 INFO epoch # 9231 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.001 -loss = 0.003323768742120592
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:04,823 INFO epoch # 9232 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032698138925297826
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:04,845 INFO epoch # 9233 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003279466856838553
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:04,867 INFO epoch # 9234 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032798878992252867
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:04,888 INFO epoch # 9235 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003271744145422417
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:04,910 INFO epoch # 9236 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032781532281660475
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:04,931 INFO epoch # 9237 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032719525315769715
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:04,952 INFO epoch # 9238 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003910702732355276
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:04,973 INFO epoch # 9239 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003268698393185332
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:04,996 INFO epoch # 9240 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003274186442467908
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:57:04,996 INFO *** epoch 9240, rolling-avg-loss (window=10)= 0.003342837486388817
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:05,018 INFO epoch # 9241 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00362338329978229
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:05,040 INFO epoch # 9242 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032697912101866677
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:05,061 INFO epoch # 9243 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032918644456003676
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:05,083 INFO epoch # 9244 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003274757661529293
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:05,105 INFO epoch # 9245 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0033046043554350035
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:05,126 INFO epoch # 9246 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003325315200527257
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:05,147 INFO epoch # 9247 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032745552534834133
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:05,168 INFO epoch # 9248 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003289498557933257
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:05,189 INFO epoch # 9249 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00329389602302399
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:05,211 INFO epoch # 9250 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003363849718880374
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:57:05,211 INFO *** epoch 9250, rolling-avg-loss (window=10)= 0.0033311515726381913
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:05,233 INFO epoch # 9251 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003338365535455523
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:05,256 INFO epoch # 9252 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032704239852137107
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:05,278 INFO epoch # 9253 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032885598366192426
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:05,299 INFO epoch # 9254 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032700146321076318
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:05,321 INFO epoch # 9255 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032946826686384156
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:05,342 INFO epoch # 9256 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003355820259457687
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:05,363 INFO epoch # 9257 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0033048318127839593
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:05,384 INFO epoch # 9258 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032682527589713573
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:05,406 INFO epoch # 9259 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032806657181936316
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:05,428 INFO epoch # 9260 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003294488247775007
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:57:05,428 INFO *** epoch 9260, rolling-avg-loss (window=10)= 0.0032966105455216168
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:05,450 INFO epoch # 9261 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0033512673744553467
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:05,472 INFO epoch # 9262 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003338115660881158
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:05,494 INFO epoch # 9263 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032716072691982845
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:05,515 INFO epoch # 9264 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0033013437168847304
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:05,536 INFO epoch # 9265 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0039341905885521555
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:05,557 INFO epoch # 9266 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032785823041194817
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:05,578 INFO epoch # 9267 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003303033702650282
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:05,599 INFO epoch # 9268 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0033478116965852678
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:05,621 INFO epoch # 9269 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003300155593024101
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:05,642 INFO epoch # 9270 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032703758106436
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:57:05,642 INFO *** epoch 9270, rolling-avg-loss (window=10)= 0.0033696483716994406
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:05,664 INFO epoch # 9271 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032886124981814646
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:05,686 INFO epoch # 9272 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032807133966343827
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:05,708 INFO epoch # 9273 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032847965030669
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:05,730 INFO epoch # 9274 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003270157852966804
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:05,753 INFO epoch # 9275 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00337908232359041
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:05,774 INFO epoch # 9276 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003289000098448014
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:05,795 INFO epoch # 9277 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00327227506932104
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:05,816 INFO epoch # 9278 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032819345742609585
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:05,838 INFO epoch # 9279 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003872806733852485
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:05,860 INFO epoch # 9280 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0033033715499186656
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:57:05,860 INFO *** epoch 9280, rolling-avg-loss (window=10)= 0.0033522750600241125
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:05,882 INFO epoch # 9281 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003274739698099438
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:05,904 INFO epoch # 9282 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032793054615467554
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:05,925 INFO epoch # 9283 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003265870301220275
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:05,947 INFO epoch # 9284 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003306232116301544
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:05,969 INFO epoch # 9285 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0036418031822904595
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:05,990 INFO epoch # 9286 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032682972932889243
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:06,011 INFO epoch # 9287 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032859887505765073
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:06,032 INFO epoch # 9288 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0035933564277002006
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:06,054 INFO epoch # 9289 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003286708290943352
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:06,075 INFO epoch # 9290 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032837520202519954
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:57:06,075 INFO *** epoch 9290, rolling-avg-loss (window=10)= 0.0033486053542219453
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:06,097 INFO epoch # 9291 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003265984438257874
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:06,119 INFO epoch # 9292 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032670786285962095
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:06,141 INFO epoch # 9293 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032679146806913195
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:06,163 INFO epoch # 9294 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003327450059259718
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:06,184 INFO epoch # 9295 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003298120480394573
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:06,205 INFO epoch # 9296 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0033596906050661346
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:06,226 INFO epoch # 9297 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003266436245667137
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:06,248 INFO epoch # 9298 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003354677831339359
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:06,269 INFO epoch # 9299 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003272427495176089
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:06,292 INFO epoch # 9300 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003364453446920379
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:57:06,292 INFO *** epoch 9300, rolling-avg-loss (window=10)= 0.0033044233911368793
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:06,313 INFO epoch # 9301 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00326698026037775
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:06,335 INFO epoch # 9302 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032877595385798486
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:06,357 INFO epoch # 9303 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003273405473009916
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:06,379 INFO epoch # 9304 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032977036735246656
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:06,400 INFO epoch # 9305 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032818224108268623
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:06,422 INFO epoch # 9306 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003273128697401262
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:06,443 INFO epoch # 9307 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032698079940018943
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:06,464 INFO epoch # 9308 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032846436188265216
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:06,485 INFO epoch # 9309 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032679508221917786
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:06,507 INFO epoch # 9310 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032647375498982
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:57:06,507 INFO *** epoch 9310, rolling-avg-loss (window=10)= 0.0032767940038638697
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:06,529 INFO epoch # 9311 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003282341703197744
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:06,551 INFO epoch # 9312 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0036844425230810884
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:06,572 INFO epoch # 9313 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0033004380011334433
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:06,594 INFO epoch # 9314 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032659467256053176
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:06,616 INFO epoch # 9315 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032810149641591124
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:06,637 INFO epoch # 9316 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003305150001324364
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:06,659 INFO epoch # 9317 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032728175565353013
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:06,680 INFO epoch # 9318 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003266495021762239
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:06,701 INFO epoch # 9319 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003265411185566336
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:06,723 INFO epoch # 9320 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003313333603728097
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:57:06,723 INFO *** epoch 9320, rolling-avg-loss (window=10)= 0.0033237391286093042
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:06,746 INFO epoch # 9321 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003309583815280348
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:06,768 INFO epoch # 9322 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0033035616879715235
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:06,790 INFO epoch # 9323 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032650944217493816
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:06,812 INFO epoch # 9324 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032872388264877372
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:06,833 INFO epoch # 9325 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003308150344309979
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:06,854 INFO epoch # 9326 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003910287943654112
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:06,875 INFO epoch # 9327 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032827617615112104
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:06,896 INFO epoch # 9328 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003379633523763914
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:06,918 INFO epoch # 9329 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032864143104234245
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:06,939 INFO epoch # 9330 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0033917848613782553
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:57:06,939 INFO *** epoch 9330, rolling-avg-loss (window=10)= 0.0033724511496529886
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:06,961 INFO epoch # 9331 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032630552009322855
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:06,984 INFO epoch # 9332 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032671108165232
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:07,006 INFO epoch # 9333 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032911011712712934
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:07,027 INFO epoch # 9334 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032780335805000504
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:07,049 INFO epoch # 9335 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032814072710607434
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:07,070 INFO epoch # 9336 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032768648543424206
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:07,091 INFO epoch # 9337 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032951848097582115
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:07,112 INFO epoch # 9338 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0033164523738378193
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:07,134 INFO epoch # 9339 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032919995583142736
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:07,156 INFO epoch # 9340 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0033305590450254385
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:57:07,156 INFO *** epoch 9340, rolling-avg-loss (window=10)= 0.0032891768681565735
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:07,177 INFO epoch # 9341 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003270419520958967
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:07,199 INFO epoch # 9342 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0038686507714373874
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:07,221 INFO epoch # 9343 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032919026098170434
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:07,242 INFO epoch # 9344 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032812331955938134
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:07,265 INFO epoch # 9345 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003262313804270889
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:07,287 INFO epoch # 9346 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00326248908368143
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:07,308 INFO epoch # 9347 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00327174680569442
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:07,329 INFO epoch # 9348 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0033186227828991832
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:07,350 INFO epoch # 9349 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0036729506937263068
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:07,372 INFO epoch # 9350 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003308898795694404
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:57:07,372 INFO *** epoch 9350, rolling-avg-loss (window=10)= 0.0033809228063773843
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:07,394 INFO epoch # 9351 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003283386682596756
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:07,416 INFO epoch # 9352 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003316972502943827
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:07,439 INFO epoch # 9353 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003274325925303856
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:07,461 INFO epoch # 9354 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003270749937655637
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:07,482 INFO epoch # 9355 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0033227851999981795
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:07,504 INFO epoch # 9356 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032948454272627714
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:07,525 INFO epoch # 9357 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0033626840286160586
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:07,546 INFO epoch # 9358 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032949204887700034
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:07,567 INFO epoch # 9359 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003282473742729053
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:07,589 INFO epoch # 9360 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003267532613790536
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:57:07,589 INFO *** epoch 9360, rolling-avg-loss (window=10)= 0.0032970676549666676
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:07,611 INFO epoch # 9361 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0033000478524627397
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:07,633 INFO epoch # 9362 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032652913778292714
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:07,655 INFO epoch # 9363 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032759643472672906
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:07,677 INFO epoch # 9364 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003261804621615738
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:07,698 INFO epoch # 9365 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032647473472025013
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:07,719 INFO epoch # 9366 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032666151673765853
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:07,740 INFO epoch # 9367 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032610934290460136
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:07,762 INFO epoch # 9368 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032665213566360762
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:07,784 INFO epoch # 9369 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003283848793216748
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:07,806 INFO epoch # 9370 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.004132803642278304
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:57:07,806 INFO *** epoch 9370, rolling-avg-loss (window=10)= 0.003357873793493127
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:07,828 INFO epoch # 9371 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0033610637956371647
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:07,850 INFO epoch # 9372 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032992090837069554
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:07,872 INFO epoch # 9373 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032955712649709312
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:07,893 INFO epoch # 9374 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003271482338277565
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:07,915 INFO epoch # 9375 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003275872587437334
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:07,936 INFO epoch # 9376 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032811761884659063
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:07,957 INFO epoch # 9377 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003284938886281452
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:07,978 INFO epoch # 9378 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032645496603436186
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:07,999 INFO epoch # 9379 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032676740647730185
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:08,021 INFO epoch # 9380 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032704366094549187
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:57:08,021 INFO *** epoch 9380, rolling-avg-loss (window=10)= 0.0032871974479348866
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:08,043 INFO epoch # 9381 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032717014905756514
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:08,065 INFO epoch # 9382 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0033214656959899003
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:08,087 INFO epoch # 9383 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032615631653243327
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:08,109 INFO epoch # 9384 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032720049894123804
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:08,130 INFO epoch # 9385 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003268569251304143
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:08,151 INFO epoch # 9386 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032610513735562563
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:08,172 INFO epoch # 9387 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032735693275753874
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:08,193 INFO epoch # 9388 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003347065264279081
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:08,214 INFO epoch # 9389 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032908924567891518
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:08,236 INFO epoch # 9390 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0039073479729268
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:57:08,236 INFO *** epoch 9390, rolling-avg-loss (window=10)= 0.0033475230987733084
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:08,258 INFO epoch # 9391 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0033205296113010263
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:08,280 INFO epoch # 9392 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003279798613220919
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:08,302 INFO epoch # 9393 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003299476348729513
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:08,324 INFO epoch # 9394 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032932143285506754
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:08,345 INFO epoch # 9395 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003358283219313307
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:08,367 INFO epoch # 9396 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0033220588893527747
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:08,388 INFO epoch # 9397 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003280934877693653
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:08,409 INFO epoch # 9398 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0033084804736063234
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:08,431 INFO epoch # 9399 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003264821068114543
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:08,452 INFO epoch # 9400 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032731268188399554
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:57:08,452 INFO *** epoch 9400, rolling-avg-loss (window=10)= 0.003300072424872269
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:08,474 INFO epoch # 9401 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032711111980461283
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:08,496 INFO epoch # 9402 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003311843908704759
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:08,518 INFO epoch # 9403 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032882001705729635
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:08,539 INFO epoch # 9404 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032848233204276767
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:08,561 INFO epoch # 9405 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032756249893282074
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:08,582 INFO epoch # 9406 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003667951167699357
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:08,603 INFO epoch # 9407 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032672196703060763
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:08,625 INFO epoch # 9408 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032668900921635213
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:08,646 INFO epoch # 9409 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003278115153989347
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:08,668 INFO epoch # 9410 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003611181849919376
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:57:08,668 INFO *** epoch 9410, rolling-avg-loss (window=10)= 0.0033522961521157413
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:08,690 INFO epoch # 9411 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003272148349424242
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:08,711 INFO epoch # 9412 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032630650430292008
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:08,733 INFO epoch # 9413 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032845813966559945
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:08,755 INFO epoch # 9414 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0038951473870838527
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:08,776 INFO epoch # 9415 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003926931751266238
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:08,798 INFO epoch # 9416 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0033557710630702786
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:08,819 INFO epoch # 9417 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003322793212646502
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:08,840 INFO epoch # 9418 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00326271992889815
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:08,861 INFO epoch # 9419 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0033287245114479447
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:08,883 INFO epoch # 9420 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032906492306210566
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:57:08,883 INFO *** epoch 9420, rolling-avg-loss (window=10)= 0.003420253187414346
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:08,906 INFO epoch # 9421 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003307412592221226
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:08,931 INFO epoch # 9422 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003289420351393346
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:08,953 INFO epoch # 9423 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003671559945360059
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:08,974 INFO epoch # 9424 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032713796572352294
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:08,996 INFO epoch # 9425 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003305301526779658
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:09,017 INFO epoch # 9426 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032576403391431086
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:09,038 INFO epoch # 9427 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032573796661381493
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:09,059 INFO epoch # 9428 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003350778703861579
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:09,080 INFO epoch # 9429 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003304294992631185
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:09,103 INFO epoch # 9430 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032588789508736227
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:57:09,103 INFO *** epoch 9430, rolling-avg-loss (window=10)= 0.0033274046725637165
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:09,124 INFO epoch # 9431 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032686823869880755
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:09,146 INFO epoch # 9432 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003284672857262194
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:09,168 INFO epoch # 9433 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003257458875850716
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:09,189 INFO epoch # 9434 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003345059669300099
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:09,211 INFO epoch # 9435 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003267253802732739
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:09,232 INFO epoch # 9436 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003264959391344746
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:09,255 INFO epoch # 9437 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0033188760298799025
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:09,276 INFO epoch # 9438 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0033027967874659225
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:09,297 INFO epoch # 9439 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003272583140642382
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:09,319 INFO epoch # 9440 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032697945953259477
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:57:09,319 INFO *** epoch 9440, rolling-avg-loss (window=10)= 0.0032852137536792726
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:09,341 INFO epoch # 9441 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003260669659539417
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:09,363 INFO epoch # 9442 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003308631354229874
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:09,385 INFO epoch # 9443 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003335910638270434
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:09,406 INFO epoch # 9444 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032802436071506236
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:09,428 INFO epoch # 9445 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003267343219704344
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:09,449 INFO epoch # 9446 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0033209571229235735
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:09,470 INFO epoch # 9447 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003263378243900661
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:09,491 INFO epoch # 9448 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00325685569214329
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:09,512 INFO epoch # 9449 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0036052172417839756
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:09,534 INFO epoch # 9450 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032733010684751207
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:57:09,534 INFO *** epoch 9450, rolling-avg-loss (window=10)= 0.0033172507848121314
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:09,556 INFO epoch # 9451 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032575646864643204
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:09,578 INFO epoch # 9452 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0033058657154469984
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:09,600 INFO epoch # 9453 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003272752604971174
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:09,621 INFO epoch # 9454 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.004164410107478034
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:09,643 INFO epoch # 9455 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003945577605009021
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:09,664 INFO epoch # 9456 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032841534030012554
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:09,685 INFO epoch # 9457 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003262249468207301
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:09,706 INFO epoch # 9458 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003256234679156478
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:09,727 INFO epoch # 9459 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032810659522510832
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:09,750 INFO epoch # 9460 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032723547501518624
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:57:09,750 INFO *** epoch 9460, rolling-avg-loss (window=10)= 0.0034302228972137526
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:09,772 INFO epoch # 9461 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003287407227617223
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:09,794 INFO epoch # 9462 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032799000564409653
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:09,816 INFO epoch # 9463 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0033213032056664815
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:09,837 INFO epoch # 9464 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032550749733673
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:09,859 INFO epoch # 9465 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.004272104038136604
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:09,880 INFO epoch # 9466 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003257709337049164
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:09,901 INFO epoch # 9467 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032688186120140017
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:09,922 INFO epoch # 9468 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032687253196854726
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:09,943 INFO epoch # 9469 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032683917797839968
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:09,965 INFO epoch # 9470 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00366697308345465
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:57:09,966 INFO *** epoch 9470, rolling-avg-loss (window=10)= 0.0034146407633215857
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:09,987 INFO epoch # 9471 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032682350420145667
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:10,009 INFO epoch # 9472 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.004287503817977267
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:10,031 INFO epoch # 9473 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003313235705718398
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:10,053 INFO epoch # 9474 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032974142750390456
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:10,074 INFO epoch # 9475 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003259652834458393
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:10,096 INFO epoch # 9476 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0042584867387631675
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:10,117 INFO epoch # 9477 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003325296749608242
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:10,138 INFO epoch # 9478 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032988318016577978
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:10,159 INFO epoch # 9479 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032650820330673014
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:10,181 INFO epoch # 9480 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032758901252236683
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:57:10,181 INFO *** epoch 9480, rolling-avg-loss (window=10)= 0.0034849629123527848
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:10,203 INFO epoch # 9481 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0033139163278974593
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:10,224 INFO epoch # 9482 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032687291832189658
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:10,246 INFO epoch # 9483 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003282044931438577
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:10,268 INFO epoch # 9484 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032659556027283543
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:10,290 INFO epoch # 9485 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032554216541029746
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:10,311 INFO epoch # 9486 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003262739035562845
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:10,332 INFO epoch # 9487 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00328454804730427
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:10,353 INFO epoch # 9488 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0033721071849868167
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:10,374 INFO epoch # 9489 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032888855639612302
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:10,396 INFO epoch # 9490 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032762134360382333
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:57:10,397 INFO *** epoch 9490, rolling-avg-loss (window=10)= 0.0032870560967239726
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:10,419 INFO epoch # 9491 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032582435460426495
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:10,440 INFO epoch # 9492 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032961520319076953
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:10,463 INFO epoch # 9493 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0033078319947890122
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:10,484 INFO epoch # 9494 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032626965148665477
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:10,506 INFO epoch # 9495 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003290169952379074
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:10,528 INFO epoch # 9496 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0033180057544086594
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:10,549 INFO epoch # 9497 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0033456697046858608
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:10,570 INFO epoch # 9498 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003253634411976236
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:10,592 INFO epoch # 9499 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003269387707405258
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:10,614 INFO epoch # 9500 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003281046303527546
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:57:10,614 INFO *** epoch 9500, rolling-avg-loss (window=10)= 0.0032882837921988537
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:10,636 INFO epoch # 9501 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032581309942543157
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:10,658 INFO epoch # 9502 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003262993039243156
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:10,680 INFO epoch # 9503 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032546841835028317
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:10,702 INFO epoch # 9504 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003272559588367585
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:10,723 INFO epoch # 9505 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032924911047302885
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:10,745 INFO epoch # 9506 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0036294847368480987
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:10,767 INFO epoch # 9507 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00333344944374403
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:10,788 INFO epoch # 9508 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003279025875599473
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:10,810 INFO epoch # 9509 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032546333386562765
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:10,832 INFO epoch # 9510 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032774366382000153
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:57:10,832 INFO *** epoch 9510, rolling-avg-loss (window=10)= 0.003311488894314607
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:10,854 INFO epoch # 9511 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032538048035348766
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:10,876 INFO epoch # 9512 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0033453915757490904
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:10,898 INFO epoch # 9513 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003251750886647642
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:10,920 INFO epoch # 9514 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003264036459768249
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:10,941 INFO epoch # 9515 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032743638366810046
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:10,962 INFO epoch # 9516 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003260116006458702
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:10,983 INFO epoch # 9517 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032576763496763306
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:11,005 INFO epoch # 9518 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032875204742595088
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:11,027 INFO epoch # 9519 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032529231843909656
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:11,049 INFO epoch # 9520 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032659343250998063
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:57:11,049 INFO *** epoch 9520, rolling-avg-loss (window=10)= 0.0032713517902266177
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:11,071 INFO epoch # 9521 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032556244277657242
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:11,093 INFO epoch # 9522 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032560579893470276
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:11,115 INFO epoch # 9523 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003261631263740128
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:11,136 INFO epoch # 9524 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032864347849681508
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:11,158 INFO epoch # 9525 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0034120853424610686
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:11,179 INFO epoch # 9526 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032623424340272322
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:11,200 INFO epoch # 9527 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0039034851606629672
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:11,221 INFO epoch # 9528 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032912626447796356
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:11,242 INFO epoch # 9529 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0033222697929886635
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:11,265 INFO epoch # 9530 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003252374556268478
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:57:11,265 INFO *** epoch 9530, rolling-avg-loss (window=10)= 0.0033503568397009074
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:11,287 INFO epoch # 9531 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032628126500640064
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:11,309 INFO epoch # 9532 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003255873822126887
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:11,331 INFO epoch # 9533 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003275685422522656
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:11,353 INFO epoch # 9534 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003315587148790655
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:11,375 INFO epoch # 9535 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032616248299746076
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:11,396 INFO epoch # 9536 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00327102151732106
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:11,417 INFO epoch # 9537 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003250763624691899
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:11,438 INFO epoch # 9538 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003331805728521431
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:11,460 INFO epoch # 9539 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003272879968790221
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:11,481 INFO epoch # 9540 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003298653519777872
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:57:11,482 INFO *** epoch 9540, rolling-avg-loss (window=10)= 0.0032796708232581294
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:11,503 INFO epoch # 9541 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032794855960673885
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:11,525 INFO epoch # 9542 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032988834082061658
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:11,547 INFO epoch # 9543 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0038908476267351944
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:11,568 INFO epoch # 9544 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0038856671717439895
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:11,590 INFO epoch # 9545 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003298932910183794
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:11,612 INFO epoch # 9546 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003330626459501218
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:11,633 INFO epoch # 9547 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032507954301763675
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:11,654 INFO epoch # 9548 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003274427235737676
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:11,675 INFO epoch # 9549 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0033281843625445617
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:11,697 INFO epoch # 9550 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032622227572574047
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:57:11,697 INFO *** epoch 9550, rolling-avg-loss (window=10)= 0.003410007295815376
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:11,719 INFO epoch # 9551 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032715893767090165
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:11,740 INFO epoch # 9552 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032754929134171107
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:11,763 INFO epoch # 9553 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032767416532806237
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:11,784 INFO epoch # 9554 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032707561094866833
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:11,806 INFO epoch # 9555 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003375929518369958
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:11,827 INFO epoch # 9556 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003250558700528927
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:11,848 INFO epoch # 9557 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032942113211902324
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:11,870 INFO epoch # 9558 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003293835169642989
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:11,891 INFO epoch # 9559 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003253390083045815
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:11,913 INFO epoch # 9560 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0033062275797419716
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:57:11,913 INFO *** epoch 9560, rolling-avg-loss (window=10)= 0.0032868732425413326
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:11,935 INFO epoch # 9561 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003285225717263529
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:11,957 INFO epoch # 9562 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003262073285441147
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:11,979 INFO epoch # 9563 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003282569642578892
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:12,000 INFO epoch # 9564 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003264119067353022
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:12,021 INFO epoch # 9565 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00325020372565632
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:12,042 INFO epoch # 9566 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003989114827163576
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:12,063 INFO epoch # 9567 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003313924538815627
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:12,085 INFO epoch # 9568 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032490202506778587
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:12,106 INFO epoch # 9569 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032501266964573006
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:12,128 INFO epoch # 9570 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032601725361018907
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:57:12,128 INFO *** epoch 9570, rolling-avg-loss (window=10)= 0.0033406550287509162
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:12,150 INFO epoch # 9571 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003674834532830573
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:12,171 INFO epoch # 9572 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003267049614805728
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:12,193 INFO epoch # 9573 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032529975960642332
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:12,214 INFO epoch # 9574 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032656165276421234
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:12,235 INFO epoch # 9575 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003331735601022956
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:12,257 INFO epoch # 9576 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003276534875112702
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:12,278 INFO epoch # 9577 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032560191316406417
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:12,300 INFO epoch # 9578 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00325248105218634
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:12,322 INFO epoch # 9579 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.004183508368441835
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:12,344 INFO epoch # 9580 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0033008590471581556
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:57:12,344 INFO *** epoch 9580, rolling-avg-loss (window=10)= 0.0034061636346905287
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:12,366 INFO epoch # 9581 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032590922764939023
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:12,387 INFO epoch # 9582 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003333035099785775
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:12,409 INFO epoch # 9583 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003333276709781785
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:12,431 INFO epoch # 9584 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032566002973908326
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:12,452 INFO epoch # 9585 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032547673326916993
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:12,474 INFO epoch # 9586 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032563103004576988
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:12,495 INFO epoch # 9587 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003356226240612159
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:12,516 INFO epoch # 9588 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003366686087247217
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:12,537 INFO epoch # 9589 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032512036159459967
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:12,559 INFO epoch # 9590 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0038831939727970166
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:57:12,559 INFO *** epoch 9590, rolling-avg-loss (window=10)= 0.003355039193320408
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:12,581 INFO epoch # 9591 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.004136609201850661
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:12,603 INFO epoch # 9592 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003259664323195466
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:12,625 INFO epoch # 9593 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032584657728875754
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:12,647 INFO epoch # 9594 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003283796248069848
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:12,669 INFO epoch # 9595 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003271127468906343
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:12,690 INFO epoch # 9596 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032694011861167382
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:12,711 INFO epoch # 9597 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032633434884701273
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:12,732 INFO epoch # 9598 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0033137923610411235
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:12,754 INFO epoch # 9599 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0033032804167305585
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:12,776 INFO epoch # 9600 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003249486619097297
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:57:12,776 INFO *** epoch 9600, rolling-avg-loss (window=10)= 0.003360896708636574
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:12,798 INFO epoch # 9601 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0033346711716149002
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:12,820 INFO epoch # 9602 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032790151963126846
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:12,842 INFO epoch # 9603 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0033017836403814727
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:12,864 INFO epoch # 9604 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032622292301311973
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:12,885 INFO epoch # 9605 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032791184094094206
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:12,907 INFO epoch # 9606 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003304329709862941
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:12,928 INFO epoch # 9607 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00329127065197099
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:12,949 INFO epoch # 9608 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032696337711968226
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:12,970 INFO epoch # 9609 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0036593512068066048
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:12,992 INFO epoch # 9610 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00329753784899367
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:57:12,992 INFO *** epoch 9610, rolling-avg-loss (window=10)= 0.0033278940836680704
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:13,014 INFO epoch # 9611 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032930774414126063
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:13,036 INFO epoch # 9612 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032623785536998184
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:13,058 INFO epoch # 9613 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0033291582385572838
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:13,080 INFO epoch # 9614 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0033682313369354233
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:13,102 INFO epoch # 9615 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0036424731461011106
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:13,123 INFO epoch # 9616 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032747945169830928
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:13,144 INFO epoch # 9617 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032675196835043607
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:13,165 INFO epoch # 9618 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003247569287850638
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:13,187 INFO epoch # 9619 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032506569777979166
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:13,208 INFO epoch # 9620 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003246518396281317
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:57:13,208 INFO *** epoch 9620, rolling-avg-loss (window=10)= 0.003318237757912357
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:13,231 INFO epoch # 9621 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032925438672464225
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:13,253 INFO epoch # 9622 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003249398044317786
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:13,275 INFO epoch # 9623 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0033766044580261223
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:13,297 INFO epoch # 9624 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032632796519465046
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:13,319 INFO epoch # 9625 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032624649511490134
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:13,340 INFO epoch # 9626 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032472866150783375
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:13,361 INFO epoch # 9627 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003247320205446158
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:13,382 INFO epoch # 9628 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032946095016086474
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:13,404 INFO epoch # 9629 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003261127918449347
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:13,426 INFO epoch # 9630 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032581536506768316
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:57:13,426 INFO *** epoch 9630, rolling-avg-loss (window=10)= 0.003275278886394517
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:13,448 INFO epoch # 9631 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003296053287158429
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:13,470 INFO epoch # 9632 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032624519371893257
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:13,492 INFO epoch # 9633 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032788971129775746
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:13,513 INFO epoch # 9634 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003247087714044028
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:13,535 INFO epoch # 9635 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.004123071898902708
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:13,556 INFO epoch # 9636 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003260990402850439
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:13,578 INFO epoch # 9637 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003730492193426471
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:13,599 INFO epoch # 9638 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032583003621766693
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:13,620 INFO epoch # 9639 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003652809891718789
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:13,643 INFO epoch # 9640 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003257451614445017
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:57:13,643 INFO *** epoch 9640, rolling-avg-loss (window=10)= 0.003436760641488945
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:13,665 INFO epoch # 9641 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032497402471562964
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:13,687 INFO epoch # 9642 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032473306437168503
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:13,708 INFO epoch # 9643 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0033367609794368036
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:13,730 INFO epoch # 9644 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0033956595761992503
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:13,753 INFO epoch # 9645 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003256422295635275
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:13,774 INFO epoch # 9646 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003244248725422949
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:13,796 INFO epoch # 9647 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003254713497881312
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:13,817 INFO epoch # 9648 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003932845849703881
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:13,838 INFO epoch # 9649 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003249190691349213
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:13,860 INFO epoch # 9650 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032572350437476416
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:57:13,860 INFO *** epoch 9650, rolling-avg-loss (window=10)= 0.0033424147550249472
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:13,882 INFO epoch # 9651 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032502874792044167
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:13,904 INFO epoch # 9652 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003244152917432075
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:13,926 INFO epoch # 9653 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032536376838834258
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:13,947 INFO epoch # 9654 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003247671085773618
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:13,969 INFO epoch # 9655 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003255707455537049
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:13,990 INFO epoch # 9656 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032656187413522275
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:14,011 INFO epoch # 9657 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032496083967998857
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:14,032 INFO epoch # 9658 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.004259597750206012
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:14,053 INFO epoch # 9659 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032541163764108205
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:14,075 INFO epoch # 9660 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003282842020780663
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:57:14,075 INFO *** epoch 9660, rolling-avg-loss (window=10)= 0.0033563239907380194
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:14,097 INFO epoch # 9661 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032792728015920147
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:14,119 INFO epoch # 9662 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032648717024130747
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:14,141 INFO epoch # 9663 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003283335429841827
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:14,162 INFO epoch # 9664 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032531109673072933
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:14,184 INFO epoch # 9665 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032635934576319414
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:14,205 INFO epoch # 9666 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003265200016357994
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:14,226 INFO epoch # 9667 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003252124557548086
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:14,248 INFO epoch # 9668 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032642231599311344
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:14,270 INFO epoch # 9669 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003263966589656775
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:14,292 INFO epoch # 9670 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032547650898777647
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:57:14,292 INFO *** epoch 9670, rolling-avg-loss (window=10)= 0.0032644463772157906
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:14,314 INFO epoch # 9671 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003327814418298658
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:14,336 INFO epoch # 9672 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032649028944433667
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:14,359 INFO epoch # 9673 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00327307210136496
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:14,381 INFO epoch # 9674 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032635180723445956
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:14,402 INFO epoch # 9675 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003254845984884014
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:14,424 INFO epoch # 9676 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032504342307220213
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:14,445 INFO epoch # 9677 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003241947681090096
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:14,466 INFO epoch # 9678 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032921365718721063
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:14,488 INFO epoch # 9679 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032586467004875885
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:14,509 INFO epoch # 9680 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032511707931917044
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:57:14,509 INFO *** epoch 9680, rolling-avg-loss (window=10)= 0.003267848944869911
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:14,531 INFO epoch # 9681 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032580114930169657
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:14,553 INFO epoch # 9682 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003316609148896532
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:14,575 INFO epoch # 9683 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003288357556812116
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:14,597 INFO epoch # 9684 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0038805685107945465
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:14,618 INFO epoch # 9685 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032435874013572175
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:14,639 INFO epoch # 9686 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003244455746425956
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:14,661 INFO epoch # 9687 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032751104645285523
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:14,682 INFO epoch # 9688 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032851992978066846
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:14,703 INFO epoch # 9689 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003275388437032234
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:14,725 INFO epoch # 9690 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032990646068356
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:57:14,725 INFO *** epoch 9690, rolling-avg-loss (window=10)= 0.0033366352663506404
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:14,747 INFO epoch # 9691 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0033085996201407397
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:14,770 INFO epoch # 9692 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032629137685944443
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:14,792 INFO epoch # 9693 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032877170324354665
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:14,813 INFO epoch # 9694 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003362225723321899
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:14,835 INFO epoch # 9695 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003871434446409694
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:14,856 INFO epoch # 9696 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003298293179796019
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:14,877 INFO epoch # 9697 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0033211814688911545
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:14,898 INFO epoch # 9698 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.004249933840583253
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:14,920 INFO epoch # 9699 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032401509938608797
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:14,942 INFO epoch # 9700 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0033766655415092828
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:57:14,942 INFO *** epoch 9700, rolling-avg-loss (window=10)= 0.0034579115615542833
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:14,964 INFO epoch # 9701 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003248748214900843
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:14,985 INFO epoch # 9702 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003258073516917648
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:15,007 INFO epoch # 9703 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032760845315351617
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:15,029 INFO epoch # 9704 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032755646789155435
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:15,050 INFO epoch # 9705 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0035973399399154005
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:15,072 INFO epoch # 9706 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003251996457038331
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:15,093 INFO epoch # 9707 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0033419377523387084
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:15,114 INFO epoch # 9708 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032578696627751924
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:15,135 INFO epoch # 9709 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003321032219901099
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:15,157 INFO epoch # 9710 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003332460431010986
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:57:15,157 INFO *** epoch 9710, rolling-avg-loss (window=10)= 0.003316110740524891
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:15,179 INFO epoch # 9711 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003258109840317047
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:15,201 INFO epoch # 9712 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003244419641305285
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:15,222 INFO epoch # 9713 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0033162070121761644
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:15,244 INFO epoch # 9714 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032866443834791426
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:15,266 INFO epoch # 9715 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003242424761992879
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:15,288 INFO epoch # 9716 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0033068169504986145
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:15,309 INFO epoch # 9717 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003244945154619927
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:15,330 INFO epoch # 9718 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032657494539307663
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:15,351 INFO epoch # 9719 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032810369430080755
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:15,373 INFO epoch # 9720 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003292334581601608
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:57:15,373 INFO *** epoch 9720, rolling-avg-loss (window=10)= 0.003273868872292951
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:15,395 INFO epoch # 9721 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003258812033891445
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:15,417 INFO epoch # 9722 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003278218962805113
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:15,438 INFO epoch # 9723 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003252374295698246
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:15,460 INFO epoch # 9724 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032439473225167603
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:15,481 INFO epoch # 9725 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0036152098036836833
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:15,503 INFO epoch # 9726 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003262111034928239
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:15,524 INFO epoch # 9727 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0035063403392996406
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:15,545 INFO epoch # 9728 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00325225569667964
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:15,566 INFO epoch # 9729 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032440735303680412
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:15,588 INFO epoch # 9730 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003239308700813126
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:57:15,588 INFO *** epoch 9730, rolling-avg-loss (window=10)= 0.0033152651720683934
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:15,610 INFO epoch # 9731 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0033037450648407685
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:15,632 INFO epoch # 9732 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003240249711780052
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:15,654 INFO epoch # 9733 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032547410555707756
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:15,675 INFO epoch # 9734 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003906573036147165
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:15,697 INFO epoch # 9735 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003277551850260352
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:15,718 INFO epoch # 9736 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032559239498368697
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:15,739 INFO epoch # 9737 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032471270314999856
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:15,761 INFO epoch # 9738 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032769134377304
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:15,783 INFO epoch # 9739 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032411981815130275
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:15,805 INFO epoch # 9740 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032473957726324443
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:57:15,805 INFO *** epoch 9740, rolling-avg-loss (window=10)= 0.003325141909181184
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:15,827 INFO epoch # 9741 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032457493671245174
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:15,849 INFO epoch # 9742 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032545759404456476
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:15,871 INFO epoch # 9743 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032559138344367966
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:15,893 INFO epoch # 9744 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003316063206511899
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:15,914 INFO epoch # 9745 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032561524112679763
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:15,935 INFO epoch # 9746 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00326926510388148
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:15,957 INFO epoch # 9747 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032430847986688605
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:15,978 INFO epoch # 9748 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0033307629801129224
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:15,999 INFO epoch # 9749 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003246004638640443
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:16,021 INFO epoch # 9750 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032645605515426723
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:57:16,021 INFO *** epoch 9750, rolling-avg-loss (window=10)= 0.0032682132832633215
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:16,043 INFO epoch # 9751 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032776639873191016
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:16,065 INFO epoch # 9752 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032561412826908054
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:16,087 INFO epoch # 9753 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003257360588577285
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:16,109 INFO epoch # 9754 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032539355270273518
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:16,130 INFO epoch # 9755 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0033436005978728645
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:16,152 INFO epoch # 9756 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0036677194484582287
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:16,173 INFO epoch # 9757 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032407507715106476
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:16,194 INFO epoch # 9758 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003316808912131819
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:16,215 INFO epoch # 9759 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00331550265855185
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:16,237 INFO epoch # 9760 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0033635769177635666
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:57:16,237 INFO *** epoch 9760, rolling-avg-loss (window=10)= 0.003329306069190352
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:16,259 INFO epoch # 9761 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032472735683768406
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:16,281 INFO epoch # 9762 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00409570006740978
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:16,303 INFO epoch # 9763 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032766023323347326
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:16,325 INFO epoch # 9764 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032603742047285778
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:16,347 INFO epoch # 9765 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032408599445261643
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:16,368 INFO epoch # 9766 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032390537621722615
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:16,389 INFO epoch # 9767 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032835053589224117
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:16,410 INFO epoch # 9768 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032732515883253654
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:16,432 INFO epoch # 9769 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032656852763466304
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:16,454 INFO epoch # 9770 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003244214990445471
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:57:16,454 INFO *** epoch 9770, rolling-avg-loss (window=10)= 0.0033426521093588234
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:16,476 INFO epoch # 9771 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003238497766687942
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:16,498 INFO epoch # 9772 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032462316667078994
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:16,519 INFO epoch # 9773 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032566554054938024
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:16,541 INFO epoch # 9774 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003256825251810369
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:16,563 INFO epoch # 9775 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032520143104193266
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:16,585 INFO epoch # 9776 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003356701226948644
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:16,606 INFO epoch # 9777 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032434699478471885
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:16,628 INFO epoch # 9778 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00326069490165537
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:16,650 INFO epoch # 9779 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032393405490438454
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:16,672 INFO epoch # 9780 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003243267417019524
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:57:16,672 INFO *** epoch 9780, rolling-avg-loss (window=10)= 0.003259369844363391
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:16,694 INFO epoch # 9781 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032429920402137213
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:16,716 INFO epoch # 9782 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032740473534431658
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:16,739 INFO epoch # 9783 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003284710192019702
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:16,760 INFO epoch # 9784 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003273405354775605
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:16,782 INFO epoch # 9785 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003278153668361483
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:16,804 INFO epoch # 9786 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003241351884753385
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:16,825 INFO epoch # 9787 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003235794215925125
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:16,846 INFO epoch # 9788 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003247140882194799
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:16,867 INFO epoch # 9789 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0033093965030275285
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:16,889 INFO epoch # 9790 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032547770751989447
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:57:16,890 INFO *** epoch 9790, rolling-avg-loss (window=10)= 0.003264176916991346
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:16,911 INFO epoch # 9791 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003246355179726379
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:16,933 INFO epoch # 9792 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032738313739173464
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:16,955 INFO epoch # 9793 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003263651631641551
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:16,977 INFO epoch # 9794 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032500267916475423
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:16,998 INFO epoch # 9795 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003288945576059632
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:17,019 INFO epoch # 9796 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032433927171950927
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:17,040 INFO epoch # 9797 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00376199713718961
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:17,062 INFO epoch # 9798 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003272195918725629
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:17,083 INFO epoch # 9799 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032378517689721775
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:17,105 INFO epoch # 9800 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003248325361710158
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:57:17,105 INFO *** epoch 9800, rolling-avg-loss (window=10)= 0.003308657345678512
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:17,127 INFO epoch # 9801 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003317807661005645
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:17,149 INFO epoch # 9802 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032662188923495705
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:17,171 INFO epoch # 9803 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003281393683209899
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:17,192 INFO epoch # 9804 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0033580798053662875
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:17,214 INFO epoch # 9805 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00324078487483348
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:17,235 INFO epoch # 9806 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00327479833686084
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:17,257 INFO epoch # 9807 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032394405388913583
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:17,278 INFO epoch # 9808 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032538494197069667
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:17,299 INFO epoch # 9809 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032384613468821044
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:17,321 INFO epoch # 9810 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003240185755203129
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:57:17,321 INFO *** epoch 9810, rolling-avg-loss (window=10)= 0.003271102031430928
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:17,343 INFO epoch # 9811 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032574513970757835
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:17,365 INFO epoch # 9812 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032578607333562104
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:17,387 INFO epoch # 9813 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032347402002415038
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:17,408 INFO epoch # 9814 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0033980729331233306
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:17,430 INFO epoch # 9815 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032594738850093563
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:17,452 INFO epoch # 9816 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003266594485467067
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:17,473 INFO epoch # 9817 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032361615662921395
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:17,494 INFO epoch # 9818 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032627480704832124
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:17,515 INFO epoch # 9819 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003280844672190142
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:17,537 INFO epoch # 9820 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032472142220285605
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:57:17,537 INFO *** epoch 9820, rolling-avg-loss (window=10)= 0.0032701162165267306
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:17,559 INFO epoch # 9821 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003233418602576421
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:17,581 INFO epoch # 9822 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0033510320417917683
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:17,603 INFO epoch # 9823 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003246971582484548
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:17,625 INFO epoch # 9824 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003288447564045782
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:17,646 INFO epoch # 9825 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003239869595745404
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:17,667 INFO epoch # 9826 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003246626088184712
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:17,689 INFO epoch # 9827 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003321983031128184
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:17,710 INFO epoch # 9828 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032372516980103683
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:17,731 INFO epoch # 9829 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0036376443440531148
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:17,754 INFO epoch # 9830 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003240001502490486
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:57:17,754 INFO *** epoch 9830, rolling-avg-loss (window=10)= 0.0033043246050510787
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:17,776 INFO epoch # 9831 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032590506075393932
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:17,798 INFO epoch # 9832 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032731557284932933
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:17,820 INFO epoch # 9833 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032360273362428416
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:17,842 INFO epoch # 9834 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003247345777708688
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:17,863 INFO epoch # 9835 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032656607199896825
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:17,884 INFO epoch # 9836 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003236462012409902
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:17,905 INFO epoch # 9837 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032376499839301687
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:17,927 INFO epoch # 9838 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003238776818761835
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:17,948 INFO epoch # 9839 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032618134700896917
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:17,970 INFO epoch # 9840 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032880154276426765
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:57:17,970 INFO *** epoch 9840, rolling-avg-loss (window=10)= 0.003254395788280817
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:17,992 INFO epoch # 9841 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032376789204136003
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:18,014 INFO epoch # 9842 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.004106095990209724
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:18,036 INFO epoch # 9843 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032584985510766273
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:18,058 INFO epoch # 9844 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032365621809731238
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:18,079 INFO epoch # 9845 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032589510847174097
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:18,100 INFO epoch # 9846 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032478881967108464
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:18,121 INFO epoch # 9847 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032629459201416466
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:18,143 INFO epoch # 9848 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003291107994300546
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:18,164 INFO epoch # 9849 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0033041464803318377
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:18,185 INFO epoch # 9850 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032358225444113486
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:57:18,186 INFO *** epoch 9850, rolling-avg-loss (window=10)= 0.003343969786328671
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:18,207 INFO epoch # 9851 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032468332210555673
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:18,229 INFO epoch # 9852 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003310053630229959
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:18,251 INFO epoch # 9853 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032325132619916985
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:18,273 INFO epoch # 9854 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032420287679997273
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:18,295 INFO epoch # 9855 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003249057472203276
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:18,316 INFO epoch # 9856 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003245359852371621
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:18,337 INFO epoch # 9857 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032586255356363836
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:18,358 INFO epoch # 9858 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003282325744294212
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:18,379 INFO epoch # 9859 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032675421425665263
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:18,401 INFO epoch # 9860 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032492731079400983
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:57:18,402 INFO *** epoch 9860, rolling-avg-loss (window=10)= 0.003258361273628907
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:18,424 INFO epoch # 9861 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032417374377473607
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:18,445 INFO epoch # 9862 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003236558237404097
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:18,467 INFO epoch # 9863 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032447667144879233
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:18,489 INFO epoch # 9864 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003232590720472217
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:18,510 INFO epoch # 9865 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032786465180834057
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:18,532 INFO epoch # 9866 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032507638788956683
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:18,553 INFO epoch # 9867 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032515077027710504
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:18,574 INFO epoch # 9868 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032396384067396866
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:18,595 INFO epoch # 9869 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032583803276793333
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:18,618 INFO epoch # 9870 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032401173211837886
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:57:18,618 INFO *** epoch 9870, rolling-avg-loss (window=10)= 0.003247470726546453
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:18,640 INFO epoch # 9871 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0033206926891580224
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:18,662 INFO epoch # 9872 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.004233559851854807
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:18,683 INFO epoch # 9873 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032345947893190896
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:18,705 INFO epoch # 9874 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003278504704212537
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:18,726 INFO epoch # 9875 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032360682907892624
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:18,748 INFO epoch # 9876 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00328272579190525
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:18,770 INFO epoch # 9877 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032354201230191393
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:18,791 INFO epoch # 9878 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032411058818979654
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:18,812 INFO epoch # 9879 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032304033875334426
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:18,835 INFO epoch # 9880 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032772416179795982
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:57:18,835 INFO *** epoch 9880, rolling-avg-loss (window=10)= 0.0033570317127669114
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:18,857 INFO epoch # 9881 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032370694334531436
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:18,879 INFO epoch # 9882 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032343439361284254
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:18,901 INFO epoch # 9883 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032396547412645305
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:18,922 INFO epoch # 9884 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003280528572759067
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:18,944 INFO epoch # 9885 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032600100266790832
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:18,965 INFO epoch # 9886 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003237748132960405
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:18,986 INFO epoch # 9887 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032387022220063955
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:19,007 INFO epoch # 9888 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0033029808018909534
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:19,029 INFO epoch # 9889 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032422391486761626
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:19,051 INFO epoch # 9890 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032835795973369386
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:57:19,051 INFO *** epoch 9890, rolling-avg-loss (window=10)= 0.0032556856613155105
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:19,073 INFO epoch # 9891 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003257806203691871
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:19,095 INFO epoch # 9892 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032643513804941904
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:19,116 INFO epoch # 9893 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032354735867556883
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:19,138 INFO epoch # 9894 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032565269284532405
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:19,159 INFO epoch # 9895 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003237426548366784
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:19,180 INFO epoch # 9896 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003244520945372642
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:19,202 INFO epoch # 9897 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032666596698618378
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:19,223 INFO epoch # 9898 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003237668423935247
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:19,244 INFO epoch # 9899 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032454658057758934
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:19,266 INFO epoch # 9900 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003239028181269532
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:57:19,266 INFO *** epoch 9900, rolling-avg-loss (window=10)= 0.0032484927673976927
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:19,288 INFO epoch # 9901 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0033201810092577944
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:19,310 INFO epoch # 9902 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032385497070208658
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:19,332 INFO epoch # 9903 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003233196129258431
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:19,354 INFO epoch # 9904 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032527931998629356
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:19,376 INFO epoch # 9905 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003229329825444438
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:19,397 INFO epoch # 9906 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003263257061917102
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:19,418 INFO epoch # 9907 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003231290966141387
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:19,440 INFO epoch # 9908 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032365157931053545
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:19,461 INFO epoch # 9909 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032441574412587215
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:19,483 INFO epoch # 9910 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032296104891429422
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:57:19,483 INFO *** epoch 9910, rolling-avg-loss (window=10)= 0.003247888162240997
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:19,505 INFO epoch # 9911 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003277199500644201
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:19,527 INFO epoch # 9912 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032413778999398346
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:19,549 INFO epoch # 9913 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032933516690718534
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:19,571 INFO epoch # 9914 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032568318802077556
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:19,593 INFO epoch # 9915 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003244695813918952
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:19,614 INFO epoch # 9916 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003233315087527444
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:19,636 INFO epoch # 9917 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003254371473303763
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:19,657 INFO epoch # 9918 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003278843700172729
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:19,678 INFO epoch # 9919 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003228481702535646
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:19,700 INFO epoch # 9920 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032436659739687457
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:57:19,700 INFO *** epoch 9920, rolling-avg-loss (window=10)= 0.0032552134701290926
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:19,726 INFO epoch # 9921 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003265339724748628
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:19,749 INFO epoch # 9922 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032711461371945916
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:19,771 INFO epoch # 9923 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032311153909176937
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:19,793 INFO epoch # 9924 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003230595882087073
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:19,815 INFO epoch # 9925 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032390162859883276
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:19,836 INFO epoch # 9926 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032302634253937867
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:19,857 INFO epoch # 9927 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032289545833918964
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:19,878 INFO epoch # 9928 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003241055087528366
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:19,900 INFO epoch # 9929 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032305684271705104
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:19,922 INFO epoch # 9930 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003236840594581736
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:57:19,922 INFO *** epoch 9930, rolling-avg-loss (window=10)= 0.0032404895539002608
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:19,944 INFO epoch # 9931 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003229372127862007
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:19,966 INFO epoch # 9932 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00325246586544381
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:19,988 INFO epoch # 9933 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032342791582777863
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:20,009 INFO epoch # 9934 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032346596617571777
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:20,031 INFO epoch # 9935 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003277810098552436
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:20,052 INFO epoch # 9936 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032587959512966336
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:20,073 INFO epoch # 9937 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032359755041397875
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:20,094 INFO epoch # 9938 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032340440457119257
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:20,116 INFO epoch # 9939 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032397578806921956
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:20,138 INFO epoch # 9940 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032326871078112163
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:57:20,138 INFO *** epoch 9940, rolling-avg-loss (window=10)= 0.0032429847401544976
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:20,160 INFO epoch # 9941 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032404153562310967
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:20,182 INFO epoch # 9942 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0038517456814588513
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:20,203 INFO epoch # 9943 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032329892437701346
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:20,225 INFO epoch # 9944 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032897282553676632
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:20,246 INFO epoch # 9945 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032567474809184205
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:20,268 INFO epoch # 9946 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032903334067668766
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:20,289 INFO epoch # 9947 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00323799407487968
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:20,310 INFO epoch # 9948 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003225625948743982
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:20,332 INFO epoch # 9949 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003228383362511522
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:20,354 INFO epoch # 9950 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003230717048609222
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:57:20,354 INFO *** epoch 9950, rolling-avg-loss (window=10)= 0.003308467985925745
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:20,376 INFO epoch # 9951 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003226672694381705
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:20,397 INFO epoch # 9952 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032404429348389385
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:20,419 INFO epoch # 9953 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003232396428757056
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:20,440 INFO epoch # 9954 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003324774585053092
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:20,462 INFO epoch # 9955 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003242137659981381
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:20,483 INFO epoch # 9956 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00323001283868507
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:20,504 INFO epoch # 9957 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003233438755160023
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:20,525 INFO epoch # 9958 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0033708704422679148
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:20,547 INFO epoch # 9959 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032577223846601555
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:20,570 INFO epoch # 9960 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032390018513979157
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:57:20,570 INFO *** epoch 9960, rolling-avg-loss (window=10)= 0.003259747057518325
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:20,593 INFO epoch # 9961 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032248918610093824
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:20,616 INFO epoch # 9962 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032648463784425985
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:20,638 INFO epoch # 9963 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003236565284169046
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:20,660 INFO epoch # 9964 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003240498988816398
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:20,681 INFO epoch # 9965 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032564518241997575
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:20,702 INFO epoch # 9966 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003323451594042126
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:20,724 INFO epoch # 9967 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032403698833149974
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:20,745 INFO epoch # 9968 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032255791834359115
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:20,767 INFO epoch # 9969 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032898996041694772
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:20,789 INFO epoch # 9970 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032379509011661867
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:57:20,789 INFO *** epoch 9970, rolling-avg-loss (window=10)= 0.0032540505502765883
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:20,811 INFO epoch # 9971 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003227134726330405
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:20,833 INFO epoch # 9972 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0033110800259237294
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:20,855 INFO epoch # 9973 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003230097266168741
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:20,877 INFO epoch # 9974 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032406620603069314
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:20,899 INFO epoch # 9975 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003234507143133669
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:20,920 INFO epoch # 9976 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003235161746488302
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:20,941 INFO epoch # 9977 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032502259746252093
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:20,962 INFO epoch # 9978 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003228175987715076
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:20,983 INFO epoch # 9979 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032470082842337433
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:21,005 INFO epoch # 9980 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0033487096734461375
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:57:21,005 INFO *** epoch 9980, rolling-avg-loss (window=10)= 0.0032552762888371943
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:21,027 INFO epoch # 9981 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032284795724990545
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:21,049 INFO epoch # 9982 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003232981191104045
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:21,071 INFO epoch # 9983 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032235658427453018
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:21,093 INFO epoch # 9984 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003343995583236392
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:21,114 INFO epoch # 9985 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003227889385925664
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:21,136 INFO epoch # 9986 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003250000208936399
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:21,157 INFO epoch # 9987 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003313550312668667
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:21,178 INFO epoch # 9988 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00324623703272664
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:21,199 INFO epoch # 9989 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032330621288565453
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:21,221 INFO epoch # 9990 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00322887175843789
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:57:21,221 INFO *** epoch 9990, rolling-avg-loss (window=10)= 0.00325286330171366
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:21,243 INFO epoch # 9991 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00322367510989352
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:21,265 INFO epoch # 9992 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032493971675648936
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:21,287 INFO epoch # 9993 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00333540507563157
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:21,309 INFO epoch # 9994 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0033112412920672796
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:21,331 INFO epoch # 9995 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032351420995837543
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:21,352 INFO epoch # 9996 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003259379330302181
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:21,373 INFO epoch # 9997 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003226744255698577
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:21,395 INFO epoch # 9998 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003250693902373314
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:21,416 INFO epoch # 9999 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.003250254658269114
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:57:21,438 INFO epoch # 10000 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0032526584745937726
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:57:21,438 INFO *** epoch 10000, rolling-avg-loss (window=10)= 0.0032594591365977975
[experiments_sandbox.py:768 -   <module>()] 2023-04-24 14:57:21,438 INFO training time in seconds = 216
[experiments_sandbox.py:772 -   <module>()] 2023-04-24 14:57:21,439 INFO train-epochs-loss curve df :
[experiments_sandbox.py:773 -   <module>()] 2023-04-24 14:57:21,457 INFO 
     epochs  rolling-avg-loss
0        10          0.740819
1        20          0.570007
2        30          0.494086
3        40          0.461769
4        50          0.416371
5        60          0.381873
6        70          0.355513
7        80          0.324948
8        90          0.300699
9       100          0.279169
10      110          0.256572
11      120          0.243062
12      130          0.224450
13      140          0.209204
14      150          0.196245
15      160          0.184694
16      170          0.172725
17      180          0.167020
18      190          0.156722
19      200          0.152248
20      210          0.140258
21      220          0.133058
22      230          0.127587
23      240          0.121858
24      250          0.116986
25      260          0.113528
26      270          0.109270
27      280          0.107420
28      290          0.103690
29      300          0.095966
30      310          0.095243
31      320          0.090227
32      330          0.089880
33      340          0.083612
34      350          0.082919
35      360          0.080042
36      370          0.078197
37      380          0.074050
38      390          0.073162
39      400          0.070288
40      410          0.068398
41      420          0.069313
42      430          0.067486
43      440          0.063637
44      450          0.062708
45      460          0.061012
46      470          0.059371
47      480          0.062454
48      490          0.059108
49      500          0.054944
50      510          0.055519
51      520          0.053169
52      530          0.052884
53      540          0.051690
54      550          0.049886
55      560          0.051151
56      570          0.047759
57      580          0.048169
58      590          0.046729
59      600          0.045141
60      610          0.044419
61      620          0.046274
62      630          0.043487
63      640          0.043533
64      650          0.042040
65      660          0.041938
66      670          0.040556
67      680          0.039535
68      690          0.039889
69      700          0.040099
70      710          0.038281
71      720          0.038414
72      730          0.036779
73      740          0.035986
74      750          0.036165
75      760          0.034808
76      770          0.035451
77      780          0.034880
78      790          0.033494
79      800          0.035124
80      810          0.032613
81      820          0.033431
82      830          0.031726
83      840          0.032356
84      850          0.031433
85      860          0.031240
86      870          0.030891
87      880          0.029760
88      890          0.029839
89      900          0.028885
90      910          0.029739
91      920          0.028289
92      930          0.027966
93      940          0.028448
94      950          0.027565
95      960          0.027146
96      970          0.026783
97      980          0.028020
98      990          0.026421
99     1000          0.025766
100    1010          0.027559
101    1020          0.025866
102    1030          0.025290
103    1040          0.025227
104    1050          0.024615
105    1060          0.024375
106    1070          0.024484
107    1080          0.023703
108    1090          0.024580
109    1100          0.023926
110    1110          0.023420
111    1120          0.023143
112    1130          0.023248
113    1140          0.022453
114    1150          0.022658
115    1160          0.022344
116    1170          0.021854
117    1180          0.021717
118    1190          0.021411
119    1200          0.021673
120    1210          0.021450
121    1220          0.020959
122    1230          0.021033
123    1240          0.021295
124    1250          0.020330
125    1260          0.020106
126    1270          0.019919
127    1280          0.020030
128    1290          0.019885
129    1300          0.019502
130    1310          0.019341
131    1320          0.019183
132    1330          0.019296
133    1340          0.019024
134    1350          0.018821
135    1360          0.019103
136    1370          0.018433
137    1380          0.018972
138    1390          0.018139
139    1400          0.018008
140    1410          0.018341
141    1420          0.017910
142    1430          0.017569
143    1440          0.017956
144    1450          0.017262
145    1460          0.017215
146    1470          0.017450
147    1480          0.016989
148    1490          0.017510
149    1500          0.016670
150    1510          0.016741
151    1520          0.016506
152    1530          0.016396
153    1540          0.016447
154    1550          0.016316
155    1560          0.016389
156    1570          0.015918
157    1580          0.016149
158    1590          0.015716
159    1600          0.015665
160    1610          0.015501
161    1620          0.015337
162    1630          0.015200
163    1640          0.015359
164    1650          0.015127
165    1660          0.015002
166    1670          0.015458
167    1680          0.015038
168    1690          0.014774
169    1700          0.014895
170    1710          0.014776
171    1720          0.014557
172    1730          0.014538
173    1740          0.014405
174    1750          0.014146
175    1760          0.014031
176    1770          0.013963
177    1780          0.014305
178    1790          0.013724
179    1800          0.013838
180    1810          0.013800
181    1820          0.013675
182    1830          0.014201
183    1840          0.013288
184    1850          0.013223
185    1860          0.013473
186    1870          0.013070
187    1880          0.013552
188    1890          0.012989
189    1900          0.013106
190    1910          0.013130
191    1920          0.012701
192    1930          0.012632
193    1940          0.012767
194    1950          0.012785
195    1960          0.012828
196    1970          0.012497
197    1980          0.012396
198    1990          0.012613
199    2000          0.012865
200    2010          0.012481
201    2020          0.012052
202    2030          0.012090
203    2040          0.012137
204    2050          0.012270
205    2060          0.011787
206    2070          0.011722
207    2080          0.011619
208    2090          0.011726
209    2100          0.011804
210    2110          0.011533
211    2120          0.011754
212    2130          0.011400
213    2140          0.011403
214    2150          0.011233
215    2160          0.011407
216    2170          0.011315
217    2180          0.011173
218    2190          0.011154
219    2200          0.011123
220    2210          0.011539
221    2220          0.011019
222    2230          0.010800
223    2240          0.010935
224    2250          0.010972
225    2260          0.010640
226    2270          0.010598
227    2280          0.010957
228    2290          0.010614
229    2300          0.011240
230    2310          0.011370
231    2320          0.010343
232    2330          0.010452
233    2340          0.011302
234    2350          0.010661
235    2360          0.010435
236    2370          0.010232
237    2380          0.010114
238    2390          0.009994
239    2400          0.010055
240    2410          0.010132
241    2420          0.009989
242    2430          0.009882
243    2440          0.009833
244    2450          0.010055
245    2460          0.010010
246    2470          0.009693
247    2480          0.009612
248    2490          0.009637
249    2500          0.009541
250    2510          0.009702
251    2520          0.009675
252    2530          0.009761
253    2540          0.009372
254    2550          0.009792
255    2560          0.009303
256    2570          0.009329
257    2580          0.009247
258    2590          0.009365
259    2600          0.009763
260    2610          0.009298
261    2620          0.009327
262    2630          0.009044
263    2640          0.009165
264    2650          0.008958
265    2660          0.008990
266    2670          0.009344
267    2680          0.009036
268    2690          0.008783
269    2700          0.009116
270    2710          0.009421
271    2720          0.008980
272    2730          0.009069
273    2740          0.008639
274    2750          0.008735
275    2760          0.008707
276    2770          0.008576
277    2780          0.008593
278    2790          0.008488
279    2800          0.008476
280    2810          0.008549
281    2820          0.008386
282    2830          0.008550
283    2840          0.008313
284    2850          0.008424
285    2860          0.008229
286    2870          0.008215
287    2880          0.008326
288    2890          0.008610
289    2900          0.008183
290    2910          0.008087
291    2920          0.008139
292    2930          0.008181
293    2940          0.007986
294    2950          0.007982
295    2960          0.008099
296    2970          0.007953
297    2980          0.007886
298    2990          0.007939
299    3000          0.007960
300    3010          0.007823
301    3020          0.007865
302    3030          0.007771
303    3040          0.007732
304    3050          0.008000
305    3060          0.008201
306    3070          0.007675
307    3080          0.007656
308    3090          0.007642
309    3100          0.007686
310    3110          0.007816
311    3120          0.007491
312    3130          0.007475
313    3140          0.007623
314    3150          0.007822
315    3160          0.007407
316    3170          0.007394
317    3180          0.007390
318    3190          0.007514
319    3200          0.007455
320    3210          0.007345
321    3220          0.007307
322    3230          0.007406
323    3240          0.007239
324    3250          0.007207
325    3260          0.007256
326    3270          0.007173
327    3280          0.007199
328    3290          0.007132
329    3300          0.007135
330    3310          0.007180
331    3320          0.007067
332    3330          0.007388
333    3340          0.007002
334    3350          0.007132
335    3360          0.007023
336    3370          0.007139
337    3380          0.006985
338    3390          0.006961
339    3400          0.007001
340    3410          0.007184
341    3420          0.007090
342    3430          0.006882
343    3440          0.006853
344    3450          0.006994
345    3460          0.006736
346    3470          0.007158
347    3480          0.006934
348    3490          0.006672
349    3500          0.006990
350    3510          0.006653
351    3520          0.006636
352    3530          0.006638
353    3540          0.006577
354    3550          0.006670
355    3560          0.006751
356    3570          0.006564
357    3580          0.006559
358    3590          0.006564
359    3600          0.006460
360    3610          0.006503
361    3620          0.006582
362    3630          0.006453
363    3640          0.006391
364    3650          0.006441
365    3660          0.006518
366    3670          0.006587
367    3680          0.006688
368    3690          0.006426
369    3700          0.006392
370    3710          0.006296
371    3720          0.006273
372    3730          0.006443
373    3740          0.006263
374    3750          0.006326
375    3760          0.006192
376    3770          0.006176
377    3780          0.006194
378    3790          0.006200
379    3800          0.006160
380    3810          0.006837
381    3820          0.006117
382    3830          0.006072
383    3840          0.006216
384    3850          0.006050
385    3860          0.006029
386    3870          0.006174
387    3880          0.006059
388    3890          0.005982
389    3900          0.006003
390    3910          0.005972
391    3920          0.005997
392    3930          0.005932
393    3940          0.005968
394    3950          0.005935
395    3960          0.005897
396    3970          0.006126
397    3980          0.005840
398    3990          0.005960
399    4000          0.005842
400    4010          0.005867
401    4020          0.005836
402    4030          0.005942
403    4040          0.005921
404    4050          0.005781
405    4060          0.005911
406    4070          0.005744
407    4080          0.005760
408    4090          0.005786
409    4100          0.005943
410    4110          0.005863
411    4120          0.005666
412    4130          0.005899
413    4140          0.005611
414    4150          0.005704
415    4160          0.005747
416    4170          0.005583
417    4180          0.005589
418    4190          0.005852
419    4200          0.005566
420    4210          0.005600
421    4220          0.005540
422    4230          0.005600
423    4240          0.005551
424    4250          0.005517
425    4260          0.005507
426    4270          0.005550
427    4280          0.005524
428    4290          0.005553
429    4300          0.005421
430    4310          0.005403
431    4320          0.005703
432    4330          0.005465
433    4340          0.005413
434    4350          0.005370
435    4360          0.005598
436    4370          0.005345
437    4380          0.005750
438    4390          0.005310
439    4400          0.005459
440    4410          0.005284
441    4420          0.005355
442    4430          0.005310
443    4440          0.005265
444    4450          0.005245
445    4460          0.005336
446    4470          0.005369
447    4480          0.005204
448    4490          0.005292
449    4500          0.005240
450    4510          0.005162
451    4520          0.005385
452    4530          0.005197
453    4540          0.005401
454    4550          0.005145
455    4560          0.005423
456    4570          0.005316
457    4580          0.005090
458    4590          0.005137
459    4600          0.005149
460    4610          0.005141
461    4620          0.005285
462    4630          0.005138
463    4640          0.005137
464    4650          0.005017
465    4660          0.005015
466    4670          0.005029
467    4680          0.005032
468    4690          0.005186
469    4700          0.005284
470    4710          0.004971
471    4720          0.005050
472    4730          0.004933
473    4740          0.005171
474    4750          0.004936
475    4760          0.004919
476    4770          0.004932
477    4780          0.004902
478    4790          0.004918
479    4800          0.004899
480    4810          0.004992
481    4820          0.004903
482    4830          0.004948
483    4840          0.004858
484    4850          0.004944
485    4860          0.005021
486    4870          0.004888
487    4880          0.004819
488    4890          0.004841
489    4900          0.005021
490    4910          0.004861
491    4920          0.004767
492    4930          0.004773
493    4940          0.004737
494    4950          0.004991
495    4960          0.004943
496    4970          0.004809
497    4980          0.004730
498    4990          0.004766
499    5000          0.004716
500    5010          0.004934
501    5020          0.004701
502    5030          0.004683
503    5040          0.004684
504    5050          0.004662
505    5060          0.004770
506    5070          0.004637
507    5080          0.004713
508    5090          0.004718
509    5100          0.004737
510    5110          0.004605
511    5120          0.004712
512    5130          0.004943
513    5140          0.004580
514    5150          0.004572
515    5160          0.004618
516    5170          0.004829
517    5180          0.004557
518    5190          0.004742
519    5200          0.004813
520    5210          0.004649
521    5220          0.004620
522    5230          0.004560
523    5240          0.004650
524    5250          0.004624
525    5260          0.004474
526    5270          0.004565
527    5280          0.004507
528    5290          0.004568
529    5300          0.004718
530    5310          0.004475
531    5320          0.004524
532    5330          0.004457
533    5340          0.004449
534    5350          0.004470
535    5360          0.004420
536    5370          0.004427
537    5380          0.004545
538    5390          0.004406
539    5400          0.004393
540    5410          0.004393
541    5420          0.004556
542    5430          0.004529
543    5440          0.004426
544    5450          0.004640
545    5460          0.004451
546    5470          0.004354
547    5480          0.004327
548    5490          0.004323
549    5500          0.004426
550    5510          0.004314
551    5520          0.004399
552    5530          0.004293
553    5540          0.004408
554    5550          0.004470
555    5560          0.004289
556    5570          0.004291
557    5580          0.004295
558    5590          0.004567
559    5600          0.004377
560    5610          0.004297
561    5620          0.004272
562    5630          0.004327
563    5640          0.004323
564    5650          0.004385
565    5660          0.004210
566    5670          0.004220
567    5680          0.004327
568    5690          0.004249
569    5700          0.004191
570    5710          0.004209
571    5720          0.004468
572    5730          0.004304
573    5740          0.004449
574    5750          0.004290
575    5760          0.004249
576    5770          0.004190
577    5780          0.004140
578    5790          0.004203
579    5800          0.004302
580    5810          0.004136
581    5820          0.004485
582    5830          0.004127
583    5840          0.004134
584    5850          0.004108
585    5860          0.004206
586    5870          0.004095
587    5880          0.004185
588    5890          0.004125
589    5900          0.004089
590    5910          0.004204
591    5920          0.004068
592    5930          0.004098
593    5940          0.004078
594    5950          0.004108
595    5960          0.004353
596    5970          0.004050
597    5980          0.004151
598    5990          0.004041
599    6000          0.004037
600    6010          0.004295
601    6020          0.004113
602    6030          0.004057
603    6040          0.004014
604    6050          0.004050
605    6060          0.004018
606    6070          0.004109
607    6080          0.003981
608    6090          0.004101
609    6100          0.004068
610    6110          0.004012
611    6120          0.004055
612    6130          0.003982
613    6140          0.003965
614    6150          0.004044
615    6160          0.003958
616    6170          0.004016
617    6180          0.003954
618    6190          0.003947
619    6200          0.003960
620    6210          0.004035
621    6220          0.003926
622    6230          0.003948
623    6240          0.003912
624    6250          0.003908
625    6260          0.003911
626    6270          0.003908
627    6280          0.003940
628    6290          0.003895
629    6300          0.003953
630    6310          0.004043
631    6320          0.003906
632    6330          0.003879
633    6340          0.003997
634    6350          0.003949
635    6360          0.003856
636    6370          0.004009
637    6380          0.003853
638    6390          0.003931
639    6400          0.003887
640    6410          0.003865
641    6420          0.003985
642    6430          0.003866
643    6440          0.003957
644    6450          0.003836
645    6460          0.003813
646    6470          0.003830
647    6480          0.003945
648    6490          0.003972
649    6500          0.003836
650    6510          0.003899
651    6520          0.003910
652    6530          0.003801
653    6540          0.003975
654    6550          0.004040
655    6560          0.003907
656    6570          0.003892
657    6580          0.003921
658    6590          0.003781
659    6600          0.003801
660    6610          0.003894
661    6620          0.003905
662    6630          0.003811
663    6640          0.003759
664    6650          0.003801
665    6660          0.003963
666    6670          0.003762
667    6680          0.003886
668    6690          0.003740
669    6700          0.003831
670    6710          0.003823
671    6720          0.003785
672    6730          0.003761
673    6740          0.003870
674    6750          0.003767
675    6760          0.003821
676    6770          0.003712
677    6780          0.003728
678    6790          0.003720
679    6800          0.003815
680    6810          0.003845
681    6820          0.003940
682    6830          0.003775
683    6840          0.003698
684    6850          0.003782
685    6860          0.003699
686    6870          0.003693
687    6880          0.003688
688    6890          0.003672
689    6900          0.003677
690    6910          0.003761
691    6920          0.003759
692    6930          0.003786
693    6940          0.003736
694    6950          0.003665
695    6960          0.003754
696    6970          0.003690
697    6980          0.003667
698    6990          0.003694
699    7000          0.003638
700    7010          0.003647
701    7020          0.003637
702    7030          0.003625
703    7040          0.003624
704    7050          0.003684
705    7060          0.003623
706    7070          0.003649
707    7080          0.003775
708    7090          0.003643
709    7100          0.003683
710    7110          0.003648
711    7120          0.003733
712    7130          0.003753
713    7140          0.003701
714    7150          0.003668
715    7160          0.003593
716    7170          0.003752
717    7180          0.003826
718    7190          0.003586
719    7200          0.003659
720    7210          0.003594
721    7220          0.003777
722    7230          0.003628
723    7240          0.003651
724    7250          0.003663
725    7260          0.003631
726    7270          0.003607
727    7280          0.003577
728    7290          0.003631
729    7300          0.003562
730    7310          0.003670
731    7320          0.003781
732    7330          0.003641
733    7340          0.003561
734    7350          0.003599
735    7360          0.003626
736    7370          0.003709
737    7380          0.003788
738    7390          0.003564
739    7400          0.003706
740    7410          0.003526
741    7420          0.003676
742    7430          0.003588
743    7440          0.003624
744    7450          0.003558
745    7460          0.003644
746    7470          0.003595
747    7480          0.003545
748    7490          0.003630
749    7500          0.003521
750    7510          0.003587
751    7520          0.003526
752    7530          0.003648
753    7540          0.003743
754    7550          0.003507
755    7560          0.003553
756    7570          0.003502
757    7580          0.003785
758    7590          0.003487
759    7600          0.003587
760    7610          0.003525
761    7620          0.003481
762    7630          0.003567
763    7640          0.003707
764    7650          0.003531
765    7660          0.003579
766    7670          0.003516
767    7680          0.003671
768    7690          0.003595
769    7700          0.003561
770    7710          0.003478
771    7720          0.003608
772    7730          0.003485
773    7740          0.003594
774    7750          0.003463
775    7760          0.003539
776    7770          0.003461
777    7780          0.003707
778    7790          0.003449
779    7800          0.003463
780    7810          0.003489
781    7820          0.003458
782    7830          0.003474
783    7840          0.003443
784    7850          0.003510
785    7860          0.003457
786    7870          0.003441
787    7880          0.003473
788    7890          0.003447
789    7900          0.003457
790    7910          0.003597
791    7920          0.003523
792    7930          0.003508
793    7940          0.003493
794    7950          0.003478
795    7960          0.003532
796    7970          0.003461
797    7980          0.003588
798    7990          0.003553
799    8000          0.003543
800    8010          0.003529
801    8020          0.003462
802    8030          0.003613
803    8040          0.003432
804    8050          0.003492
805    8060          0.003481
806    8070          0.003493
807    8080          0.003421
808    8090          0.003570
809    8100          0.003500
810    8110          0.003424
811    8120          0.003431
812    8130          0.003402
813    8140          0.003617
814    8150          0.003451
815    8160          0.003406
816    8170          0.003467
817    8180          0.003417
818    8190          0.003388
819    8200          0.003473
820    8210          0.003402
821    8220          0.003506
822    8230          0.003584
823    8240          0.003424
824    8250          0.003400
825    8260          0.003387
826    8270          0.003382
827    8280          0.003393
828    8290          0.003402
829    8300          0.003460
830    8310          0.003409
831    8320          0.003454
832    8330          0.003445
833    8340          0.003370
834    8350          0.003471
835    8360          0.003371
836    8370          0.003366
837    8380          0.003466
838    8390          0.003380
839    8400          0.003560
840    8410          0.003438
841    8420          0.003374
842    8430          0.003365
843    8440          0.003358
844    8450          0.003383
845    8460          0.003363
846    8470          0.003431
847    8480          0.003355
848    8490          0.003547
849    8500          0.003495
850    8510          0.003418
851    8520          0.003364
852    8530          0.003401
853    8540          0.003352
854    8550          0.003391
855    8560          0.003432
856    8570          0.003366
857    8580          0.003417
858    8590          0.003421
859    8600          0.003361
860    8610          0.003358
861    8620          0.003436
862    8630          0.003376
863    8640          0.003386
864    8650          0.003346
865    8660          0.003432
866    8670          0.003408
867    8680          0.003346
868    8690          0.003364
869    8700          0.003410
870    8710          0.003490
871    8720          0.003442
872    8730          0.003416
873    8740          0.003423
874    8750          0.003446
875    8760          0.003435
876    8770          0.003361
877    8780          0.003408
878    8790          0.003371
879    8800          0.003463
880    8810          0.003393
881    8820          0.003429
882    8830          0.003361
883    8840          0.003329
884    8850          0.003418
885    8860          0.003328
886    8870          0.003454
887    8880          0.003365
888    8890          0.003309
889    8900          0.003354
890    8910          0.003310
891    8920          0.003314
892    8930          0.003354
893    8940          0.003464
894    8950          0.003324
895    8960          0.003422
896    8970          0.003320
897    8980          0.003324
898    8990          0.003526
899    9000          0.003444
900    9010          0.003397
901    9020          0.003305
902    9030          0.003509
903    9040          0.003378
904    9050          0.003445
905    9060          0.003345
906    9070          0.003386
907    9080          0.003314
908    9090          0.003383
909    9100          0.003330
910    9110          0.003300
911    9120          0.003347
912    9130          0.003313
913    9140          0.003299
914    9150          0.003307
915    9160          0.003368
916    9170          0.003425
917    9180          0.003406
918    9190          0.003376
919    9200          0.003486
920    9210          0.003311
921    9220          0.003297
922    9230          0.003307
923    9240          0.003343
924    9250          0.003331
925    9260          0.003297
926    9270          0.003370
927    9280          0.003352
928    9290          0.003349
929    9300          0.003304
930    9310          0.003277
931    9320          0.003324
932    9330          0.003372
933    9340          0.003289
934    9350          0.003381
935    9360          0.003297
936    9370          0.003358
937    9380          0.003287
938    9390          0.003348
939    9400          0.003300
940    9410          0.003352
941    9420          0.003420
942    9430          0.003327
943    9440          0.003285
944    9450          0.003317
945    9460          0.003430
946    9470          0.003415
947    9480          0.003485
948    9490          0.003287
949    9500          0.003288
950    9510          0.003311
951    9520          0.003271
952    9530          0.003350
953    9540          0.003280
954    9550          0.003410
955    9560          0.003287
956    9570          0.003341
957    9580          0.003406
958    9590          0.003355
959    9600          0.003361
960    9610          0.003328
961    9620          0.003318
962    9630          0.003275
963    9640          0.003437
964    9650          0.003342
965    9660          0.003356
966    9670          0.003264
967    9680          0.003268
968    9690          0.003337
969    9700          0.003458
970    9710          0.003316
971    9720          0.003274
972    9730          0.003315
973    9740          0.003325
974    9750          0.003268
975    9760          0.003329
976    9770          0.003343
977    9780          0.003259
978    9790          0.003264
979    9800          0.003309
980    9810          0.003271
981    9820          0.003270
982    9830          0.003304
983    9840          0.003254
984    9850          0.003344
985    9860          0.003258
986    9870          0.003247
987    9880          0.003357
988    9890          0.003256
989    9900          0.003248
990    9910          0.003248
991    9920          0.003255
992    9930          0.003240
993    9940          0.003243
994    9950          0.003308
995    9960          0.003260
996    9970          0.003254
997    9980          0.003255
998    9990          0.003253
999   10000          0.003259
[experiments_sandbox.py:776 -   <module>()] 2023-04-24 14:57:21,457 INFO Out-of sample batch-test
[experiments_sandbox.py:781 -   <module>()] 2023-04-24 14:57:21,457 INFO test-batch  # 0 => test-loss = 0.057429324835538864
[experiments_sandbox.py:781 -   <module>()] 2023-04-24 14:57:21,458 INFO test-batch  # 1 => test-loss = 0.013696838170289993
[experiments_sandbox.py:781 -   <module>()] 2023-04-24 14:57:21,458 INFO test-batch  # 2 => test-loss = 0.017966771498322487
[experiments_sandbox.py:781 -   <module>()] 2023-04-24 14:57:21,458 INFO test-batch  # 3 => test-loss = 0.01090681180357933
[experiments_sandbox.py:781 -   <module>()] 2023-04-24 14:57:21,459 INFO test-batch  # 4 => test-loss = 0.022275585681200027
[experiments_sandbox.py:781 -   <module>()] 2023-04-24 14:57:21,459 INFO test-batch  # 5 => test-loss = 0.01124025508761406
[experiments_sandbox.py:781 -   <module>()] 2023-04-24 14:57:21,460 INFO test-batch  # 6 => test-loss = 0.009511508978903294
[experiments_sandbox.py:781 -   <module>()] 2023-04-24 14:57:21,460 INFO test-batch  # 7 => test-loss = 0.0178229957818985
[experiments_sandbox.py:781 -   <module>()] 2023-04-24 14:57:21,460 INFO test-batch  # 8 => test-loss = 0.005413820501416922
[experiments_sandbox.py:781 -   <module>()] 2023-04-24 14:57:21,461 INFO test-batch  # 9 => test-loss = 0.0046805934980511665
[experiments_sandbox.py:781 -   <module>()] 2023-04-24 14:57:21,461 INFO test-batch  # 10 => test-loss = 0.0042696623131632805
[experiments_sandbox.py:781 -   <module>()] 2023-04-24 14:57:21,461 INFO test-batch  # 11 => test-loss = 1.8259776830673218
[experiments_sandbox.py:781 -   <module>()] 2023-04-24 14:57:21,462 INFO test-batch  # 12 => test-loss = 0.010510120540857315
[experiments_sandbox.py:781 -   <module>()] 2023-04-24 14:57:21,462 INFO test-batch  # 13 => test-loss = 0.011578740552067757
[experiments_sandbox.py:781 -   <module>()] 2023-04-24 14:57:21,462 INFO test-batch  # 14 => test-loss = 0.0060332114808261395
[experiments_sandbox.py:781 -   <module>()] 2023-04-24 14:57:21,463 INFO test-batch  # 15 => test-loss = 0.005942650604993105
[experiments_sandbox.py:781 -   <module>()] 2023-04-24 14:57:21,463 INFO test-batch  # 16 => test-loss = 0.00494920602068305
[experiments_sandbox.py:781 -   <module>()] 2023-04-24 14:57:21,464 INFO test-batch  # 17 => test-loss = 0.01948677934706211
[experiments_sandbox.py:781 -   <module>()] 2023-04-24 14:57:21,464 INFO test-batch  # 18 => test-loss = 0.005940258037298918
[experiments_sandbox.py:781 -   <module>()] 2023-04-24 14:57:21,464 INFO test-batch  # 19 => test-loss = 0.010402246378362179
[experiments_sandbox.py:781 -   <module>()] 2023-04-24 14:57:21,465 INFO test-batch  # 20 => test-loss = 0.013117715716362
[experiments_sandbox.py:781 -   <module>()] 2023-04-24 14:57:21,465 INFO test-batch  # 21 => test-loss = 0.007340323179960251
[experiments_sandbox.py:781 -   <module>()] 2023-04-24 14:57:21,465 INFO test-batch  # 22 => test-loss = 0.01102004386484623
[experiments_sandbox.py:781 -   <module>()] 2023-04-24 14:57:21,466 INFO test-batch  # 23 => test-loss = 0.011824624612927437
[experiments_sandbox.py:781 -   <module>()] 2023-04-24 14:57:21,466 INFO test-batch  # 24 => test-loss = 0.019983254373073578
[experiments_sandbox.py:781 -   <module>()] 2023-04-24 14:57:21,466 INFO test-batch  # 25 => test-loss = 0.023478984832763672
[experiments_sandbox.py:781 -   <module>()] 2023-04-24 14:57:21,467 INFO test-batch  # 26 => test-loss = 0.013629421591758728
[experiments_sandbox.py:781 -   <module>()] 2023-04-24 14:57:21,467 INFO test-batch  # 27 => test-loss = 0.0050247590988874435
[experiments_sandbox.py:781 -   <module>()] 2023-04-24 14:57:21,468 INFO test-batch  # 28 => test-loss = 0.005647716112434864
[experiments_sandbox.py:781 -   <module>()] 2023-04-24 14:57:21,468 INFO test-batch  # 29 => test-loss = 0.007804493885487318
[experiments_sandbox.py:781 -   <module>()] 2023-04-24 14:57:21,468 INFO test-batch  # 30 => test-loss = 0.007936571724712849
[experiments_sandbox.py:781 -   <module>()] 2023-04-24 14:57:21,469 INFO test-batch  # 31 => test-loss = 0.05014752969145775
