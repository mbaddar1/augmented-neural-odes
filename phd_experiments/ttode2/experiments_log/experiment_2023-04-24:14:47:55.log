[experiments_sandbox.py:611 -   <module>()] 2023-04-24 14:47:55,281 INFO SEED = 42
[experiments_sandbox.py:677 -   <module>()] 2023-04-24 14:47:55,282 INFO model = 
***
NN-Model 
Sequential(
  (0): Linear(in_features=2, out_features=50, bias=True)
  (1): Identity()
  (2): Tanh()
  (3): Linear(in_features=50, out_features=2, bias=True)
)
numel_learnable = 252
***
[experiments_sandbox.py:678 -   <module>()] 2023-04-24 14:47:55,282 INFO optimizer  = SGD (
Parameter Group 0
    dampening: 0
    differentiable: False
    foreach: None
    lr: 0.01
    maximize: False
    momentum: 0
    nesterov: False
    weight_decay: 0
)
[experiments_sandbox.py:685 -   <module>()] 2023-04-24 14:47:55,282 INFO lr_scheduler = <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7fcc412ab250>
[experiments_sandbox.py:688 -   <module>()] 2023-04-24 14:47:55,282 INFO Normalize-Data-source-X-train = True
[experiments_sandbox.py:689 -   <module>()] 2023-04-24 14:47:55,282 INFO Normalize-Data-source-Y-train = True
[experiments_sandbox.py:690 -   <module>()] 2023-04-24 14:47:55,282 INFO Normalize-Data-source-X-test = True
[experiments_sandbox.py:691 -   <module>()] 2023-04-24 14:47:55,282 INFO Normalize-Data-source-Y-test = True
[experiments_sandbox.py:710 -   <module>()] 2023-04-24 14:47:55,283 INFO train-dataset = ***
VDP Dataset
N=1000
mio = 0.5
x_gen_norm_mean = 10
x_gen_norm_std = 100
normalize_X = True
normalize_Y = True
train-or-test = train
***
[experiments_sandbox.py:711 -   <module>()] 2023-04-24 14:47:55,283 INFO test-dataset = ***
VDP Dataset
N=1000
mio = 0.5
x_gen_norm_mean = 10
x_gen_norm_std = 100
normalize_X = True
normalize_Y = True
train-or-test = test
***
[experiments_sandbox.py:712 -   <module>()] 2023-04-24 14:47:55,283 INFO train-epochs = 10000
[experiments_sandbox.py:716 -   <module>()] 2023-04-24 14:47:55,283 INFO Input batch normalization = False
[experiments_sandbox.py:717 -   <module>()] 2023-04-24 14:47:55,283 INFO Output Normalization = None
[experiments_sandbox.py:718 -   <module>()] 2023-04-24 14:47:55,283 INFO Gradient-clipping max-norm = 10
[experiments_sandbox.py:720 -   <module>()] 2023-04-24 14:47:55,283 INFO epochs_losses_window = 10
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:56,878 INFO epoch # 0 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 9.44065509736538
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:56,896 INFO epoch # 1 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.6189819946885109
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:56,915 INFO epoch # 2 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.4139318512752652
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:56,933 INFO epoch # 3 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.33643670729361475
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:56,951 INFO epoch # 4 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.27583420695737004
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:56,970 INFO epoch # 5 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.24615491298027337
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:56,988 INFO epoch # 6 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.21616716613061726
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:57,007 INFO epoch # 7 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.19902389706112444
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:57,025 INFO epoch # 8 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.1853454444790259
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:57,044 INFO epoch # 9 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.1709139714948833
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:57,062 INFO epoch # 10 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.15756473608780652
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:47:57,062 INFO *** epoch 10, rolling-avg-loss (window=10)= 0.2820354888448492
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:57,081 INFO epoch # 11 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.15161568531766534
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:57,100 INFO epoch # 12 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.14372842304874212
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:57,119 INFO epoch # 13 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.1425226036226377
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:57,138 INFO epoch # 14 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.1335818002698943
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:57,157 INFO epoch # 15 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.12825483869528398
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:57,176 INFO epoch # 16 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.12463685736292973
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:57,195 INFO epoch # 17 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.12250615685479715
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:57,213 INFO epoch # 18 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.12278724281350151
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:57,232 INFO epoch # 19 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.11640741192968562
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:57,250 INFO epoch # 20 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.11592449527233839
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:47:57,250 INFO *** epoch 20, rolling-avg-loss (window=10)= 0.1301965515187476
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:57,269 INFO epoch # 21 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.11343964608386159
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:57,288 INFO epoch # 22 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.11049797356827185
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:57,307 INFO epoch # 23 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.10921389295253903
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:57,326 INFO epoch # 24 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.10721019405173138
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:57,345 INFO epoch # 25 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.10637025290634483
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:57,364 INFO epoch # 26 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.10512291279155761
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:57,383 INFO epoch # 27 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.10385519976262003
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:57,401 INFO epoch # 28 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.10511188639793545
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:57,420 INFO epoch # 29 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.10195552493678406
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:57,438 INFO epoch # 30 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.10150915663689375
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:47:57,438 INFO *** epoch 30, rolling-avg-loss (window=10)= 0.10642866400885395
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:57,457 INFO epoch # 31 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.10273346572648734
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:57,475 INFO epoch # 32 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.09819839050760493
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:57,494 INFO epoch # 33 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.10094942559953779
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:57,513 INFO epoch # 34 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0964352946029976
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:57,532 INFO epoch # 35 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.09595697780605406
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:57,550 INFO epoch # 36 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.09785293025197461
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:57,569 INFO epoch # 37 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.09247018466703594
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:57,588 INFO epoch # 38 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.09158761752769351
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:57,607 INFO epoch # 39 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.09014099632622674
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:57,625 INFO epoch # 40 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.08947677141986787
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:47:57,625 INFO *** epoch 40, rolling-avg-loss (window=10)= 0.09558020544354803
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:57,644 INFO epoch # 41 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.08856194384861737
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:57,662 INFO epoch # 42 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.09010208590188995
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:57,680 INFO epoch # 43 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.08685963478637859
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:57,699 INFO epoch # 44 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.08752134075621143
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:57,718 INFO epoch # 45 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0846113219158724
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:57,737 INFO epoch # 46 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.08365547127323225
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:57,755 INFO epoch # 47 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.08277700986946002
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:57,774 INFO epoch # 48 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.08271283190697432
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:57,793 INFO epoch # 49 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.08118961664149538
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:57,811 INFO epoch # 50 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.08062411437276751
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:47:57,812 INFO *** epoch 50, rolling-avg-loss (window=10)= 0.08486153712728992
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:57,830 INFO epoch # 51 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.08071309875231236
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:57,848 INFO epoch # 52 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.07998553093057126
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:57,866 INFO epoch # 53 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.07866495772032067
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:57,885 INFO epoch # 54 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.07832470338325948
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:57,904 INFO epoch # 55 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.07764395058620721
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:57,922 INFO epoch # 56 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.07545778807252645
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:57,941 INFO epoch # 57 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.07489857939071953
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:57,960 INFO epoch # 58 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.11156067479168996
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:57,979 INFO epoch # 59 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.07882343314122409
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:57,998 INFO epoch # 60 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.07340758526697755
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:47:57,998 INFO *** epoch 60, rolling-avg-loss (window=10)= 0.08094803020358085
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:58,016 INFO epoch # 61 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.07349469850305468
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:58,034 INFO epoch # 62 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.07229973602807149
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:58,053 INFO epoch # 63 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.07314850168768317
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:58,071 INFO epoch # 64 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.07227816875092685
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:58,089 INFO epoch # 65 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.07115839060861617
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:58,108 INFO epoch # 66 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.06935764907393605
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:58,127 INFO epoch # 67 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.06914651353145018
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:58,147 INFO epoch # 68 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.06833533552708104
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:58,166 INFO epoch # 69 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.06778897048207
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:58,185 INFO epoch # 70 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.06702945751021616
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:47:58,185 INFO *** epoch 70, rolling-avg-loss (window=10)= 0.07040374217031058
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:58,204 INFO epoch # 71 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.06711918249493465
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:58,222 INFO epoch # 72 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.06614802149124444
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:58,241 INFO epoch # 73 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.06519153466797434
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:58,259 INFO epoch # 74 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.06468923069769517
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:58,277 INFO epoch # 75 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.06403982528718188
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:58,296 INFO epoch # 76 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.06444145849673077
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:58,315 INFO epoch # 77 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.06361044241930358
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:58,333 INFO epoch # 78 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.06318572160671465
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:58,352 INFO epoch # 79 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.06164156025624834
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:58,371 INFO epoch # 80 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.06125460722250864
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:47:58,371 INFO *** epoch 80, rolling-avg-loss (window=10)= 0.06413215846405365
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:58,390 INFO epoch # 81 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.061852098238887265
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:58,409 INFO epoch # 82 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.06234789761947468
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:58,427 INFO epoch # 83 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.060283450700808316
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:58,445 INFO epoch # 84 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.06005758512765169
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:58,463 INFO epoch # 85 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.05852882828912698
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:58,482 INFO epoch # 86 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0591526631033048
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:58,500 INFO epoch # 87 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.08234918676316738
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:58,519 INFO epoch # 88 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.05844970961334184
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:58,538 INFO epoch # 89 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.057805334887234494
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:58,560 INFO epoch # 90 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0598146359261591
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:47:58,560 INFO *** epoch 90, rolling-avg-loss (window=10)= 0.062064139026915655
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:58,583 INFO epoch # 91 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.05673465892323293
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:58,603 INFO epoch # 92 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.05639370990684256
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:58,624 INFO epoch # 93 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.05541589148924686
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:58,643 INFO epoch # 94 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0552384810289368
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:58,661 INFO epoch # 95 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.05509003531187773
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:58,679 INFO epoch # 96 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.05478816130198538
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:58,697 INFO epoch # 97 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.054148452094523236
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:58,717 INFO epoch # 98 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.05311632278608158
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:58,737 INFO epoch # 99 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.053693999245297164
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:58,757 INFO epoch # 100 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.05274847082910128
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:47:58,757 INFO *** epoch 100, rolling-avg-loss (window=10)= 0.05473681829171255
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:58,777 INFO epoch # 101 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.05276288985623978
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:58,797 INFO epoch # 102 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.05239323619753122
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:58,816 INFO epoch # 103 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.05151211822521873
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:58,835 INFO epoch # 104 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.05129644926637411
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:58,853 INFO epoch # 105 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.05159208134864457
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:58,871 INFO epoch # 106 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.050583869000547566
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:58,890 INFO epoch # 107 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.05036762359668501
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:58,908 INFO epoch # 108 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.050120420375606045
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:58,927 INFO epoch # 109 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.049764653158490546
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:58,947 INFO epoch # 110 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.04955658980179578
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:47:58,947 INFO *** epoch 110, rolling-avg-loss (window=10)= 0.05099499308271334
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:58,967 INFO epoch # 111 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.049930156354093924
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:58,987 INFO epoch # 112 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.048958931787637994
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:59,007 INFO epoch # 113 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.04978045975440182
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:59,027 INFO epoch # 114 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.04940579482354224
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:59,045 INFO epoch # 115 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.04891847536782734
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:59,064 INFO epoch # 116 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.04751013495842926
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:59,082 INFO epoch # 117 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.04755616966576781
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:59,100 INFO epoch # 118 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.04741752646805253
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:59,121 INFO epoch # 119 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.04683073572232388
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:59,140 INFO epoch # 120 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.046752964321058244
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:47:59,140 INFO *** epoch 120, rolling-avg-loss (window=10)= 0.048306134922313504
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:59,160 INFO epoch # 121 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0464720030722674
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:59,180 INFO epoch # 122 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.046786292805336416
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:59,200 INFO epoch # 123 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.04646454341127537
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:59,220 INFO epoch # 124 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0468892476928886
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:59,240 INFO epoch # 125 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.04550516991002951
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:59,258 INFO epoch # 126 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.04536871597520076
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:59,276 INFO epoch # 127 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.04533410017029382
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:59,294 INFO epoch # 128 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.049974434106843546
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:59,313 INFO epoch # 129 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0450804598222021
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:59,331 INFO epoch # 130 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.044207756262039766
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:47:59,331 INFO *** epoch 130, rolling-avg-loss (window=10)= 0.04620827232283773
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:59,350 INFO epoch # 131 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.04438446811400354
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:59,370 INFO epoch # 132 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.04447773838182911
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:59,390 INFO epoch # 133 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.044430579378968105
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:59,410 INFO epoch # 134 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.05934879477717914
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:59,430 INFO epoch # 135 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.04654585287789814
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:59,450 INFO epoch # 136 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.04377280085464008
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:59,468 INFO epoch # 137 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.04266502626705915
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:59,486 INFO epoch # 138 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.04304271101136692
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:59,505 INFO epoch # 139 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.05714965288643725
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:59,523 INFO epoch # 140 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.044850000558653846
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:47:59,523 INFO *** epoch 140, rolling-avg-loss (window=10)= 0.04706676251080353
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:59,541 INFO epoch # 141 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.04192612392944284
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:59,560 INFO epoch # 142 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.04145175436860882
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:59,580 INFO epoch # 143 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.04183897821349092
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:59,600 INFO epoch # 144 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.04238904558587819
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:59,623 INFO epoch # 145 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0410281590957311
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:59,642 INFO epoch # 146 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.041158501320751384
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:59,660 INFO epoch # 147 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0411694906943012
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:59,679 INFO epoch # 148 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.041352671425556764
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:59,697 INFO epoch # 149 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.041654249231214635
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:59,715 INFO epoch # 150 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0409739372698823
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:47:59,715 INFO *** epoch 150, rolling-avg-loss (window=10)= 0.041494291113485814
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:59,734 INFO epoch # 151 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.039776158111635596
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:59,752 INFO epoch # 152 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.06054025943740271
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:59,770 INFO epoch # 153 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.04263188989716582
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:59,788 INFO epoch # 154 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03990107367280871
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:59,807 INFO epoch # 155 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03985388840374071
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:59,825 INFO epoch # 156 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03954445690033026
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:59,844 INFO epoch # 157 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0391511298075784
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:59,862 INFO epoch # 158 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.039202629661303945
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:59,881 INFO epoch # 159 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03842146636452526
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:59,899 INFO epoch # 160 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.038796065346105024
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:47:59,899 INFO *** epoch 160, rolling-avg-loss (window=10)= 0.04178190176025964
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:59,917 INFO epoch # 161 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03833489611861296
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:59,936 INFO epoch # 162 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03884991828817874
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:59,954 INFO epoch # 163 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03853218938456848
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:59,972 INFO epoch # 164 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.038547509131603874
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:47:59,991 INFO epoch # 165 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.038009446900105104
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:00,009 INFO epoch # 166 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03827569042914547
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:00,028 INFO epoch # 167 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.038154314359417185
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:00,046 INFO epoch # 168 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03760276359389536
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:00,065 INFO epoch # 169 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.05239085266657639
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:00,083 INFO epoch # 170 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03909172555722762
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:00,083 INFO *** epoch 170, rolling-avg-loss (window=10)= 0.03977893064293312
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:00,102 INFO epoch # 171 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.037459242827026173
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:00,120 INFO epoch # 172 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03716745603014715
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:00,139 INFO epoch # 173 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03706319589400664
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:00,157 INFO epoch # 174 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03718511406623293
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:00,175 INFO epoch # 175 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03720043980865739
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:00,194 INFO epoch # 176 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.037009272011346184
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:00,212 INFO epoch # 177 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03648694002185948
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:00,231 INFO epoch # 178 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.036310162860900164
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:00,249 INFO epoch # 179 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.036912225412379485
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:00,268 INFO epoch # 180 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03662961746158544
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:00,268 INFO *** epoch 180, rolling-avg-loss (window=10)= 0.0369423666394141
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:00,287 INFO epoch # 181 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03646606227266602
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:00,305 INFO epoch # 182 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.038567454292206094
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:00,324 INFO epoch # 183 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03679862774151843
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:00,342 INFO epoch # 184 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.035674148093676195
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:00,361 INFO epoch # 185 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03557350506889634
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:00,379 INFO epoch # 186 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.035720929969102144
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:00,397 INFO epoch # 187 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03497201349819079
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:00,415 INFO epoch # 188 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0345449175365502
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:00,434 INFO epoch # 189 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03508862647868227
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:00,452 INFO epoch # 190 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03488594081136398
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:00,453 INFO *** epoch 190, rolling-avg-loss (window=10)= 0.03582922257628525
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:00,471 INFO epoch # 191 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.034477246546885
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:00,489 INFO epoch # 192 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.035046598452026956
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:00,508 INFO epoch # 193 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.034799314162228256
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:00,527 INFO epoch # 194 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.038059780752519146
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:00,545 INFO epoch # 195 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0357388904230902
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:00,563 INFO epoch # 196 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03439907083520666
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:00,581 INFO epoch # 197 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03495942000881769
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:00,599 INFO epoch # 198 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.034504332157666795
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:00,619 INFO epoch # 199 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03423048465629108
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:00,637 INFO epoch # 200 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03418427024735138
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:00,637 INFO *** epoch 200, rolling-avg-loss (window=10)= 0.03503994082420832
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:00,656 INFO epoch # 201 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03405729400401469
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:00,674 INFO epoch # 202 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03357274552399758
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:00,692 INFO epoch # 203 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03403955732937902
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:00,711 INFO epoch # 204 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.033627231619902886
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:00,729 INFO epoch # 205 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.033453534211730585
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:00,747 INFO epoch # 206 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.033720876221195795
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:00,765 INFO epoch # 207 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03340787264460232
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:00,784 INFO epoch # 208 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03312334824295249
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:00,802 INFO epoch # 209 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03339220501948148
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:00,820 INFO epoch # 210 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.033319902344373986
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:00,820 INFO *** epoch 210, rolling-avg-loss (window=10)= 0.03357145671616309
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:00,839 INFO epoch # 211 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.032623105245875195
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:00,858 INFO epoch # 212 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03264212676731404
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:00,876 INFO epoch # 213 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03263486576906871
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:00,895 INFO epoch # 214 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.04556862500612624
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:00,914 INFO epoch # 215 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03352175067993812
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:00,932 INFO epoch # 216 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03285436151782051
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:00,951 INFO epoch # 217 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.035900280287023634
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:00,969 INFO epoch # 218 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03363899375835899
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:00,987 INFO epoch # 219 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03270975321356673
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:01,005 INFO epoch # 220 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.031739791549625807
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:01,006 INFO *** epoch 220, rolling-avg-loss (window=10)= 0.0343833653794718
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:01,024 INFO epoch # 221 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03233327085035853
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:01,042 INFO epoch # 222 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03176918579265475
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:01,061 INFO epoch # 223 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0322589541610796
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:01,079 INFO epoch # 224 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.031743827916216105
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:01,097 INFO epoch # 225 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.031731985465739854
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:01,116 INFO epoch # 226 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03179586042824667
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:01,135 INFO epoch # 227 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03169225536112208
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:01,153 INFO epoch # 228 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.031114160927245393
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:01,172 INFO epoch # 229 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0315673290315317
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:01,190 INFO epoch # 230 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03135666715388652
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:01,190 INFO *** epoch 230, rolling-avg-loss (window=10)= 0.03173634970880812
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:01,208 INFO epoch # 231 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.031206042956910096
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:01,227 INFO epoch # 232 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03172892861766741
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:01,245 INFO epoch # 233 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03134137945016846
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:01,263 INFO epoch # 234 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.031280755647458136
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:01,282 INFO epoch # 235 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.031055841856868938
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:01,300 INFO epoch # 236 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.031100337699172087
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:01,319 INFO epoch # 237 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.031032859085826203
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:01,338 INFO epoch # 238 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.031016788685519714
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:01,356 INFO epoch # 239 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.031089537384104915
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:01,375 INFO epoch # 240 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.030776627478189766
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:01,375 INFO *** epoch 240, rolling-avg-loss (window=10)= 0.031162909886188573
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:01,393 INFO epoch # 241 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.030471498823317233
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:01,411 INFO epoch # 242 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.030769454780966043
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:01,429 INFO epoch # 243 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03134303432307206
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:01,448 INFO epoch # 244 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03032926205196418
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:01,466 INFO epoch # 245 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.030175621155649424
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:01,484 INFO epoch # 246 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.031001410374301486
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:01,503 INFO epoch # 247 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03200368580291979
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:01,521 INFO epoch # 248 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.030803312576608732
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:01,540 INFO epoch # 249 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.030207096599042416
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:01,558 INFO epoch # 250 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.030235525424359366
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:01,558 INFO *** epoch 250, rolling-avg-loss (window=10)= 0.030733990191220074
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:01,576 INFO epoch # 251 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02959258182090707
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:01,595 INFO epoch # 252 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.030287499976111576
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:01,613 INFO epoch # 253 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03023474066867493
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:01,632 INFO epoch # 254 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.029858567242627032
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:01,651 INFO epoch # 255 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02986560174031183
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:01,670 INFO epoch # 256 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02957605522533413
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:01,688 INFO epoch # 257 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02978920612076763
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:01,707 INFO epoch # 258 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02952044222911354
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:01,726 INFO epoch # 259 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.029829245395376347
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:01,744 INFO epoch # 260 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02974750509019941
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:01,744 INFO *** epoch 260, rolling-avg-loss (window=10)= 0.02983014455094235
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:01,763 INFO epoch # 261 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.030086738130194135
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:01,781 INFO epoch # 262 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.029099595310981385
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:01,799 INFO epoch # 263 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02961539260286372
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:01,817 INFO epoch # 264 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.040900109423091635
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:01,836 INFO epoch # 265 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03171807338367216
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:01,854 INFO epoch # 266 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.029853202126105316
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:01,872 INFO epoch # 267 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.029216921917395666
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:01,891 INFO epoch # 268 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.028880262034363113
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:01,910 INFO epoch # 269 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.029178188953665085
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:01,929 INFO epoch # 270 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.043814780277898535
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:01,929 INFO *** epoch 270, rolling-avg-loss (window=10)= 0.03223632641602307
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:01,948 INFO epoch # 271 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.030923144644475542
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:01,967 INFO epoch # 272 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02911966119427234
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:01,985 INFO epoch # 273 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.031043680806760676
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:02,003 INFO epoch # 274 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02903619506105315
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:02,022 INFO epoch # 275 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.029227711376734078
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:02,040 INFO epoch # 276 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02840874032699503
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:02,058 INFO epoch # 277 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02835319445875939
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:02,077 INFO epoch # 278 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.028789020478143357
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:02,095 INFO epoch # 279 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02823582624841947
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:02,114 INFO epoch # 280 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.028476992942159995
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:02,114 INFO *** epoch 280, rolling-avg-loss (window=10)= 0.029161416753777303
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:02,133 INFO epoch # 281 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.028820629566325806
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:02,152 INFO epoch # 282 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02840381345595233
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:02,170 INFO epoch # 283 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02839543067966588
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:02,189 INFO epoch # 284 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.028214227757416666
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:02,207 INFO epoch # 285 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02813911057455698
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:02,225 INFO epoch # 286 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02837370765337255
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:02,243 INFO epoch # 287 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.031185337851638906
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:02,261 INFO epoch # 288 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02840529035893269
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:02,280 INFO epoch # 289 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02797788509633392
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:02,298 INFO epoch # 290 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.043907986517297104
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:02,299 INFO *** epoch 290, rolling-avg-loss (window=10)= 0.030182341951149282
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:02,317 INFO epoch # 291 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.03141257195966318
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:02,335 INFO epoch # 292 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.028378333168802783
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:02,354 INFO epoch # 293 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02801558827923145
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:02,372 INFO epoch # 294 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02818510557699483
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:02,391 INFO epoch # 295 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02797111580730416
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:02,409 INFO epoch # 296 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02823499037185684
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:02,428 INFO epoch # 297 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02841268654447049
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:02,446 INFO epoch # 298 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.027903301146579906
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:02,464 INFO epoch # 299 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.027835226166644134
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:02,483 INFO epoch # 300 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.027713061004760675
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:02,483 INFO *** epoch 300, rolling-avg-loss (window=10)= 0.028406198002630844
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:02,501 INFO epoch # 301 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02761499934422318
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:02,520 INFO epoch # 302 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02776016591815278
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:02,538 INFO epoch # 303 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.027735278665204532
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:02,557 INFO epoch # 304 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02764810655207839
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:02,575 INFO epoch # 305 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.027270020262221806
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:02,593 INFO epoch # 306 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.027556603439734317
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:02,612 INFO epoch # 307 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.028063719350029714
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:02,630 INFO epoch # 308 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.027277083208900876
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:02,648 INFO epoch # 309 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.027818399481475353
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:02,667 INFO epoch # 310 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.026951688836561516
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:02,667 INFO *** epoch 310, rolling-avg-loss (window=10)= 0.027569606505858248
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:02,685 INFO epoch # 311 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.027853137435158715
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:02,704 INFO epoch # 312 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.027457830772618763
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:02,723 INFO epoch # 313 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02738290512934327
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:02,741 INFO epoch # 314 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02707958327664528
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:02,760 INFO epoch # 315 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.027552358573302627
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:02,778 INFO epoch # 316 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.027305732292006724
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:02,797 INFO epoch # 317 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.026899075499386527
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:02,815 INFO epoch # 318 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02730232990870718
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:02,833 INFO epoch # 319 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02716389858687762
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:02,852 INFO epoch # 320 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.026968107660650276
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:02,852 INFO *** epoch 320, rolling-avg-loss (window=10)= 0.0272964959134697
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:02,870 INFO epoch # 321 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.027036334198783152
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:02,888 INFO epoch # 322 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.026900228927843273
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:02,907 INFO epoch # 323 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.027314538761856966
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:02,926 INFO epoch # 324 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.026574388190056197
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:02,944 INFO epoch # 325 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.026620352262398228
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:02,963 INFO epoch # 326 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.026786227914271876
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:02,981 INFO epoch # 327 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02664906083373353
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:03,000 INFO epoch # 328 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02660687707248144
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:03,018 INFO epoch # 329 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02671028110489715
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:03,037 INFO epoch # 330 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.026644624609616585
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:03,037 INFO *** epoch 330, rolling-avg-loss (window=10)= 0.02678429138759384
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:03,055 INFO epoch # 331 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.025959550082916394
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:03,073 INFO epoch # 332 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.026709294295869768
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:03,092 INFO epoch # 333 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.026103892334504053
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:03,110 INFO epoch # 334 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02637965242320206
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:03,129 INFO epoch # 335 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.026452762438566424
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:03,148 INFO epoch # 336 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.026254914206219837
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:03,166 INFO epoch # 337 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.02640367575804703
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:03,185 INFO epoch # 338 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.0261892682465259
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:03,203 INFO epoch # 339 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.026206814276520163
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:03,221 INFO epoch # 340 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.026644239624147303
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:03,222 INFO *** epoch 340, rolling-avg-loss (window=10)= 0.026330406368651894
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:03,240 INFO epoch # 341 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.01 -loss = 0.026128228986635804
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:03,258 INFO epoch # 342 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.01-> 0.0099 -loss = 0.026460344888619147
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:03,276 INFO epoch # 343 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.025993344796006568
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:03,295 INFO epoch # 344 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.025721575162606314
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:03,313 INFO epoch # 345 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.025900577209540643
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:03,331 INFO epoch # 346 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.026170035562245175
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:03,350 INFO epoch # 347 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.025757009687367827
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:03,368 INFO epoch # 348 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.026133180916076526
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:03,387 INFO epoch # 349 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.025958092664950527
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:03,405 INFO epoch # 350 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.02678549890697468
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:03,405 INFO *** epoch 350, rolling-avg-loss (window=10)= 0.02610078887810232
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:03,424 INFO epoch # 351 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.02754290628945455
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:03,442 INFO epoch # 352 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.025738097581779584
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:03,460 INFO epoch # 353 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.026329773987527005
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:03,478 INFO epoch # 354 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.025459141499595717
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:03,497 INFO epoch # 355 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.02568827474169666
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:03,515 INFO epoch # 356 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.025523756616166793
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:03,534 INFO epoch # 357 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.025864608614938334
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:03,552 INFO epoch # 358 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.026099325026734732
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:03,571 INFO epoch # 359 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.02592713842750527
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:03,590 INFO epoch # 360 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.02532464977412019
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:03,590 INFO *** epoch 360, rolling-avg-loss (window=10)= 0.025949767255951883
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:03,608 INFO epoch # 361 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.02598392301297281
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:03,627 INFO epoch # 362 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.025451896552112885
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:03,645 INFO epoch # 363 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.02558367511664983
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:03,663 INFO epoch # 364 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.025759861935512163
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:03,681 INFO epoch # 365 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.025101249513681978
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:03,700 INFO epoch # 366 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.025304541020886973
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:03,718 INFO epoch # 367 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.025533559106406756
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:03,737 INFO epoch # 368 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.02486166836024495
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:03,756 INFO epoch # 369 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.025073208496905863
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:03,774 INFO epoch # 370 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.02519679145916598
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:03,774 INFO *** epoch 370, rolling-avg-loss (window=10)= 0.02538503745745402
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:03,793 INFO epoch # 371 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.025138876429991797
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:03,811 INFO epoch # 372 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.02514117477403488
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:03,830 INFO epoch # 373 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.02466957717842888
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:03,848 INFO epoch # 374 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.025088086986215785
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:03,866 INFO epoch # 375 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.026126824028324336
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:03,885 INFO epoch # 376 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.025351405536639504
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:03,903 INFO epoch # 377 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.025217670132406056
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:03,922 INFO epoch # 378 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.025006606825627387
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:03,940 INFO epoch # 379 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.024625299622130115
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:03,959 INFO epoch # 380 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.024954283588158432
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:03,959 INFO *** epoch 380, rolling-avg-loss (window=10)= 0.025131980510195717
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:03,978 INFO epoch # 381 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.024896360759157687
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:03,997 INFO epoch # 382 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.025527077770675533
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:04,015 INFO epoch # 383 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.02486668089113664
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:04,034 INFO epoch # 384 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.02501994818157982
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:04,052 INFO epoch # 385 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.025135918956948444
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:04,070 INFO epoch # 386 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.024749335541855544
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:04,089 INFO epoch # 387 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.02463508323126007
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:04,107 INFO epoch # 388 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.024881462173652835
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:04,126 INFO epoch # 389 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.024484162757289596
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:04,145 INFO epoch # 390 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.024589958673459478
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:04,145 INFO *** epoch 390, rolling-avg-loss (window=10)= 0.024878598893701566
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:04,163 INFO epoch # 391 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.02474884645198472
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:04,182 INFO epoch # 392 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.024239104401203804
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:04,201 INFO epoch # 393 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.024594281683675945
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:04,219 INFO epoch # 394 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.0244403297547251
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:04,237 INFO epoch # 395 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.024636513699078932
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:04,256 INFO epoch # 396 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.024603689365903847
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:04,274 INFO epoch # 397 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.024534846714232117
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:04,292 INFO epoch # 398 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.02427603527030442
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:04,311 INFO epoch # 399 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.024204374407418072
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:04,329 INFO epoch # 400 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.024655119166709483
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:04,329 INFO *** epoch 400, rolling-avg-loss (window=10)= 0.024493314091523645
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:04,348 INFO epoch # 401 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.02421439935278613
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:04,366 INFO epoch # 402 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.024341518590517808
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:04,385 INFO epoch # 403 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.023943935695569962
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:04,403 INFO epoch # 404 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.024211297393776476
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:04,422 INFO epoch # 405 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.02408559521427378
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:04,440 INFO epoch # 406 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.02403828078240622
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:04,458 INFO epoch # 407 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.024146517156623304
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:04,476 INFO epoch # 408 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.02400486308033578
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:04,495 INFO epoch # 409 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.023677003286138643
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:04,513 INFO epoch # 410 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.02467551061999984
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:04,513 INFO *** epoch 410, rolling-avg-loss (window=10)= 0.024133892117242796
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:04,532 INFO epoch # 411 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.02405813886434771
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:04,551 INFO epoch # 412 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.024067652455414645
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:04,569 INFO epoch # 413 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.024040631062234752
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:04,588 INFO epoch # 414 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.023705682426225394
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:04,606 INFO epoch # 415 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.023795133878593333
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:04,626 INFO epoch # 416 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.0236022543758736
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:04,646 INFO epoch # 417 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.0243121075181989
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:04,664 INFO epoch # 418 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.02419241238385439
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:04,683 INFO epoch # 419 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.023926536247017793
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:04,701 INFO epoch # 420 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.023784087250533048
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:04,701 INFO *** epoch 420, rolling-avg-loss (window=10)= 0.023948463646229358
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:04,720 INFO epoch # 421 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.023353888413112145
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:04,738 INFO epoch # 422 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.02356898666039342
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:04,757 INFO epoch # 423 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.023733512352919206
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:04,776 INFO epoch # 424 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.024054739289567806
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:04,795 INFO epoch # 425 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.03685831399343442
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:04,813 INFO epoch # 426 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.026137771892535966
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:04,832 INFO epoch # 427 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.0245943963091122
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:04,850 INFO epoch # 428 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.02422812199802138
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:04,869 INFO epoch # 429 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.0248370338085806
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:04,887 INFO epoch # 430 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.02404325967654586
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:04,887 INFO *** epoch 430, rolling-avg-loss (window=10)= 0.0255410024394223
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:04,906 INFO epoch # 431 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.02359820428682724
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:04,924 INFO epoch # 432 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.02333805029047653
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:04,942 INFO epoch # 433 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.023287052346859127
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:04,961 INFO epoch # 434 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.02334786966093816
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:04,979 INFO epoch # 435 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.02339873909659218
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:04,998 INFO epoch # 436 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.023128641580115072
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:05,017 INFO epoch # 437 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.023737739757052623
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:05,035 INFO epoch # 438 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.023290967030334286
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:05,053 INFO epoch # 439 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.02362328850722406
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:05,072 INFO epoch # 440 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.023416791620547883
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:05,072 INFO *** epoch 440, rolling-avg-loss (window=10)= 0.023416734417696716
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:05,090 INFO epoch # 441 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.023123073857277632
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:05,108 INFO epoch # 442 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.023325636735535227
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:05,127 INFO epoch # 443 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.0230856357520679
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:05,145 INFO epoch # 444 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.022963788971537724
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:05,164 INFO epoch # 445 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.023272187027032487
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:05,182 INFO epoch # 446 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.023134153678256553
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:05,201 INFO epoch # 447 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.023033233359456062
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:05,219 INFO epoch # 448 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.022894757334142923
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:05,238 INFO epoch # 449 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.02370141021674499
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:05,256 INFO epoch # 450 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.024544482119381428
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:05,256 INFO *** epoch 450, rolling-avg-loss (window=10)= 0.023307835905143293
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:05,274 INFO epoch # 451 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.023477742943214253
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:05,293 INFO epoch # 452 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.02266942230926361
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:05,311 INFO epoch # 453 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.022863513164338656
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:05,329 INFO epoch # 454 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.023067751317285
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:05,348 INFO epoch # 455 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.023063859072863124
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:05,366 INFO epoch # 456 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.022732018449460156
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:05,385 INFO epoch # 457 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.03575779246602906
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:05,403 INFO epoch # 458 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.024687979064765386
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:05,422 INFO epoch # 459 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.02323795756092295
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:05,440 INFO epoch # 460 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.022934907945455052
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:05,440 INFO *** epoch 460, rolling-avg-loss (window=10)= 0.024449294429359725
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:05,458 INFO epoch # 461 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.023129941459046677
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:05,477 INFO epoch # 462 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.02277300923014991
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:05,495 INFO epoch # 463 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.022589209183934145
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:05,513 INFO epoch # 464 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.023173967478214763
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:05,531 INFO epoch # 465 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.022405930154491216
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:05,550 INFO epoch # 466 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.023616213962668553
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:05,568 INFO epoch # 467 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.022748186718672514
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:05,587 INFO epoch # 468 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.02334439111291431
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:05,605 INFO epoch # 469 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.022768129289033823
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:05,625 INFO epoch # 470 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.02203233579348307
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:05,625 INFO *** epoch 470, rolling-avg-loss (window=10)= 0.022858131438260897
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:05,643 INFO epoch # 471 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.02276777764200233
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:05,662 INFO epoch # 472 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.022705347611918114
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:05,680 INFO epoch # 473 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.02237497560417978
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:05,698 INFO epoch # 474 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.02252987372048665
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:05,716 INFO epoch # 475 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.022181663567607757
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:05,735 INFO epoch # 476 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.022534783420269378
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:05,753 INFO epoch # 477 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.022337615548167378
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:05,772 INFO epoch # 478 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.022192222750163637
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:05,790 INFO epoch # 479 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.02266711318225134
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:05,808 INFO epoch # 480 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0099 -loss = 0.022286541818175465
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:05,809 INFO *** epoch 480, rolling-avg-loss (window=10)= 0.02245779148652218
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:05,827 INFO epoch # 481 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0099-> 0.0098 -loss = 0.022626050777034834
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:05,846 INFO epoch # 482 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.022370255013811402
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:05,864 INFO epoch # 483 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.022317481656500604
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:05,882 INFO epoch # 484 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.02226263801276218
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:05,900 INFO epoch # 485 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.02388975239591673
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:05,919 INFO epoch # 486 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.0228237912961049
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:05,937 INFO epoch # 487 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.02201268779754173
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:05,956 INFO epoch # 488 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.02342679732828401
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:05,974 INFO epoch # 489 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.021802664661663584
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:05,993 INFO epoch # 490 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.03338559820258524
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:05,993 INFO *** epoch 490, rolling-avg-loss (window=10)= 0.023691771714220523
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:06,012 INFO epoch # 491 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.024153511825716123
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:06,030 INFO epoch # 492 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.021958090626867488
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:06,049 INFO epoch # 493 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.02250621182611212
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:06,067 INFO epoch # 494 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.02257837435172405
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:06,085 INFO epoch # 495 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.022985656585660763
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:06,103 INFO epoch # 496 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.022693939332384616
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:06,122 INFO epoch # 497 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.022411213896702975
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:06,141 INFO epoch # 498 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.021995308183250017
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:06,159 INFO epoch # 499 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.021741484822996426
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:06,178 INFO epoch # 500 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.021700938370486256
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:06,178 INFO *** epoch 500, rolling-avg-loss (window=10)= 0.022472472982190083
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:06,196 INFO epoch # 501 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.023351881885901093
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:06,215 INFO epoch # 502 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.02178051829105243
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:06,233 INFO epoch # 503 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.021777114634460304
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:06,252 INFO epoch # 504 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.021750820393208414
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:06,270 INFO epoch # 505 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.021679159421182703
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:06,288 INFO epoch # 506 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.021987841217196546
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:06,307 INFO epoch # 507 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.021881286971620284
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:06,325 INFO epoch # 508 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.02272169374191435
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:06,344 INFO epoch # 509 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.021744155586929992
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:06,362 INFO epoch # 510 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.021237278437183704
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:06,362 INFO *** epoch 510, rolling-avg-loss (window=10)= 0.02199117505806498
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:06,381 INFO epoch # 511 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.02195853532612091
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:06,400 INFO epoch # 512 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.02175676696060691
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:06,418 INFO epoch # 513 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.02146053910109913
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:06,437 INFO epoch # 514 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.021543828515859786
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:06,455 INFO epoch # 515 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.02194919783505611
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:06,473 INFO epoch # 516 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.02215078641893342
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:06,492 INFO epoch # 517 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.02132509116199799
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:06,510 INFO epoch # 518 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.02144196214794647
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:06,529 INFO epoch # 519 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.02156176471908111
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:06,547 INFO epoch # 520 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0098 -loss = 0.021305899368599057
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:06,547 INFO *** epoch 520, rolling-avg-loss (window=10)= 0.02164543715553009
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:06,566 INFO epoch # 521 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0098-> 0.0097 -loss = 0.032582037907559425
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:06,584 INFO epoch # 522 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.02333077829098329
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:06,603 INFO epoch # 523 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.021203141164733097
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:06,622 INFO epoch # 524 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.02124369922967162
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:06,641 INFO epoch # 525 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.022910624349606223
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:06,659 INFO epoch # 526 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.02183150411292445
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:06,677 INFO epoch # 527 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.022611650900216773
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:06,696 INFO epoch # 528 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.021046859386842698
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:06,714 INFO epoch # 529 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.021320772197213955
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:06,732 INFO epoch # 530 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.021054692042525858
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:06,732 INFO *** epoch 530, rolling-avg-loss (window=10)= 0.02291357595822774
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:06,751 INFO epoch # 531 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.02158349433739204
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:06,770 INFO epoch # 532 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.021145777063793503
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:06,788 INFO epoch # 533 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.02311327868665103
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:06,807 INFO epoch # 534 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.021255538536934182
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:06,825 INFO epoch # 535 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.02125281942426227
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:06,844 INFO epoch # 536 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.020845131286478136
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:06,862 INFO epoch # 537 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.02101565297198249
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:06,881 INFO epoch # 538 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.021822295144374948
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:06,899 INFO epoch # 539 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.02083602690254338
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:06,917 INFO epoch # 540 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.02043967707140837
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:06,917 INFO *** epoch 540, rolling-avg-loss (window=10)= 0.021330969142582035
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:06,935 INFO epoch # 541 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.020904161385260522
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:06,954 INFO epoch # 542 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.02077534746786114
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:06,972 INFO epoch # 543 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.02199913887307048
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:06,991 INFO epoch # 544 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.022055867419112474
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:07,009 INFO epoch # 545 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.021618911079713143
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:07,028 INFO epoch # 546 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.02070624659245368
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:07,047 INFO epoch # 547 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.020757818827405572
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:07,065 INFO epoch # 548 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.02076163711899426
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:07,084 INFO epoch # 549 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.020975405583158135
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:07,103 INFO epoch # 550 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0097 -loss = 0.020865649596089497
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:07,103 INFO *** epoch 550, rolling-avg-loss (window=10)= 0.02114201839431189
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:07,121 INFO epoch # 551 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0097-> 0.0096 -loss = 0.020762463464052416
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:07,140 INFO epoch # 552 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0096-> 0.0096 -loss = 0.020644200369133614
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:07,158 INFO epoch # 553 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0096-> 0.0096 -loss = 0.02083746976859402
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:07,177 INFO epoch # 554 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0096-> 0.0096 -loss = 0.02078968119167257
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:07,195 INFO epoch # 555 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0096-> 0.0096 -loss = 0.020532070207991637
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:07,214 INFO epoch # 556 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0096-> 0.0096 -loss = 0.020527097687590867
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:07,232 INFO epoch # 557 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0096-> 0.0096 -loss = 0.021077077282825485
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:07,251 INFO epoch # 558 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0096-> 0.0096 -loss = 0.02094958073575981
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:07,269 INFO epoch # 559 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0096-> 0.0096 -loss = 0.021008130148402415
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:07,288 INFO epoch # 560 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0096-> 0.0096 -loss = 0.020488758105784655
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:07,288 INFO *** epoch 560, rolling-avg-loss (window=10)= 0.02076165289618075
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:07,306 INFO epoch # 561 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0096-> 0.0096 -loss = 0.020835158036788926
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:07,324 INFO epoch # 562 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0096-> 0.0095 -loss = 0.03024742248817347
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:07,343 INFO epoch # 563 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0095-> 0.0095 -loss = 0.020880980184301734
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:07,361 INFO epoch # 564 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0095-> 0.0095 -loss = 0.020856825554801617
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:07,380 INFO epoch # 565 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0095-> 0.0095 -loss = 0.021863641930394806
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:07,398 INFO epoch # 566 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0095-> 0.0095 -loss = 0.020593340159393847
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:07,417 INFO epoch # 567 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0095-> 0.0095 -loss = 0.020344602919067256
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:07,435 INFO epoch # 568 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0095-> 0.0095 -loss = 0.020243923718226142
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:07,454 INFO epoch # 569 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0095-> 0.0095 -loss = 0.02052550319058355
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:07,472 INFO epoch # 570 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0095-> 0.0095 -loss = 0.02069376864528749
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:07,472 INFO *** epoch 570, rolling-avg-loss (window=10)= 0.021708516682701885
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:07,491 INFO epoch # 571 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0095-> 0.0095 -loss = 0.020843992184381932
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:07,509 INFO epoch # 572 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0095-> 0.0095 -loss = 0.020481468563957606
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:07,527 INFO epoch # 573 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0095-> 0.0095 -loss = 0.02029283656156622
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:07,545 INFO epoch # 574 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0095-> 0.0095 -loss = 0.020387285025208257
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:07,563 INFO epoch # 575 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0095-> 0.0095 -loss = 0.020649121972383
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:07,582 INFO epoch # 576 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0095-> 0.0095 -loss = 0.020463835462578572
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:07,600 INFO epoch # 577 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0095-> 0.0095 -loss = 0.020139356965955812
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:07,620 INFO epoch # 578 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0095-> 0.0095 -loss = 0.019804892915999517
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:07,638 INFO epoch # 579 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0095-> 0.0095 -loss = 0.020335550274467096
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:07,657 INFO epoch # 580 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0095-> 0.0095 -loss = 0.020228910274454392
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:07,657 INFO *** epoch 580, rolling-avg-loss (window=10)= 0.02036272502009524
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:07,676 INFO epoch # 581 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0095-> 0.0095 -loss = 0.020203879728796892
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:07,694 INFO epoch # 582 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0095-> 0.0095 -loss = 0.020031645966810174
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:07,712 INFO epoch # 583 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0095-> 0.0095 -loss = 0.02010375458485214
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:07,730 INFO epoch # 584 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0095-> 0.0095 -loss = 0.02018534117087256
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:07,749 INFO epoch # 585 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0095-> 0.0095 -loss = 0.020200436862069182
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:07,767 INFO epoch # 586 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0095-> 0.0095 -loss = 0.02019813036895357
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:07,786 INFO epoch # 587 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0095-> 0.0095 -loss = 0.01983535855106311
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:07,804 INFO epoch # 588 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0095-> 0.0095 -loss = 0.019854641606798396
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:07,823 INFO epoch # 589 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0095-> 0.0094 -loss = 0.02168869599699974
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:07,841 INFO epoch # 590 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0094-> 0.0094 -loss = 0.020041970667080022
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:07,841 INFO *** epoch 590, rolling-avg-loss (window=10)= 0.020234385550429577
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:07,860 INFO epoch # 591 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0094-> 0.0094 -loss = 0.020328169863205403
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:07,879 INFO epoch # 592 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0094-> 0.0094 -loss = 0.019965886662248522
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:07,897 INFO epoch # 593 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0094-> 0.0094 -loss = 0.019724590303667355
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:07,915 INFO epoch # 594 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0094-> 0.0094 -loss = 0.020375599327962846
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:07,934 INFO epoch # 595 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0094-> 0.0094 -loss = 0.019891042684321292
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:07,952 INFO epoch # 596 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0094-> 0.0094 -loss = 0.019791619168245234
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:07,970 INFO epoch # 597 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0094-> 0.0094 -loss = 0.019782812465564348
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:07,989 INFO epoch # 598 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0094-> 0.0094 -loss = 0.0201968376422883
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:08,007 INFO epoch # 599 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0094-> 0.0094 -loss = 0.019847912815748714
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:08,026 INFO epoch # 600 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0094-> 0.0094 -loss = 0.02012759594072122
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:08,026 INFO *** epoch 600, rolling-avg-loss (window=10)= 0.020003206687397322
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:08,045 INFO epoch # 601 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0094-> 0.0094 -loss = 0.019890555427991785
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:08,063 INFO epoch # 602 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0094-> 0.0094 -loss = 0.019980835073511116
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:08,082 INFO epoch # 603 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0094-> 0.0094 -loss = 0.020131346042035148
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:08,100 INFO epoch # 604 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0094-> 0.0094 -loss = 0.01960095961112529
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:08,119 INFO epoch # 605 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0094-> 0.0094 -loss = 0.019761095129069872
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:08,137 INFO epoch # 606 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0094-> 0.0094 -loss = 0.019919458289223257
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:08,155 INFO epoch # 607 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0094-> 0.0094 -loss = 0.020044250843056943
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:08,174 INFO epoch # 608 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0094-> 0.0094 -loss = 0.019531190067937132
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:08,192 INFO epoch # 609 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0094-> 0.0094 -loss = 0.019599644525442272
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:08,210 INFO epoch # 610 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0094-> 0.0094 -loss = 0.019639367412310094
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:08,211 INFO *** epoch 610, rolling-avg-loss (window=10)= 0.01980987024217029
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:08,229 INFO epoch # 611 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0094-> 0.0094 -loss = 0.019876879938237835
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:08,248 INFO epoch # 612 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0094-> 0.0094 -loss = 0.019574221136281267
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:08,266 INFO epoch # 613 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0094-> 0.0094 -loss = 0.01973914439440705
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:08,285 INFO epoch # 614 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0094-> 0.0094 -loss = 0.0197893928270787
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:08,303 INFO epoch # 615 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0094-> 0.0094 -loss = 0.019432829300058074
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:08,322 INFO epoch # 616 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0094-> 0.0094 -loss = 0.0193645430408651
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:08,340 INFO epoch # 617 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0094-> 0.0094 -loss = 0.0194695228128694
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:08,358 INFO epoch # 618 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0094-> 0.0094 -loss = 0.01930097351578297
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:08,376 INFO epoch # 619 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0094-> 0.0094 -loss = 0.02137347963434877
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:08,395 INFO epoch # 620 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0094-> 0.0094 -loss = 0.019777203822741285
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:08,395 INFO *** epoch 620, rolling-avg-loss (window=10)= 0.019769819042267045
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:08,414 INFO epoch # 621 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0094-> 0.0094 -loss = 0.020466918853344396
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:08,432 INFO epoch # 622 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0094-> 0.0094 -loss = 0.019701159180840477
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:08,451 INFO epoch # 623 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0094-> 0.0094 -loss = 0.019745133045944385
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:08,469 INFO epoch # 624 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0094-> 0.0094 -loss = 0.01951557803840842
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:08,488 INFO epoch # 625 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0094-> 0.0094 -loss = 0.019268417192506604
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:08,506 INFO epoch # 626 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0094-> 0.0094 -loss = 0.019129272433929145
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:08,524 INFO epoch # 627 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0094-> 0.0094 -loss = 0.019528515244019218
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:08,542 INFO epoch # 628 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0094-> 0.0094 -loss = 0.019520549874869175
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:08,560 INFO epoch # 629 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0094-> 0.0094 -loss = 0.019241592235630378
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:08,579 INFO epoch # 630 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0094-> 0.0094 -loss = 0.019743770579225384
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:08,579 INFO *** epoch 630, rolling-avg-loss (window=10)= 0.01958609066787176
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:08,597 INFO epoch # 631 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0094-> 0.0094 -loss = 0.01976666459813714
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:08,616 INFO epoch # 632 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0094-> 0.0094 -loss = 0.019235034924349748
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:08,635 INFO epoch # 633 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0094-> 0.0094 -loss = 0.01961364377348218
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:08,653 INFO epoch # 634 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0094-> 0.0094 -loss = 0.019088561661192216
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:08,672 INFO epoch # 635 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0094-> 0.0094 -loss = 0.019316113044624217
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:08,690 INFO epoch # 636 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0094-> 0.0094 -loss = 0.019233151266234927
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:08,709 INFO epoch # 637 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0094-> 0.0094 -loss = 0.020444970061362255
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:08,727 INFO epoch # 638 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0094-> 0.0094 -loss = 0.019201652648916934
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:08,746 INFO epoch # 639 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0094-> 0.0094 -loss = 0.019548661104636267
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:08,764 INFO epoch # 640 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0094-> 0.0094 -loss = 0.01974175393115729
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:08,764 INFO *** epoch 640, rolling-avg-loss (window=10)= 0.019519020701409318
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:08,782 INFO epoch # 641 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0094-> 0.0094 -loss = 0.01931065173994284
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:08,801 INFO epoch # 642 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0094-> 0.0094 -loss = 0.019936648175644223
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:08,819 INFO epoch # 643 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0094-> 0.0094 -loss = 0.019586794929637108
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:08,838 INFO epoch # 644 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0094-> 0.0094 -loss = 0.01912798466219101
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:08,856 INFO epoch # 645 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0094-> 0.0093 -loss = 0.019172934800735675
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:08,875 INFO epoch # 646 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.019196806140826084
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:08,893 INFO epoch # 647 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.019096133139100857
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:08,912 INFO epoch # 648 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.019236897540395148
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:08,930 INFO epoch # 649 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.019112858361040708
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:08,948 INFO epoch # 650 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.018855244437872898
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:08,948 INFO *** epoch 650, rolling-avg-loss (window=10)= 0.019263295392738654
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:08,966 INFO epoch # 651 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.018927829652966466
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:08,985 INFO epoch # 652 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.01917949852941092
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:09,003 INFO epoch # 653 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.019000685009814333
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:09,022 INFO epoch # 654 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.019282884284621105
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:09,040 INFO epoch # 655 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.019107089741737582
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:09,059 INFO epoch # 656 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.01889383848174475
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:09,078 INFO epoch # 657 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.028952314329217188
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:09,097 INFO epoch # 658 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.021445251753902994
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:09,116 INFO epoch # 659 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.019058456098719034
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:09,134 INFO epoch # 660 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0093 -loss = 0.01934135922783753
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:09,134 INFO *** epoch 660, rolling-avg-loss (window=10)= 0.02031892071099719
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:09,153 INFO epoch # 661 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0093-> 0.0092 -loss = 0.019072129754931666
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:09,171 INFO epoch # 662 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.018972929290612228
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:09,189 INFO epoch # 663 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.019139452633680776
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:09,208 INFO epoch # 664 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.018596081848954782
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:09,226 INFO epoch # 665 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.018504077634133864
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:09,245 INFO epoch # 666 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.019077284181548748
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:09,263 INFO epoch # 667 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.018876292946515605
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:09,282 INFO epoch # 668 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.01906244337442331
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:09,301 INFO epoch # 669 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.018746195652056485
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:09,319 INFO epoch # 670 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.01897811573871877
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:09,319 INFO *** epoch 670, rolling-avg-loss (window=10)= 0.018902500305557624
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:09,338 INFO epoch # 671 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.018627123747137375
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:09,356 INFO epoch # 672 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.01865460651606554
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:09,375 INFO epoch # 673 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.018837867348338477
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:09,393 INFO epoch # 674 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.018703717956668697
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:09,411 INFO epoch # 675 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0092 -loss = 0.018741290041361935
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:09,430 INFO epoch # 676 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0092-> 0.0091 -loss = 0.018517368800530676
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:09,448 INFO epoch # 677 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0091-> 0.0091 -loss = 0.019167231148458086
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:09,467 INFO epoch # 678 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0091-> 0.0091 -loss = 0.018490328242478427
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:09,486 INFO epoch # 679 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0091-> 0.0091 -loss = 0.01867712633975316
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:09,505 INFO epoch # 680 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0091-> 0.0091 -loss = 0.02617788613133598
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:09,505 INFO *** epoch 680, rolling-avg-loss (window=10)= 0.019459454627212835
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:09,523 INFO epoch # 681 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0091-> 0.0091 -loss = 0.0193707759026438
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:09,542 INFO epoch # 682 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0091-> 0.0091 -loss = 0.01884498749859631
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:09,560 INFO epoch # 683 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0091-> 0.0091 -loss = 0.018358394634560682
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:09,578 INFO epoch # 684 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0091-> 0.0091 -loss = 0.018497245451726485
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:09,597 INFO epoch # 685 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0091-> 0.0091 -loss = 0.018384377588517964
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:09,616 INFO epoch # 686 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0091-> 0.0091 -loss = 0.018444152257870883
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:09,635 INFO epoch # 687 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0091-> 0.0091 -loss = 0.02497788768960163
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:09,654 INFO epoch # 688 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0091-> 0.0091 -loss = 0.020028100138006266
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:09,673 INFO epoch # 689 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0091-> 0.0091 -loss = 0.018549093198089395
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:09,692 INFO epoch # 690 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0091-> 0.0091 -loss = 0.01833091511070961
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:09,692 INFO *** epoch 690, rolling-avg-loss (window=10)= 0.019378592947032303
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:09,711 INFO epoch # 691 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0091-> 0.0091 -loss = 0.018511551708797924
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:09,730 INFO epoch # 692 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0091-> 0.0091 -loss = 0.018288610561285168
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:09,748 INFO epoch # 693 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0091-> 0.0091 -loss = 0.018377373897237703
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:09,767 INFO epoch # 694 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0091-> 0.0091 -loss = 0.018625029202667065
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:09,785 INFO epoch # 695 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0091-> 0.0091 -loss = 0.018216539407148957
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:09,803 INFO epoch # 696 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0091-> 0.0091 -loss = 0.018397163003101014
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:09,822 INFO epoch # 697 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0091-> 0.0091 -loss = 0.018195623204519507
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:09,841 INFO epoch # 698 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0091-> 0.0091 -loss = 0.01830293696548324
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:09,860 INFO epoch # 699 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0091-> 0.0091 -loss = 0.01815341829933459
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:09,879 INFO epoch # 700 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0091-> 0.0091 -loss = 0.018122337460226845
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:09,879 INFO *** epoch 700, rolling-avg-loss (window=10)= 0.0183190583709802
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:09,906 INFO epoch # 701 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0091-> 0.0091 -loss = 0.018316707595658954
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:09,928 INFO epoch # 702 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0091-> 0.0091 -loss = 0.018176639590819832
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:09,950 INFO epoch # 703 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0091-> 0.0091 -loss = 0.017817882020608522
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:09,972 INFO epoch # 704 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0091-> 0.0091 -loss = 0.018186608685937244
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:09,992 INFO epoch # 705 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0091-> 0.0091 -loss = 0.018311908934265375
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:10,011 INFO epoch # 706 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0091-> 0.0091 -loss = 0.01811315369559452
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:10,030 INFO epoch # 707 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0091-> 0.0091 -loss = 0.019165651232469827
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:10,049 INFO epoch # 708 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0091-> 0.0091 -loss = 0.018219098725239746
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:10,068 INFO epoch # 709 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0091-> 0.0091 -loss = 0.018356191721977666
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:10,088 INFO epoch # 710 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0091-> 0.0091 -loss = 0.01819185858767014
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:10,088 INFO *** epoch 710, rolling-avg-loss (window=10)= 0.018285570079024184
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:10,107 INFO epoch # 711 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0091-> 0.0091 -loss = 0.017887029360281304
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:10,127 INFO epoch # 712 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0091-> 0.0091 -loss = 0.017968441708944738
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:10,146 INFO epoch # 713 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0091-> 0.0091 -loss = 0.017832307901699096
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:10,165 INFO epoch # 714 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0091-> 0.009 -loss = 0.017925707237736788
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:10,185 INFO epoch # 715 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.009 -loss = 0.018129137009964325
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:10,206 INFO epoch # 716 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.009 -loss = 0.01807135748094879
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:10,228 INFO epoch # 717 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.009 -loss = 0.01798041166330222
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:10,252 INFO epoch # 718 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.009 -loss = 0.017930250280187465
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:10,274 INFO epoch # 719 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.009 -loss = 0.017925812346220482
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:10,296 INFO epoch # 720 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.009 -loss = 0.017843531742983032
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:10,296 INFO *** epoch 720, rolling-avg-loss (window=10)= 0.017949398673226823
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:10,317 INFO epoch # 721 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.009 -loss = 0.018165352492360398
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:10,338 INFO epoch # 722 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.009 -loss = 0.017763299023499712
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:10,358 INFO epoch # 723 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.009 -loss = 0.018138551342417486
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:10,377 INFO epoch # 724 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.009 -loss = 0.017986502447456587
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:10,396 INFO epoch # 725 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.009 -loss = 0.017980679294851143
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:10,415 INFO epoch # 726 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.009 -loss = 0.018163627275498584
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:10,435 INFO epoch # 727 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.009 -loss = 0.018084866991557647
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:10,454 INFO epoch # 728 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.009 -loss = 0.019578771250962745
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:10,473 INFO epoch # 729 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.009 -loss = 0.01824070716247661
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:10,492 INFO epoch # 730 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.009 -loss = 0.017814533202908933
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:10,492 INFO *** epoch 730, rolling-avg-loss (window=10)= 0.018191689048398983
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:10,511 INFO epoch # 731 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.009 -loss = 0.028179061497212388
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:10,530 INFO epoch # 732 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.009 -loss = 0.019105600396869704
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:10,557 INFO epoch # 733 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.009 -loss = 0.017956997973669786
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:10,589 INFO epoch # 734 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.009 -loss = 0.018086821932229213
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:10,620 INFO epoch # 735 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.009 -loss = 0.01794540481932927
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:10,639 INFO epoch # 736 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.009 -loss = 0.017968647727684584
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:10,658 INFO epoch # 737 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.009 -loss = 0.01777605441020569
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:10,677 INFO epoch # 738 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.009 -loss = 0.01775136011565337
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:10,696 INFO epoch # 739 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.009 -loss = 0.01876882105716504
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:10,715 INFO epoch # 740 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.009 -loss = 0.017752291620126925
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:10,715 INFO *** epoch 740, rolling-avg-loss (window=10)= 0.0191291061550146
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:10,735 INFO epoch # 741 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.009 -loss = 0.017728477803757414
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:10,754 INFO epoch # 742 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.009 -loss = 0.017466912933741696
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:10,773 INFO epoch # 743 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.009 -loss = 0.017600979714188725
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:10,792 INFO epoch # 744 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.009 -loss = 0.017628094166866504
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:10,814 INFO epoch # 745 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.009 -loss = 0.018116865008778404
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:10,836 INFO epoch # 746 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.009 -loss = 0.017760055561666377
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:10,860 INFO epoch # 747 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.009 -loss = 0.01765346436877735
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:10,882 INFO epoch # 748 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.009 -loss = 0.017833956735557877
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:10,905 INFO epoch # 749 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.009 -loss = 0.01766930073790718
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:10,928 INFO epoch # 750 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.009 -loss = 0.01752643803774845
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:10,928 INFO *** epoch 750, rolling-avg-loss (window=10)= 0.017698454506898997
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:10,950 INFO epoch # 751 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.009 -loss = 0.01809407290420495
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:10,972 INFO epoch # 752 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.009 -loss = 0.017586483256309293
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:10,993 INFO epoch # 753 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.009-> 0.0089 -loss = 0.01823845815670211
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:11,012 INFO epoch # 754 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.017469334743509535
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:11,031 INFO epoch # 755 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.017489752288383897
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:11,051 INFO epoch # 756 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.017693800749839284
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:11,070 INFO epoch # 757 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.017566213122336194
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:11,089 INFO epoch # 758 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.017689825108391233
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:11,108 INFO epoch # 759 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.017899120277434122
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:11,129 INFO epoch # 760 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.017484300486103166
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:11,129 INFO *** epoch 760, rolling-avg-loss (window=10)= 0.017721136109321377
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:11,149 INFO epoch # 761 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.017261736968066543
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:11,168 INFO epoch # 762 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.017627846049435902
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:11,188 INFO epoch # 763 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.017455707566114143
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:11,208 INFO epoch # 764 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.0173703400650993
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:11,227 INFO epoch # 765 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.017302619038673583
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:11,246 INFO epoch # 766 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.017291842101258226
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:11,265 INFO epoch # 767 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.017401988749043085
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:11,285 INFO epoch # 768 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.01744060663622804
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:11,304 INFO epoch # 769 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.017377242220391054
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:11,324 INFO epoch # 770 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.01716561190551147
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:11,324 INFO *** epoch 770, rolling-avg-loss (window=10)= 0.017369554129982135
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:11,343 INFO epoch # 771 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.01735415362782078
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:11,363 INFO epoch # 772 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.01735529108555056
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:11,383 INFO epoch # 773 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.017695527101750486
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:11,402 INFO epoch # 774 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.01734491299430374
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:11,421 INFO epoch # 775 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.01728053128317697
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:11,440 INFO epoch # 776 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.017145759687991813
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:11,459 INFO epoch # 777 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.01712834064528579
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:11,479 INFO epoch # 778 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.01787035123561509
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:11,498 INFO epoch # 779 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.01723831455456093
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:11,517 INFO epoch # 780 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.017582384891284164
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:11,517 INFO *** epoch 780, rolling-avg-loss (window=10)= 0.01739955671073403
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:11,537 INFO epoch # 781 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.017150308842246886
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:11,559 INFO epoch # 782 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.024766098154941574
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:11,578 INFO epoch # 783 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.019290277414256707
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:11,597 INFO epoch # 784 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.01704208714363631
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:11,616 INFO epoch # 785 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.01710798902786337
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:11,636 INFO epoch # 786 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.017185660908580758
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:11,655 INFO epoch # 787 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.017456279339967296
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:11,674 INFO epoch # 788 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.017172134852444287
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:11,693 INFO epoch # 789 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.017024992594087962
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:11,712 INFO epoch # 790 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.017368298453220632
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:11,712 INFO *** epoch 790, rolling-avg-loss (window=10)= 0.018156412673124577
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:11,731 INFO epoch # 791 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.017003518318233546
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:11,750 INFO epoch # 792 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.017606035646167584
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:11,769 INFO epoch # 793 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.017182802053866908
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:11,794 INFO epoch # 794 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.017205891745106783
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:11,817 INFO epoch # 795 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.017028200360073242
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:11,839 INFO epoch # 796 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.017010448456858285
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:11,859 INFO epoch # 797 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.01696659962181002
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:11,878 INFO epoch # 798 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.01734172568831127
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:11,897 INFO epoch # 799 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.017062315077055246
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:11,916 INFO epoch # 800 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.017065088635717984
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:11,916 INFO *** epoch 800, rolling-avg-loss (window=10)= 0.017147262560320085
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:11,936 INFO epoch # 801 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.017444235520088114
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:11,955 INFO epoch # 802 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.017001755579258315
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:11,974 INFO epoch # 803 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.016958683692791965
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:11,993 INFO epoch # 804 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.016867041580553632
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:12,012 INFO epoch # 805 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.01721438850654522
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:12,031 INFO epoch # 806 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.01729203092691023
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:12,050 INFO epoch # 807 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.016719207538699266
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:12,069 INFO epoch # 808 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.017527829848404508
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:12,088 INFO epoch # 809 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.017316027173365
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:12,106 INFO epoch # 810 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.01702316081355093
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:12,106 INFO *** epoch 810, rolling-avg-loss (window=10)= 0.01713643611801672
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:12,124 INFO epoch # 811 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.01708240428706631
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:12,143 INFO epoch # 812 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.016848903549544048
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:12,161 INFO epoch # 813 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.016551728585909586
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:12,180 INFO epoch # 814 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.01693596913901274
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:12,198 INFO epoch # 815 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.016986783637548797
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:12,217 INFO epoch # 816 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.016857783775776625
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:12,235 INFO epoch # 817 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.017228937897016294
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:12,253 INFO epoch # 818 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.018338274348934647
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:12,271 INFO epoch # 819 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.01676474092528224
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:12,290 INFO epoch # 820 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.01681738375191344
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:12,290 INFO *** epoch 820, rolling-avg-loss (window=10)= 0.01704129098980047
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:12,308 INFO epoch # 821 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.0168338261792087
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:12,326 INFO epoch # 822 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.026995833453838713
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:12,345 INFO epoch # 823 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0089 -loss = 0.018701130189583637
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:12,363 INFO epoch # 824 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0089-> 0.0088 -loss = 0.01691694525652565
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:12,381 INFO epoch # 825 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0088-> 0.0088 -loss = 0.016596547364315484
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:12,400 INFO epoch # 826 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0088-> 0.0088 -loss = 0.01660732644086238
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:12,418 INFO epoch # 827 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0088-> 0.0088 -loss = 0.01683775791025255
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:12,437 INFO epoch # 828 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0088-> 0.0088 -loss = 0.016855414396559354
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:12,455 INFO epoch # 829 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0088-> 0.0088 -loss = 0.0166646091020084
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:12,473 INFO epoch # 830 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0088-> 0.0088 -loss = 0.016811124398373067
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:12,473 INFO *** epoch 830, rolling-avg-loss (window=10)= 0.017982051469152792
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:12,492 INFO epoch # 831 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0088-> 0.0088 -loss = 0.016412048993515782
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:12,510 INFO epoch # 832 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0088-> 0.0088 -loss = 0.016500641366292257
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:12,528 INFO epoch # 833 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0088-> 0.0088 -loss = 0.01646320517465938
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:12,547 INFO epoch # 834 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0088-> 0.0088 -loss = 0.016500473091582535
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:12,566 INFO epoch # 835 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0088-> 0.0088 -loss = 0.016467496228870004
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:12,584 INFO epoch # 836 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0088-> 0.0088 -loss = 0.016736331621359568
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:12,603 INFO epoch # 837 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0088-> 0.0088 -loss = 0.016828735533636063
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:12,622 INFO epoch # 838 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0088-> 0.0088 -loss = 0.016457648405776126
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:12,640 INFO epoch # 839 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0088-> 0.0088 -loss = 0.01683846746891504
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:12,659 INFO epoch # 840 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0088-> 0.0088 -loss = 0.016614449545159005
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:12,659 INFO *** epoch 840, rolling-avg-loss (window=10)= 0.016581949742976575
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:12,677 INFO epoch # 841 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0088-> 0.0088 -loss = 0.016885263336007483
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:12,695 INFO epoch # 842 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0088-> 0.0087 -loss = 0.01669166109059006
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:12,713 INFO epoch # 843 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.016251348941295873
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:12,732 INFO epoch # 844 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.016940799410804175
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:12,750 INFO epoch # 845 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.01634485707472777
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:12,769 INFO epoch # 846 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.01644767032121308
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:12,787 INFO epoch # 847 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.016739294180297293
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:12,806 INFO epoch # 848 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.01633696989301825
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:12,824 INFO epoch # 849 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.01654995293210959
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:12,843 INFO epoch # 850 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.01633693164694705
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:12,843 INFO *** epoch 850, rolling-avg-loss (window=10)= 0.016552474882701063
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:12,861 INFO epoch # 851 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.0167623654124327
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:12,879 INFO epoch # 852 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.01650449171575019
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:12,898 INFO epoch # 853 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0087 -loss = 0.01655630365712568
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:12,917 INFO epoch # 854 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0087-> 0.0086 -loss = 0.016343944545951672
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:12,935 INFO epoch # 855 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0086-> 0.0086 -loss = 0.016231829504249617
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:12,954 INFO epoch # 856 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0086-> 0.0086 -loss = 0.016535268958250526
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:12,972 INFO epoch # 857 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0086-> 0.0086 -loss = 0.01641359884524718
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:12,991 INFO epoch # 858 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0086-> 0.0086 -loss = 0.01637332177051576
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:13,009 INFO epoch # 859 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0086-> 0.0086 -loss = 0.01650421499653021
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:13,028 INFO epoch # 860 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0086-> 0.0086 -loss = 0.016712833443307318
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:13,028 INFO *** epoch 860, rolling-avg-loss (window=10)= 0.016493817284936086
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:13,047 INFO epoch # 861 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0086-> 0.0086 -loss = 0.016313698433805257
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:13,068 INFO epoch # 862 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0086-> 0.0086 -loss = 0.01633605011011241
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:13,087 INFO epoch # 863 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0086-> 0.0086 -loss = 0.016688885356415994
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:13,106 INFO epoch # 864 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0086-> 0.0086 -loss = 0.01636555940785911
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:13,124 INFO epoch # 865 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0086-> 0.0086 -loss = 0.016337609820766374
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:13,143 INFO epoch # 866 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0086-> 0.0086 -loss = 0.016179434343939647
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:13,161 INFO epoch # 867 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0086-> 0.0086 -loss = 0.01641480840044096
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:13,179 INFO epoch # 868 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0086-> 0.0086 -loss = 0.016044702686485834
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:13,198 INFO epoch # 869 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0086-> 0.0086 -loss = 0.01627217864006525
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:13,216 INFO epoch # 870 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0086-> 0.0086 -loss = 0.01595623562025139
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:13,216 INFO *** epoch 870, rolling-avg-loss (window=10)= 0.016290916282014224
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:13,235 INFO epoch # 871 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0086-> 0.0086 -loss = 0.01618988168775104
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:13,253 INFO epoch # 872 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0086-> 0.0086 -loss = 0.016296254645567387
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:13,272 INFO epoch # 873 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0086-> 0.0086 -loss = 0.0164150683558546
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:13,290 INFO epoch # 874 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0086-> 0.0086 -loss = 0.016136483056470752
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:13,308 INFO epoch # 875 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0086-> 0.0086 -loss = 0.023185210295196157
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:13,326 INFO epoch # 876 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0086-> 0.0086 -loss = 0.01699293067213148
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:13,345 INFO epoch # 877 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0086-> 0.0086 -loss = 0.016210206937103067
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:13,363 INFO epoch # 878 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0086-> 0.0086 -loss = 0.01649773371173069
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:13,382 INFO epoch # 879 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0086-> 0.0086 -loss = 0.016059580171713606
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:13,400 INFO epoch # 880 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0086-> 0.0086 -loss = 0.01580795377958566
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:13,400 INFO *** epoch 880, rolling-avg-loss (window=10)= 0.016979130331310443
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:13,419 INFO epoch # 881 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0086-> 0.0086 -loss = 0.016255128539341968
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:13,437 INFO epoch # 882 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0086-> 0.0086 -loss = 0.016354387924366165
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:13,455 INFO epoch # 883 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0086-> 0.0086 -loss = 0.016511534653545823
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:13,474 INFO epoch # 884 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0086-> 0.0086 -loss = 0.016242184035945684
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:13,492 INFO epoch # 885 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0086-> 0.0086 -loss = 0.016506640320585575
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:13,510 INFO epoch # 886 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0086-> 0.0086 -loss = 0.015886676679656375
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:13,528 INFO epoch # 887 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0086-> 0.0086 -loss = 0.016069220000645146
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:13,547 INFO epoch # 888 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0086-> 0.0086 -loss = 0.01702953539643204
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:13,565 INFO epoch # 889 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0086-> 0.0086 -loss = 0.016147351409017574
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:13,583 INFO epoch # 890 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0086-> 0.0086 -loss = 0.016148575261468068
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:13,584 INFO *** epoch 890, rolling-avg-loss (window=10)= 0.016315123422100442
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:13,602 INFO epoch # 891 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0086-> 0.0085 -loss = 0.01602524478221312
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:13,621 INFO epoch # 892 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0085-> 0.0085 -loss = 0.015856152094784193
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:13,639 INFO epoch # 893 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0085-> 0.0085 -loss = 0.015992507149348967
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:13,658 INFO epoch # 894 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0085-> 0.0085 -loss = 0.01595103791623842
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:13,676 INFO epoch # 895 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0085-> 0.0085 -loss = 0.015861420753935818
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:13,695 INFO epoch # 896 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0085-> 0.0085 -loss = 0.01618073727877345
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:13,714 INFO epoch # 897 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0085-> 0.0085 -loss = 0.016652945494570304
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:13,732 INFO epoch # 898 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0085-> 0.0085 -loss = 0.015811926692549605
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:13,751 INFO epoch # 899 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0085-> 0.0085 -loss = 0.015903238469036296
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:13,769 INFO epoch # 900 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0085-> 0.0085 -loss = 0.015952416666550562
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:13,769 INFO *** epoch 900, rolling-avg-loss (window=10)= 0.016018762729800073
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:13,787 INFO epoch # 901 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0085-> 0.0085 -loss = 0.015926458589092363
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:13,806 INFO epoch # 902 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0085-> 0.0085 -loss = 0.015658867130696308
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:13,824 INFO epoch # 903 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0085-> 0.0085 -loss = 0.015976525799487717
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:13,843 INFO epoch # 904 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0085-> 0.0085 -loss = 0.015857135476835538
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:13,861 INFO epoch # 905 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0085-> 0.0085 -loss = 0.016111175762489438
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:13,880 INFO epoch # 906 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0085-> 0.0085 -loss = 0.01604599097481696
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:13,898 INFO epoch # 907 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0085-> 0.0085 -loss = 0.01606711482600076
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:13,916 INFO epoch # 908 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0085-> 0.0085 -loss = 0.016217326337937266
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:13,935 INFO epoch # 909 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0085-> 0.0085 -loss = 0.016562833843636326
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:13,954 INFO epoch # 910 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0085-> 0.0085 -loss = 0.01608324286644347
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:13,954 INFO *** epoch 910, rolling-avg-loss (window=10)= 0.016050667160743614
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:13,972 INFO epoch # 911 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0085-> 0.0085 -loss = 0.015982166354660876
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:13,991 INFO epoch # 912 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0085-> 0.0085 -loss = 0.01628382298076758
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:14,010 INFO epoch # 913 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0085-> 0.0084 -loss = 0.015736654997454025
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:14,029 INFO epoch # 914 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0084-> 0.0084 -loss = 0.01579857548495056
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:14,048 INFO epoch # 915 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0084-> 0.0084 -loss = 0.015781882757437415
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:14,068 INFO epoch # 916 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0084-> 0.0084 -loss = 0.01591869047115324
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:14,086 INFO epoch # 917 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0084-> 0.0084 -loss = 0.015728252750704996
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:14,105 INFO epoch # 918 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0084-> 0.0084 -loss = 0.015758460700453725
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:14,124 INFO epoch # 919 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0084-> 0.0084 -loss = 0.01603900756163057
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:14,142 INFO epoch # 920 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0084-> 0.0084 -loss = 0.015724963370303158
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:14,142 INFO *** epoch 920, rolling-avg-loss (window=10)= 0.015875247742951615
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:14,161 INFO epoch # 921 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0084-> 0.0084 -loss = 0.015527137387834955
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:14,180 INFO epoch # 922 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0084-> 0.0084 -loss = 0.015772441191074904
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:14,198 INFO epoch # 923 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0084-> 0.0084 -loss = 0.01593794063956011
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:14,217 INFO epoch # 924 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0084-> 0.0084 -loss = 0.015856598802201916
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:14,236 INFO epoch # 925 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0084-> 0.0084 -loss = 0.01588575849746121
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:14,255 INFO epoch # 926 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0084-> 0.0084 -loss = 0.015643553706468083
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:14,273 INFO epoch # 927 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0084-> 0.0084 -loss = 0.01561171749199275
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:14,292 INFO epoch # 928 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0084-> 0.0084 -loss = 0.015554931203951128
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:14,311 INFO epoch # 929 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0084-> 0.0084 -loss = 0.015774265797517728
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:14,329 INFO epoch # 930 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0084-> 0.0084 -loss = 0.01566086008097045
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:14,329 INFO *** epoch 930, rolling-avg-loss (window=10)= 0.015722520479903322
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:14,348 INFO epoch # 931 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0084-> 0.0084 -loss = 0.015941196856147144
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:14,366 INFO epoch # 932 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0084-> 0.0083 -loss = 0.015641165067791007
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:14,385 INFO epoch # 933 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0083-> 0.0083 -loss = 0.015490348137973342
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:14,404 INFO epoch # 934 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0083-> 0.0083 -loss = 0.015646224601368885
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:14,423 INFO epoch # 935 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0083-> 0.0083 -loss = 0.015543333574896678
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:14,442 INFO epoch # 936 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0083-> 0.0083 -loss = 0.015654703696782235
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:14,461 INFO epoch # 937 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0083-> 0.0083 -loss = 0.015530833232332952
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:14,479 INFO epoch # 938 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0083-> 0.0083 -loss = 0.015854333010793198
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:14,498 INFO epoch # 939 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0083-> 0.0083 -loss = 0.015452263876795769
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:14,517 INFO epoch # 940 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0083-> 0.0083 -loss = 0.015632047259714454
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:14,517 INFO *** epoch 940, rolling-avg-loss (window=10)= 0.015638644931459566
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:14,535 INFO epoch # 941 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0083-> 0.0083 -loss = 0.015618144876498263
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:14,554 INFO epoch # 942 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0083-> 0.0083 -loss = 0.016356587897462305
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:14,573 INFO epoch # 943 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0083-> 0.0083 -loss = 0.015670050008338876
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:14,591 INFO epoch # 944 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0083-> 0.0083 -loss = 0.0155608033091994
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:14,610 INFO epoch # 945 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0083-> 0.0083 -loss = 0.016550324362469837
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:14,629 INFO epoch # 946 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0083-> 0.0083 -loss = 0.015606880449922755
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:14,647 INFO epoch # 947 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0083-> 0.0083 -loss = 0.015408451414259616
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:14,666 INFO epoch # 948 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0083-> 0.0083 -loss = 0.01552856873604469
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:14,685 INFO epoch # 949 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0083-> 0.0083 -loss = 0.015636984586308245
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:14,704 INFO epoch # 950 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0083-> 0.0083 -loss = 0.015489398349018302
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:14,704 INFO *** epoch 950, rolling-avg-loss (window=10)= 0.015742619398952228
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:14,723 INFO epoch # 951 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0083-> 0.0083 -loss = 0.015462659721379168
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:14,742 INFO epoch # 952 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0083-> 0.0083 -loss = 0.016059066190791782
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:14,760 INFO epoch # 953 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0083-> 0.0083 -loss = 0.015613558920449577
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:14,779 INFO epoch # 954 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0083-> 0.0083 -loss = 0.015572879499814007
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:14,798 INFO epoch # 955 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0083-> 0.0083 -loss = 0.015017731268017087
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:14,816 INFO epoch # 956 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0083-> 0.0083 -loss = 0.015388717634778004
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:14,836 INFO epoch # 957 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0083-> 0.0083 -loss = 0.015622225051629357
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:14,855 INFO epoch # 958 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0083-> 0.0083 -loss = 0.015447776604560204
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:14,873 INFO epoch # 959 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0083-> 0.0083 -loss = 0.015505536255659536
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:14,892 INFO epoch # 960 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0083-> 0.0083 -loss = 0.01527062420063885
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:14,892 INFO *** epoch 960, rolling-avg-loss (window=10)= 0.015496077534771757
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:14,912 INFO epoch # 961 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0083-> 0.0083 -loss = 0.020465774432523176
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:14,930 INFO epoch # 962 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0083-> 0.0083 -loss = 0.016227489271841478
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:14,948 INFO epoch # 963 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0083-> 0.0083 -loss = 0.01549505720322486
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:14,967 INFO epoch # 964 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0083-> 0.0083 -loss = 0.015338877085014246
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:14,986 INFO epoch # 965 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0083-> 0.0083 -loss = 0.015336603028117679
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:15,004 INFO epoch # 966 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0083-> 0.0083 -loss = 0.017460627816035412
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:15,023 INFO epoch # 967 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0083-> 0.0083 -loss = 0.015599305028445087
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:15,042 INFO epoch # 968 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0083-> 0.0083 -loss = 0.01605510680383304
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:15,060 INFO epoch # 969 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0083-> 0.0083 -loss = 0.015419613555422984
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:15,079 INFO epoch # 970 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0083-> 0.0083 -loss = 0.015663656246033497
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:15,079 INFO *** epoch 970, rolling-avg-loss (window=10)= 0.016306211047049147
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:15,097 INFO epoch # 971 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0083-> 0.0083 -loss = 0.015233135476591997
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:15,116 INFO epoch # 972 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0083-> 0.0083 -loss = 0.015152033483900595
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:15,134 INFO epoch # 973 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0083-> 0.0083 -loss = 0.015117703143914696
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:15,152 INFO epoch # 974 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0083-> 0.0083 -loss = 0.015402847493533045
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:15,171 INFO epoch # 975 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0083-> 0.0083 -loss = 0.015389832435175776
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:15,189 INFO epoch # 976 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0083-> 0.0083 -loss = 0.015394018664665055
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:15,207 INFO epoch # 977 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0083-> 0.0082 -loss = 0.015118977615202311
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:15,225 INFO epoch # 978 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0082-> 0.0082 -loss = 0.015101038501597941
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:15,244 INFO epoch # 979 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0082-> 0.0082 -loss = 0.015085304512467701
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:15,262 INFO epoch # 980 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0082-> 0.0082 -loss = 0.015170218168350402
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:15,262 INFO *** epoch 980, rolling-avg-loss (window=10)= 0.015216510949539953
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:15,281 INFO epoch # 981 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0082-> 0.0082 -loss = 0.01523106373497285
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:15,299 INFO epoch # 982 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0082-> 0.0082 -loss = 0.015410701555083506
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:15,318 INFO epoch # 983 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0082-> 0.0082 -loss = 0.015240816166624427
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:15,336 INFO epoch # 984 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0082-> 0.0082 -loss = 0.015325066022342071
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:15,354 INFO epoch # 985 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0082-> 0.0082 -loss = 0.014949678079574369
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:15,372 INFO epoch # 986 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0082-> 0.0082 -loss = 0.015747475044918247
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:15,391 INFO epoch # 987 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0082-> 0.0082 -loss = 0.015333412207837682
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:15,409 INFO epoch # 988 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0082-> 0.0082 -loss = 0.015101178469194565
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:15,427 INFO epoch # 989 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0082-> 0.0082 -loss = 0.015232896104862448
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:15,446 INFO epoch # 990 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0082-> 0.0082 -loss = 0.015000328887254
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:15,446 INFO *** epoch 990, rolling-avg-loss (window=10)= 0.015257261627266417
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:15,464 INFO epoch # 991 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0082-> 0.0082 -loss = 0.01516971318051219
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:15,482 INFO epoch # 992 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0082-> 0.0082 -loss = 0.015283902161172591
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:15,501 INFO epoch # 993 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0082-> 0.0082 -loss = 0.01502310825890163
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:15,519 INFO epoch # 994 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0082-> 0.0082 -loss = 0.015009470909717493
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:15,538 INFO epoch # 995 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0082-> 0.0082 -loss = 0.015082543541211635
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:15,556 INFO epoch # 996 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0082-> 0.0081 -loss = 0.015390868349641096
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:15,574 INFO epoch # 997 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.015059290039062034
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:15,592 INFO epoch # 998 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.015037055338325445
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:15,610 INFO epoch # 999 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.014952051351428963
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:15,629 INFO epoch # 1000 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.015150811988860369
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:15,629 INFO *** epoch 1000, rolling-avg-loss (window=10)= 0.015115881511883344
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:15,647 INFO epoch # 1001 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.015007853959104978
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:15,665 INFO epoch # 1002 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.014916734748112503
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:15,684 INFO epoch # 1003 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.02323283326404635
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:15,702 INFO epoch # 1004 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.016621750939521007
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:15,720 INFO epoch # 1005 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.014874963395413943
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:15,739 INFO epoch # 1006 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.019853089273965452
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:15,757 INFO epoch # 1007 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.01596557411539834
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:15,775 INFO epoch # 1008 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.015000354935182258
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:15,794 INFO epoch # 1009 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.016042244707932696
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:15,812 INFO epoch # 1010 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.014945647351851221
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:15,812 INFO *** epoch 1010, rolling-avg-loss (window=10)= 0.016646104669052874
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:15,830 INFO epoch # 1011 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.014940025728719775
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:15,849 INFO epoch # 1012 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.015100859156518709
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:15,867 INFO epoch # 1013 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.014934815480955876
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:15,885 INFO epoch # 1014 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.014839137867966201
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:15,904 INFO epoch # 1015 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.014874244581733365
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:15,922 INFO epoch # 1016 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.016057236018241383
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:15,941 INFO epoch # 1017 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.01488159915606957
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:15,960 INFO epoch # 1018 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.014840232615824789
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:15,978 INFO epoch # 1019 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.015249099109496456
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:15,996 INFO epoch # 1020 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.014967472387070302
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:15,997 INFO *** epoch 1020, rolling-avg-loss (window=10)= 0.015068472210259642
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:16,015 INFO epoch # 1021 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.01478756996220909
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:16,033 INFO epoch # 1022 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.014715132921992335
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:16,052 INFO epoch # 1023 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.01490489483694546
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:16,070 INFO epoch # 1024 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.014690527343191206
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:16,089 INFO epoch # 1025 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.014787067615543492
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:16,107 INFO epoch # 1026 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.015064330800669268
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:16,126 INFO epoch # 1027 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.014844951721897814
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:16,144 INFO epoch # 1028 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.01470870075354469
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:16,162 INFO epoch # 1029 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.014704693385283463
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:16,181 INFO epoch # 1030 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.015002579013525974
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:16,181 INFO *** epoch 1030, rolling-avg-loss (window=10)= 0.014821044835480279
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:16,199 INFO epoch # 1031 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.014650277262262534
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:16,217 INFO epoch # 1032 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.014777773569221608
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:16,235 INFO epoch # 1033 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.014803648977249395
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:16,254 INFO epoch # 1034 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.015386795035738032
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:16,272 INFO epoch # 1035 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.01503916261572158
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:16,291 INFO epoch # 1036 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.014889810496242717
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:16,309 INFO epoch # 1037 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.014782536927668843
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:16,327 INFO epoch # 1038 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.015485325842746533
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:16,345 INFO epoch # 1039 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.014509846929286141
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:16,364 INFO epoch # 1040 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.014665513488580473
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:16,364 INFO *** epoch 1040, rolling-avg-loss (window=10)= 0.014899069114471785
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:16,382 INFO epoch # 1041 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.014909442470525391
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:16,400 INFO epoch # 1042 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.015082362806424499
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:16,418 INFO epoch # 1043 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.01451976827956969
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:16,436 INFO epoch # 1044 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.014533073335769586
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:16,455 INFO epoch # 1045 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.014666654766188003
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:16,473 INFO epoch # 1046 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.014472206821665168
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:16,491 INFO epoch # 1047 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.014533642162859906
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:16,510 INFO epoch # 1048 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.014726857683854178
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:16,528 INFO epoch # 1049 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.014704222194268368
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:16,547 INFO epoch # 1050 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.014857420203043148
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:16,547 INFO *** epoch 1050, rolling-avg-loss (window=10)= 0.014700565072416794
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:16,565 INFO epoch # 1051 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.014573594478861196
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:16,583 INFO epoch # 1052 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.014525790655170567
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:16,601 INFO epoch # 1053 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.014535367874486838
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:16,620 INFO epoch # 1054 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.014579188471543603
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:16,638 INFO epoch # 1055 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.01455617885949323
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:16,656 INFO epoch # 1056 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.0081 -loss = 0.01466967916348949
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:16,675 INFO epoch # 1057 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0081-> 0.008 -loss = 0.014648863136244472
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:16,693 INFO epoch # 1058 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.008-> 0.008 -loss = 0.014454727206612006
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:16,711 INFO epoch # 1059 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.008-> 0.008 -loss = 0.01453992749156896
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:16,730 INFO epoch # 1060 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.008-> 0.008 -loss = 0.014610613230615854
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:16,730 INFO *** epoch 1060, rolling-avg-loss (window=10)= 0.014569393056808622
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:16,748 INFO epoch # 1061 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.008-> 0.008 -loss = 0.0145105370102101
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:16,767 INFO epoch # 1062 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.008-> 0.008 -loss = 0.014472432609181851
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:16,785 INFO epoch # 1063 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.008-> 0.008 -loss = 0.014464300045801792
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:16,803 INFO epoch # 1064 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.008-> 0.008 -loss = 0.015429863466124516
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:16,821 INFO epoch # 1065 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.008-> 0.008 -loss = 0.014913850296579767
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:16,840 INFO epoch # 1066 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.008-> 0.008 -loss = 0.0142466119468736
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:16,858 INFO epoch # 1067 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.008-> 0.008 -loss = 0.014773262832022738
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:16,877 INFO epoch # 1068 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.008-> 0.008 -loss = 0.014545131783961551
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:16,895 INFO epoch # 1069 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.008-> 0.008 -loss = 0.014532832632539794
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:16,914 INFO epoch # 1070 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.008-> 0.008 -loss = 0.014362089372298215
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:16,914 INFO *** epoch 1070, rolling-avg-loss (window=10)= 0.014625091199559393
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:16,932 INFO epoch # 1071 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.008-> 0.008 -loss = 0.014490263842162676
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:16,951 INFO epoch # 1072 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.008-> 0.008 -loss = 0.01450511420989642
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:16,969 INFO epoch # 1073 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.008-> 0.008 -loss = 0.014349779612530256
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:16,987 INFO epoch # 1074 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.008-> 0.008 -loss = 0.014323485833301675
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:17,006 INFO epoch # 1075 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.008-> 0.008 -loss = 0.01447092952003004
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:17,024 INFO epoch # 1076 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.008-> 0.008 -loss = 0.014370208358741365
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:17,042 INFO epoch # 1077 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.008-> 0.0079 -loss = 0.01459993469325127
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:17,061 INFO epoch # 1078 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0079-> 0.0079 -loss = 0.014569284292520024
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:17,079 INFO epoch # 1079 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0079-> 0.0079 -loss = 0.014551343287166674
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:17,097 INFO epoch # 1080 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0079-> 0.0079 -loss = 0.01449525589850964
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:17,098 INFO *** epoch 1080, rolling-avg-loss (window=10)= 0.014472559954811004
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:17,116 INFO epoch # 1081 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0079-> 0.0079 -loss = 0.014295583649072796
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:17,135 INFO epoch # 1082 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0079-> 0.0079 -loss = 0.0142016459358274
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:17,153 INFO epoch # 1083 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0079-> 0.0079 -loss = 0.014230028937163297
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:17,172 INFO epoch # 1084 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0079-> 0.0079 -loss = 0.01456516425969312
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:17,190 INFO epoch # 1085 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0079-> 0.0079 -loss = 0.01441643557336647
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:17,208 INFO epoch # 1086 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0079-> 0.0079 -loss = 0.014330363781482447
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:17,226 INFO epoch # 1087 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0079-> 0.0079 -loss = 0.014443546737311408
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:17,244 INFO epoch # 1088 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0079-> 0.0079 -loss = 0.01884842722938629
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:17,263 INFO epoch # 1089 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0079-> 0.0079 -loss = 0.014436388344620354
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:17,281 INFO epoch # 1090 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0079-> 0.0079 -loss = 0.01442249164392706
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:17,281 INFO *** epoch 1090, rolling-avg-loss (window=10)= 0.014819007609185064
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:17,300 INFO epoch # 1091 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0079-> 0.0079 -loss = 0.014199971337802708
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:17,318 INFO epoch # 1092 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0079-> 0.0079 -loss = 0.014165768698148895
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:17,336 INFO epoch # 1093 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0079-> 0.0079 -loss = 0.014264273435401265
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:17,355 INFO epoch # 1094 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0079-> 0.0079 -loss = 0.01427257468458265
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:17,374 INFO epoch # 1095 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0079-> 0.0079 -loss = 0.014196150972566102
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:17,392 INFO epoch # 1096 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0079-> 0.0079 -loss = 0.014215953735401854
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:17,410 INFO epoch # 1097 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0079-> 0.0079 -loss = 0.014406292299099732
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:17,429 INFO epoch # 1098 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0079-> 0.0079 -loss = 0.014245674625271931
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:17,447 INFO epoch # 1099 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0079-> 0.0079 -loss = 0.014255396687076427
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:17,465 INFO epoch # 1100 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0079-> 0.0079 -loss = 0.014111647426034324
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:17,465 INFO *** epoch 1100, rolling-avg-loss (window=10)= 0.014233370390138588
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:17,483 INFO epoch # 1101 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0079-> 0.0079 -loss = 0.014288448059232906
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:17,502 INFO epoch # 1102 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0079-> 0.0079 -loss = 0.014078472209803294
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:17,520 INFO epoch # 1103 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0079-> 0.0079 -loss = 0.014285647390352096
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:17,538 INFO epoch # 1104 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0079-> 0.0079 -loss = 0.014013264073582832
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:17,557 INFO epoch # 1105 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0079-> 0.0079 -loss = 0.014462416278547607
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:17,575 INFO epoch # 1106 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0079-> 0.0079 -loss = 0.013967639955808409
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:17,593 INFO epoch # 1107 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0079-> 0.0079 -loss = 0.014673814708658028
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:17,612 INFO epoch # 1108 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0079-> 0.0079 -loss = 0.014267698948970065
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:17,630 INFO epoch # 1109 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0079-> 0.0079 -loss = 0.014587302823201753
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:17,648 INFO epoch # 1110 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0079-> 0.0079 -loss = 0.014079020562348887
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:17,648 INFO *** epoch 1110, rolling-avg-loss (window=10)= 0.014270372501050588
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:17,666 INFO epoch # 1111 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0079-> 0.0079 -loss = 0.014177050528815016
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:17,685 INFO epoch # 1112 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0079-> 0.0079 -loss = 0.014404205241589807
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:17,703 INFO epoch # 1113 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0079-> 0.0079 -loss = 0.014101546294114087
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:17,721 INFO epoch # 1114 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0079-> 0.0079 -loss = 0.018479257385479286
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:17,740 INFO epoch # 1115 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0079-> 0.0079 -loss = 0.015264062392816413
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:17,758 INFO epoch # 1116 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0079-> 0.0079 -loss = 0.013991285057272762
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:17,777 INFO epoch # 1117 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0079-> 0.0079 -loss = 0.013918285265390296
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:17,795 INFO epoch # 1118 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0079-> 0.0079 -loss = 0.014121859545412008
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:17,813 INFO epoch # 1119 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0079-> 0.0079 -loss = 0.014309967467852402
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:17,832 INFO epoch # 1120 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0079-> 0.0079 -loss = 0.014560266128682997
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:17,832 INFO *** epoch 1120, rolling-avg-loss (window=10)= 0.014732778530742507
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:17,850 INFO epoch # 1121 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0079-> 0.0079 -loss = 0.01395308075734647
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:17,868 INFO epoch # 1122 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0079-> 0.0079 -loss = 0.014043679409951437
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:17,886 INFO epoch # 1123 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0079-> 0.0079 -loss = 0.014028990619408432
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:17,905 INFO epoch # 1124 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0079-> 0.0079 -loss = 0.014297220601292793
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:17,923 INFO epoch # 1125 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0079-> 0.0079 -loss = 0.014562097960151732
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:17,942 INFO epoch # 1126 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0079-> 0.0079 -loss = 0.014253371045924723
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:17,960 INFO epoch # 1127 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0079-> 0.0079 -loss = 0.014022431583725847
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:17,979 INFO epoch # 1128 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0079-> 0.0079 -loss = 0.014904293639119714
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:17,997 INFO epoch # 1129 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0079-> 0.0079 -loss = 0.014232351910322905
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:18,015 INFO epoch # 1130 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0079-> 0.0079 -loss = 0.013931444234913215
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:18,016 INFO *** epoch 1130, rolling-avg-loss (window=10)= 0.014222896176215727
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:18,034 INFO epoch # 1131 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0079-> 0.0079 -loss = 0.014119772837148048
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:18,052 INFO epoch # 1132 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0079-> 0.0079 -loss = 0.013983999800984748
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:18,071 INFO epoch # 1133 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0079-> 0.0079 -loss = 0.013957671813841444
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:18,089 INFO epoch # 1134 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0079-> 0.0079 -loss = 0.014451034490775783
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:18,107 INFO epoch # 1135 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0079-> 0.0079 -loss = 0.014160098085994832
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:18,126 INFO epoch # 1136 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0079-> 0.0079 -loss = 0.013993768370710313
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:18,144 INFO epoch # 1137 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0079-> 0.0079 -loss = 0.014155350909277331
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:18,163 INFO epoch # 1138 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0079-> 0.0079 -loss = 0.014455019525485113
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:18,181 INFO epoch # 1139 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0079-> 0.0078 -loss = 0.014173220486554783
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:18,199 INFO epoch # 1140 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0078-> 0.0078 -loss = 0.013933847294538282
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:18,200 INFO *** epoch 1140, rolling-avg-loss (window=10)= 0.014138378361531067
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:18,218 INFO epoch # 1141 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0078-> 0.0078 -loss = 0.015139653551159427
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:18,236 INFO epoch # 1142 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0078-> 0.0078 -loss = 0.014012578561960254
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:18,254 INFO epoch # 1143 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0078-> 0.0078 -loss = 0.01391221539961407
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:18,272 INFO epoch # 1144 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0078-> 0.0078 -loss = 0.01396027347072959
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:18,291 INFO epoch # 1145 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0078-> 0.0078 -loss = 0.013910151792515535
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:18,309 INFO epoch # 1146 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0078-> 0.0078 -loss = 0.01382403376919683
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:18,327 INFO epoch # 1147 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0078-> 0.0078 -loss = 0.014848044782411307
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:18,346 INFO epoch # 1148 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0078-> 0.0078 -loss = 0.013988485887239221
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:18,364 INFO epoch # 1149 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0078-> 0.0078 -loss = 0.013947384599305224
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:18,383 INFO epoch # 1150 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0078-> 0.0078 -loss = 0.014112871293036733
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:18,383 INFO *** epoch 1150, rolling-avg-loss (window=10)= 0.01416556931071682
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:18,401 INFO epoch # 1151 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0078-> 0.0078 -loss = 0.01400282459508162
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:18,420 INFO epoch # 1152 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0078-> 0.0078 -loss = 0.014109480151091702
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:18,438 INFO epoch # 1153 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0078-> 0.0078 -loss = 0.013850364521204028
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:18,456 INFO epoch # 1154 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0078-> 0.0078 -loss = 0.014126408379524946
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:18,474 INFO epoch # 1155 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0078-> 0.0078 -loss = 0.013801130960928276
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:18,493 INFO epoch # 1156 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0078-> 0.0078 -loss = 0.013931840439909138
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:18,511 INFO epoch # 1157 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0078-> 0.0078 -loss = 0.013824350862705614
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:18,529 INFO epoch # 1158 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0078-> 0.0078 -loss = 0.01398178195086075
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:18,547 INFO epoch # 1159 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0078-> 0.0078 -loss = 0.013837300495652016
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:18,566 INFO epoch # 1160 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0078-> 0.0078 -loss = 0.01400185348757077
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:18,566 INFO *** epoch 1160, rolling-avg-loss (window=10)= 0.013946733584452886
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:18,584 INFO epoch # 1161 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0078-> 0.0078 -loss = 0.0138282205152791
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:18,603 INFO epoch # 1162 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0078-> 0.0078 -loss = 0.013914305585785769
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:18,621 INFO epoch # 1163 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0078-> 0.0078 -loss = 0.013773827689874452
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:18,640 INFO epoch # 1164 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0078-> 0.0078 -loss = 0.013938885895186104
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:18,658 INFO epoch # 1165 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0078-> 0.0078 -loss = 0.0141237361531239
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:18,676 INFO epoch # 1166 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0078-> 0.0078 -loss = 0.01386515063495608
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:18,694 INFO epoch # 1167 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0078-> 0.0078 -loss = 0.013705018493055832
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:18,713 INFO epoch # 1168 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0078-> 0.0078 -loss = 0.014371456643857528
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:18,731 INFO epoch # 1169 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0078-> 0.0078 -loss = 0.01375673022994306
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:18,750 INFO epoch # 1170 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0078-> 0.0078 -loss = 0.013881654369470198
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:18,750 INFO *** epoch 1170, rolling-avg-loss (window=10)= 0.013915898621053201
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:18,768 INFO epoch # 1171 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0078-> 0.0078 -loss = 0.01364526981342351
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:18,786 INFO epoch # 1172 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0078-> 0.0078 -loss = 0.013944357247964945
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:18,805 INFO epoch # 1173 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0078-> 0.0078 -loss = 0.013985724814119749
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:18,823 INFO epoch # 1174 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0078-> 0.0078 -loss = 0.01368605942116119
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:18,842 INFO epoch # 1175 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0078-> 0.0078 -loss = 0.013896868622396141
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:18,860 INFO epoch # 1176 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0078-> 0.0078 -loss = 0.013467943485011347
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:18,878 INFO epoch # 1177 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0078-> 0.0078 -loss = 0.013646211453306023
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:18,897 INFO epoch # 1178 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0078-> 0.0078 -loss = 0.01354603400977794
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:18,915 INFO epoch # 1179 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0078-> 0.0078 -loss = 0.013752140701399185
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:18,933 INFO epoch # 1180 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0078-> 0.0078 -loss = 0.0138162893417757
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:18,933 INFO *** epoch 1180, rolling-avg-loss (window=10)= 0.013738689891033573
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:18,952 INFO epoch # 1181 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0078-> 0.0078 -loss = 0.01373754074666067
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:18,970 INFO epoch # 1182 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0078-> 0.0078 -loss = 0.013669410902366508
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:18,989 INFO epoch # 1183 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0078-> 0.0078 -loss = 0.013613247516332194
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:19,008 INFO epoch # 1184 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0078-> 0.0078 -loss = 0.01374841587676201
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:19,026 INFO epoch # 1185 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0078-> 0.0078 -loss = 0.013796478313452099
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:19,045 INFO epoch # 1186 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0078-> 0.0078 -loss = 0.013710826868191361
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:19,064 INFO epoch # 1187 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0078-> 0.0077 -loss = 0.013694083514565136
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:19,082 INFO epoch # 1188 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0077-> 0.0077 -loss = 0.013593028095783666
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:19,100 INFO epoch # 1189 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0077-> 0.0077 -loss = 0.014694183744722977
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:19,118 INFO epoch # 1190 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0077-> 0.0077 -loss = 0.01371044090774376
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:19,119 INFO *** epoch 1190, rolling-avg-loss (window=10)= 0.013796765648658038
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:19,137 INFO epoch # 1191 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0077-> 0.0077 -loss = 0.01362113950017374
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:19,155 INFO epoch # 1192 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0077-> 0.0077 -loss = 0.01368638542771805
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:19,173 INFO epoch # 1193 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0077-> 0.0077 -loss = 0.013545354566304013
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:19,192 INFO epoch # 1194 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0077-> 0.0077 -loss = 0.013671775901457295
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:19,210 INFO epoch # 1195 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0077-> 0.0077 -loss = 0.013686596263141837
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:19,229 INFO epoch # 1196 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0077-> 0.0077 -loss = 0.013740304690145422
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:19,247 INFO epoch # 1197 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0077-> 0.0077 -loss = 0.013556715326558333
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:19,266 INFO epoch # 1198 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0077-> 0.0076 -loss = 0.01807963011378888
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:19,284 INFO epoch # 1199 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0076-> 0.0076 -loss = 0.014733668853295967
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:19,302 INFO epoch # 1200 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0076-> 0.0076 -loss = 0.013684072968317196
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:19,302 INFO *** epoch 1200, rolling-avg-loss (window=10)= 0.014200564361090073
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:19,320 INFO epoch # 1201 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0076-> 0.0076 -loss = 0.013522929279133677
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:19,339 INFO epoch # 1202 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0076-> 0.0076 -loss = 0.013455366766720545
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:19,357 INFO epoch # 1203 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0076-> 0.0076 -loss = 0.014282611213275231
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:19,376 INFO epoch # 1204 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0076-> 0.0076 -loss = 0.013693174056243151
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:19,394 INFO epoch # 1205 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0076-> 0.0076 -loss = 0.01338649180252105
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:19,412 INFO epoch # 1206 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0076-> 0.0076 -loss = 0.013422311836620793
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:19,431 INFO epoch # 1207 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0076-> 0.0076 -loss = 0.01371928022854263
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:19,449 INFO epoch # 1208 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0076-> 0.0076 -loss = 0.013575884368037805
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:19,467 INFO epoch # 1209 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0076-> 0.0076 -loss = 0.013307346489455085
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:19,485 INFO epoch # 1210 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0076-> 0.0076 -loss = 0.01438289217185229
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:19,486 INFO *** epoch 1210, rolling-avg-loss (window=10)= 0.013674828821240225
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:19,504 INFO epoch # 1211 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0076-> 0.0076 -loss = 0.013639983386383392
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:19,522 INFO epoch # 1212 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0076-> 0.0076 -loss = 0.0135837649795576
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:19,540 INFO epoch # 1213 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0076-> 0.0076 -loss = 0.013575136064901017
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:19,559 INFO epoch # 1214 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0076-> 0.0076 -loss = 0.013573643751442432
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:19,577 INFO epoch # 1215 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0076-> 0.0076 -loss = 0.013476780237397179
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:19,596 INFO epoch # 1216 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0076-> 0.0076 -loss = 0.013470988560584374
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:19,614 INFO epoch # 1217 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0076-> 0.0076 -loss = 0.013319587938894983
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:19,633 INFO epoch # 1218 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0076-> 0.0076 -loss = 0.013413980745099252
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:19,651 INFO epoch # 1219 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0076-> 0.0076 -loss = 0.01335600706806872
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:19,670 INFO epoch # 1220 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0076-> 0.0075 -loss = 0.013468544479110278
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:19,670 INFO *** epoch 1220, rolling-avg-loss (window=10)= 0.013487841721143923
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:19,688 INFO epoch # 1221 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0075-> 0.0075 -loss = 0.013277622427267488
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:19,706 INFO epoch # 1222 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0075-> 0.0075 -loss = 0.013393194662057795
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:19,724 INFO epoch # 1223 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0075-> 0.0075 -loss = 0.013377154333284125
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:19,742 INFO epoch # 1224 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0075-> 0.0075 -loss = 0.01369958547729766
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:19,761 INFO epoch # 1225 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0075-> 0.0075 -loss = 0.013531955730286427
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:19,780 INFO epoch # 1226 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0075-> 0.0075 -loss = 0.013398796414548997
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:19,798 INFO epoch # 1227 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0075-> 0.0075 -loss = 0.013296023680595681
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:19,816 INFO epoch # 1228 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0075-> 0.0075 -loss = 0.013512675417587161
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:19,835 INFO epoch # 1229 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0075-> 0.0075 -loss = 0.013080303127935622
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:19,853 INFO epoch # 1230 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0075-> 0.0075 -loss = 0.014081381435971707
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:19,853 INFO *** epoch 1230, rolling-avg-loss (window=10)= 0.013464869270683267
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:19,872 INFO epoch # 1231 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0075-> 0.0075 -loss = 0.013487196440109983
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:19,890 INFO epoch # 1232 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0075-> 0.0075 -loss = 0.01392836731247371
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:19,908 INFO epoch # 1233 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0075-> 0.0075 -loss = 0.01387964502646355
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:19,926 INFO epoch # 1234 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0075-> 0.0075 -loss = 0.013312064271303825
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:19,944 INFO epoch # 1235 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0075-> 0.0075 -loss = 0.013485743795172311
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:19,963 INFO epoch # 1236 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0075-> 0.0075 -loss = 0.0133173712019925
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:19,981 INFO epoch # 1237 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0075-> 0.0075 -loss = 0.013848552909621503
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:20,000 INFO epoch # 1238 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0075-> 0.0075 -loss = 0.013328147713764338
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:20,019 INFO epoch # 1239 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0075-> 0.0075 -loss = 0.013273847795062466
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:20,037 INFO epoch # 1240 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0075-> 0.0075 -loss = 0.013519722742785234
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:20,037 INFO *** epoch 1240, rolling-avg-loss (window=10)= 0.013538065920874942
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:20,056 INFO epoch # 1241 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0075-> 0.0075 -loss = 0.013449069003399927
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:20,074 INFO epoch # 1242 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0075-> 0.0075 -loss = 0.013598922683740966
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:20,092 INFO epoch # 1243 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0075-> 0.0075 -loss = 0.013399859511991963
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:20,110 INFO epoch # 1244 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0075-> 0.0075 -loss = 0.01337864005472511
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:20,129 INFO epoch # 1245 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0075-> 0.0075 -loss = 0.01337422620417783
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:20,147 INFO epoch # 1246 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0075-> 0.0075 -loss = 0.013399803108768538
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:20,165 INFO epoch # 1247 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0075-> 0.0075 -loss = 0.01316307381785009
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:20,184 INFO epoch # 1248 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0075-> 0.0075 -loss = 0.013253985162009485
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:20,202 INFO epoch # 1249 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0075-> 0.0075 -loss = 0.01332357856881572
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:20,220 INFO epoch # 1250 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0075-> 0.0075 -loss = 0.013404523968347348
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:20,220 INFO *** epoch 1250, rolling-avg-loss (window=10)= 0.013374568208382698
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:20,239 INFO epoch # 1251 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0075-> 0.0074 -loss = 0.013221658511611167
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:20,257 INFO epoch # 1252 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0074-> 0.0074 -loss = 0.017935309442691505
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:20,276 INFO epoch # 1253 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0074-> 0.0074 -loss = 0.013603488689113874
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:20,294 INFO epoch # 1254 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0074-> 0.0074 -loss = 0.013160179412807338
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:20,312 INFO epoch # 1255 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0074-> 0.0074 -loss = 0.013155561420717277
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:20,330 INFO epoch # 1256 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0074-> 0.0074 -loss = 0.013303529922268353
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:20,348 INFO epoch # 1257 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0074-> 0.0074 -loss = 0.01309245168522466
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:20,367 INFO epoch # 1258 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0074-> 0.0074 -loss = 0.013344430102733895
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:20,385 INFO epoch # 1259 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0074-> 0.0074 -loss = 0.013201282141380943
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:20,404 INFO epoch # 1260 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0074-> 0.0074 -loss = 0.013133346692484338
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:20,404 INFO *** epoch 1260, rolling-avg-loss (window=10)= 0.013715123802103334
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:20,422 INFO epoch # 1261 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0074-> 0.0074 -loss = 0.013260887259093579
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:20,440 INFO epoch # 1262 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0074-> 0.0073 -loss = 0.013160949456505477
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:20,459 INFO epoch # 1263 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0073-> 0.0073 -loss = 0.012974309902347159
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:20,477 INFO epoch # 1264 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0073-> 0.0073 -loss = 0.013024436586420052
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:20,495 INFO epoch # 1265 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0073-> 0.0073 -loss = 0.013675546899321489
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:20,514 INFO epoch # 1266 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0073-> 0.0073 -loss = 0.013016857228649314
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:20,532 INFO epoch # 1267 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0073-> 0.0073 -loss = 0.013203296119172592
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:20,550 INFO epoch # 1268 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0073-> 0.0073 -loss = 0.013160636539396364
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:20,569 INFO epoch # 1269 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0073-> 0.0073 -loss = 0.01319986127782613
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:20,588 INFO epoch # 1270 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0073-> 0.0073 -loss = 0.013306686538271606
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:20,588 INFO *** epoch 1270, rolling-avg-loss (window=10)= 0.013198346780700376
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:20,606 INFO epoch # 1271 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0073-> 0.0073 -loss = 0.013045833809883334
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:20,625 INFO epoch # 1272 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0073-> 0.0073 -loss = 0.013452230341499671
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:20,644 INFO epoch # 1273 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0073-> 0.0073 -loss = 0.013153495383448899
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:20,662 INFO epoch # 1274 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0073-> 0.0072 -loss = 0.013414363114861771
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:20,681 INFO epoch # 1275 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.013596613658592105
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:20,699 INFO epoch # 1276 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.013365359816816635
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:20,717 INFO epoch # 1277 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.013298483623657376
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:20,736 INFO epoch # 1278 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.012980195231648395
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:20,754 INFO epoch # 1279 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.013347682048333809
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:20,772 INFO epoch # 1280 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.013055964634986594
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:20,772 INFO *** epoch 1280, rolling-avg-loss (window=10)= 0.013271022166372859
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:20,790 INFO epoch # 1281 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.012909918710647617
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:20,809 INFO epoch # 1282 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.012906388925330248
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:20,827 INFO epoch # 1283 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.013382262724917382
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:20,846 INFO epoch # 1284 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.012959347252035514
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:20,864 INFO epoch # 1285 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.01302815365488641
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:20,883 INFO epoch # 1286 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.013260257386718877
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:20,901 INFO epoch # 1287 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.013313201598066371
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:20,920 INFO epoch # 1288 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.013015515069128014
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:20,938 INFO epoch # 1289 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.013003541665966623
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:20,956 INFO epoch # 1290 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.013045265004620887
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:20,956 INFO *** epoch 1290, rolling-avg-loss (window=10)= 0.013082385199231794
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:20,974 INFO epoch # 1291 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.01319927455188008
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:20,993 INFO epoch # 1292 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.013154199448763393
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:21,012 INFO epoch # 1293 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.012811866887204815
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:21,031 INFO epoch # 1294 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.013105153804644942
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:21,049 INFO epoch # 1295 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.013009417358261999
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:21,068 INFO epoch # 1296 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.012892252882011235
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:21,086 INFO epoch # 1297 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.013110289241012651
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:21,104 INFO epoch # 1298 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.013152808889572043
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:21,122 INFO epoch # 1299 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.01301254391000839
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:21,141 INFO epoch # 1300 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.01310754899168387
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:21,141 INFO *** epoch 1300, rolling-avg-loss (window=10)= 0.013055535596504343
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:21,159 INFO epoch # 1301 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.012843226119002793
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:21,177 INFO epoch # 1302 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.013237223043688573
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:21,195 INFO epoch # 1303 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.013097347044094931
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:21,214 INFO epoch # 1304 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.013857582824130077
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:21,232 INFO epoch # 1305 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.012979927123524249
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:21,250 INFO epoch # 1306 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.012800024487660266
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:21,269 INFO epoch # 1307 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.01268029042694252
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:21,287 INFO epoch # 1308 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.013000835999264382
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:21,306 INFO epoch # 1309 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.012956609651155304
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:21,324 INFO epoch # 1310 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.012708456393738743
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:21,324 INFO *** epoch 1310, rolling-avg-loss (window=10)= 0.013016152311320184
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:21,342 INFO epoch # 1311 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.012809972729883157
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:21,360 INFO epoch # 1312 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.012962017717654817
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:21,378 INFO epoch # 1313 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.012905276598758064
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:21,397 INFO epoch # 1314 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.012800526717910543
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:21,415 INFO epoch # 1315 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.012933151621837169
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:21,433 INFO epoch # 1316 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.012962576700374484
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:21,452 INFO epoch # 1317 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0072 -loss = 0.013033036062552128
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:21,470 INFO epoch # 1318 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0072-> 0.0071 -loss = 0.012696884441538714
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:21,488 INFO epoch # 1319 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0071-> 0.0071 -loss = 0.0128366449062014
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:21,507 INFO epoch # 1320 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0071-> 0.0071 -loss = 0.0127927196881501
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:21,507 INFO *** epoch 1320, rolling-avg-loss (window=10)= 0.012873280718486058
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:21,525 INFO epoch # 1321 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0071-> 0.0071 -loss = 0.012781926270690747
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:21,543 INFO epoch # 1322 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0071-> 0.0071 -loss = 0.0126172966483864
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:21,562 INFO epoch # 1323 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0071-> 0.0071 -loss = 0.013000999722862616
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:21,580 INFO epoch # 1324 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0071-> 0.0071 -loss = 0.012527856742963195
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:21,598 INFO epoch # 1325 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0071-> 0.0071 -loss = 0.012665515241678804
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:21,617 INFO epoch # 1326 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0071-> 0.0071 -loss = 0.012815424997825176
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:21,635 INFO epoch # 1327 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0071-> 0.0071 -loss = 0.012812576860596891
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:21,654 INFO epoch # 1328 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0071-> 0.0071 -loss = 0.012819978008337785
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:21,672 INFO epoch # 1329 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0071-> 0.0071 -loss = 0.012881293274404015
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:21,691 INFO epoch # 1330 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0071-> 0.0071 -loss = 0.012650925309571903
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:21,691 INFO *** epoch 1330, rolling-avg-loss (window=10)= 0.012757379307731753
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:21,709 INFO epoch # 1331 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0071-> 0.0071 -loss = 0.012714579759631306
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:21,728 INFO epoch # 1332 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0071-> 0.0071 -loss = 0.012915103412524331
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:21,746 INFO epoch # 1333 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0071-> 0.0071 -loss = 0.013011088565690443
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:21,764 INFO epoch # 1334 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0071-> 0.0071 -loss = 0.012946040100359824
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:21,783 INFO epoch # 1335 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0071-> 0.007 -loss = 0.012886340897239279
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:21,801 INFO epoch # 1336 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.007-> 0.007 -loss = 0.012768909888109192
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:21,819 INFO epoch # 1337 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.007-> 0.007 -loss = 0.012797209405107424
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:21,838 INFO epoch # 1338 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.007-> 0.007 -loss = 0.012655654296395369
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:21,856 INFO epoch # 1339 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.007-> 0.007 -loss = 0.0128673104554764
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:21,875 INFO epoch # 1340 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.007-> 0.007 -loss = 0.012869807316747028
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:21,875 INFO *** epoch 1340, rolling-avg-loss (window=10)= 0.01284320440972806
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:21,893 INFO epoch # 1341 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.007-> 0.007 -loss = 0.01270213327370584
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:21,912 INFO epoch # 1342 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.007-> 0.007 -loss = 0.012556051427964121
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:21,930 INFO epoch # 1343 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.007-> 0.007 -loss = 0.012563783675432205
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:21,949 INFO epoch # 1344 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.007-> 0.007 -loss = 0.012937572450027801
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:21,967 INFO epoch # 1345 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.007-> 0.007 -loss = 0.012856327499321196
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:21,986 INFO epoch # 1346 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.007-> 0.007 -loss = 0.012803443962184247
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:22,004 INFO epoch # 1347 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.007-> 0.007 -loss = 0.012552953936392441
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:22,022 INFO epoch # 1348 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.007-> 0.007 -loss = 0.01256948892842047
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:22,041 INFO epoch # 1349 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.007-> 0.007 -loss = 0.01254881748900516
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:22,059 INFO epoch # 1350 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.007-> 0.007 -loss = 0.012815069887437858
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:22,059 INFO *** epoch 1350, rolling-avg-loss (window=10)= 0.012690564252989135
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:22,078 INFO epoch # 1351 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.007-> 0.007 -loss = 0.012705426459433511
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:22,096 INFO epoch # 1352 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.007-> 0.007 -loss = 0.012659370797337033
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:22,115 INFO epoch # 1353 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.007-> 0.007 -loss = 0.012599836707522627
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:22,133 INFO epoch # 1354 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.007-> 0.007 -loss = 0.012823667399061378
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:22,152 INFO epoch # 1355 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.007-> 0.007 -loss = 0.012846137913584244
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:22,170 INFO epoch # 1356 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.007-> 0.007 -loss = 0.01285002332588192
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:22,188 INFO epoch # 1357 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.007-> 0.0069 -loss = 0.012805894177290611
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:22,206 INFO epoch # 1358 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0069-> 0.0069 -loss = 0.012720242491923273
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:22,224 INFO epoch # 1359 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0069-> 0.0069 -loss = 0.012732995848637074
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:22,243 INFO epoch # 1360 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0069-> 0.0069 -loss = 0.012741152175294701
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:22,243 INFO *** epoch 1360, rolling-avg-loss (window=10)= 0.012748474729596638
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:22,261 INFO epoch # 1361 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0069-> 0.0069 -loss = 0.019883226494130213
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:22,280 INFO epoch # 1362 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0069-> 0.0069 -loss = 0.01344047858583508
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:22,298 INFO epoch # 1363 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0069-> 0.0069 -loss = 0.012626483767235186
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:22,316 INFO epoch # 1364 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0069-> 0.0069 -loss = 0.012686484784353524
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:22,335 INFO epoch # 1365 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0069-> 0.0069 -loss = 0.013306928507518023
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:22,353 INFO epoch # 1366 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0069-> 0.0069 -loss = 0.012306158474530093
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:22,371 INFO epoch # 1367 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0069-> 0.0069 -loss = 0.012382569362671347
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:22,390 INFO epoch # 1368 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0069-> 0.0069 -loss = 0.012569903934490867
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:22,408 INFO epoch # 1369 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0069-> 0.0069 -loss = 0.012494311507907696
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:22,426 INFO epoch # 1370 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0069-> 0.0069 -loss = 0.012583874311530963
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:22,426 INFO *** epoch 1370, rolling-avg-loss (window=10)= 0.0134280419730203
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:22,444 INFO epoch # 1371 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0069-> 0.0069 -loss = 0.012558426584291738
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:22,463 INFO epoch # 1372 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0069-> 0.0069 -loss = 0.013023048915783875
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:22,481 INFO epoch # 1373 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0069-> 0.0069 -loss = 0.012665044851019047
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:22,500 INFO epoch # 1374 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0069-> 0.0069 -loss = 0.012530175132269505
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:22,518 INFO epoch # 1375 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0069-> 0.0069 -loss = 0.012662392226047814
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:22,537 INFO epoch # 1376 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0069-> 0.0069 -loss = 0.013844782268279232
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:22,555 INFO epoch # 1377 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0069-> 0.0068 -loss = 0.012690912692050915
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:22,573 INFO epoch # 1378 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0068-> 0.0068 -loss = 0.012432935916876886
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:22,592 INFO epoch # 1379 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0068-> 0.0068 -loss = 0.012584376956510823
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:22,610 INFO epoch # 1380 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0068-> 0.0068 -loss = 0.012375902275380213
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:22,610 INFO *** epoch 1380, rolling-avg-loss (window=10)= 0.012736799781851004
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:22,628 INFO epoch # 1381 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0068-> 0.0068 -loss = 0.012341215733613353
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:22,647 INFO epoch # 1382 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0068-> 0.0068 -loss = 0.013178050889109727
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:22,665 INFO epoch # 1383 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0068-> 0.0068 -loss = 0.012741548227495514
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:22,684 INFO epoch # 1384 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0068-> 0.0068 -loss = 0.012543582917714957
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:22,702 INFO epoch # 1385 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0068-> 0.0068 -loss = 0.012601988055394031
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:22,721 INFO epoch # 1386 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0068-> 0.0068 -loss = 0.012633495214686263
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:22,739 INFO epoch # 1387 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0068-> 0.0068 -loss = 0.012292517829337157
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:22,757 INFO epoch # 1388 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0068-> 0.0068 -loss = 0.012436360004357994
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:22,776 INFO epoch # 1389 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0068-> 0.0068 -loss = 0.012583893192640971
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:22,794 INFO epoch # 1390 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0068-> 0.0068 -loss = 0.012304093601414934
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:22,794 INFO *** epoch 1390, rolling-avg-loss (window=10)= 0.01256567456657649
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:22,812 INFO epoch # 1391 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0068-> 0.0068 -loss = 0.012453174880647566
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:22,831 INFO epoch # 1392 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0068-> 0.0068 -loss = 0.0124453399257618
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:22,849 INFO epoch # 1393 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0068-> 0.0068 -loss = 0.012349917902611196
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:22,867 INFO epoch # 1394 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0068-> 0.0068 -loss = 0.012370748750981875
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:22,886 INFO epoch # 1395 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0068-> 0.0068 -loss = 0.01242550257302355
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:22,904 INFO epoch # 1396 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0068-> 0.0068 -loss = 0.012372316166874953
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:22,923 INFO epoch # 1397 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0068-> 0.0068 -loss = 0.012457333137717796
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:22,941 INFO epoch # 1398 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0068-> 0.0068 -loss = 0.012503534053394105
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:22,960 INFO epoch # 1399 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0068-> 0.0068 -loss = 0.012335954772424884
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:22,978 INFO epoch # 1400 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0068-> 0.0068 -loss = 0.012360297499981243
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:22,978 INFO *** epoch 1400, rolling-avg-loss (window=10)= 0.012407411966341897
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:22,996 INFO epoch # 1401 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0068-> 0.0068 -loss = 0.012202882069686893
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:23,014 INFO epoch # 1402 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0068-> 0.0068 -loss = 0.01265501090529142
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:23,033 INFO epoch # 1403 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0068-> 0.0068 -loss = 0.012318737179157324
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:23,051 INFO epoch # 1404 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0068-> 0.0068 -loss = 0.01258838926878525
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:23,070 INFO epoch # 1405 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0068-> 0.0068 -loss = 0.012468539309338666
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:23,088 INFO epoch # 1406 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0068-> 0.0068 -loss = 0.012540853669634089
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:23,107 INFO epoch # 1407 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0068-> 0.0068 -loss = 0.012266164281754754
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:23,125 INFO epoch # 1408 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0068-> 0.0068 -loss = 0.01219695733016124
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:23,143 INFO epoch # 1409 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0068-> 0.0068 -loss = 0.012363040055788588
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:23,162 INFO epoch # 1410 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0068-> 0.0068 -loss = 0.012291758321225643
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:23,162 INFO *** epoch 1410, rolling-avg-loss (window=10)= 0.012389233239082387
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:23,180 INFO epoch # 1411 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0068-> 0.0068 -loss = 0.012324459363298956
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:23,198 INFO epoch # 1412 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0068-> 0.0068 -loss = 0.012584413365402725
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:23,216 INFO epoch # 1413 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0068-> 0.0068 -loss = 0.012255896224814933
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:23,235 INFO epoch # 1414 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0068-> 0.0068 -loss = 0.012264207827684004
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:23,253 INFO epoch # 1415 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0068-> 0.0068 -loss = 0.012277342611923814
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:23,271 INFO epoch # 1416 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0068-> 0.0068 -loss = 0.012355546401522588
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:23,290 INFO epoch # 1417 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0068-> 0.0068 -loss = 0.012287265199120156
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:23,308 INFO epoch # 1418 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0068-> 0.0068 -loss = 0.012241606695170049
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:23,327 INFO epoch # 1419 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0068-> 0.0067 -loss = 0.012276574889256153
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:23,345 INFO epoch # 1420 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0067-> 0.0067 -loss = 0.01238336296955822
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:23,345 INFO *** epoch 1420, rolling-avg-loss (window=10)= 0.01232506755477516
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:23,363 INFO epoch # 1421 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0067-> 0.0067 -loss = 0.012360577427898534
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:23,382 INFO epoch # 1422 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0067-> 0.0067 -loss = 0.012666159425862134
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:23,400 INFO epoch # 1423 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0067-> 0.0067 -loss = 0.012255654350155964
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:23,418 INFO epoch # 1424 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0067-> 0.0067 -loss = 0.012434279458830133
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:23,437 INFO epoch # 1425 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0067-> 0.0067 -loss = 0.012318793829763308
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:23,458 INFO epoch # 1426 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0067-> 0.0067 -loss = 0.01210038062708918
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:23,477 INFO epoch # 1427 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0067-> 0.0067 -loss = 0.012250419487827457
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:23,495 INFO epoch # 1428 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0067-> 0.0067 -loss = 0.01236284297920065
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:23,514 INFO epoch # 1429 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0067-> 0.0067 -loss = 0.012281689661904238
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:23,533 INFO epoch # 1430 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0067-> 0.0067 -loss = 0.012377552484394982
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:23,533 INFO *** epoch 1430, rolling-avg-loss (window=10)= 0.012340834973292658
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:23,551 INFO epoch # 1431 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0067-> 0.0067 -loss = 0.012339071516180411
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:23,570 INFO epoch # 1432 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0067-> 0.0067 -loss = 0.012188949149276596
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:23,588 INFO epoch # 1433 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0067-> 0.0067 -loss = 0.013042465645412449
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:23,606 INFO epoch # 1434 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0067-> 0.0067 -loss = 0.012091063661500812
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:23,624 INFO epoch # 1435 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0067-> 0.0067 -loss = 0.012799035110219847
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:23,643 INFO epoch # 1436 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0067-> 0.0067 -loss = 0.012275222936295904
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:23,662 INFO epoch # 1437 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0067-> 0.0067 -loss = 0.011844776599900797
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:23,680 INFO epoch # 1438 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0067-> 0.0067 -loss = 0.01254820959729841
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:23,699 INFO epoch # 1439 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0067-> 0.0067 -loss = 0.012226863094838336
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:23,717 INFO epoch # 1440 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0067-> 0.0067 -loss = 0.011988431346253492
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:23,717 INFO *** epoch 1440, rolling-avg-loss (window=10)= 0.012334408865717706
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:23,735 INFO epoch # 1441 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0067-> 0.0067 -loss = 0.012132054333051201
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:23,754 INFO epoch # 1442 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0067-> 0.0067 -loss = 0.012384339490381535
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:23,772 INFO epoch # 1443 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0067-> 0.0067 -loss = 0.012568631529575214
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:23,790 INFO epoch # 1444 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0067-> 0.0067 -loss = 0.01229005908680847
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:23,809 INFO epoch # 1445 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0067-> 0.0067 -loss = 0.012086632086720783
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:23,827 INFO epoch # 1446 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0067-> 0.0067 -loss = 0.012312175938859582
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:23,845 INFO epoch # 1447 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0067-> 0.0067 -loss = 0.012514512018242385
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:23,863 INFO epoch # 1448 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0067-> 0.0066 -loss = 0.012203050893731415
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:23,882 INFO epoch # 1449 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0066-> 0.0066 -loss = 0.012244232384546194
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:23,900 INFO epoch # 1450 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0066-> 0.0066 -loss = 0.012442418010323308
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:23,900 INFO *** epoch 1450, rolling-avg-loss (window=10)= 0.012317810577224008
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:23,919 INFO epoch # 1451 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0066-> 0.0066 -loss = 0.012063738555298187
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:23,937 INFO epoch # 1452 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0066-> 0.0066 -loss = 0.012156012737250421
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:23,955 INFO epoch # 1453 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0066-> 0.0066 -loss = 0.012192235386464745
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:23,974 INFO epoch # 1454 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0066-> 0.0066 -loss = 0.012153121235314757
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:23,992 INFO epoch # 1455 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0066-> 0.0066 -loss = 0.01203236699802801
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:24,010 INFO epoch # 1456 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0066-> 0.0066 -loss = 0.012029814377456205
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:24,029 INFO epoch # 1457 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0066-> 0.0066 -loss = 0.012076727805833798
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:24,047 INFO epoch # 1458 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0066-> 0.0066 -loss = 0.012084285561286379
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:24,065 INFO epoch # 1459 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0066-> 0.0066 -loss = 0.012456192271201871
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:24,083 INFO epoch # 1460 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0066-> 0.0066 -loss = 0.012161541133536957
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:24,083 INFO *** epoch 1460, rolling-avg-loss (window=10)= 0.012140603606167134
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:24,102 INFO epoch # 1461 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0066-> 0.0066 -loss = 0.012037253560265526
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:24,120 INFO epoch # 1462 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0066-> 0.0066 -loss = 0.012245527403138112
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:24,138 INFO epoch # 1463 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0066-> 0.0066 -loss = 0.012057871608703863
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:24,157 INFO epoch # 1464 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0066-> 0.0066 -loss = 0.012243738477991428
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:24,175 INFO epoch # 1465 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0066-> 0.0066 -loss = 0.01204629332642071
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:24,193 INFO epoch # 1466 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0066-> 0.0066 -loss = 0.012126077504944988
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:24,212 INFO epoch # 1467 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0066-> 0.0066 -loss = 0.012003904783341568
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:24,230 INFO epoch # 1468 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0066-> 0.0066 -loss = 0.012264689408766571
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:24,248 INFO epoch # 1469 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0066-> 0.0066 -loss = 0.012080013068043627
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:24,266 INFO epoch # 1470 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0066-> 0.0065 -loss = 0.011972346532274969
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:24,266 INFO *** epoch 1470, rolling-avg-loss (window=10)= 0.012107771567389135
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:24,285 INFO epoch # 1471 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0065-> 0.0065 -loss = 0.012314752362726722
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:24,303 INFO epoch # 1472 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0065-> 0.0065 -loss = 0.0120085653179558
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:24,322 INFO epoch # 1473 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0065-> 0.0065 -loss = 0.011914310394786298
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:24,340 INFO epoch # 1474 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0065-> 0.0065 -loss = 0.011940519347263034
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:24,358 INFO epoch # 1475 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0065-> 0.0065 -loss = 0.012067638082953636
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:24,377 INFO epoch # 1476 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0065-> 0.0065 -loss = 0.012183458951767534
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:24,395 INFO epoch # 1477 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0065-> 0.0065 -loss = 0.011987934885837603
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:24,413 INFO epoch # 1478 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0065-> 0.0065 -loss = 0.012126845664170105
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:24,432 INFO epoch # 1479 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0065-> 0.0065 -loss = 0.018675778097531293
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:24,450 INFO epoch # 1480 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0065-> 0.0065 -loss = 0.013149842889106367
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:24,450 INFO *** epoch 1480, rolling-avg-loss (window=10)= 0.012836964599409839
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:24,469 INFO epoch # 1481 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0065-> 0.0064 -loss = 0.012013554740406107
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:24,487 INFO epoch # 1482 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0064-> 0.0064 -loss = 0.011952985558309592
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:24,505 INFO epoch # 1483 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0064-> 0.0064 -loss = 0.011860377257107757
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:24,524 INFO epoch # 1484 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0064-> 0.0064 -loss = 0.01177699461550219
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:24,542 INFO epoch # 1485 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0064-> 0.0064 -loss = 0.011959896299231332
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:24,560 INFO epoch # 1486 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0064-> 0.0064 -loss = 0.011780126194935292
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:24,579 INFO epoch # 1487 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0064-> 0.0064 -loss = 0.012265690245840233
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:24,597 INFO epoch # 1488 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0064-> 0.0064 -loss = 0.012237872724654153
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:24,616 INFO epoch # 1489 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0064-> 0.0064 -loss = 0.011830079209175892
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:24,634 INFO epoch # 1490 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0064-> 0.0064 -loss = 0.01199172624910716
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:24,634 INFO *** epoch 1490, rolling-avg-loss (window=10)= 0.01196693030942697
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:24,652 INFO epoch # 1491 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0064-> 0.0064 -loss = 0.01207595050072996
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:24,670 INFO epoch # 1492 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0064-> 0.0064 -loss = 0.01171895387233235
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:24,689 INFO epoch # 1493 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0064-> 0.0064 -loss = 0.011974261178693268
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:24,707 INFO epoch # 1494 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0064-> 0.0064 -loss = 0.012334339786320925
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:24,725 INFO epoch # 1495 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0064-> 0.0064 -loss = 0.011971799391176319
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:24,744 INFO epoch # 1496 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0064-> 0.0064 -loss = 0.011925021390197799
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:24,762 INFO epoch # 1497 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0064-> 0.0064 -loss = 0.01198706662398763
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:24,781 INFO epoch # 1498 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0064-> 0.0064 -loss = 0.011928284766327124
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:24,799 INFO epoch # 1499 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0064-> 0.0064 -loss = 0.01885265723831253
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:24,817 INFO epoch # 1500 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0064-> 0.0064 -loss = 0.01275366769550601
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:24,817 INFO *** epoch 1500, rolling-avg-loss (window=10)= 0.012752200244358391
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:24,835 INFO epoch # 1501 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0064-> 0.0064 -loss = 0.011882901133503765
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:24,854 INFO epoch # 1502 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0064-> 0.0064 -loss = 0.012764378770953044
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:24,872 INFO epoch # 1503 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0064-> 0.0064 -loss = 0.012001062648778316
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:24,890 INFO epoch # 1504 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0064-> 0.0064 -loss = 0.011996229535725433
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:24,909 INFO epoch # 1505 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0064-> 0.0064 -loss = 0.011642764391581295
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:24,927 INFO epoch # 1506 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0064-> 0.0064 -loss = 0.011809565941803157
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:24,946 INFO epoch # 1507 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0064-> 0.0064 -loss = 0.011859273949085036
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:24,964 INFO epoch # 1508 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0064-> 0.0064 -loss = 0.01181992338388227
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:24,982 INFO epoch # 1509 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0064-> 0.0064 -loss = 0.011700776442012284
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:25,001 INFO epoch # 1510 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0064-> 0.0064 -loss = 0.011760121415136382
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:25,001 INFO *** epoch 1510, rolling-avg-loss (window=10)= 0.011923699761246099
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:25,019 INFO epoch # 1511 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0064-> 0.0064 -loss = 0.011848323323647492
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:25,038 INFO epoch # 1512 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0064-> 0.0064 -loss = 0.011842719992273487
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:25,056 INFO epoch # 1513 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0064-> 0.0064 -loss = 0.018736571306362748
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:25,074 INFO epoch # 1514 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0064-> 0.0064 -loss = 0.01280826859147055
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:25,092 INFO epoch # 1515 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0064-> 0.0064 -loss = 0.011732399623724632
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:25,111 INFO epoch # 1516 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0064-> 0.0063 -loss = 0.01252043589920504
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:25,129 INFO epoch # 1517 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0063-> 0.0063 -loss = 0.012016777487588115
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:25,148 INFO epoch # 1518 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0063-> 0.0063 -loss = 0.012015923450235277
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:25,167 INFO epoch # 1519 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0063-> 0.0063 -loss = 0.01184983553685015
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:25,186 INFO epoch # 1520 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0063-> 0.0063 -loss = 0.011867484150570817
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:25,186 INFO *** epoch 1520, rolling-avg-loss (window=10)= 0.012723873936192832
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:25,205 INFO epoch # 1521 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0063-> 0.0063 -loss = 0.011895619762071874
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:25,223 INFO epoch # 1522 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0063-> 0.0063 -loss = 0.01173590312100714
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:25,242 INFO epoch # 1523 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0063-> 0.0063 -loss = 0.011780851360526867
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:25,260 INFO epoch # 1524 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0063-> 0.0063 -loss = 0.011711618717527017
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:25,278 INFO epoch # 1525 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0063-> 0.0063 -loss = 0.011833148411824368
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:25,296 INFO epoch # 1526 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0063-> 0.0063 -loss = 0.012705360568361357
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:25,315 INFO epoch # 1527 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0063-> 0.0062 -loss = 0.012925544782774523
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:25,333 INFO epoch # 1528 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0062-> 0.0062 -loss = 0.011899297824129462
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:25,351 INFO epoch # 1529 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0062-> 0.0062 -loss = 0.011688323069392936
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:25,370 INFO epoch # 1530 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0062-> 0.0062 -loss = 0.011647973718936555
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:25,370 INFO *** epoch 1530, rolling-avg-loss (window=10)= 0.01198236413365521
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:25,389 INFO epoch # 1531 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0062-> 0.0062 -loss = 0.011757185788155766
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:25,407 INFO epoch # 1532 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0062-> 0.0062 -loss = 0.011625224447925575
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:25,425 INFO epoch # 1533 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0062-> 0.0062 -loss = 0.011700755123456474
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:25,444 INFO epoch # 1534 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0062-> 0.0062 -loss = 0.011855401717184577
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:25,462 INFO epoch # 1535 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0062-> 0.0062 -loss = 0.011730934373190394
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:25,480 INFO epoch # 1536 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0062-> 0.0062 -loss = 0.01179964718176052
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:25,499 INFO epoch # 1537 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0062-> 0.0062 -loss = 0.01206163405731786
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:25,517 INFO epoch # 1538 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0062-> 0.0062 -loss = 0.011715042550349608
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:25,535 INFO epoch # 1539 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0062-> 0.0062 -loss = 0.01158406514878152
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:25,553 INFO epoch # 1540 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0062-> 0.0062 -loss = 0.011708364538208116
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:25,553 INFO *** epoch 1540, rolling-avg-loss (window=10)= 0.011753825492633041
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:25,572 INFO epoch # 1541 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0062-> 0.0062 -loss = 0.011686157744406955
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:25,590 INFO epoch # 1542 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0062-> 0.0062 -loss = 0.01164948743826244
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:25,609 INFO epoch # 1543 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0062-> 0.0062 -loss = 0.011606815598497633
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:25,627 INFO epoch # 1544 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0062-> 0.0062 -loss = 0.011598301498452201
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:25,646 INFO epoch # 1545 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0062-> 0.0062 -loss = 0.01160727391106775
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:25,664 INFO epoch # 1546 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0062-> 0.0062 -loss = 0.01166799571365118
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:25,682 INFO epoch # 1547 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0062-> 0.0062 -loss = 0.011695445762597956
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:25,701 INFO epoch # 1548 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0062-> 0.0062 -loss = 0.011748555101803504
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:25,719 INFO epoch # 1549 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0062-> 0.0062 -loss = 0.011641814729955513
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:25,737 INFO epoch # 1550 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0062-> 0.0062 -loss = 0.01180223400297109
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:25,737 INFO *** epoch 1550, rolling-avg-loss (window=10)= 0.011670408150166622
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:25,755 INFO epoch # 1551 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0062-> 0.0062 -loss = 0.011766926130803768
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:25,774 INFO epoch # 1552 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0062-> 0.0062 -loss = 0.011549911188922124
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:25,792 INFO epoch # 1553 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0062-> 0.0062 -loss = 0.011717131892510224
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:25,811 INFO epoch # 1554 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0062-> 0.0062 -loss = 0.011737608125258703
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:25,830 INFO epoch # 1555 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0062-> 0.0062 -loss = 0.011906897743756417
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:25,848 INFO epoch # 1556 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0062-> 0.0062 -loss = 0.011861175626108889
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:25,866 INFO epoch # 1557 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0062-> 0.0062 -loss = 0.01168498757033376
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:25,885 INFO epoch # 1558 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0062-> 0.0062 -loss = 0.011554158241779078
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:25,903 INFO epoch # 1559 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0062-> 0.0062 -loss = 0.011595549251069315
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:25,921 INFO epoch # 1560 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0062-> 0.0062 -loss = 0.011630683271505404
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:25,921 INFO *** epoch 1560, rolling-avg-loss (window=10)= 0.011700502904204768
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:25,940 INFO epoch # 1561 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0062-> 0.0062 -loss = 0.011627156869508326
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:25,958 INFO epoch # 1562 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0062-> 0.0062 -loss = 0.011607948843447957
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:25,976 INFO epoch # 1563 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0062-> 0.0061 -loss = 0.011548838534508832
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:25,994 INFO epoch # 1564 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0061-> 0.0061 -loss = 0.011675086483592167
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:26,013 INFO epoch # 1565 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0061-> 0.0061 -loss = 0.011609773588133976
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:26,031 INFO epoch # 1566 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0061-> 0.0061 -loss = 0.011731720318493899
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:26,050 INFO epoch # 1567 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0061-> 0.0061 -loss = 0.011609770946961362
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:26,068 INFO epoch # 1568 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0061-> 0.0061 -loss = 0.011707263474818319
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:26,086 INFO epoch # 1569 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0061-> 0.0061 -loss = 0.011443704606790561
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:26,105 INFO epoch # 1570 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0061-> 0.0061 -loss = 0.011673599801724777
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:26,105 INFO *** epoch 1570, rolling-avg-loss (window=10)= 0.011623486346798018
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:26,123 INFO epoch # 1571 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0061-> 0.0061 -loss = 0.011559470811334904
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:26,141 INFO epoch # 1572 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0061-> 0.0061 -loss = 0.011494135243992787
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:26,160 INFO epoch # 1573 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0061-> 0.0061 -loss = 0.011759575187170412
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:26,178 INFO epoch # 1574 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0061-> 0.0061 -loss = 0.01151025845319964
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:26,196 INFO epoch # 1575 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0061-> 0.0061 -loss = 0.011506869966979139
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:26,215 INFO epoch # 1576 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0061-> 0.0061 -loss = 0.01131981593061937
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:26,233 INFO epoch # 1577 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0061-> 0.0061 -loss = 0.011463624632597202
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:26,251 INFO epoch # 1578 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0061-> 0.0061 -loss = 0.011477360123535618
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:26,270 INFO epoch # 1579 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0061-> 0.0061 -loss = 0.015845676760363858
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:26,288 INFO epoch # 1580 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0061-> 0.0061 -loss = 0.012108219823858235
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:26,288 INFO *** epoch 1580, rolling-avg-loss (window=10)= 0.012004500693365117
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:26,306 INFO epoch # 1581 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0061-> 0.0061 -loss = 0.01155255813500844
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:26,325 INFO epoch # 1582 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0061-> 0.0061 -loss = 0.01153032947331667
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:26,343 INFO epoch # 1583 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0061-> 0.0061 -loss = 0.011329541957820766
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:26,361 INFO epoch # 1584 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0061-> 0.0061 -loss = 0.011531542513694149
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:26,379 INFO epoch # 1585 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0061-> 0.0061 -loss = 0.011567721943720244
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:26,398 INFO epoch # 1586 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0061-> 0.0061 -loss = 0.011472315640276065
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:26,416 INFO epoch # 1587 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0061-> 0.0061 -loss = 0.011411892992327921
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:26,435 INFO epoch # 1588 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0061-> 0.0061 -loss = 0.011503668945806567
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:26,453 INFO epoch # 1589 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0061-> 0.0061 -loss = 0.011427688914409373
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:26,471 INFO epoch # 1590 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0061-> 0.0061 -loss = 0.01179984550253721
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:26,472 INFO *** epoch 1590, rolling-avg-loss (window=10)= 0.01151271060189174
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:26,490 INFO epoch # 1591 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0061-> 0.0061 -loss = 0.011547005866304971
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:26,508 INFO epoch # 1592 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0061-> 0.0061 -loss = 0.011576130636967719
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:26,527 INFO epoch # 1593 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0061-> 0.0061 -loss = 0.011595096897508483
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:26,545 INFO epoch # 1594 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0061-> 0.0061 -loss = 0.011404066877730656
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:26,563 INFO epoch # 1595 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0061-> 0.0061 -loss = 0.011419866459618788
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:26,582 INFO epoch # 1596 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0061-> 0.0061 -loss = 0.011409608101530466
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:26,600 INFO epoch # 1597 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0061-> 0.0061 -loss = 0.011741866590455174
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:26,619 INFO epoch # 1598 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0061-> 0.006 -loss = 0.011697915047989227
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:26,637 INFO epoch # 1599 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.006-> 0.006 -loss = 0.011552465752174612
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:26,656 INFO epoch # 1600 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.006-> 0.006 -loss = 0.011431946739321575
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:26,656 INFO *** epoch 1600, rolling-avg-loss (window=10)= 0.011537596896960167
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:26,674 INFO epoch # 1601 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.006-> 0.006 -loss = 0.011598772420256864
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:26,692 INFO epoch # 1602 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.006-> 0.006 -loss = 0.011507947034260724
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:26,711 INFO epoch # 1603 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.006-> 0.006 -loss = 0.012414260512741748
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:26,729 INFO epoch # 1604 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.006-> 0.006 -loss = 0.011353632122336421
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:26,747 INFO epoch # 1605 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.006-> 0.006 -loss = 0.011587030567170586
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:26,766 INFO epoch # 1606 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.006-> 0.006 -loss = 0.011538191662111785
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:26,784 INFO epoch # 1607 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.006-> 0.006 -loss = 0.011673347908072174
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:26,802 INFO epoch # 1608 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.006-> 0.006 -loss = 0.011548733957170043
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:26,821 INFO epoch # 1609 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.006-> 0.0059 -loss = 0.01151858939556405
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:26,839 INFO epoch # 1610 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0059-> 0.0059 -loss = 0.011427501998696243
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:26,839 INFO *** epoch 1610, rolling-avg-loss (window=10)= 0.011616800757838063
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:26,858 INFO epoch # 1611 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0059-> 0.0059 -loss = 0.0115062342301826
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:26,876 INFO epoch # 1612 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0059-> 0.0059 -loss = 0.011365599428245332
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:26,895 INFO epoch # 1613 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0059-> 0.0059 -loss = 0.011452482733147917
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:26,913 INFO epoch # 1614 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0059-> 0.0059 -loss = 0.011382562151993625
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:26,931 INFO epoch # 1615 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0059-> 0.0059 -loss = 0.011425808079366107
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:26,949 INFO epoch # 1616 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0059-> 0.0059 -loss = 0.011294672891381197
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:26,968 INFO epoch # 1617 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0059-> 0.0059 -loss = 0.011500040716782678
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:26,986 INFO epoch # 1618 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0059-> 0.0059 -loss = 0.011441080721851904
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:27,004 INFO epoch # 1619 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0059-> 0.0059 -loss = 0.011386295002012048
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:27,023 INFO epoch # 1620 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0059-> 0.0059 -loss = 0.011343352685798891
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:27,023 INFO *** epoch 1620, rolling-avg-loss (window=10)= 0.011409812864076229
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:27,041 INFO epoch # 1621 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0059-> 0.0059 -loss = 0.01136359299562173
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:27,060 INFO epoch # 1622 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0059-> 0.0059 -loss = 0.011314877479890129
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:27,078 INFO epoch # 1623 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0059-> 0.0059 -loss = 0.011357022587617394
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:27,097 INFO epoch # 1624 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0059-> 0.0059 -loss = 0.011264904373092577
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:27,115 INFO epoch # 1625 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0059-> 0.0059 -loss = 0.011379861949535552
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:27,133 INFO epoch # 1626 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0059-> 0.0059 -loss = 0.011212728379177861
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:27,152 INFO epoch # 1627 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0059-> 0.0059 -loss = 0.011337811309203971
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:27,170 INFO epoch # 1628 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0059-> 0.0059 -loss = 0.0117761497022002
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:27,188 INFO epoch # 1629 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0059-> 0.0059 -loss = 0.01138381494092755
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:27,206 INFO epoch # 1630 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0059-> 0.0059 -loss = 0.011257440601184499
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:27,207 INFO *** epoch 1630, rolling-avg-loss (window=10)= 0.011364820431845146
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:27,225 INFO epoch # 1631 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0059-> 0.0059 -loss = 0.011268644506344572
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:27,243 INFO epoch # 1632 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0059-> 0.0059 -loss = 0.011448706049122848
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:27,262 INFO epoch # 1633 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0059-> 0.0059 -loss = 0.011271978675722494
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:27,280 INFO epoch # 1634 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0059-> 0.0059 -loss = 0.01117597871052567
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:27,299 INFO epoch # 1635 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0059-> 0.0059 -loss = 0.01142422428529244
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:27,317 INFO epoch # 1636 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0059-> 0.0059 -loss = 0.01125537133339094
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:27,335 INFO epoch # 1637 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0059-> 0.0059 -loss = 0.011213968278752873
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:27,353 INFO epoch # 1638 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0059-> 0.0059 -loss = 0.011319235876726452
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:27,372 INFO epoch # 1639 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0059-> 0.0059 -loss = 0.01122869219398126
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:27,390 INFO epoch # 1640 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0059-> 0.0059 -loss = 0.011301513193757273
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:27,390 INFO *** epoch 1640, rolling-avg-loss (window=10)= 0.011290831310361682
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:27,408 INFO epoch # 1641 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0059-> 0.0059 -loss = 0.01173043960443465
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:27,427 INFO epoch # 1642 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0059-> 0.0059 -loss = 0.011438404231739696
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:27,445 INFO epoch # 1643 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0059-> 0.0059 -loss = 0.011243080560234375
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:27,464 INFO epoch # 1644 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0059-> 0.0059 -loss = 0.011283581261523068
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:27,482 INFO epoch # 1645 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0059-> 0.0059 -loss = 0.011365618200215977
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:27,501 INFO epoch # 1646 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0059-> 0.0059 -loss = 0.011021802238246892
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:27,519 INFO epoch # 1647 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0059-> 0.0059 -loss = 0.011597879263717914
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:27,537 INFO epoch # 1648 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0059-> 0.0059 -loss = 0.011122345917101484
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:27,555 INFO epoch # 1649 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0059-> 0.0059 -loss = 0.011280396734946407
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:27,574 INFO epoch # 1650 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0059-> 0.0059 -loss = 0.011292155249975622
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:27,574 INFO *** epoch 1650, rolling-avg-loss (window=10)= 0.011337570326213608
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:27,592 INFO epoch # 1651 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0059-> 0.0059 -loss = 0.011113083397503942
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:27,610 INFO epoch # 1652 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0059-> 0.0059 -loss = 0.011367063081706874
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:27,629 INFO epoch # 1653 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0059-> 0.0059 -loss = 0.0114788113933173
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:27,648 INFO epoch # 1654 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0059-> 0.0059 -loss = 0.011268067923083436
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:27,667 INFO epoch # 1655 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0059-> 0.0059 -loss = 0.011194228136446327
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:27,685 INFO epoch # 1656 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0059-> 0.0059 -loss = 0.01117697073641466
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:27,703 INFO epoch # 1657 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0059-> 0.0058 -loss = 0.01165590144955786
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:27,722 INFO epoch # 1658 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0058-> 0.0058 -loss = 0.01144001536158612
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:27,740 INFO epoch # 1659 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0058-> 0.0058 -loss = 0.011323937847919296
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:27,758 INFO epoch # 1660 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0058-> 0.0058 -loss = 0.011315543531964067
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:27,758 INFO *** epoch 1660, rolling-avg-loss (window=10)= 0.011333362285949989
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:27,776 INFO epoch # 1661 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0058-> 0.0058 -loss = 0.011101938107458409
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:27,795 INFO epoch # 1662 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0058-> 0.0058 -loss = 0.011124928685603663
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:27,813 INFO epoch # 1663 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0058-> 0.0058 -loss = 0.011369790372555144
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:27,831 INFO epoch # 1664 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0058-> 0.0058 -loss = 0.01120193687529536
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:27,850 INFO epoch # 1665 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0058-> 0.0058 -loss = 0.011162086389958858
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:27,868 INFO epoch # 1666 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0058-> 0.0058 -loss = 0.011247253831243142
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:27,887 INFO epoch # 1667 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0058-> 0.0058 -loss = 0.011301524136797525
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:27,905 INFO epoch # 1668 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0058-> 0.0058 -loss = 0.011182918227859773
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:27,924 INFO epoch # 1669 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0058-> 0.0058 -loss = 0.011154617637657793
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:27,943 INFO epoch # 1670 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0058-> 0.0058 -loss = 0.011261887346336152
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:27,943 INFO *** epoch 1670, rolling-avg-loss (window=10)= 0.011210888161076581
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:27,961 INFO epoch # 1671 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0058-> 0.0058 -loss = 0.011235268677410204
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:27,980 INFO epoch # 1672 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0058-> 0.0058 -loss = 0.011071076667576563
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:27,998 INFO epoch # 1673 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0058-> 0.0058 -loss = 0.011147610166517552
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:28,017 INFO epoch # 1674 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0058-> 0.0058 -loss = 0.011154568463098258
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:28,035 INFO epoch # 1675 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0058-> 0.0058 -loss = 0.011180176596099045
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:28,053 INFO epoch # 1676 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0058-> 0.0058 -loss = 0.011124892407678999
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:28,072 INFO epoch # 1677 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0058-> 0.0058 -loss = 0.01105453995114658
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:28,090 INFO epoch # 1678 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0058-> 0.0058 -loss = 0.011355561437085271
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:28,109 INFO epoch # 1679 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0058-> 0.0057 -loss = 0.011570164693694096
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:28,127 INFO epoch # 1680 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0057-> 0.0057 -loss = 0.011046645988244563
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:28,127 INFO *** epoch 1680, rolling-avg-loss (window=10)= 0.011194050504855113
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:28,145 INFO epoch # 1681 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0057-> 0.0057 -loss = 0.011063442849263083
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:28,163 INFO epoch # 1682 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0057-> 0.0057 -loss = 0.011256609701376874
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:28,182 INFO epoch # 1683 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0057-> 0.0057 -loss = 0.01114719246106688
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:28,200 INFO epoch # 1684 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0057-> 0.0057 -loss = 0.011195146129466593
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:28,218 INFO epoch # 1685 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0057-> 0.0057 -loss = 0.011067082530644257
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:28,237 INFO epoch # 1686 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0057-> 0.0057 -loss = 0.011247991627897136
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:28,255 INFO epoch # 1687 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0057-> 0.0057 -loss = 0.011178117791132536
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:28,273 INFO epoch # 1688 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0057-> 0.0057 -loss = 0.011087311468145344
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:28,292 INFO epoch # 1689 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0057-> 0.0057 -loss = 0.011066222286899574
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:28,310 INFO epoch # 1690 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0057-> 0.0056 -loss = 0.01128424254420679
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:28,310 INFO *** epoch 1690, rolling-avg-loss (window=10)= 0.011159335939009907
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:28,329 INFO epoch # 1691 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0056-> 0.0056 -loss = 0.01089949991001049
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:28,347 INFO epoch # 1692 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0056-> 0.0056 -loss = 0.0110327499860432
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:28,365 INFO epoch # 1693 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0056-> 0.0056 -loss = 0.011246489302720875
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:28,383 INFO epoch # 1694 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0056-> 0.0056 -loss = 0.011096297319454607
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:28,402 INFO epoch # 1695 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0056-> 0.0056 -loss = 0.011383069911971688
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:28,420 INFO epoch # 1696 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0056-> 0.0056 -loss = 0.011013593939424027
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:28,438 INFO epoch # 1697 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0056-> 0.0056 -loss = 0.011139453810756095
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:28,457 INFO epoch # 1698 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0056-> 0.0056 -loss = 0.010955102974548936
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:28,475 INFO epoch # 1699 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0056-> 0.0056 -loss = 0.011288909532595426
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:28,493 INFO epoch # 1700 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0056-> 0.0056 -loss = 0.011159320572915021
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:28,494 INFO *** epoch 1700, rolling-avg-loss (window=10)= 0.011121448726044036
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:28,512 INFO epoch # 1701 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0056-> 0.0056 -loss = 0.011705362179782242
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:28,530 INFO epoch # 1702 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0056-> 0.0056 -loss = 0.011221085194847547
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:28,549 INFO epoch # 1703 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0056-> 0.0056 -loss = 0.01104926697735209
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:28,567 INFO epoch # 1704 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0056-> 0.0056 -loss = 0.011047043110011145
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:28,585 INFO epoch # 1705 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0056-> 0.0056 -loss = 0.01101682957232697
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:28,603 INFO epoch # 1706 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0056-> 0.0056 -loss = 0.01108423268306069
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:28,622 INFO epoch # 1707 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0056-> 0.0056 -loss = 0.011069574735302012
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:28,640 INFO epoch # 1708 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0056-> 0.0056 -loss = 0.010971634706947953
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:28,658 INFO epoch # 1709 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0056-> 0.0056 -loss = 0.011223366302147042
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:28,677 INFO epoch # 1710 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0056-> 0.0056 -loss = 0.011005101987393573
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:28,677 INFO *** epoch 1710, rolling-avg-loss (window=10)= 0.011139349744917126
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:28,695 INFO epoch # 1711 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0056-> 0.0056 -loss = 0.011309119072393514
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:28,714 INFO epoch # 1712 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0056-> 0.0056 -loss = 0.010957990918541327
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:28,732 INFO epoch # 1713 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0056-> 0.0055 -loss = 0.011026204709196463
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:28,750 INFO epoch # 1714 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0055-> 0.0055 -loss = 0.011033622329705395
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:28,769 INFO epoch # 1715 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0055-> 0.0055 -loss = 0.011122571762825828
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:28,787 INFO epoch # 1716 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0055-> 0.0055 -loss = 0.010900489705818472
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:28,805 INFO epoch # 1717 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0055-> 0.0055 -loss = 0.011155990294355433
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:28,823 INFO epoch # 1718 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0055-> 0.0055 -loss = 0.011003936684574
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:28,842 INFO epoch # 1719 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0055-> 0.0055 -loss = 0.011694429100316484
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:28,860 INFO epoch # 1720 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0055-> 0.0055 -loss = 0.010974071199598256
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:28,861 INFO *** epoch 1720, rolling-avg-loss (window=10)= 0.011117842577732517
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:28,879 INFO epoch # 1721 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0055-> 0.0055 -loss = 0.010896685496845748
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:28,897 INFO epoch # 1722 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0055-> 0.0055 -loss = 0.011067082967201713
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:28,916 INFO epoch # 1723 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0055-> 0.0055 -loss = 0.010881770649575628
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:28,934 INFO epoch # 1724 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0055-> 0.0055 -loss = 0.011116982415842358
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:28,952 INFO epoch # 1725 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0055-> 0.0055 -loss = 0.011174463346833363
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:28,971 INFO epoch # 1726 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0055-> 0.0055 -loss = 0.010963064931274857
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:28,990 INFO epoch # 1727 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0055-> 0.0055 -loss = 0.011177625005075242
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:29,009 INFO epoch # 1728 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0055-> 0.0055 -loss = 0.010975722459988901
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:29,028 INFO epoch # 1729 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0055-> 0.0055 -loss = 0.010886206491704797
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:29,047 INFO epoch # 1730 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0055-> 0.0055 -loss = 0.011004237399902195
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:29,047 INFO *** epoch 1730, rolling-avg-loss (window=10)= 0.01101438411642448
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:29,066 INFO epoch # 1731 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0055-> 0.0055 -loss = 0.01092898197384784
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:29,085 INFO epoch # 1732 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0055-> 0.0055 -loss = 0.01424395394133171
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:29,103 INFO epoch # 1733 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0055-> 0.0055 -loss = 0.01118823369324673
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:29,122 INFO epoch # 1734 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0055-> 0.0055 -loss = 0.010956815865938552
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:29,140 INFO epoch # 1735 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0055-> 0.0055 -loss = 0.010846971817954909
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:29,158 INFO epoch # 1736 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0055-> 0.0055 -loss = 0.010913757956586778
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:29,176 INFO epoch # 1737 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0055-> 0.0055 -loss = 0.010958552549709566
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:29,195 INFO epoch # 1738 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0055-> 0.0055 -loss = 0.010924295995209832
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:29,213 INFO epoch # 1739 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0055-> 0.0055 -loss = 0.01084590997925261
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:29,231 INFO epoch # 1740 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0055-> 0.0055 -loss = 0.010956065212667454
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:29,231 INFO *** epoch 1740, rolling-avg-loss (window=10)= 0.011276353898574598
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:29,250 INFO epoch # 1741 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0055-> 0.0055 -loss = 0.010848764221009333
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:29,268 INFO epoch # 1742 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0055-> 0.0055 -loss = 0.01090888768521836
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:29,286 INFO epoch # 1743 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0055-> 0.0055 -loss = 0.011001494298398029
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:29,305 INFO epoch # 1744 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0055-> 0.0055 -loss = 0.010853931424207985
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:29,323 INFO epoch # 1745 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0055-> 0.0055 -loss = 0.011079448500822764
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:29,342 INFO epoch # 1746 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0055-> 0.0054 -loss = 0.011047835418139584
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:29,360 INFO epoch # 1747 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0054-> 0.0054 -loss = 0.010813785534992348
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:29,378 INFO epoch # 1748 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0054-> 0.0054 -loss = 0.010825524303072598
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:29,396 INFO epoch # 1749 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0054-> 0.0054 -loss = 0.010877638531383127
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:29,415 INFO epoch # 1750 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0054-> 0.0054 -loss = 0.010918617841525702
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:29,415 INFO *** epoch 1750, rolling-avg-loss (window=10)= 0.010917592775876983
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:29,433 INFO epoch # 1751 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0054-> 0.0054 -loss = 0.010957696540572215
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:29,451 INFO epoch # 1752 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0054-> 0.0054 -loss = 0.010903865084401332
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:29,470 INFO epoch # 1753 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0054-> 0.0054 -loss = 0.01079606651182985
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:29,488 INFO epoch # 1754 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0054-> 0.0054 -loss = 0.010853283682081383
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:29,506 INFO epoch # 1755 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0054-> 0.0054 -loss = 0.010851370323507581
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:29,525 INFO epoch # 1756 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0054-> 0.0054 -loss = 0.011081990232924
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:29,543 INFO epoch # 1757 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0054-> 0.0054 -loss = 0.01105389878648566
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:29,561 INFO epoch # 1758 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0054-> 0.0054 -loss = 0.011078418829129077
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:29,579 INFO epoch # 1759 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0054-> 0.0054 -loss = 0.010800078460306395
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:29,598 INFO epoch # 1760 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0054-> 0.0054 -loss = 0.010820590181538137
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:29,598 INFO *** epoch 1760, rolling-avg-loss (window=10)= 0.010919725863277562
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:29,616 INFO epoch # 1761 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0054-> 0.0054 -loss = 0.010805597485159524
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:29,634 INFO epoch # 1762 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0054-> 0.0054 -loss = 0.010826362216903362
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:29,652 INFO epoch # 1763 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0054-> 0.0054 -loss = 0.010819457944307942
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:29,671 INFO epoch # 1764 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0054-> 0.0054 -loss = 0.011327372660161927
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:29,689 INFO epoch # 1765 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0054-> 0.0054 -loss = 0.011049911299778614
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:29,708 INFO epoch # 1766 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0054-> 0.0054 -loss = 0.010678450904379133
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:29,726 INFO epoch # 1767 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0054-> 0.0054 -loss = 0.010831427403900307
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:29,745 INFO epoch # 1768 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0054-> 0.0054 -loss = 0.010819591261679307
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:29,763 INFO epoch # 1769 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0054-> 0.0054 -loss = 0.010765008730231784
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:29,782 INFO epoch # 1770 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0054-> 0.0054 -loss = 0.010812700318638235
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:29,782 INFO *** epoch 1770, rolling-avg-loss (window=10)= 0.010873588022514013
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:29,800 INFO epoch # 1771 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0054-> 0.0054 -loss = 0.011009209636540618
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:29,818 INFO epoch # 1772 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0054-> 0.0054 -loss = 0.01073970741708763
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:29,837 INFO epoch # 1773 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0054-> 0.0054 -loss = 0.010748477863671724
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:29,856 INFO epoch # 1774 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0054-> 0.0054 -loss = 0.011099130817456171
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:29,874 INFO epoch # 1775 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0054-> 0.0054 -loss = 0.010841001072549261
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:29,892 INFO epoch # 1776 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0054-> 0.0054 -loss = 0.010783302328491118
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:29,911 INFO epoch # 1777 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0054-> 0.0053 -loss = 0.010788173749460839
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:29,929 INFO epoch # 1778 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0053-> 0.0053 -loss = 0.010948588751489297
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:29,947 INFO epoch # 1779 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0053-> 0.0053 -loss = 0.010697771809645928
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:29,966 INFO epoch # 1780 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0053-> 0.0053 -loss = 0.010693883734347764
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:29,966 INFO *** epoch 1780, rolling-avg-loss (window=10)= 0.010834924718074035
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:29,984 INFO epoch # 1781 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0053-> 0.0053 -loss = 0.010743120707047638
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:30,002 INFO epoch # 1782 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0053-> 0.0053 -loss = 0.010858280620595906
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:30,020 INFO epoch # 1783 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0053-> 0.0053 -loss = 0.01070141921081813
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:30,038 INFO epoch # 1784 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0053-> 0.0053 -loss = 0.011415968147048261
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:30,056 INFO epoch # 1785 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0053-> 0.0053 -loss = 0.010799282150401268
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:30,075 INFO epoch # 1786 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0053-> 0.0053 -loss = 0.010711045048083179
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:30,093 INFO epoch # 1787 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0053-> 0.0053 -loss = 0.010818581635248847
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:30,111 INFO epoch # 1788 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0053-> 0.0053 -loss = 0.011003319930750877
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:30,130 INFO epoch # 1789 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0053-> 0.0053 -loss = 0.011129265607451089
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:30,149 INFO epoch # 1790 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0053-> 0.0053 -loss = 0.010666139834938804
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:30,149 INFO *** epoch 1790, rolling-avg-loss (window=10)= 0.0108846422892384
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:30,167 INFO epoch # 1791 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0053-> 0.0053 -loss = 0.010812204302055761
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:30,185 INFO epoch # 1792 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0053-> 0.0053 -loss = 0.010655371959728654
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:30,204 INFO epoch # 1793 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0053-> 0.0053 -loss = 0.010833126660145354
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:30,222 INFO epoch # 1794 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0053-> 0.0053 -loss = 0.010569397600193042
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:30,240 INFO epoch # 1795 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0053-> 0.0053 -loss = 0.01092913122556638
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:30,259 INFO epoch # 1796 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0053-> 0.0053 -loss = 0.0106034238342545
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:30,277 INFO epoch # 1797 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0053-> 0.0053 -loss = 0.010735490228398703
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:30,295 INFO epoch # 1798 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0053-> 0.0053 -loss = 0.010694234755646903
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:30,314 INFO epoch # 1799 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0053-> 0.0053 -loss = 0.010806227357534226
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:30,332 INFO epoch # 1800 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0053-> 0.0053 -loss = 0.010712512834288646
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:30,332 INFO *** epoch 1800, rolling-avg-loss (window=10)= 0.010735112075781216
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:30,351 INFO epoch # 1801 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0053-> 0.0053 -loss = 0.010698469617636874
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:30,369 INFO epoch # 1802 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0053-> 0.0053 -loss = 0.010710006288718432
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:30,387 INFO epoch # 1803 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0053-> 0.0053 -loss = 0.010892959689954296
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:30,406 INFO epoch # 1804 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0053-> 0.0053 -loss = 0.011006498418282717
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:30,424 INFO epoch # 1805 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0053-> 0.0052 -loss = 0.01079191639291821
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:30,442 INFO epoch # 1806 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0052-> 0.0052 -loss = 0.010596540825645206
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:30,460 INFO epoch # 1807 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0052-> 0.0052 -loss = 0.010661839856766164
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:30,479 INFO epoch # 1808 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0052-> 0.0052 -loss = 0.010757737632957287
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:30,497 INFO epoch # 1809 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0052-> 0.0052 -loss = 0.013947414823633153
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:30,515 INFO epoch # 1810 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0052-> 0.0052 -loss = 0.011297729397483636
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:30,515 INFO *** epoch 1810, rolling-avg-loss (window=10)= 0.011136111294399597
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:30,534 INFO epoch # 1811 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0052-> 0.0052 -loss = 0.011341470686602406
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:30,552 INFO epoch # 1812 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0052-> 0.0052 -loss = 0.013601125217974186
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:30,571 INFO epoch # 1813 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0052-> 0.0052 -loss = 0.011230891162995249
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:30,590 INFO epoch # 1814 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0052-> 0.0052 -loss = 0.01058111160818953
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:30,609 INFO epoch # 1815 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0052-> 0.0052 -loss = 0.010699878388550133
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:30,627 INFO epoch # 1816 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0052-> 0.0052 -loss = 0.010616498730087187
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:30,645 INFO epoch # 1817 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0052-> 0.0052 -loss = 0.01055887697293656
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:30,664 INFO epoch # 1818 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0052-> 0.0052 -loss = 0.02032467985554831
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:30,682 INFO epoch # 1819 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0052-> 0.0052 -loss = 0.011301923288556281
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:30,700 INFO epoch # 1820 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0052-> 0.0052 -loss = 0.010697247897041962
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:30,700 INFO *** epoch 1820, rolling-avg-loss (window=10)= 0.01209537038084818
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:30,719 INFO epoch # 1821 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0052-> 0.0052 -loss = 0.010770665139716584
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:30,737 INFO epoch # 1822 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0052-> 0.0052 -loss = 0.010628900221490767
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:30,755 INFO epoch # 1823 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0052-> 0.0052 -loss = 0.010531870277191047
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:30,774 INFO epoch # 1824 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0052-> 0.0052 -loss = 0.010563687603280414
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:30,792 INFO epoch # 1825 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0052-> 0.0052 -loss = 0.010712183771829586
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:30,810 INFO epoch # 1826 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0052-> 0.0052 -loss = 0.010575506334134843
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:30,828 INFO epoch # 1827 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0052-> 0.0052 -loss = 0.010529907522141002
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:30,847 INFO epoch # 1828 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0052-> 0.0052 -loss = 0.010492124769371003
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:30,866 INFO epoch # 1829 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0052-> 0.0052 -loss = 0.01057295053760754
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:30,884 INFO epoch # 1830 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0052-> 0.0052 -loss = 0.010609414875943912
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:30,885 INFO *** epoch 1830, rolling-avg-loss (window=10)= 0.010598721105270669
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:30,903 INFO epoch # 1831 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0052-> 0.0052 -loss = 0.010580234753433615
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:30,922 INFO epoch # 1832 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0052-> 0.0052 -loss = 0.010557687848631758
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:30,940 INFO epoch # 1833 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0052-> 0.0052 -loss = 0.010665802437870298
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:30,959 INFO epoch # 1834 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0052-> 0.0052 -loss = 0.010530194405873772
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:30,977 INFO epoch # 1835 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0052-> 0.0052 -loss = 0.010704620581236668
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:30,995 INFO epoch # 1836 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0052-> 0.0052 -loss = 0.010505855738301761
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:31,014 INFO epoch # 1837 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0052-> 0.0052 -loss = 0.010525763434998225
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:31,033 INFO epoch # 1838 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0052-> 0.0052 -loss = 0.011276288292719983
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:31,051 INFO epoch # 1839 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0052-> 0.0051 -loss = 0.010776759052532725
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:31,070 INFO epoch # 1840 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0051-> 0.0051 -loss = 0.010782291785289999
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:31,070 INFO *** epoch 1840, rolling-avg-loss (window=10)= 0.01069054983308888
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:31,088 INFO epoch # 1841 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0051-> 0.0051 -loss = 0.011202660265553277
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:31,106 INFO epoch # 1842 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0051-> 0.0051 -loss = 0.010574140265816823
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:31,125 INFO epoch # 1843 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0051-> 0.0051 -loss = 0.010537316346017178
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:31,143 INFO epoch # 1844 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0051-> 0.0051 -loss = 0.01049533315381268
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:31,161 INFO epoch # 1845 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0051-> 0.0051 -loss = 0.010961172105453443
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:31,180 INFO epoch # 1846 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0051-> 0.0051 -loss = 0.010628490941599011
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:31,198 INFO epoch # 1847 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0051-> 0.0051 -loss = 0.010490368360478897
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:31,216 INFO epoch # 1848 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0051-> 0.0051 -loss = 0.010525093581236433
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:31,234 INFO epoch # 1849 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0051-> 0.0051 -loss = 0.010549881379120052
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:31,253 INFO epoch # 1850 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0051-> 0.0051 -loss = 0.010631967743393034
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:31,253 INFO *** epoch 1850, rolling-avg-loss (window=10)= 0.010659642414248082
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:31,271 INFO epoch # 1851 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0051-> 0.0051 -loss = 0.010497276776732178
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:31,289 INFO epoch # 1852 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0051-> 0.0051 -loss = 0.010553919244557619
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:31,308 INFO epoch # 1853 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0051-> 0.0051 -loss = 0.01108055862277979
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:31,326 INFO epoch # 1854 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0051-> 0.0051 -loss = 0.010535056801018072
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:31,344 INFO epoch # 1855 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0051-> 0.0051 -loss = 0.010477832052856684
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:31,363 INFO epoch # 1856 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0051-> 0.0051 -loss = 0.010447890505020041
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:31,381 INFO epoch # 1857 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0051-> 0.0051 -loss = 0.010529379062063526
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:31,400 INFO epoch # 1858 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0051-> 0.0051 -loss = 0.010567977755272295
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:31,418 INFO epoch # 1859 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0051-> 0.0051 -loss = 0.010490123080671765
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:31,436 INFO epoch # 1860 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0051-> 0.0051 -loss = 0.010572402701654937
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:31,436 INFO *** epoch 1860, rolling-avg-loss (window=10)= 0.01057524166026269
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:31,454 INFO epoch # 1861 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0051-> 0.0051 -loss = 0.010531099665968213
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:31,473 INFO epoch # 1862 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0051-> 0.0051 -loss = 0.010509804604225792
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:31,491 INFO epoch # 1863 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0051-> 0.0051 -loss = 0.010431031609186903
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:31,509 INFO epoch # 1864 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0051-> 0.0051 -loss = 0.010606583276967285
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:31,528 INFO epoch # 1865 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0051-> 0.0051 -loss = 0.010500847383809742
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:31,546 INFO epoch # 1866 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0051-> 0.0051 -loss = 0.010420750171761028
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:31,564 INFO epoch # 1867 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0051-> 0.0051 -loss = 0.010528296614211285
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:31,583 INFO epoch # 1868 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0051-> 0.0051 -loss = 0.0105132741300622
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:31,602 INFO epoch # 1869 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0051-> 0.0051 -loss = 0.010654230929503683
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:31,621 INFO epoch # 1870 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0051-> 0.0051 -loss = 0.01033961758366786
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:31,621 INFO *** epoch 1870, rolling-avg-loss (window=10)= 0.010503553596936398
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:31,640 INFO epoch # 1871 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0051-> 0.0051 -loss = 0.010470494176843204
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:31,658 INFO epoch # 1872 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0051-> 0.0051 -loss = 0.010548007274337579
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:31,676 INFO epoch # 1873 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0051-> 0.0051 -loss = 0.010438077251819777
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:31,694 INFO epoch # 1874 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0051-> 0.0051 -loss = 0.010641243847203441
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:31,713 INFO epoch # 1875 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0051-> 0.0051 -loss = 0.010598108900012448
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:31,731 INFO epoch # 1876 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0051-> 0.0051 -loss = 0.010480757213372272
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:31,749 INFO epoch # 1877 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0051-> 0.0051 -loss = 0.010376629408710869
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:31,768 INFO epoch # 1878 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0051-> 0.0051 -loss = 0.01063555789005477
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:31,786 INFO epoch # 1879 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0051-> 0.0051 -loss = 0.010435000585857779
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:31,804 INFO epoch # 1880 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0051-> 0.0051 -loss = 0.01031892238825094
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:31,804 INFO *** epoch 1880, rolling-avg-loss (window=10)= 0.010494279893646308
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:31,823 INFO epoch # 1881 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0051-> 0.0051 -loss = 0.010460404650075361
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:31,841 INFO epoch # 1882 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0051-> 0.0051 -loss = 0.010543839627644047
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:31,859 INFO epoch # 1883 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0051-> 0.0051 -loss = 0.010492734807485249
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:31,877 INFO epoch # 1884 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0051-> 0.0051 -loss = 0.010516038135392591
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:31,896 INFO epoch # 1885 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0051-> 0.0051 -loss = 0.010511993896216154
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:31,914 INFO epoch # 1886 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0051-> 0.0051 -loss = 0.010393811382527929
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:31,932 INFO epoch # 1887 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0051-> 0.0051 -loss = 0.010376916761742905
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:31,951 INFO epoch # 1888 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0051-> 0.0051 -loss = 0.010337814914237242
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:31,969 INFO epoch # 1889 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0051-> 0.0051 -loss = 0.010361259901401354
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:31,988 INFO epoch # 1890 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0051-> 0.0051 -loss = 0.01042989082634449
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:31,988 INFO *** epoch 1890, rolling-avg-loss (window=10)= 0.010442470490306732
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:32,006 INFO epoch # 1891 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0051-> 0.005 -loss = 0.010588997429294977
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:32,024 INFO epoch # 1892 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.005-> 0.005 -loss = 0.010398177619208582
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:32,043 INFO epoch # 1893 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.005-> 0.005 -loss = 0.010380343082943
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:32,061 INFO epoch # 1894 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.005-> 0.005 -loss = 0.01061667370959185
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:32,079 INFO epoch # 1895 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.005-> 0.005 -loss = 0.010361709104472538
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:32,097 INFO epoch # 1896 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.005-> 0.005 -loss = 0.010360472249885788
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:32,115 INFO epoch # 1897 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.005-> 0.005 -loss = 0.01144721212767763
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:32,134 INFO epoch # 1898 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.005-> 0.005 -loss = 0.01036825107439654
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:32,152 INFO epoch # 1899 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.005-> 0.005 -loss = 0.010307761433068663
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:32,170 INFO epoch # 1900 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.005-> 0.005 -loss = 0.010441203361551743
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:32,171 INFO *** epoch 1900, rolling-avg-loss (window=10)= 0.010527080119209132
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:32,189 INFO epoch # 1901 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.005-> 0.005 -loss = 0.011194509723281953
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:32,207 INFO epoch # 1902 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.005-> 0.005 -loss = 0.01042252175102476
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:32,225 INFO epoch # 1903 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.005-> 0.005 -loss = 0.010558951893472113
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:32,244 INFO epoch # 1904 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.005-> 0.005 -loss = 0.010348136973334476
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:32,262 INFO epoch # 1905 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.005-> 0.005 -loss = 0.010247904181596823
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:32,280 INFO epoch # 1906 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.005-> 0.005 -loss = 0.010285528071108274
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:32,298 INFO epoch # 1907 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.005-> 0.005 -loss = 0.010514592329855077
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:32,317 INFO epoch # 1908 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.005-> 0.005 -loss = 0.011265862980508246
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:32,335 INFO epoch # 1909 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.005-> 0.005 -loss = 0.01013402624084847
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:32,353 INFO epoch # 1910 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.005-> 0.005 -loss = 0.010820241765031824
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:32,353 INFO *** epoch 1910, rolling-avg-loss (window=10)= 0.010579227591006202
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:32,372 INFO epoch # 1911 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.005-> 0.005 -loss = 0.011055325034249108
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:32,390 INFO epoch # 1912 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.005-> 0.005 -loss = 0.010275419128447538
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:32,409 INFO epoch # 1913 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.005-> 0.005 -loss = 0.016281605647236574
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:32,427 INFO epoch # 1914 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.005-> 0.005 -loss = 0.01096916887036059
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:32,445 INFO epoch # 1915 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.005-> 0.005 -loss = 0.01053389210574096
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:32,464 INFO epoch # 1916 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.005-> 0.005 -loss = 0.01032449413469294
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:32,482 INFO epoch # 1917 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.005-> 0.005 -loss = 0.010318399206880713
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:32,500 INFO epoch # 1918 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.005-> 0.005 -loss = 0.010456177558808122
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:32,518 INFO epoch # 1919 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.005-> 0.005 -loss = 0.010468898217368405
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:32,537 INFO epoch # 1920 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.005-> 0.005 -loss = 0.010560146904026624
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:32,537 INFO *** epoch 1920, rolling-avg-loss (window=10)= 0.011124352680781158
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:32,555 INFO epoch # 1921 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.005-> 0.005 -loss = 0.010359025465731975
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:32,573 INFO epoch # 1922 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.005-> 0.005 -loss = 0.010278866917360574
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:32,592 INFO epoch # 1923 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.005-> 0.005 -loss = 0.01025881536770612
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:32,611 INFO epoch # 1924 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.005-> 0.005 -loss = 0.010590832811431028
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:32,630 INFO epoch # 1925 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.005-> 0.005 -loss = 0.010444771600305103
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:32,649 INFO epoch # 1926 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.005-> 0.005 -loss = 0.01044895310769789
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:32,668 INFO epoch # 1927 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.005-> 0.005 -loss = 0.010286679535056464
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:32,686 INFO epoch # 1928 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.005-> 0.005 -loss = 0.010255968551064143
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:32,704 INFO epoch # 1929 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.005-> 0.005 -loss = 0.010310059435141739
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:32,722 INFO epoch # 1930 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.005-> 0.005 -loss = 0.01024635075009428
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:32,723 INFO *** epoch 1930, rolling-avg-loss (window=10)= 0.010348032354158931
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:32,741 INFO epoch # 1931 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.005-> 0.0049 -loss = 0.010400287108495831
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:32,759 INFO epoch # 1932 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0049-> 0.0049 -loss = 0.010173979298997438
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:32,778 INFO epoch # 1933 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0049-> 0.0049 -loss = 0.010282661045494024
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:32,796 INFO epoch # 1934 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0049-> 0.0049 -loss = 0.010296680258761626
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:32,814 INFO epoch # 1935 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0049-> 0.0049 -loss = 0.016137016711581964
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:32,833 INFO epoch # 1936 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0049-> 0.0049 -loss = 0.011079261923441663
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:32,851 INFO epoch # 1937 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0049-> 0.0049 -loss = 0.01038059943675762
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:32,869 INFO epoch # 1938 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0049-> 0.0049 -loss = 0.010405403096228838
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:32,887 INFO epoch # 1939 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0049-> 0.0049 -loss = 0.01025505548750516
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:32,906 INFO epoch # 1940 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0049-> 0.0049 -loss = 0.01030563853419153
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:32,906 INFO *** epoch 1940, rolling-avg-loss (window=10)= 0.01097165829014557
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:32,924 INFO epoch # 1941 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0049-> 0.0049 -loss = 0.010452621972945053
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:32,942 INFO epoch # 1942 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0049-> 0.0049 -loss = 0.010303738297807286
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:32,961 INFO epoch # 1943 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0049-> 0.0049 -loss = 0.010228837731119711
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:32,979 INFO epoch # 1944 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0049-> 0.0049 -loss = 0.010185876839386765
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:32,997 INFO epoch # 1945 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0049-> 0.0049 -loss = 0.010261929797707126
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:33,016 INFO epoch # 1946 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0049-> 0.0049 -loss = 0.010332629943150096
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:33,034 INFO epoch # 1947 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0049-> 0.0049 -loss = 0.010238371789455414
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:33,053 INFO epoch # 1948 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0049-> 0.0049 -loss = 0.01020879989664536
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:33,071 INFO epoch # 1949 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0049-> 0.0049 -loss = 0.010174697112233844
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:33,090 INFO epoch # 1950 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0049-> 0.0049 -loss = 0.010117162542883307
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:33,090 INFO *** epoch 1950, rolling-avg-loss (window=10)= 0.010250466592333396
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:33,108 INFO epoch # 1951 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0049-> 0.0049 -loss = 0.010126321198185906
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:33,126 INFO epoch # 1952 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0049-> 0.0049 -loss = 0.010305222203896847
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:33,144 INFO epoch # 1953 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0049-> 0.0049 -loss = 0.010236489033559337
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:33,163 INFO epoch # 1954 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0049-> 0.0049 -loss = 0.010316312145732809
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:33,181 INFO epoch # 1955 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0049-> 0.0049 -loss = 0.010397752950666472
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:33,199 INFO epoch # 1956 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0049-> 0.0049 -loss = 0.010151475602469873
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:33,218 INFO epoch # 1957 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0049-> 0.0049 -loss = 0.010309936449630186
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:33,236 INFO epoch # 1958 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0049-> 0.0049 -loss = 0.01014333774219267
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:33,254 INFO epoch # 1959 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0049-> 0.0049 -loss = 0.010237281567242462
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:33,272 INFO epoch # 1960 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0049-> 0.0049 -loss = 0.010215759255515877
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:33,273 INFO *** epoch 1960, rolling-avg-loss (window=10)= 0.010243988814909243
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:33,291 INFO epoch # 1961 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0049-> 0.0048 -loss = 0.010209343658061698
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:33,309 INFO epoch # 1962 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0048-> 0.0048 -loss = 0.010052668658317998
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:33,327 INFO epoch # 1963 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0048-> 0.0048 -loss = 0.010166243599087466
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:33,346 INFO epoch # 1964 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0048-> 0.0048 -loss = 0.010214978123258334
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:33,364 INFO epoch # 1965 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0048-> 0.0048 -loss = 0.010161381294892635
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:33,382 INFO epoch # 1966 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0048-> 0.0048 -loss = 0.010170079542149324
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:33,401 INFO epoch # 1967 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0048-> 0.0048 -loss = 0.010144011950615095
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:33,419 INFO epoch # 1968 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0048-> 0.0048 -loss = 0.010372082273534033
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:33,437 INFO epoch # 1969 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0048-> 0.0048 -loss = 0.010444877592817647
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:33,455 INFO epoch # 1970 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0048-> 0.0048 -loss = 0.010380013496614993
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:33,456 INFO *** epoch 1970, rolling-avg-loss (window=10)= 0.010231568018934923
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:33,474 INFO epoch # 1971 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0048-> 0.0048 -loss = 0.010386690773884766
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:33,492 INFO epoch # 1972 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0048-> 0.0048 -loss = 0.010096642639837228
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:33,511 INFO epoch # 1973 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0048-> 0.0048 -loss = 0.010241036412480753
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:33,529 INFO epoch # 1974 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0048-> 0.0048 -loss = 0.010073799639940262
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:33,547 INFO epoch # 1975 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0048-> 0.0048 -loss = 0.010170356072194409
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:33,565 INFO epoch # 1976 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0048-> 0.0048 -loss = 0.010183219295868184
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:33,584 INFO epoch # 1977 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0048-> 0.0048 -loss = 0.010160366189666092
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:33,602 INFO epoch # 1978 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0048-> 0.0048 -loss = 0.010113062875461765
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:33,621 INFO epoch # 1979 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0048-> 0.0048 -loss = 0.015818414467503317
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:33,639 INFO epoch # 1980 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0048-> 0.0048 -loss = 0.010638663712597918
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:33,639 INFO *** epoch 1980, rolling-avg-loss (window=10)= 0.01078822520794347
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:33,658 INFO epoch # 1981 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0048-> 0.0048 -loss = 0.010187961783231003
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:33,676 INFO epoch # 1982 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0048-> 0.0048 -loss = 0.010125477048859466
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:33,694 INFO epoch # 1983 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0048-> 0.0048 -loss = 0.010572982573648915
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:33,713 INFO epoch # 1984 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0048-> 0.0048 -loss = 0.01021645762375556
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:33,731 INFO epoch # 1985 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0048-> 0.0048 -loss = 0.010312635502486955
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:33,749 INFO epoch # 1986 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0048-> 0.0048 -loss = 0.01037183403968811
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:33,768 INFO epoch # 1987 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0048-> 0.0048 -loss = 0.010237621616397519
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:33,786 INFO epoch # 1988 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0048-> 0.0048 -loss = 0.010283818912284914
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:33,804 INFO epoch # 1989 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0048-> 0.0048 -loss = 0.010073373745399294
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:33,823 INFO epoch # 1990 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0048-> 0.0048 -loss = 0.010125379129021894
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:33,823 INFO *** epoch 1990, rolling-avg-loss (window=10)= 0.010250754197477363
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:33,841 INFO epoch # 1991 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0048-> 0.0048 -loss = 0.010253641517920187
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:33,859 INFO epoch # 1992 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0048-> 0.0048 -loss = 0.01016587954654824
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:33,878 INFO epoch # 1993 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0048-> 0.0048 -loss = 0.010135165168321691
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:33,896 INFO epoch # 1994 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0048-> 0.0048 -loss = 0.010196860603173263
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:33,914 INFO epoch # 1995 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0048-> 0.0047 -loss = 0.010075545294967014
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:33,932 INFO epoch # 1996 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0047-> 0.0047 -loss = 0.010118312238773797
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:33,951 INFO epoch # 1997 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0047-> 0.0047 -loss = 0.010213053064944688
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:33,969 INFO epoch # 1998 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0047-> 0.0047 -loss = 0.010120740545971785
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:33,987 INFO epoch # 1999 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0047-> 0.0047 -loss = 0.010089936171425506
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:34,006 INFO epoch # 2000 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0047-> 0.0047 -loss = 0.010108611088071484
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:34,006 INFO *** epoch 2000, rolling-avg-loss (window=10)= 0.010147774524011766
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:34,024 INFO epoch # 2001 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0047-> 0.0047 -loss = 0.010054290891275741
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:34,043 INFO epoch # 2002 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0047-> 0.0047 -loss = 0.010050083947135136
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:34,061 INFO epoch # 2003 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0047-> 0.0047 -loss = 0.010087520196975674
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:34,079 INFO epoch # 2004 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0047-> 0.0047 -loss = 0.010067760937090497
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:34,098 INFO epoch # 2005 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0047-> 0.0047 -loss = 0.010081082524266094
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:34,117 INFO epoch # 2006 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0047-> 0.0047 -loss = 0.010177686068345793
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:34,135 INFO epoch # 2007 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0047-> 0.0047 -loss = 0.010319990211428376
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:34,154 INFO epoch # 2008 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0047-> 0.0047 -loss = 0.01016606081975624
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:34,172 INFO epoch # 2009 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0047-> 0.0047 -loss = 0.010407112109533045
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:34,190 INFO epoch # 2010 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0047-> 0.0047 -loss = 0.010045222563348943
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:34,190 INFO *** epoch 2010, rolling-avg-loss (window=10)= 0.010145681026915553
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:34,209 INFO epoch # 2011 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0047-> 0.0047 -loss = 0.010045100061688572
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:34,227 INFO epoch # 2012 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0047-> 0.0047 -loss = 0.010010631704062689
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:34,245 INFO epoch # 2013 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0047-> 0.0047 -loss = 0.010113250609720126
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:34,264 INFO epoch # 2014 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0047-> 0.0047 -loss = 0.01009368612722028
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:34,282 INFO epoch # 2015 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0047-> 0.0047 -loss = 0.010053153113403823
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:34,300 INFO epoch # 2016 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0047-> 0.0047 -loss = 0.010123288884642534
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:34,319 INFO epoch # 2017 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0047-> 0.0047 -loss = 0.01028596461401321
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:34,337 INFO epoch # 2018 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0047-> 0.0047 -loss = 0.010024192622950068
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:34,355 INFO epoch # 2019 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0047-> 0.0047 -loss = 0.010432265495182946
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:34,373 INFO epoch # 2020 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0047-> 0.0047 -loss = 0.010022971568105277
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:34,373 INFO *** epoch 2020, rolling-avg-loss (window=10)= 0.010120450480098953
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:34,392 INFO epoch # 2021 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0047-> 0.0047 -loss = 0.010028738830442308
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:34,410 INFO epoch # 2022 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0047-> 0.0047 -loss = 0.00997298783477163
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:34,429 INFO epoch # 2023 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0047-> 0.0047 -loss = 0.010205969359958544
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:34,447 INFO epoch # 2024 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0047-> 0.0047 -loss = 0.010022176677011885
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:34,465 INFO epoch # 2025 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0047-> 0.0047 -loss = 0.010107526053616311
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:34,484 INFO epoch # 2026 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0047-> 0.0047 -loss = 0.010790006126626395
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:34,502 INFO epoch # 2027 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0047-> 0.0047 -loss = 0.010012547361839097
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:34,520 INFO epoch # 2028 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0047-> 0.0047 -loss = 0.009992667688493384
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:34,539 INFO epoch # 2029 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0047-> 0.0047 -loss = 0.010047529445728287
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:34,557 INFO epoch # 2030 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0047-> 0.0047 -loss = 0.010026778771134559
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:34,557 INFO *** epoch 2030, rolling-avg-loss (window=10)= 0.01012069281496224
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:34,575 INFO epoch # 2031 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0047-> 0.0047 -loss = 0.009943727101926925
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:34,594 INFO epoch # 2032 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0047-> 0.0047 -loss = 0.010052995377918705
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:34,612 INFO epoch # 2033 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0047-> 0.0047 -loss = 0.009916885072016157
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:34,631 INFO epoch # 2034 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0047-> 0.0047 -loss = 0.009919532858475577
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:34,649 INFO epoch # 2035 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0047-> 0.0047 -loss = 0.009910375636536628
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:34,667 INFO epoch # 2036 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0047-> 0.0047 -loss = 0.010003897456044797
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:34,686 INFO epoch # 2037 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0047-> 0.0047 -loss = 0.010091641117469408
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:34,704 INFO epoch # 2038 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0047-> 0.0047 -loss = 0.010045190807431936
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:34,722 INFO epoch # 2039 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0047-> 0.0047 -loss = 0.010086433518154081
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:34,741 INFO epoch # 2040 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0047-> 0.0047 -loss = 0.009952073771273717
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:34,741 INFO *** epoch 2040, rolling-avg-loss (window=10)= 0.009992275271724794
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:34,759 INFO epoch # 2041 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0047-> 0.0047 -loss = 0.010178537522733677
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:34,777 INFO epoch # 2042 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0047-> 0.0047 -loss = 0.010124369036930148
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:34,795 INFO epoch # 2043 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0047-> 0.0047 -loss = 0.010103528751642443
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:34,814 INFO epoch # 2044 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0047-> 0.0047 -loss = 0.010063219400763046
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:34,832 INFO epoch # 2045 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0047-> 0.0047 -loss = 0.009944271812855732
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:34,851 INFO epoch # 2046 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0047-> 0.0047 -loss = 0.010127921035746112
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:34,869 INFO epoch # 2047 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0047-> 0.0047 -loss = 0.01005915362475207
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:34,887 INFO epoch # 2048 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0047-> 0.0047 -loss = 0.010139048710698262
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:34,906 INFO epoch # 2049 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0047-> 0.0047 -loss = 0.010035004539531656
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:34,924 INFO epoch # 2050 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0047-> 0.0047 -loss = 0.009907861865940504
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:34,924 INFO *** epoch 2050, rolling-avg-loss (window=10)= 0.010068291630159366
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:34,942 INFO epoch # 2051 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0047-> 0.0047 -loss = 0.009942627937562065
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:34,960 INFO epoch # 2052 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0047-> 0.0047 -loss = 0.009936770191416144
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:34,978 INFO epoch # 2053 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0047-> 0.0047 -loss = 0.010111442636116408
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:34,997 INFO epoch # 2054 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0047-> 0.0047 -loss = 0.009960133458662312
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:35,015 INFO epoch # 2055 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0047-> 0.0047 -loss = 0.010249041151837446
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:35,033 INFO epoch # 2056 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0047-> 0.0047 -loss = 0.010267286910675466
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:35,052 INFO epoch # 2057 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0047-> 0.0047 -loss = 0.009934965579304844
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:35,070 INFO epoch # 2058 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0047-> 0.0047 -loss = 0.00997804183862172
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:35,089 INFO epoch # 2059 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0047-> 0.0047 -loss = 0.009918921525240876
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:35,107 INFO epoch # 2060 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0047-> 0.0047 -loss = 0.010036586310889106
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:35,107 INFO *** epoch 2060, rolling-avg-loss (window=10)= 0.010033581754032638
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:35,126 INFO epoch # 2061 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0047-> 0.0046 -loss = 0.009996989057981409
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:35,144 INFO epoch # 2062 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0046-> 0.0046 -loss = 0.009964725984900724
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:35,162 INFO epoch # 2063 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0046-> 0.0046 -loss = 0.009896210456645349
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:35,181 INFO epoch # 2064 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0046-> 0.0046 -loss = 0.009810443356400356
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:35,199 INFO epoch # 2065 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0046-> 0.0046 -loss = 0.009945579917257419
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:35,218 INFO epoch # 2066 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0046-> 0.0046 -loss = 0.009887029260426061
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:35,236 INFO epoch # 2067 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0046-> 0.0046 -loss = 0.010010089434217662
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:35,254 INFO epoch # 2068 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0046-> 0.0046 -loss = 0.009896755465888418
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:35,273 INFO epoch # 2069 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0046-> 0.0046 -loss = 0.009837387675361242
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:35,291 INFO epoch # 2070 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0046-> 0.0046 -loss = 0.009831245130044408
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:35,291 INFO *** epoch 2070, rolling-avg-loss (window=10)= 0.009907645573912304
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:35,310 INFO epoch # 2071 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0046-> 0.0046 -loss = 0.009817524129175581
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:35,328 INFO epoch # 2072 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0046-> 0.0046 -loss = 0.009912419322063215
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:35,346 INFO epoch # 2073 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0046-> 0.0046 -loss = 0.009904184509650804
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:35,364 INFO epoch # 2074 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0046-> 0.0046 -loss = 0.009896115167066455
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:35,382 INFO epoch # 2075 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0046-> 0.0046 -loss = 0.010098823964654002
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:35,400 INFO epoch # 2076 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0046-> 0.0046 -loss = 0.009848660556599498
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:35,419 INFO epoch # 2077 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0046-> 0.0046 -loss = 0.010090382260386832
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:35,437 INFO epoch # 2078 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0046-> 0.0046 -loss = 0.009845700558798853
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:35,455 INFO epoch # 2079 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0046-> 0.0046 -loss = 0.009818645758059574
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:35,474 INFO epoch # 2080 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0046-> 0.0046 -loss = 0.009898605589114595
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:35,474 INFO *** epoch 2080, rolling-avg-loss (window=10)= 0.009913106181556941
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:35,492 INFO epoch # 2081 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0046-> 0.0046 -loss = 0.009858081481070258
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:35,510 INFO epoch # 2082 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0046-> 0.0046 -loss = 0.009837220730332774
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:35,529 INFO epoch # 2083 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0046-> 0.0046 -loss = 0.009854856987658422
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:35,547 INFO epoch # 2084 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0046-> 0.0046 -loss = 0.009748841370310402
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:35,565 INFO epoch # 2085 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0046-> 0.0046 -loss = 0.010082942731969524
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:35,583 INFO epoch # 2086 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0046-> 0.0046 -loss = 0.009859477053396404
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:35,602 INFO epoch # 2087 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0046-> 0.0046 -loss = 0.009923969126248267
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:35,620 INFO epoch # 2088 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0046-> 0.0046 -loss = 0.0103188265056815
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:35,638 INFO epoch # 2089 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0046-> 0.0046 -loss = 0.009936142356309574
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:35,656 INFO epoch # 2090 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0046-> 0.0046 -loss = 0.0099122014362365
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:35,657 INFO *** epoch 2090, rolling-avg-loss (window=10)= 0.009933255977921362
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:35,675 INFO epoch # 2091 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0046-> 0.0046 -loss = 0.009777975399629213
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:35,693 INFO epoch # 2092 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0046-> 0.0046 -loss = 0.009793914843612583
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:35,712 INFO epoch # 2093 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0046-> 0.0046 -loss = 0.009906508406857029
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:35,730 INFO epoch # 2094 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0046-> 0.0046 -loss = 0.00976726187946042
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:35,748 INFO epoch # 2095 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0046-> 0.0045 -loss = 0.010705143547966145
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:35,766 INFO epoch # 2096 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0045-> 0.0045 -loss = 0.009927259128744481
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:35,784 INFO epoch # 2097 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0045-> 0.0045 -loss = 0.009865758176601958
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:35,803 INFO epoch # 2098 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0045-> 0.0045 -loss = 0.010648094226780813
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:35,821 INFO epoch # 2099 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0045-> 0.0045 -loss = 0.010094206809299067
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:35,839 INFO epoch # 2100 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0045-> 0.0045 -loss = 0.00974806590602384
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:35,840 INFO *** epoch 2100, rolling-avg-loss (window=10)= 0.010023418832497554
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:35,858 INFO epoch # 2101 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0045-> 0.0045 -loss = 0.01048482767509995
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:35,876 INFO epoch # 2102 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0045-> 0.0045 -loss = 0.010167732791160233
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:35,895 INFO epoch # 2103 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0045-> 0.0045 -loss = 0.010579490401141811
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:35,913 INFO epoch # 2104 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0045-> 0.0045 -loss = 0.009971314604626969
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:35,931 INFO epoch # 2105 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0045-> 0.0045 -loss = 0.009963032745872624
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:35,950 INFO epoch # 2106 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0045-> 0.0045 -loss = 0.009753897422342561
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:35,968 INFO epoch # 2107 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0045-> 0.0045 -loss = 0.009946703423338477
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:35,987 INFO epoch # 2108 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0045-> 0.0045 -loss = 0.009833062951656757
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:36,005 INFO epoch # 2109 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0045-> 0.0045 -loss = 0.009676928391854744
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:36,024 INFO epoch # 2110 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0045-> 0.0045 -loss = 0.009736556086863857
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:36,024 INFO *** epoch 2110, rolling-avg-loss (window=10)= 0.010011354649395798
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:36,042 INFO epoch # 2111 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0045-> 0.0045 -loss = 0.009787792776478454
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:36,060 INFO epoch # 2112 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0045-> 0.0045 -loss = 0.009685398588771932
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:36,079 INFO epoch # 2113 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0045-> 0.0045 -loss = 0.00972959837235976
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:36,097 INFO epoch # 2114 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0045-> 0.0045 -loss = 0.009855147036432754
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:36,116 INFO epoch # 2115 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0045-> 0.0045 -loss = 0.009835047982051037
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:36,135 INFO epoch # 2116 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0045-> 0.0045 -loss = 0.009775934246135876
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:36,153 INFO epoch # 2117 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0045-> 0.0045 -loss = 0.009906602652336005
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:36,171 INFO epoch # 2118 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0045-> 0.0045 -loss = 0.009779159910976887
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:36,190 INFO epoch # 2119 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0045-> 0.0045 -loss = 0.009826777124544606
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:36,208 INFO epoch # 2120 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0045-> 0.0044 -loss = 0.009738905791891739
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:36,208 INFO *** epoch 2120, rolling-avg-loss (window=10)= 0.009792036448197905
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:36,226 INFO epoch # 2121 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0044-> 0.0044 -loss = 0.009829545473621693
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:36,245 INFO epoch # 2122 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0044-> 0.0044 -loss = 0.00977607436652761
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:36,263 INFO epoch # 2123 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0044-> 0.0044 -loss = 0.009770099291927181
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:36,282 INFO epoch # 2124 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0044-> 0.0044 -loss = 0.009766679981112247
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:36,300 INFO epoch # 2125 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0044-> 0.0044 -loss = 0.009744933682668488
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:36,318 INFO epoch # 2126 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0044-> 0.0044 -loss = 0.009822973886912223
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:36,337 INFO epoch # 2127 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0044-> 0.0044 -loss = 0.00970439441880444
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:36,355 INFO epoch # 2128 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0044-> 0.0044 -loss = 0.009786920483747963
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:36,373 INFO epoch # 2129 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0044-> 0.0044 -loss = 0.0099781680983142
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:36,391 INFO epoch # 2130 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0044-> 0.0044 -loss = 0.009813737779040821
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:36,391 INFO *** epoch 2130, rolling-avg-loss (window=10)= 0.009799352746267687
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:36,409 INFO epoch # 2131 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0044-> 0.0044 -loss = 0.009719291345390957
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:36,428 INFO epoch # 2132 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0044-> 0.0044 -loss = 0.00974461468285881
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:36,446 INFO epoch # 2133 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0044-> 0.0044 -loss = 0.009786837494175415
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:36,465 INFO epoch # 2134 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0044-> 0.0044 -loss = 0.009824798864428885
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:36,483 INFO epoch # 2135 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0044-> 0.0044 -loss = 0.009648241844843142
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:36,501 INFO epoch # 2136 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0044-> 0.0044 -loss = 0.009739825865835883
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:36,520 INFO epoch # 2137 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0044-> 0.0044 -loss = 0.009774489706614986
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:36,538 INFO epoch # 2138 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0044-> 0.0044 -loss = 0.009829825845372397
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:36,556 INFO epoch # 2139 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0044-> 0.0044 -loss = 0.00978431204566732
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:36,575 INFO epoch # 2140 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0044-> 0.0044 -loss = 0.009691625007690163
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:36,575 INFO *** epoch 2140, rolling-avg-loss (window=10)= 0.009754386270287796
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:36,593 INFO epoch # 2141 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0044-> 0.0044 -loss = 0.009694062267953996
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:36,611 INFO epoch # 2142 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0044-> 0.0044 -loss = 0.009739786757563706
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:36,630 INFO epoch # 2143 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0044-> 0.0044 -loss = 0.015562046959530562
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:36,648 INFO epoch # 2144 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0044-> 0.0044 -loss = 0.010631977580487728
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:36,666 INFO epoch # 2145 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0044-> 0.0044 -loss = 0.009729164237796795
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:36,685 INFO epoch # 2146 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0044-> 0.0043 -loss = 0.009984460659325123
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:36,703 INFO epoch # 2147 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.00974219235649798
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:36,721 INFO epoch # 2148 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.010049241995147895
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:36,740 INFO epoch # 2149 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.00982523647689959
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:36,758 INFO epoch # 2150 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.009740034853166435
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:36,758 INFO *** epoch 2150, rolling-avg-loss (window=10)= 0.01046982041443698
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:36,776 INFO epoch # 2151 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.00987329513009172
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:36,795 INFO epoch # 2152 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.009724934338009916
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:36,813 INFO epoch # 2153 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.009640118514653295
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:36,831 INFO epoch # 2154 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.009609391265257727
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:36,849 INFO epoch # 2155 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.01242473188904114
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:36,868 INFO epoch # 2156 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.00991180699202232
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:36,886 INFO epoch # 2157 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.009714658590382896
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:36,904 INFO epoch # 2158 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.00970411092566792
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:36,923 INFO epoch # 2159 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.014760859310626984
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:36,941 INFO epoch # 2160 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.010253034437482711
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:36,941 INFO *** epoch 2160, rolling-avg-loss (window=10)= 0.010561694139323664
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:36,960 INFO epoch # 2161 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.009719340712763369
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:36,978 INFO epoch # 2162 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.009906382714689244
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:36,996 INFO epoch # 2163 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.009688076548627578
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:37,015 INFO epoch # 2164 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.009709515987196937
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:37,033 INFO epoch # 2165 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.009620627017284278
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:37,051 INFO epoch # 2166 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.009822217660257593
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:37,069 INFO epoch # 2167 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.00971831721108174
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:37,088 INFO epoch # 2168 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.009572902083164081
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:37,106 INFO epoch # 2169 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.009659641589678358
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:37,124 INFO epoch # 2170 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.009607534004317131
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:37,124 INFO *** epoch 2170, rolling-avg-loss (window=10)= 0.00970245555290603
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:37,143 INFO epoch # 2171 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.009691391242085956
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:37,162 INFO epoch # 2172 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.009742453985381871
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:37,181 INFO epoch # 2173 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.009589878744009184
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:37,200 INFO epoch # 2174 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.009704576281365007
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:37,218 INFO epoch # 2175 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.009648999046476092
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:37,236 INFO epoch # 2176 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.010335814142308664
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:37,254 INFO epoch # 2177 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.009668853563198354
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:37,273 INFO epoch # 2178 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.009562261730025057
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:37,291 INFO epoch # 2179 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.009566625347360969
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:37,310 INFO epoch # 2180 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.009684302156529156
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:37,310 INFO *** epoch 2180, rolling-avg-loss (window=10)= 0.00971951562387403
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:37,328 INFO epoch # 2181 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.009645786398323253
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:37,347 INFO epoch # 2182 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.009597676111297915
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:37,365 INFO epoch # 2183 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.009631516157242004
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:37,384 INFO epoch # 2184 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.009561064609442838
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:37,402 INFO epoch # 2185 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.009541698906105012
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:37,420 INFO epoch # 2186 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.009585936822986696
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:37,438 INFO epoch # 2187 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.009600725672498811
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:37,457 INFO epoch # 2188 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.00965451987576671
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:37,475 INFO epoch # 2189 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.009600485693226801
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:37,493 INFO epoch # 2190 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.01201646545814583
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:37,493 INFO *** epoch 2190, rolling-avg-loss (window=10)= 0.009843587570503586
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:37,512 INFO epoch # 2191 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.009721426336909644
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:37,530 INFO epoch # 2192 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.009728520264616236
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:37,548 INFO epoch # 2193 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.009722846407385077
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:37,567 INFO epoch # 2194 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.009615534479962662
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:37,585 INFO epoch # 2195 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.009593915441655554
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:37,603 INFO epoch # 2196 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.009662150099757127
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:37,622 INFO epoch # 2197 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.009545312845148146
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:37,641 INFO epoch # 2198 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.009555920682032593
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:37,659 INFO epoch # 2199 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.009605150513380067
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:37,678 INFO epoch # 2200 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.009678277529019397
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:37,678 INFO *** epoch 2200, rolling-avg-loss (window=10)= 0.00964290545998665
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:37,696 INFO epoch # 2201 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.009634325637307484
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:37,715 INFO epoch # 2202 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.009604809318261687
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:37,734 INFO epoch # 2203 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.009487944094871636
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:37,752 INFO epoch # 2204 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.010184691152971936
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:37,770 INFO epoch # 2205 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.009634056492359377
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:37,789 INFO epoch # 2206 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.00967308651888743
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:37,807 INFO epoch # 2207 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.00952976758708246
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:37,825 INFO epoch # 2208 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.009594072376785334
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:37,844 INFO epoch # 2209 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.00958813885517884
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:37,862 INFO epoch # 2210 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.009524884844722692
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:37,862 INFO *** epoch 2210, rolling-avg-loss (window=10)= 0.009645577687842887
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:37,880 INFO epoch # 2211 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.009554443022352643
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:37,899 INFO epoch # 2212 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.009535042678180616
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:37,917 INFO epoch # 2213 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0043 -loss = 0.009536474055494182
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:37,935 INFO epoch # 2214 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0043-> 0.0042 -loss = 0.013014751653827261
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:37,953 INFO epoch # 2215 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0042-> 0.0042 -loss = 0.00976413166790735
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:37,972 INFO epoch # 2216 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0042-> 0.0042 -loss = 0.009621297111152671
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:37,990 INFO epoch # 2217 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0042-> 0.0042 -loss = 0.01297909626737237
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:38,008 INFO epoch # 2218 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0042-> 0.0042 -loss = 0.009937927439750638
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:38,027 INFO epoch # 2219 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0042-> 0.0042 -loss = 0.009649719409935642
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:38,045 INFO epoch # 2220 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0042-> 0.0042 -loss = 0.009699064743472263
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:38,045 INFO *** epoch 2220, rolling-avg-loss (window=10)= 0.010329194804944564
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:38,063 INFO epoch # 2221 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0042-> 0.0042 -loss = 0.00952073738881154
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:38,081 INFO epoch # 2222 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0042-> 0.0042 -loss = 0.009498364808678161
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:38,100 INFO epoch # 2223 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0042-> 0.0042 -loss = 0.009736053783854004
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:38,118 INFO epoch # 2224 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0042-> 0.0042 -loss = 0.014855506335152313
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:38,137 INFO epoch # 2225 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0042-> 0.0042 -loss = 0.0097181593591813
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:38,155 INFO epoch # 2226 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0042-> 0.0042 -loss = 0.009523067237751093
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:38,173 INFO epoch # 2227 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0042-> 0.0042 -loss = 0.00946717252372764
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:38,192 INFO epoch # 2228 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0042-> 0.0042 -loss = 0.009488956133282045
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:38,210 INFO epoch # 2229 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0042-> 0.0042 -loss = 0.01438031428551767
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:38,228 INFO epoch # 2230 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0042-> 0.0042 -loss = 0.009886378102237359
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:38,228 INFO *** epoch 2230, rolling-avg-loss (window=10)= 0.010607470995819313
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:38,246 INFO epoch # 2231 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0042-> 0.0042 -loss = 0.00967011391185224
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:38,265 INFO epoch # 2232 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0042-> 0.0042 -loss = 0.0095435289258603
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:38,283 INFO epoch # 2233 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0042-> 0.0042 -loss = 0.009491321819950826
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:38,301 INFO epoch # 2234 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0042-> 0.0042 -loss = 0.009600797457096633
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:38,319 INFO epoch # 2235 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0042-> 0.0042 -loss = 0.009415798125701258
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:38,338 INFO epoch # 2236 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0042-> 0.0042 -loss = 0.009719625893922057
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:38,356 INFO epoch # 2237 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0042-> 0.0042 -loss = 0.009368817220092751
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:38,375 INFO epoch # 2238 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0042-> 0.0042 -loss = 0.009638983174227178
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:38,393 INFO epoch # 2239 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0042-> 0.0042 -loss = 0.009469138840358937
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:38,411 INFO epoch # 2240 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0042-> 0.0042 -loss = 0.009390943727339618
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:38,411 INFO *** epoch 2240, rolling-avg-loss (window=10)= 0.00953090690964018
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:38,430 INFO epoch # 2241 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0042-> 0.0042 -loss = 0.009486188391747419
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:38,448 INFO epoch # 2242 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0042-> 0.0042 -loss = 0.009576832460879814
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:38,466 INFO epoch # 2243 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0042-> 0.0042 -loss = 0.009460684734222014
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:38,484 INFO epoch # 2244 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0042-> 0.0042 -loss = 0.009937966577126645
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:38,503 INFO epoch # 2245 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0042-> 0.0042 -loss = 0.009494344601989724
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:38,521 INFO epoch # 2246 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0042-> 0.0042 -loss = 0.009461489164095838
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:38,539 INFO epoch # 2247 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0042-> 0.0042 -loss = 0.009403779884451069
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:38,558 INFO epoch # 2248 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0042-> 0.0041 -loss = 0.009475473205384333
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:38,576 INFO epoch # 2249 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0041-> 0.0041 -loss = 0.009451844096474815
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:38,595 INFO epoch # 2250 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0041-> 0.0041 -loss = 0.009442636372114066
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:38,595 INFO *** epoch 2250, rolling-avg-loss (window=10)= 0.009519123948848573
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:38,613 INFO epoch # 2251 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0041-> 0.0041 -loss = 0.009465655872190837
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:38,632 INFO epoch # 2252 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0041-> 0.0041 -loss = 0.009378004098834936
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:38,650 INFO epoch # 2253 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0041-> 0.0041 -loss = 0.009396923727763351
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:38,668 INFO epoch # 2254 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0041-> 0.0041 -loss = 0.009438068766030483
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:38,686 INFO epoch # 2255 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0041-> 0.0041 -loss = 0.009428027689864393
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:38,705 INFO epoch # 2256 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0041-> 0.0041 -loss = 0.009366529899125453
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:38,723 INFO epoch # 2257 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0041-> 0.0041 -loss = 0.009700404130853713
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:38,742 INFO epoch # 2258 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0041-> 0.0041 -loss = 0.009464762180869002
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:38,760 INFO epoch # 2259 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0041-> 0.0041 -loss = 0.009458361302677076
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:38,779 INFO epoch # 2260 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0041-> 0.0041 -loss = 0.009391124243848026
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:38,779 INFO *** epoch 2260, rolling-avg-loss (window=10)= 0.009448786191205727
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:38,797 INFO epoch # 2261 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0041-> 0.0041 -loss = 0.009472995159740094
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:38,816 INFO epoch # 2262 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0041-> 0.0041 -loss = 0.009581590122252237
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:38,834 INFO epoch # 2263 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0041-> 0.0041 -loss = 0.010280879272613674
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:38,852 INFO epoch # 2264 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0041-> 0.0041 -loss = 0.009595841132977512
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:38,870 INFO epoch # 2265 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0041-> 0.0041 -loss = 0.009539140984998085
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:38,889 INFO epoch # 2266 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0041-> 0.0041 -loss = 0.00952268393302802
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:38,907 INFO epoch # 2267 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0041-> 0.0041 -loss = 0.009494230245763902
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:38,925 INFO epoch # 2268 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0041-> 0.0041 -loss = 0.009398991031048354
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:38,944 INFO epoch # 2269 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0041-> 0.0041 -loss = 0.009671315085142851
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:38,962 INFO epoch # 2270 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0041-> 0.0041 -loss = 0.00942108671006281
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:38,962 INFO *** epoch 2270, rolling-avg-loss (window=10)= 0.009597875367762753
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:38,981 INFO epoch # 2271 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0041-> 0.0041 -loss = 0.00957489715074189
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:38,999 INFO epoch # 2272 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0041-> 0.0041 -loss = 0.009513833079836331
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:39,017 INFO epoch # 2273 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0041-> 0.0041 -loss = 0.009430003647139529
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:39,036 INFO epoch # 2274 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0041-> 0.0041 -loss = 0.009428963014215697
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:39,054 INFO epoch # 2275 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0041-> 0.0041 -loss = 0.009387510028318502
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:39,072 INFO epoch # 2276 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0041-> 0.0041 -loss = 0.009643990997574292
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:39,090 INFO epoch # 2277 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0041-> 0.0041 -loss = 0.009441462869290262
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:39,109 INFO epoch # 2278 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0041-> 0.004 -loss = 0.009461995105084497
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:39,127 INFO epoch # 2279 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.004-> 0.004 -loss = 0.009380611212691292
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:39,146 INFO epoch # 2280 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.004-> 0.004 -loss = 0.009317715554061579
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:39,146 INFO *** epoch 2280, rolling-avg-loss (window=10)= 0.009458098265895387
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:39,164 INFO epoch # 2281 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.004-> 0.004 -loss = 0.00942382629000349
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:39,182 INFO epoch # 2282 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.004-> 0.004 -loss = 0.009656869668106083
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:39,201 INFO epoch # 2283 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.004-> 0.004 -loss = 0.009473262914980296
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:39,219 INFO epoch # 2284 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.004-> 0.004 -loss = 0.009445933166716713
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:39,237 INFO epoch # 2285 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.004-> 0.004 -loss = 0.009446527554246131
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:39,255 INFO epoch # 2286 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.004-> 0.004 -loss = 0.009575401694746688
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:39,273 INFO epoch # 2287 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.004-> 0.004 -loss = 0.0094614252957399
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:39,292 INFO epoch # 2288 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.004-> 0.004 -loss = 0.009689678219729103
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:39,310 INFO epoch # 2289 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.004-> 0.004 -loss = 0.00972747070773039
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:39,328 INFO epoch # 2290 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.004-> 0.004 -loss = 0.009358271068776958
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:39,328 INFO *** epoch 2290, rolling-avg-loss (window=10)= 0.009525866658077576
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:39,347 INFO epoch # 2291 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.004-> 0.004 -loss = 0.009367488568386761
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:39,366 INFO epoch # 2292 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.004-> 0.004 -loss = 0.009435951978957746
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:39,385 INFO epoch # 2293 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.004-> 0.004 -loss = 0.009313737493357621
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:39,404 INFO epoch # 2294 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.004-> 0.004 -loss = 0.009479433399974369
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:39,422 INFO epoch # 2295 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.004-> 0.004 -loss = 0.009329236359917559
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:39,440 INFO epoch # 2296 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.004-> 0.004 -loss = 0.009434336185222492
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:39,458 INFO epoch # 2297 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.004-> 0.004 -loss = 0.009303596343670506
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:39,477 INFO epoch # 2298 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.004-> 0.004 -loss = 0.009297936998336809
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:39,495 INFO epoch # 2299 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.004-> 0.004 -loss = 0.009357620467199013
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:39,513 INFO epoch # 2300 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.004-> 0.004 -loss = 0.009250107501429738
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:39,513 INFO *** epoch 2300, rolling-avg-loss (window=10)= 0.00935694452964526
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:39,532 INFO epoch # 2301 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.004-> 0.004 -loss = 0.009603326805518009
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:39,550 INFO epoch # 2302 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.004-> 0.004 -loss = 0.009406528486579191
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:39,569 INFO epoch # 2303 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.004-> 0.004 -loss = 0.00955542932570097
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:39,587 INFO epoch # 2304 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.004-> 0.004 -loss = 0.00931314561603358
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:39,606 INFO epoch # 2305 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.004-> 0.004 -loss = 0.00937509579671314
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:39,624 INFO epoch # 2306 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.004-> 0.004 -loss = 0.009397492562129628
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:39,642 INFO epoch # 2307 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.004-> 0.004 -loss = 0.009276647055230569
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:39,660 INFO epoch # 2308 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.004-> 0.004 -loss = 0.009400092872965615
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:39,678 INFO epoch # 2309 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.004-> 0.004 -loss = 0.009356890735944035
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:39,697 INFO epoch # 2310 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.004-> 0.004 -loss = 0.009292789101891685
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:39,697 INFO *** epoch 2310, rolling-avg-loss (window=10)= 0.009397743835870642
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:39,715 INFO epoch # 2311 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.004-> 0.004 -loss = 0.009996069849876221
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:39,734 INFO epoch # 2312 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.004-> 0.004 -loss = 0.009425682459550444
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:39,752 INFO epoch # 2313 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.004-> 0.004 -loss = 0.009319922759459587
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:39,771 INFO epoch # 2314 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.004-> 0.004 -loss = 0.009375681111123413
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:39,789 INFO epoch # 2315 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.004-> 0.004 -loss = 0.009473101883486379
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:39,808 INFO epoch # 2316 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.004-> 0.004 -loss = 0.00932629451926914
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:39,826 INFO epoch # 2317 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.004-> 0.004 -loss = 0.009952424890798284
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:39,844 INFO epoch # 2318 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.004-> 0.004 -loss = 0.009345801645395113
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:39,863 INFO epoch # 2319 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.004-> 0.004 -loss = 0.009298559045419097
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:39,881 INFO epoch # 2320 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.004-> 0.004 -loss = 0.009295926516642794
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:39,881 INFO *** epoch 2320, rolling-avg-loss (window=10)= 0.009480946468102047
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:39,899 INFO epoch # 2321 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.004-> 0.004 -loss = 0.009227632890542736
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:39,918 INFO epoch # 2322 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.004-> 0.004 -loss = 0.00924657890573144
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:39,937 INFO epoch # 2323 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.004-> 0.004 -loss = 0.009326007435447536
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:39,956 INFO epoch # 2324 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.004-> 0.004 -loss = 0.009272509327274747
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:39,975 INFO epoch # 2325 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.004-> 0.004 -loss = 0.009334953989309724
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:39,993 INFO epoch # 2326 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.004-> 0.004 -loss = 0.009538286984025035
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:40,012 INFO epoch # 2327 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.004-> 0.004 -loss = 0.009253686883312184
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:40,030 INFO epoch # 2328 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.004-> 0.004 -loss = 0.009366117148601916
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:40,049 INFO epoch # 2329 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.004-> 0.004 -loss = 0.00927626602788223
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:40,067 INFO epoch # 2330 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.004-> 0.004 -loss = 0.009240483363100793
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:40,067 INFO *** epoch 2330, rolling-avg-loss (window=10)= 0.009308252295522835
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:40,085 INFO epoch # 2331 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.004-> 0.004 -loss = 0.009422885297681205
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:40,104 INFO epoch # 2332 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.004-> 0.004 -loss = 0.009170396646368317
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:40,123 INFO epoch # 2333 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.004-> 0.004 -loss = 0.009259323342121206
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:40,142 INFO epoch # 2334 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.004-> 0.004 -loss = 0.009241631931217853
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:40,160 INFO epoch # 2335 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.004-> 0.004 -loss = 0.009242688349331729
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:40,179 INFO epoch # 2336 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.004-> 0.004 -loss = 0.00984504580264911
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:40,197 INFO epoch # 2337 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.004-> 0.004 -loss = 0.009323280246462673
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:40,215 INFO epoch # 2338 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.004-> 0.004 -loss = 0.009189454474835657
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:40,234 INFO epoch # 2339 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.004-> 0.004 -loss = 0.009351882938062772
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:40,252 INFO epoch # 2340 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.004-> 0.004 -loss = 0.009203951311064884
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:40,252 INFO *** epoch 2340, rolling-avg-loss (window=10)= 0.00932505403397954
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:40,270 INFO epoch # 2341 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.004-> 0.004 -loss = 0.009408753616298782
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:40,288 INFO epoch # 2342 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.004-> 0.004 -loss = 0.009188121675833827
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:40,306 INFO epoch # 2343 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.004-> 0.0039 -loss = 0.009310086228651926
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:40,325 INFO epoch # 2344 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0039-> 0.0039 -loss = 0.00919696839991957
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:40,343 INFO epoch # 2345 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0039-> 0.0039 -loss = 0.00953456612478476
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:40,362 INFO epoch # 2346 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0039-> 0.0039 -loss = 0.01156816614093259
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:40,380 INFO epoch # 2347 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0039-> 0.0039 -loss = 0.00964554164238507
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:40,399 INFO epoch # 2348 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0039-> 0.0039 -loss = 0.009232559481461067
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:40,417 INFO epoch # 2349 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0039-> 0.0039 -loss = 0.009265828561183298
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:40,435 INFO epoch # 2350 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0039-> 0.0039 -loss = 0.009294841380324215
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:40,435 INFO *** epoch 2350, rolling-avg-loss (window=10)= 0.00956454332517751
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:40,453 INFO epoch # 2351 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0039-> 0.0039 -loss = 0.009140447844401933
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:40,472 INFO epoch # 2352 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0039-> 0.0039 -loss = 0.009694503060018178
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:40,490 INFO epoch # 2353 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0039-> 0.0039 -loss = 0.009307703268859768
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:40,508 INFO epoch # 2354 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0039-> 0.0039 -loss = 0.009307368934969418
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:40,527 INFO epoch # 2355 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0039-> 0.0039 -loss = 0.009136793385550845
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:40,545 INFO epoch # 2356 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0039-> 0.0039 -loss = 0.009185598908516113
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:40,564 INFO epoch # 2357 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0039-> 0.0039 -loss = 0.012591465565492399
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:40,582 INFO epoch # 2358 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0039-> 0.0039 -loss = 0.009419438501936384
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:40,601 INFO epoch # 2359 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0039-> 0.0039 -loss = 0.009302786515036132
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:40,619 INFO epoch # 2360 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0039-> 0.0039 -loss = 0.009255627119273413
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:40,620 INFO *** epoch 2360, rolling-avg-loss (window=10)= 0.009634173310405458
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:40,638 INFO epoch # 2361 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0039-> 0.0039 -loss = 0.009146017662715167
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:40,656 INFO epoch # 2362 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0039-> 0.0039 -loss = 0.009108325764827896
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:40,674 INFO epoch # 2363 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0039-> 0.0039 -loss = 0.009414406136784237
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:40,693 INFO epoch # 2364 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0039-> 0.0039 -loss = 0.009238556980562862
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:40,711 INFO epoch # 2365 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0039-> 0.0039 -loss = 0.009338032185041811
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:40,729 INFO epoch # 2366 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0039-> 0.0039 -loss = 0.009483210662438069
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:40,748 INFO epoch # 2367 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0039-> 0.0039 -loss = 0.00919773386704037
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:40,767 INFO epoch # 2368 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0039-> 0.0039 -loss = 0.00923719204729423
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:40,785 INFO epoch # 2369 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0039-> 0.0039 -loss = 0.009116192708461313
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:40,804 INFO epoch # 2370 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0039-> 0.0039 -loss = 0.009247786547348369
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:40,804 INFO *** epoch 2370, rolling-avg-loss (window=10)= 0.009252745456251432
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:40,822 INFO epoch # 2371 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0039-> 0.0039 -loss = 0.009279512763896491
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:40,841 INFO epoch # 2372 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0039-> 0.0039 -loss = 0.009192618250381202
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:40,859 INFO epoch # 2373 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0039-> 0.0039 -loss = 0.009195628666930133
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:40,877 INFO epoch # 2374 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0039-> 0.0039 -loss = 0.009175350351142697
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:40,895 INFO epoch # 2375 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0039-> 0.0039 -loss = 0.009071291613508947
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:40,914 INFO epoch # 2376 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0039-> 0.0039 -loss = 0.009170938268653117
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:40,932 INFO epoch # 2377 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0039-> 0.0039 -loss = 0.009277886216295883
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:40,951 INFO epoch # 2378 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0039-> 0.0039 -loss = 0.009189550459268503
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:40,969 INFO epoch # 2379 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0039-> 0.0039 -loss = 0.00977565070206765
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:40,988 INFO epoch # 2380 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0039-> 0.0039 -loss = 0.009259410257072886
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:40,988 INFO *** epoch 2380, rolling-avg-loss (window=10)= 0.009258783754921751
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:41,006 INFO epoch # 2381 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0039-> 0.0039 -loss = 0.009276576922275126
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:41,024 INFO epoch # 2382 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0039-> 0.0039 -loss = 0.00925122712214943
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:41,043 INFO epoch # 2383 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0039-> 0.0039 -loss = 0.009971417071938049
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:41,061 INFO epoch # 2384 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0039-> 0.0039 -loss = 0.00932661409751745
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:41,079 INFO epoch # 2385 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0039-> 0.0039 -loss = 0.009231698997609783
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:41,097 INFO epoch # 2386 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0039-> 0.0038 -loss = 0.009097986563574523
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:41,116 INFO epoch # 2387 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0038-> 0.0038 -loss = 0.009179904773191083
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:41,134 INFO epoch # 2388 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0038-> 0.0038 -loss = 0.009167836404230911
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:41,153 INFO epoch # 2389 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0038-> 0.0038 -loss = 0.009254419554054039
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:41,171 INFO epoch # 2390 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0038-> 0.0038 -loss = 0.009249074588296935
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:41,171 INFO *** epoch 2390, rolling-avg-loss (window=10)= 0.009300675609483732
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:41,189 INFO epoch # 2391 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0038-> 0.0038 -loss = 0.009287889886763878
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:41,208 INFO epoch # 2392 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0038-> 0.0038 -loss = 0.00912566295301076
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:41,226 INFO epoch # 2393 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0038-> 0.0038 -loss = 0.00909161501476774
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:41,245 INFO epoch # 2394 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0038-> 0.0038 -loss = 0.009133624735113699
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:41,263 INFO epoch # 2395 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0038-> 0.0038 -loss = 0.00906730022688862
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:41,281 INFO epoch # 2396 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0038-> 0.0038 -loss = 0.009166952091618441
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:41,299 INFO epoch # 2397 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0038-> 0.0038 -loss = 0.009200693035381846
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:41,318 INFO epoch # 2398 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0038-> 0.0038 -loss = 0.009181587025523186
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:41,336 INFO epoch # 2399 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0038-> 0.0038 -loss = 0.009154542054602643
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:41,355 INFO epoch # 2400 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0038-> 0.0038 -loss = 0.009256673707568552
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:41,355 INFO *** epoch 2400, rolling-avg-loss (window=10)= 0.009166654073123937
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:41,373 INFO epoch # 2401 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0038-> 0.0038 -loss = 0.009149864796199836
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:41,392 INFO epoch # 2402 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0038-> 0.0038 -loss = 0.009117459820117801
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:41,410 INFO epoch # 2403 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0038-> 0.0038 -loss = 0.009072487264347728
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:41,428 INFO epoch # 2404 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0038-> 0.0038 -loss = 0.009297256605350412
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:41,446 INFO epoch # 2405 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0038-> 0.0038 -loss = 0.009365010831970721
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:41,464 INFO epoch # 2406 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0038-> 0.0038 -loss = 0.009321552366600372
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:41,483 INFO epoch # 2407 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0038-> 0.0038 -loss = 0.009075727361050667
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:41,501 INFO epoch # 2408 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0038-> 0.0038 -loss = 0.009204326175677124
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:41,519 INFO epoch # 2409 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0038-> 0.0038 -loss = 0.009088767874345649
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:41,538 INFO epoch # 2410 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0038-> 0.0038 -loss = 0.009450571262277663
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:41,538 INFO *** epoch 2410, rolling-avg-loss (window=10)= 0.009214302435793797
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:41,556 INFO epoch # 2411 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0038-> 0.0038 -loss = 0.011842157553473953
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:41,575 INFO epoch # 2412 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0038-> 0.0038 -loss = 0.009270869835745543
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:41,593 INFO epoch # 2413 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0038-> 0.0038 -loss = 0.00909775839318172
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:41,612 INFO epoch # 2414 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0038-> 0.0038 -loss = 0.009189520940708462
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:41,630 INFO epoch # 2415 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0038-> 0.0038 -loss = 0.009371278167236596
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:41,649 INFO epoch # 2416 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0038-> 0.0038 -loss = 0.009044170532433782
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:41,667 INFO epoch # 2417 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0038-> 0.0038 -loss = 0.00912108329066541
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:41,685 INFO epoch # 2418 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0038-> 0.0038 -loss = 0.009113655003602616
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:41,703 INFO epoch # 2419 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0038-> 0.0038 -loss = 0.009066250364412554
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:41,721 INFO epoch # 2420 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0038-> 0.0038 -loss = 0.009186892733850982
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:41,721 INFO *** epoch 2420, rolling-avg-loss (window=10)= 0.009430363681531162
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:41,740 INFO epoch # 2421 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0038-> 0.0038 -loss = 0.009133642764936667
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:41,758 INFO epoch # 2422 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0038-> 0.0038 -loss = 0.009079429437406361
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:41,777 INFO epoch # 2423 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0038-> 0.0038 -loss = 0.009308234919444658
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:41,796 INFO epoch # 2424 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0038-> 0.0038 -loss = 0.00914455911697587
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:41,814 INFO epoch # 2425 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0038-> 0.0038 -loss = 0.009056117312866263
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:41,833 INFO epoch # 2426 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0038-> 0.0038 -loss = 0.00906664573631133
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:41,851 INFO epoch # 2427 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0038-> 0.0038 -loss = 0.00905385897749511
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:41,869 INFO epoch # 2428 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0038-> 0.0038 -loss = 0.009081817257538205
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:41,888 INFO epoch # 2429 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0038-> 0.0038 -loss = 0.009098438993532909
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:41,906 INFO epoch # 2430 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0038-> 0.0038 -loss = 0.009351393877295777
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:41,906 INFO *** epoch 2430, rolling-avg-loss (window=10)= 0.009137413839380316
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:41,924 INFO epoch # 2431 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0038-> 0.0038 -loss = 0.009102563693886623
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:41,943 INFO epoch # 2432 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0038-> 0.0038 -loss = 0.009421695263881702
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:41,962 INFO epoch # 2433 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0038-> 0.0038 -loss = 0.009006218300783075
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:41,981 INFO epoch # 2434 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0038-> 0.0038 -loss = 0.009054910526174353
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:41,999 INFO epoch # 2435 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0038-> 0.0038 -loss = 0.009152767437626608
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:42,018 INFO epoch # 2436 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0038-> 0.0038 -loss = 0.009244159817171749
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:42,037 INFO epoch # 2437 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0038-> 0.0038 -loss = 0.009130607817496639
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:42,055 INFO epoch # 2438 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0038-> 0.0038 -loss = 0.009062437908141874
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:42,073 INFO epoch # 2439 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0038-> 0.0038 -loss = 0.00900714761519339
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:42,092 INFO epoch # 2440 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0038-> 0.0038 -loss = 0.009119029517023591
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:42,092 INFO *** epoch 2440, rolling-avg-loss (window=10)= 0.009130153789737961
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:42,110 INFO epoch # 2441 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0038-> 0.0038 -loss = 0.008998481767775957
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:42,128 INFO epoch # 2442 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0038-> 0.0038 -loss = 0.009162821836071089
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:42,147 INFO epoch # 2443 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0038-> 0.0038 -loss = 0.009104253407713259
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:42,165 INFO epoch # 2444 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0038-> 0.0038 -loss = 0.009067002290976234
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:42,183 INFO epoch # 2445 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0038-> 0.0038 -loss = 0.010002705275837798
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:42,202 INFO epoch # 2446 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0038-> 0.0038 -loss = 0.014198259334079921
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:42,220 INFO epoch # 2447 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0038-> 0.0038 -loss = 0.009569438163453015
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:42,238 INFO epoch # 2448 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0038-> 0.0038 -loss = 0.009053168490936514
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:42,257 INFO epoch # 2449 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0038-> 0.0038 -loss = 0.009056113769474905
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:42,275 INFO epoch # 2450 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0038-> 0.0038 -loss = 0.009036475981702097
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:42,275 INFO *** epoch 2450, rolling-avg-loss (window=10)= 0.009724872031802079
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:42,293 INFO epoch # 2451 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0038-> 0.0038 -loss = 0.009075576999748591
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:42,311 INFO epoch # 2452 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0038-> 0.0038 -loss = 0.008957812824519351
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:42,330 INFO epoch # 2453 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0038-> 0.0038 -loss = 0.009214515819621738
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:42,348 INFO epoch # 2454 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0038-> 0.0038 -loss = 0.009057745730387978
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:42,366 INFO epoch # 2455 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0038-> 0.0038 -loss = 0.009082017797481967
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:42,385 INFO epoch # 2456 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0038-> 0.0038 -loss = 0.008965736138634384
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:42,403 INFO epoch # 2457 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0038-> 0.0038 -loss = 0.009008279266708996
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:42,422 INFO epoch # 2458 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0038-> 0.0038 -loss = 0.009047429746715352
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:42,440 INFO epoch # 2459 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0038-> 0.0038 -loss = 0.009019586381327827
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:42,459 INFO epoch # 2460 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0038-> 0.0038 -loss = 0.009055427035491448
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:42,459 INFO *** epoch 2460, rolling-avg-loss (window=10)= 0.009048412774063763
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:42,477 INFO epoch # 2461 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0038-> 0.0038 -loss = 0.00920633156056283
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:42,495 INFO epoch # 2462 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0038-> 0.0038 -loss = 0.009033499372890219
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:42,513 INFO epoch # 2463 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0038-> 0.0037 -loss = 0.009155595325864851
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:42,532 INFO epoch # 2464 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0037-> 0.0037 -loss = 0.008900762237317394
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:42,550 INFO epoch # 2465 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0037-> 0.0037 -loss = 0.009096182009670883
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:42,568 INFO epoch # 2466 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0037-> 0.0037 -loss = 0.009082596232474316
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:42,587 INFO epoch # 2467 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0037-> 0.0037 -loss = 0.00913223218958592
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:42,606 INFO epoch # 2468 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0037-> 0.0037 -loss = 0.009000637495773844
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:42,624 INFO epoch # 2469 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0037-> 0.0037 -loss = 0.00901335174421547
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:42,642 INFO epoch # 2470 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0037-> 0.0037 -loss = 0.008990128120785812
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:42,643 INFO *** epoch 2470, rolling-avg-loss (window=10)= 0.009061131628914153
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:42,661 INFO epoch # 2471 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0037-> 0.0037 -loss = 0.008983279771200614
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:42,679 INFO epoch # 2472 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0037-> 0.0037 -loss = 0.009012368598632747
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:42,697 INFO epoch # 2473 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0037-> 0.0037 -loss = 0.008958508777141105
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:42,715 INFO epoch # 2474 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0037-> 0.0037 -loss = 0.009288557535910513
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:42,733 INFO epoch # 2475 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0037-> 0.0037 -loss = 0.009453172635403462
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:42,752 INFO epoch # 2476 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0037-> 0.0037 -loss = 0.009073785509826848
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:42,770 INFO epoch # 2477 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0037-> 0.0037 -loss = 0.0089970728076878
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:42,788 INFO epoch # 2478 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0037-> 0.0037 -loss = 0.008943129731051158
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:42,807 INFO epoch # 2479 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0037-> 0.0037 -loss = 0.009042656594829168
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:42,825 INFO epoch # 2480 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0037-> 0.0037 -loss = 0.009034087735926732
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:42,825 INFO *** epoch 2480, rolling-avg-loss (window=10)= 0.009078661969761015
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:42,844 INFO epoch # 2481 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0037-> 0.0037 -loss = 0.008958172038546763
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:42,862 INFO epoch # 2482 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0037-> 0.0037 -loss = 0.008984698593849316
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:42,880 INFO epoch # 2483 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0037-> 0.0037 -loss = 0.008924834852223285
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:42,898 INFO epoch # 2484 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0037-> 0.0037 -loss = 0.009029740205733106
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:42,917 INFO epoch # 2485 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0037-> 0.0037 -loss = 0.008867867691151332
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:42,935 INFO epoch # 2486 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0037-> 0.0037 -loss = 0.00907162243311177
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:42,953 INFO epoch # 2487 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0037-> 0.0037 -loss = 0.009103598960791714
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:42,972 INFO epoch # 2488 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0037-> 0.0037 -loss = 0.008899582864614786
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:42,991 INFO epoch # 2489 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0037-> 0.0037 -loss = 0.008958350146713201
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:43,010 INFO epoch # 2490 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0037-> 0.0037 -loss = 0.008993568604637403
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:43,010 INFO *** epoch 2490, rolling-avg-loss (window=10)= 0.008979203639137267
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:43,029 INFO epoch # 2491 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0037-> 0.0037 -loss = 0.008953444281360134
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:43,047 INFO epoch # 2492 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0037-> 0.0037 -loss = 0.009123494382947683
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:43,066 INFO epoch # 2493 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0037-> 0.0037 -loss = 0.00900243501382647
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:43,084 INFO epoch # 2494 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0037-> 0.0037 -loss = 0.009070607437024591
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:43,102 INFO epoch # 2495 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0037-> 0.0037 -loss = 0.009102993441047147
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:43,120 INFO epoch # 2496 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0037-> 0.0037 -loss = 0.008949427465267945
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:43,139 INFO epoch # 2497 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0037-> 0.0037 -loss = 0.009103544791287277
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:43,157 INFO epoch # 2498 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0037-> 0.0037 -loss = 0.00981802970636636
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:43,175 INFO epoch # 2499 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0037-> 0.0037 -loss = 0.00902117265650304
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:43,193 INFO epoch # 2500 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0037-> 0.0037 -loss = 0.008997729659313336
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:43,194 INFO *** epoch 2500, rolling-avg-loss (window=10)= 0.009114287883494398
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:43,212 INFO epoch # 2501 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0037-> 0.0037 -loss = 0.009011663125420455
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:43,230 INFO epoch # 2502 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0037-> 0.0037 -loss = 0.008987172906927299
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:43,249 INFO epoch # 2503 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0037-> 0.0037 -loss = 0.009029706154251471
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:43,267 INFO epoch # 2504 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0037-> 0.0037 -loss = 0.009009886285639368
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:43,285 INFO epoch # 2505 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0037-> 0.0037 -loss = 0.008849890502460767
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:43,303 INFO epoch # 2506 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0037-> 0.0037 -loss = 0.008813659849693067
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:43,322 INFO epoch # 2507 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0037-> 0.0037 -loss = 0.008843937537676538
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:43,340 INFO epoch # 2508 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0037-> 0.0037 -loss = 0.008983612700831145
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:43,358 INFO epoch # 2509 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0037-> 0.0037 -loss = 0.008930555406550411
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:43,377 INFO epoch # 2510 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0037-> 0.0037 -loss = 0.009006892978504766
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:43,377 INFO *** epoch 2510, rolling-avg-loss (window=10)= 0.008946697744795529
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:43,395 INFO epoch # 2511 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0037-> 0.0037 -loss = 0.00917497068803641
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:43,413 INFO epoch # 2512 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0037-> 0.0037 -loss = 0.00932499826012645
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:43,432 INFO epoch # 2513 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0037-> 0.0037 -loss = 0.009041162396897562
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:43,450 INFO epoch # 2514 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0037-> 0.0037 -loss = 0.008982136227132287
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:43,468 INFO epoch # 2515 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0037-> 0.0037 -loss = 0.009195199352689087
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:43,487 INFO epoch # 2516 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0037-> 0.0037 -loss = 0.009013882765430026
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:43,505 INFO epoch # 2517 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0037-> 0.0036 -loss = 0.00905910569417756
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:43,523 INFO epoch # 2518 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0036-> 0.0036 -loss = 0.008988182591565419
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:43,541 INFO epoch # 2519 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0036-> 0.0036 -loss = 0.008941834392317105
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:43,560 INFO epoch # 2520 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0036-> 0.0036 -loss = 0.008910779499274213
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:43,560 INFO *** epoch 2520, rolling-avg-loss (window=10)= 0.009063225186764612
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:43,578 INFO epoch # 2521 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0036-> 0.0036 -loss = 0.00884858120844001
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:43,597 INFO epoch # 2522 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0036-> 0.0036 -loss = 0.008862762799253687
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:43,615 INFO epoch # 2523 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0036-> 0.0036 -loss = 0.008912115612474736
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:43,634 INFO epoch # 2524 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0036-> 0.0036 -loss = 0.008906260125513654
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:43,652 INFO epoch # 2525 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0036-> 0.0036 -loss = 0.008881175868737046
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:43,670 INFO epoch # 2526 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0036-> 0.0036 -loss = 0.008854863961460069
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:43,689 INFO epoch # 2527 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0036-> 0.0036 -loss = 0.009152022015769035
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:43,707 INFO epoch # 2528 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0036-> 0.0036 -loss = 0.009453560982365161
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:43,725 INFO epoch # 2529 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0036-> 0.0036 -loss = 0.008835958211420802
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:43,743 INFO epoch # 2530 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0036-> 0.0036 -loss = 0.009027527485159226
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:43,743 INFO *** epoch 2530, rolling-avg-loss (window=10)= 0.008973482827059343
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:43,762 INFO epoch # 2531 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0036-> 0.0036 -loss = 0.008756994273426244
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:43,780 INFO epoch # 2532 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0036-> 0.0036 -loss = 0.009005047431855928
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:43,799 INFO epoch # 2533 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0036-> 0.0036 -loss = 0.009307865926530212
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:43,817 INFO epoch # 2534 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0036-> 0.0036 -loss = 0.009107698846491985
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:43,836 INFO epoch # 2535 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0036-> 0.0036 -loss = 0.00896545134310145
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:43,854 INFO epoch # 2536 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0036-> 0.0036 -loss = 0.008851170779962558
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:43,873 INFO epoch # 2537 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0036-> 0.0036 -loss = 0.008855074724124279
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:43,891 INFO epoch # 2538 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0036-> 0.0036 -loss = 0.0088336435801466
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:43,909 INFO epoch # 2539 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0036-> 0.0036 -loss = 0.008894292150216643
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:43,927 INFO epoch # 2540 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0036-> 0.0036 -loss = 0.008840962356771342
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:43,927 INFO *** epoch 2540, rolling-avg-loss (window=10)= 0.008941820141262723
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:43,945 INFO epoch # 2541 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0036-> 0.0036 -loss = 0.008848291050526313
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:43,964 INFO epoch # 2542 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0036-> 0.0036 -loss = 0.00886346586048603
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:43,982 INFO epoch # 2543 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0036-> 0.0036 -loss = 0.008830253933410859
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:44,001 INFO epoch # 2544 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0036-> 0.0036 -loss = 0.008915058984712232
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:44,020 INFO epoch # 2545 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0036-> 0.0036 -loss = 0.008848826051689684
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:44,038 INFO epoch # 2546 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0036-> 0.0036 -loss = 0.008973165444331244
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:44,056 INFO epoch # 2547 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0036-> 0.0036 -loss = 0.008919248251913814
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:44,075 INFO epoch # 2548 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0036-> 0.0036 -loss = 0.008838302055664826
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:44,093 INFO epoch # 2549 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0036-> 0.0036 -loss = 0.008999327714263927
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:44,111 INFO epoch # 2550 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0036-> 0.0036 -loss = 0.008894606296962593
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:44,111 INFO *** epoch 2550, rolling-avg-loss (window=10)= 0.008893054564396152
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:44,129 INFO epoch # 2551 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0036-> 0.0036 -loss = 0.0088164683766081
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:44,147 INFO epoch # 2552 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0036-> 0.0036 -loss = 0.008855449290422257
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:44,166 INFO epoch # 2553 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0036-> 0.0035 -loss = 0.008956097248301376
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:44,184 INFO epoch # 2554 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0035-> 0.0035 -loss = 0.00893437268678099
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:44,202 INFO epoch # 2555 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0035-> 0.0035 -loss = 0.008910146723792423
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:44,221 INFO epoch # 2556 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0035-> 0.0035 -loss = 0.008805391862551915
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:44,239 INFO epoch # 2557 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0035-> 0.0035 -loss = 0.008988597044663038
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:44,258 INFO epoch # 2558 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0035-> 0.0035 -loss = 0.009012071648612618
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:44,276 INFO epoch # 2559 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0035-> 0.0035 -loss = 0.008908036536013242
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:44,294 INFO epoch # 2560 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0035-> 0.0035 -loss = 0.008914091071346775
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:44,294 INFO *** epoch 2560, rolling-avg-loss (window=10)= 0.008910072248909273
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:44,312 INFO epoch # 2561 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0035-> 0.0035 -loss = 0.00890724512282759
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:44,331 INFO epoch # 2562 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0035-> 0.0035 -loss = 0.008787423434114316
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:44,349 INFO epoch # 2563 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0035-> 0.0035 -loss = 0.008779952862823848
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:44,367 INFO epoch # 2564 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0035-> 0.0035 -loss = 0.009041750985488761
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:44,386 INFO epoch # 2565 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0035-> 0.0035 -loss = 0.008880129920726176
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:44,404 INFO epoch # 2566 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0035-> 0.0035 -loss = 0.00886524107409059
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:44,422 INFO epoch # 2567 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0035-> 0.0035 -loss = 0.008766188915615203
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:44,441 INFO epoch # 2568 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0035-> 0.0035 -loss = 0.008829954946122598
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:44,459 INFO epoch # 2569 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0035-> 0.0035 -loss = 0.008926208778575528
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:44,477 INFO epoch # 2570 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0035-> 0.0035 -loss = 0.008850978723785374
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:44,477 INFO *** epoch 2570, rolling-avg-loss (window=10)= 0.008863507476417
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:44,496 INFO epoch # 2571 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0035-> 0.0035 -loss = 0.00876304294433794
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:44,514 INFO epoch # 2572 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0035-> 0.0035 -loss = 0.008766721191932447
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:44,532 INFO epoch # 2573 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0035-> 0.0035 -loss = 0.008829487927869195
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:44,551 INFO epoch # 2574 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0035-> 0.0035 -loss = 0.008736804549698718
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:44,569 INFO epoch # 2575 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0035-> 0.0035 -loss = 0.008777659601037158
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:44,588 INFO epoch # 2576 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0035-> 0.0035 -loss = 0.008885953699063975
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:44,606 INFO epoch # 2577 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0035-> 0.0035 -loss = 0.008772090914135333
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:44,625 INFO epoch # 2578 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0035-> 0.0035 -loss = 0.008868896238709567
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:44,643 INFO epoch # 2579 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0035-> 0.0035 -loss = 0.008784866564383265
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:44,661 INFO epoch # 2580 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0035-> 0.0035 -loss = 0.00878410178120248
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:44,662 INFO *** epoch 2580, rolling-avg-loss (window=10)= 0.008796962541237009
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:44,680 INFO epoch # 2581 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0035-> 0.0035 -loss = 0.00877299768399098
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:44,698 INFO epoch # 2582 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0035-> 0.0035 -loss = 0.008744798411498778
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:44,716 INFO epoch # 2583 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0035-> 0.0035 -loss = 0.008829616384900874
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:44,735 INFO epoch # 2584 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0035-> 0.0035 -loss = 0.008770016833295813
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:44,753 INFO epoch # 2585 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0035-> 0.0034 -loss = 0.008830487182422075
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:44,771 INFO epoch # 2586 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0034-> 0.0034 -loss = 0.009132312348810956
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:44,790 INFO epoch # 2587 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0034-> 0.0034 -loss = 0.008799645605904516
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:44,808 INFO epoch # 2588 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0034-> 0.0034 -loss = 0.008828547390294261
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:44,827 INFO epoch # 2589 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0034-> 0.0034 -loss = 0.008803980308584869
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:44,845 INFO epoch # 2590 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0034-> 0.0034 -loss = 0.008720507321413606
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:44,845 INFO *** epoch 2590, rolling-avg-loss (window=10)= 0.008823290947111673
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:44,864 INFO epoch # 2591 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0034-> 0.0034 -loss = 0.00864046879723901
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:44,882 INFO epoch # 2592 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0034-> 0.0034 -loss = 0.008884372968168464
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:44,900 INFO epoch # 2593 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0034-> 0.0034 -loss = 0.00877374396804953
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:44,918 INFO epoch # 2594 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0034-> 0.0034 -loss = 0.008870083176589105
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:44,936 INFO epoch # 2595 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0034-> 0.0034 -loss = 0.008976998113212176
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:44,955 INFO epoch # 2596 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0034-> 0.0034 -loss = 0.008851314487401396
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:44,973 INFO epoch # 2597 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0034-> 0.0034 -loss = 0.008690578481036937
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:44,991 INFO epoch # 2598 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0034-> 0.0034 -loss = 0.008766977385676
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:45,010 INFO epoch # 2599 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0034-> 0.0034 -loss = 0.008855123414832633
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:45,028 INFO epoch # 2600 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0034-> 0.0034 -loss = 0.008784066842054017
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:45,028 INFO *** epoch 2600, rolling-avg-loss (window=10)= 0.008809372763425926
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:45,046 INFO epoch # 2601 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0034-> 0.0034 -loss = 0.008748547013965435
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:45,065 INFO epoch # 2602 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0034-> 0.0034 -loss = 0.009344360842078459
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:45,083 INFO epoch # 2603 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0034-> 0.0034 -loss = 0.008860110145178623
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:45,101 INFO epoch # 2604 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0034-> 0.0034 -loss = 0.00875054773496231
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:45,120 INFO epoch # 2605 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0034-> 0.0034 -loss = 0.008723196820938028
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:45,138 INFO epoch # 2606 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0034-> 0.0034 -loss = 0.008757584007980768
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:45,156 INFO epoch # 2607 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0034-> 0.0034 -loss = 0.008746656221774174
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:45,175 INFO epoch # 2608 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0034-> 0.0034 -loss = 0.008767904924752656
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:45,193 INFO epoch # 2609 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0034-> 0.0034 -loss = 0.008732983038498787
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:45,211 INFO epoch # 2610 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0034-> 0.0034 -loss = 0.008743051846977323
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:45,212 INFO *** epoch 2610, rolling-avg-loss (window=10)= 0.008817494259710656
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:45,230 INFO epoch # 2611 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0034-> 0.0034 -loss = 0.008757634896028321
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:45,248 INFO epoch # 2612 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0034-> 0.0034 -loss = 0.008750818749831524
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:45,266 INFO epoch # 2613 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0034-> 0.0034 -loss = 0.008643054654385196
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:45,285 INFO epoch # 2614 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0034-> 0.0034 -loss = 0.008767133025685325
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:45,303 INFO epoch # 2615 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0034-> 0.0034 -loss = 0.008858596404024865
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:45,321 INFO epoch # 2616 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0034-> 0.0034 -loss = 0.008745644907321548
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:45,339 INFO epoch # 2617 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0034-> 0.0034 -loss = 0.00875602427549893
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:45,358 INFO epoch # 2618 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0034-> 0.0034 -loss = 0.008739677818084601
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:45,376 INFO epoch # 2619 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0034-> 0.0034 -loss = 0.008705255117092747
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:45,394 INFO epoch # 2620 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0034-> 0.0034 -loss = 0.008801316544122528
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:45,395 INFO *** epoch 2620, rolling-avg-loss (window=10)= 0.008752515639207559
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:45,413 INFO epoch # 2621 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0034-> 0.0034 -loss = 0.008772962966759223
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:45,431 INFO epoch # 2622 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0034-> 0.0034 -loss = 0.008746757615881506
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:45,450 INFO epoch # 2623 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0034-> 0.0034 -loss = 0.008825536548101809
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:45,468 INFO epoch # 2624 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0034-> 0.0033 -loss = 0.00871508481213823
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:45,486 INFO epoch # 2625 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0033-> 0.0033 -loss = 0.008768927189521492
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:45,505 INFO epoch # 2626 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0033-> 0.0033 -loss = 0.008734013608773239
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:45,523 INFO epoch # 2627 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0033-> 0.0033 -loss = 0.008849111884046579
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:45,541 INFO epoch # 2628 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0033-> 0.0033 -loss = 0.008677652545884484
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:45,559 INFO epoch # 2629 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0033-> 0.0033 -loss = 0.008740133358514868
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:45,578 INFO epoch # 2630 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0033-> 0.0033 -loss = 0.008666888068546541
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:45,578 INFO *** epoch 2630, rolling-avg-loss (window=10)= 0.008749706859816797
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:45,596 INFO epoch # 2631 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0033-> 0.0033 -loss = 0.00869066431914689
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:45,615 INFO epoch # 2632 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0033-> 0.0033 -loss = 0.00884280378522817
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:45,633 INFO epoch # 2633 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0033-> 0.0033 -loss = 0.008670367118611466
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:45,651 INFO epoch # 2634 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0033-> 0.0033 -loss = 0.008679242600919679
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:45,670 INFO epoch # 2635 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0033-> 0.0033 -loss = 0.00867882662350894
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:45,688 INFO epoch # 2636 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0033-> 0.0033 -loss = 0.008747060273890384
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:45,706 INFO epoch # 2637 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0033-> 0.0033 -loss = 0.00896907441347139
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:45,725 INFO epoch # 2638 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0033-> 0.0033 -loss = 0.008592018813942559
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:45,743 INFO epoch # 2639 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0033-> 0.0033 -loss = 0.008622416982689174
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:45,761 INFO epoch # 2640 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0033-> 0.0033 -loss = 0.008642581742606126
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:45,761 INFO *** epoch 2640, rolling-avg-loss (window=10)= 0.008713505667401478
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:45,784 INFO epoch # 2641 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0033-> 0.0033 -loss = 0.008679969207150862
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:45,802 INFO epoch # 2642 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0033-> 0.0033 -loss = 0.00871199534230982
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:45,820 INFO epoch # 2643 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0033-> 0.0033 -loss = 0.009253922442439944
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:45,839 INFO epoch # 2644 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0033-> 0.0033 -loss = 0.008735925373912323
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:45,857 INFO epoch # 2645 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0033-> 0.0033 -loss = 0.008889882810763083
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:45,875 INFO epoch # 2646 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0033-> 0.0033 -loss = 0.009059426585736219
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:45,894 INFO epoch # 2647 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0033-> 0.0033 -loss = 0.008738680247915909
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:45,912 INFO epoch # 2648 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0033-> 0.0033 -loss = 0.008666135712701362
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:45,930 INFO epoch # 2649 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0033-> 0.0033 -loss = 0.008816172899969388
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:45,948 INFO epoch # 2650 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0033-> 0.0033 -loss = 0.008657776634208858
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:45,948 INFO *** epoch 2650, rolling-avg-loss (window=10)= 0.008820988725710776
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:45,967 INFO epoch # 2651 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0033-> 0.0033 -loss = 0.008764544691075571
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:45,985 INFO epoch # 2652 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0033-> 0.0033 -loss = 0.008844734991726
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:46,003 INFO epoch # 2653 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0033-> 0.0033 -loss = 0.008765737067733426
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:46,022 INFO epoch # 2654 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0033-> 0.0033 -loss = 0.008610631888586795
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:46,040 INFO epoch # 2655 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0033-> 0.0033 -loss = 0.008648032089695334
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:46,059 INFO epoch # 2656 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0033-> 0.0033 -loss = 0.00941859594968264
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:46,078 INFO epoch # 2657 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0033-> 0.0033 -loss = 0.008788313272816595
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:46,097 INFO epoch # 2658 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0033-> 0.0033 -loss = 0.0086648266769771
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:46,115 INFO epoch # 2659 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0033-> 0.0033 -loss = 0.008814514079858782
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:46,134 INFO epoch # 2660 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0033-> 0.0032 -loss = 0.008635918580694124
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:46,134 INFO *** epoch 2660, rolling-avg-loss (window=10)= 0.008795584928884636
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:46,152 INFO epoch # 2661 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0032-> 0.0032 -loss = 0.008759769832977327
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:46,170 INFO epoch # 2662 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0032-> 0.0032 -loss = 0.008669468959851656
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:46,188 INFO epoch # 2663 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0032-> 0.0032 -loss = 0.008674448654346634
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:46,207 INFO epoch # 2664 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0032-> 0.0032 -loss = 0.011610561392444652
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:46,225 INFO epoch # 2665 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0032-> 0.0032 -loss = 0.008836786895699333
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:46,244 INFO epoch # 2666 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0032-> 0.0032 -loss = 0.008695246502611553
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:46,262 INFO epoch # 2667 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0032-> 0.0032 -loss = 0.008718136712559499
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:46,281 INFO epoch # 2668 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0032-> 0.0032 -loss = 0.008679604936332908
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:46,299 INFO epoch # 2669 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0032-> 0.0032 -loss = 0.008885859984729905
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:46,317 INFO epoch # 2670 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0032-> 0.0032 -loss = 0.008972561125119682
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:46,317 INFO *** epoch 2670, rolling-avg-loss (window=10)= 0.009050244499667315
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:46,335 INFO epoch # 2671 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0032-> 0.0032 -loss = 0.008803609533060808
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:46,354 INFO epoch # 2672 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0032-> 0.0032 -loss = 0.00859073246101616
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:46,372 INFO epoch # 2673 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0032-> 0.0032 -loss = 0.008828643716697115
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:46,390 INFO epoch # 2674 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0032-> 0.0032 -loss = 0.008678123420395423
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:46,409 INFO epoch # 2675 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0032-> 0.0032 -loss = 0.00864168710904778
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:46,428 INFO epoch # 2676 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0032-> 0.0032 -loss = 0.008646865044283913
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:46,446 INFO epoch # 2677 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0032-> 0.0032 -loss = 0.008637798506242689
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:46,464 INFO epoch # 2678 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0032-> 0.0032 -loss = 0.00871388451923849
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:46,483 INFO epoch # 2679 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0032-> 0.0032 -loss = 0.008754843031056225
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:46,501 INFO epoch # 2680 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0032-> 0.0032 -loss = 0.008633092729724012
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:46,501 INFO *** epoch 2680, rolling-avg-loss (window=10)= 0.008692928007076262
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:46,520 INFO epoch # 2681 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0032-> 0.0032 -loss = 0.008647427530377172
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:46,538 INFO epoch # 2682 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0032-> 0.0032 -loss = 0.008594234437623527
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:46,556 INFO epoch # 2683 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0032-> 0.0032 -loss = 0.008878558695869287
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:46,574 INFO epoch # 2684 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0032-> 0.0032 -loss = 0.008715190801012795
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:46,593 INFO epoch # 2685 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0032-> 0.0032 -loss = 0.00881675842902041
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:46,611 INFO epoch # 2686 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0032-> 0.0032 -loss = 0.008633878795080818
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:46,629 INFO epoch # 2687 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0032-> 0.0032 -loss = 0.008695323813299183
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:46,648 INFO epoch # 2688 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0032-> 0.0032 -loss = 0.00865918899216922
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:46,666 INFO epoch # 2689 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0032-> 0.0032 -loss = 0.008609901702584466
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:46,685 INFO epoch # 2690 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0032-> 0.0032 -loss = 0.008597564796218649
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:46,685 INFO *** epoch 2690, rolling-avg-loss (window=10)= 0.008684802799325552
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:46,703 INFO epoch # 2691 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0032-> 0.0032 -loss = 0.008646173395391088
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:46,721 INFO epoch # 2692 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0032-> 0.0032 -loss = 0.008626466133137
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:46,740 INFO epoch # 2693 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0032-> 0.0032 -loss = 0.0086376440958702
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:46,758 INFO epoch # 2694 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0032-> 0.0031 -loss = 0.008606590563431382
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:46,777 INFO epoch # 2695 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.008592878315539565
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:46,795 INFO epoch # 2696 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.008578805180150084
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:46,813 INFO epoch # 2697 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.008647509668662678
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:46,832 INFO epoch # 2698 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.009325647159130313
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:46,850 INFO epoch # 2699 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.008672809002746362
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:46,868 INFO epoch # 2700 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.008594483202614356
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:46,869 INFO *** epoch 2700, rolling-avg-loss (window=10)= 0.008692900671667303
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:46,887 INFO epoch # 2701 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.008568523400754202
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:46,905 INFO epoch # 2702 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.008599072076322045
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:46,923 INFO epoch # 2703 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.008689749018230941
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:46,941 INFO epoch # 2704 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.008598652402724838
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:46,960 INFO epoch # 2705 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.00854154244007077
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:46,978 INFO epoch # 2706 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.008585840303567238
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:46,996 INFO epoch # 2707 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.008530770814104471
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:47,014 INFO epoch # 2708 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.008509330269589555
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:47,033 INFO epoch # 2709 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.008743397029320477
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:47,051 INFO epoch # 2710 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.00854634238203289
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:47,051 INFO *** epoch 2710, rolling-avg-loss (window=10)= 0.008591322013671743
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:47,070 INFO epoch # 2711 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.00865336384595139
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:47,088 INFO epoch # 2712 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.008597202904638834
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:47,106 INFO epoch # 2713 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.008684365813678596
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:47,125 INFO epoch # 2714 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.008572451031795936
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:47,143 INFO epoch # 2715 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.008516014815540984
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:47,161 INFO epoch # 2716 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.00856652876973385
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:47,179 INFO epoch # 2717 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.008693649775523227
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:47,198 INFO epoch # 2718 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.008602818299550563
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:47,216 INFO epoch # 2719 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.008622471774287988
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:47,235 INFO epoch # 2720 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.00854102415178204
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:47,235 INFO *** epoch 2720, rolling-avg-loss (window=10)= 0.00860498911824834
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:47,253 INFO epoch # 2721 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.008551408995117527
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:47,271 INFO epoch # 2722 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.0085421224575839
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:47,290 INFO epoch # 2723 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.008514159933838528
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:47,308 INFO epoch # 2724 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.008517516367646749
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:47,326 INFO epoch # 2725 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.008577301668992732
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:47,345 INFO epoch # 2726 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.008594897939474322
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:47,363 INFO epoch # 2727 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.008577355816669296
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:47,381 INFO epoch # 2728 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.008601760491728783
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:47,399 INFO epoch # 2729 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.008514827721228357
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:47,417 INFO epoch # 2730 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.008640252592158504
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:47,418 INFO *** epoch 2730, rolling-avg-loss (window=10)= 0.00856316039844387
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:47,436 INFO epoch # 2731 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.00865186624287162
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:47,454 INFO epoch # 2732 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.008687548812304158
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:47,472 INFO epoch # 2733 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.00854881712803035
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:47,491 INFO epoch # 2734 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.008569834957597777
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:47,509 INFO epoch # 2735 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.008473954439978115
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:47,527 INFO epoch # 2736 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.008593923928856384
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:47,546 INFO epoch # 2737 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.008572466962505132
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:47,564 INFO epoch # 2738 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.00847956984944176
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:47,582 INFO epoch # 2739 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.008936867503507528
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:47,600 INFO epoch # 2740 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.008596963649324607
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:47,600 INFO *** epoch 2740, rolling-avg-loss (window=10)= 0.008611181347441743
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:47,619 INFO epoch # 2741 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.00914260415447643
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:47,637 INFO epoch # 2742 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.00856039191421587
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:47,656 INFO epoch # 2743 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.008536915665899869
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:47,674 INFO epoch # 2744 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.008533957428880967
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:47,692 INFO epoch # 2745 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.008608985011960613
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:47,711 INFO epoch # 2746 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.008577011183660943
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:47,729 INFO epoch # 2747 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.008559540248825215
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:47,747 INFO epoch # 2748 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.00851970810253988
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:47,766 INFO epoch # 2749 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.008554229396395385
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:47,784 INFO epoch # 2750 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.008605909388279542
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:47,784 INFO *** epoch 2750, rolling-avg-loss (window=10)= 0.008619925249513471
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:47,802 INFO epoch # 2751 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.008804331770079443
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:47,821 INFO epoch # 2752 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.008514921501046047
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:47,839 INFO epoch # 2753 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.008733953858609311
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:47,857 INFO epoch # 2754 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.008541747476556338
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:47,876 INFO epoch # 2755 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.008470758268231293
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:47,894 INFO epoch # 2756 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.008498298993799835
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:47,912 INFO epoch # 2757 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.013198752792959567
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:47,931 INFO epoch # 2758 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.008848178942571394
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:47,949 INFO epoch # 2759 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.008479244297632249
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:47,967 INFO epoch # 2760 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.008811950268864166
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:47,967 INFO *** epoch 2760, rolling-avg-loss (window=10)= 0.009090213817034964
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:47,985 INFO epoch # 2761 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.008578072556701954
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:48,004 INFO epoch # 2762 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.008597154563176446
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:48,022 INFO epoch # 2763 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.008411218503169948
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:48,040 INFO epoch # 2764 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.008671024304931052
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:48,059 INFO epoch # 2765 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.008501320458890405
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:48,077 INFO epoch # 2766 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.008631174714537337
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:48,096 INFO epoch # 2767 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.008536942150385585
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:48,114 INFO epoch # 2768 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.008532118445145898
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:48,132 INFO epoch # 2769 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.008428839933912968
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:48,151 INFO epoch # 2770 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.008475440547044855
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:48,151 INFO *** epoch 2770, rolling-avg-loss (window=10)= 0.008536330617789644
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:48,169 INFO epoch # 2771 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.0084554037603084
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:48,187 INFO epoch # 2772 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.008499619951180648
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:48,205 INFO epoch # 2773 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.0031 -loss = 0.008479799231281504
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:48,224 INFO epoch # 2774 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0031-> 0.003 -loss = 0.008503620701958425
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:48,242 INFO epoch # 2775 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.003-> 0.003 -loss = 0.00844013496680418
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:48,260 INFO epoch # 2776 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.003-> 0.003 -loss = 0.008487005055940244
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:48,279 INFO epoch # 2777 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.003-> 0.003 -loss = 0.008505953341227723
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:48,297 INFO epoch # 2778 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.003-> 0.003 -loss = 0.00845289095195767
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:48,315 INFO epoch # 2779 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.003-> 0.003 -loss = 0.011538551858393475
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:48,333 INFO epoch # 2780 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.003-> 0.003 -loss = 0.00851647816671175
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:48,333 INFO *** epoch 2780, rolling-avg-loss (window=10)= 0.008787945798576401
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:48,352 INFO epoch # 2781 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.003-> 0.003 -loss = 0.0085053348193469
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:48,370 INFO epoch # 2782 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.003-> 0.003 -loss = 0.008492237840982853
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:48,388 INFO epoch # 2783 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.003-> 0.003 -loss = 0.008486964346957393
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:48,407 INFO epoch # 2784 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.003-> 0.003 -loss = 0.008510607141943183
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:48,425 INFO epoch # 2785 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.003-> 0.003 -loss = 0.00845852314523654
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:48,443 INFO epoch # 2786 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.003-> 0.003 -loss = 0.008463863166980445
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:48,462 INFO epoch # 2787 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.003-> 0.003 -loss = 0.00879310200616601
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:48,480 INFO epoch # 2788 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.003-> 0.003 -loss = 0.008463790261885151
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:48,499 INFO epoch # 2789 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.003-> 0.003 -loss = 0.008976046978204977
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:48,517 INFO epoch # 2790 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.003-> 0.003 -loss = 0.008628665797004942
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:48,517 INFO *** epoch 2790, rolling-avg-loss (window=10)= 0.008577913550470839
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:48,536 INFO epoch # 2791 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.003-> 0.003 -loss = 0.00841755833971547
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:48,554 INFO epoch # 2792 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.003-> 0.003 -loss = 0.008453440572338877
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:48,572 INFO epoch # 2793 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.003-> 0.003 -loss = 0.00851929664349882
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:48,590 INFO epoch # 2794 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.003-> 0.003 -loss = 0.008457359486783389
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:48,609 INFO epoch # 2795 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.003-> 0.003 -loss = 0.00849881736576208
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:48,627 INFO epoch # 2796 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.003-> 0.003 -loss = 0.009234264856786467
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:48,645 INFO epoch # 2797 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.003-> 0.003 -loss = 0.008574446241254918
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:48,664 INFO epoch # 2798 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.003-> 0.003 -loss = 0.008394126176426653
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:48,682 INFO epoch # 2799 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.003-> 0.003 -loss = 0.008518315953551792
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:48,700 INFO epoch # 2800 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.003-> 0.003 -loss = 0.009132098970439984
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:48,700 INFO *** epoch 2800, rolling-avg-loss (window=10)= 0.008619972460655845
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:48,719 INFO epoch # 2801 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.003-> 0.003 -loss = 0.008490249681926798
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:48,737 INFO epoch # 2802 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.003-> 0.003 -loss = 0.010514859121030895
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:48,755 INFO epoch # 2803 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.003-> 0.003 -loss = 0.008738113639992662
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:48,773 INFO epoch # 2804 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.003-> 0.003 -loss = 0.008481175627821358
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:48,792 INFO epoch # 2805 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.003-> 0.003 -loss = 0.009126126489718445
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:48,810 INFO epoch # 2806 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.003-> 0.003 -loss = 0.008418670302489772
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:48,828 INFO epoch # 2807 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.003-> 0.003 -loss = 0.008445647355983965
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:48,847 INFO epoch # 2808 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.003-> 0.003 -loss = 0.00852942624987918
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:48,865 INFO epoch # 2809 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.003-> 0.0029 -loss = 0.0085236771919881
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:48,883 INFO epoch # 2810 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0029-> 0.0029 -loss = 0.008432781480223639
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:48,884 INFO *** epoch 2810, rolling-avg-loss (window=10)= 0.008770072714105482
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:48,902 INFO epoch # 2811 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0029-> 0.0029 -loss = 0.00844977799715707
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:48,920 INFO epoch # 2812 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0029-> 0.0029 -loss = 0.008477537900034804
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:48,939 INFO epoch # 2813 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0029-> 0.0029 -loss = 0.008517004549503326
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:48,957 INFO epoch # 2814 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0029-> 0.0029 -loss = 0.009037619522132445
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:48,975 INFO epoch # 2815 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0029-> 0.0029 -loss = 0.008509374420100357
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:48,993 INFO epoch # 2816 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0029-> 0.0029 -loss = 0.008701971026312094
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:49,012 INFO epoch # 2817 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0029-> 0.0029 -loss = 0.008467065086733783
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:49,030 INFO epoch # 2818 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0029-> 0.0029 -loss = 0.008616738836281002
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:49,048 INFO epoch # 2819 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0029-> 0.0029 -loss = 0.008519132832589094
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:49,067 INFO epoch # 2820 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0029-> 0.0029 -loss = 0.008413470786763355
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:49,067 INFO *** epoch 2820, rolling-avg-loss (window=10)= 0.008570969295760733
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:49,085 INFO epoch # 2821 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0029-> 0.0029 -loss = 0.008458576769044157
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:49,104 INFO epoch # 2822 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0029-> 0.0029 -loss = 0.008361851927475072
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:49,122 INFO epoch # 2823 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0029-> 0.0029 -loss = 0.008637759499833919
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:49,141 INFO epoch # 2824 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0029-> 0.0029 -loss = 0.008404092244745698
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:49,159 INFO epoch # 2825 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0029-> 0.0029 -loss = 0.008371676260139793
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:49,178 INFO epoch # 2826 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0029-> 0.0029 -loss = 0.008441261310508708
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:49,196 INFO epoch # 2827 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0029-> 0.0029 -loss = 0.008429737557889894
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:49,214 INFO epoch # 2828 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0029-> 0.0029 -loss = 0.00843871982942801
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:49,232 INFO epoch # 2829 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0029-> 0.0029 -loss = 0.008306043418997433
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:49,251 INFO epoch # 2830 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0029-> 0.0029 -loss = 0.008896825842384715
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:49,251 INFO *** epoch 2830, rolling-avg-loss (window=10)= 0.008474654466044739
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:49,269 INFO epoch # 2831 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0029-> 0.0029 -loss = 0.008622968365671113
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:49,288 INFO epoch # 2832 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0029-> 0.0029 -loss = 0.008528326456143986
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:49,306 INFO epoch # 2833 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0029-> 0.0029 -loss = 0.008396694734983612
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:49,324 INFO epoch # 2834 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0029-> 0.0029 -loss = 0.0083640881057363
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:49,343 INFO epoch # 2835 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0029-> 0.0029 -loss = 0.008528158607077785
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:49,361 INFO epoch # 2836 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0029-> 0.0029 -loss = 0.009047989966347814
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:49,379 INFO epoch # 2837 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0029-> 0.0029 -loss = 0.008503529366862494
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:49,398 INFO epoch # 2838 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0029-> 0.0029 -loss = 0.008358739625691669
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:49,416 INFO epoch # 2839 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0029-> 0.0029 -loss = 0.00838240260782186
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:49,434 INFO epoch # 2840 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0029-> 0.0029 -loss = 0.008407879111473449
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:49,434 INFO *** epoch 2840, rolling-avg-loss (window=10)= 0.008514077694781009
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:49,452 INFO epoch # 2841 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0029-> 0.0029 -loss = 0.008501210548274685
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:49,471 INFO epoch # 2842 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0029-> 0.0029 -loss = 0.008433829294517636
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:49,489 INFO epoch # 2843 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0029-> 0.0029 -loss = 0.008355270281754201
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:49,507 INFO epoch # 2844 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0029-> 0.0029 -loss = 0.00872831870947266
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:49,526 INFO epoch # 2845 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0029-> 0.0029 -loss = 0.008392997973714955
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:49,544 INFO epoch # 2846 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0029-> 0.0029 -loss = 0.008418041696131695
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:49,562 INFO epoch # 2847 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0029-> 0.0029 -loss = 0.008410241549427155
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:49,581 INFO epoch # 2848 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0029-> 0.0029 -loss = 0.00875454155902844
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:49,599 INFO epoch # 2849 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0029-> 0.0029 -loss = 0.008516650268575177
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:49,617 INFO epoch # 2850 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0029-> 0.0029 -loss = 0.00843354850076139
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:49,617 INFO *** epoch 2850, rolling-avg-loss (window=10)= 0.0084944650381658
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:49,636 INFO epoch # 2851 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0029-> 0.0028 -loss = 0.008346772025106475
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:49,654 INFO epoch # 2852 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.008352473476406885
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:49,672 INFO epoch # 2853 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.008465128325042315
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:49,691 INFO epoch # 2854 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.008369944345758995
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:49,709 INFO epoch # 2855 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.008495879781548865
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:49,727 INFO epoch # 2856 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.008382368487218628
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:49,746 INFO epoch # 2857 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.008327267358254176
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:49,764 INFO epoch # 2858 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.008405716776906047
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:49,782 INFO epoch # 2859 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.008347204093297478
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:49,800 INFO epoch # 2860 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.009594785689841956
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:49,800 INFO *** epoch 2860, rolling-avg-loss (window=10)= 0.008508754035938182
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:49,819 INFO epoch # 2861 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.00842338821530575
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:49,837 INFO epoch # 2862 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.00838406391630997
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:49,856 INFO epoch # 2863 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.00831966774421744
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:49,874 INFO epoch # 2864 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.00845559811568819
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:49,892 INFO epoch # 2865 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.008358116578165209
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:49,910 INFO epoch # 2866 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.008895914710592479
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:49,929 INFO epoch # 2867 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.008658515478600748
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:49,947 INFO epoch # 2868 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.008549819744075648
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:49,965 INFO epoch # 2869 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.009078475537535269
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:49,983 INFO epoch # 2870 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.008347347953531425
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:49,983 INFO *** epoch 2870, rolling-avg-loss (window=10)= 0.008547090799402213
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:50,002 INFO epoch # 2871 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.012808742467314005
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:50,020 INFO epoch # 2872 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.008582412738178391
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:50,038 INFO epoch # 2873 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.0084073760008323
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:50,057 INFO epoch # 2874 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.008327487099450082
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:50,075 INFO epoch # 2875 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.008359977829968557
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:50,094 INFO epoch # 2876 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.008386466950469185
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:50,112 INFO epoch # 2877 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.008306775176606607
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:50,131 INFO epoch # 2878 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.008373434138775337
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:50,149 INFO epoch # 2879 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.008502846110786777
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:50,168 INFO epoch # 2880 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.008253699048509588
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:50,168 INFO *** epoch 2880, rolling-avg-loss (window=10)= 0.008830921756089082
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:50,186 INFO epoch # 2881 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.008725528336071875
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:50,204 INFO epoch # 2882 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.008551543643989135
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:50,222 INFO epoch # 2883 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.008351150325324852
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:50,241 INFO epoch # 2884 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.008979000438557705
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:50,259 INFO epoch # 2885 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.008422456223343033
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:50,278 INFO epoch # 2886 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.008319479838974075
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:50,296 INFO epoch # 2887 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.008264308446086943
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:50,314 INFO epoch # 2888 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.008307443429657724
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:50,333 INFO epoch # 2889 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.008264151812909404
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:50,351 INFO epoch # 2890 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.008375767065444961
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:50,351 INFO *** epoch 2890, rolling-avg-loss (window=10)= 0.008456082956035971
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:50,370 INFO epoch # 2891 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.00883960888677393
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:50,389 INFO epoch # 2892 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.008280855996417813
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:50,407 INFO epoch # 2893 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.008335453687323024
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:50,425 INFO epoch # 2894 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.008334423386259004
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:50,444 INFO epoch # 2895 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.008736227355257142
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:50,462 INFO epoch # 2896 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.008436689415248111
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:50,480 INFO epoch # 2897 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.008347097449586727
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:50,499 INFO epoch # 2898 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.008344308524101507
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:50,517 INFO epoch # 2899 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.008367173883016221
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:50,536 INFO epoch # 2900 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.008317877516674343
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:50,536 INFO *** epoch 2900, rolling-avg-loss (window=10)= 0.008433971610065783
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:50,554 INFO epoch # 2901 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0028 -loss = 0.008295588588225655
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:50,572 INFO epoch # 2902 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0028-> 0.0027 -loss = 0.00833837793834391
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:50,590 INFO epoch # 2903 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0027-> 0.0027 -loss = 0.008299535569676664
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:50,609 INFO epoch # 2904 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0027-> 0.0027 -loss = 0.008310267352499068
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:50,627 INFO epoch # 2905 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0027-> 0.0027 -loss = 0.008281974922283553
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:50,645 INFO epoch # 2906 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0027-> 0.0027 -loss = 0.008226632948208135
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:50,663 INFO epoch # 2907 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0027-> 0.0027 -loss = 0.008308945154567482
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:50,682 INFO epoch # 2908 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0027-> 0.0027 -loss = 0.008246611370850587
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:50,701 INFO epoch # 2909 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0027-> 0.0027 -loss = 0.00842243003717158
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:50,719 INFO epoch # 2910 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0027-> 0.0027 -loss = 0.008394563337787986
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:50,719 INFO *** epoch 2910, rolling-avg-loss (window=10)= 0.008312492721961462
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:50,738 INFO epoch # 2911 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0027-> 0.0027 -loss = 0.008339235675521195
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:50,756 INFO epoch # 2912 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0027-> 0.0027 -loss = 0.008387287256482523
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:50,774 INFO epoch # 2913 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0027-> 0.0027 -loss = 0.008299747823912185
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:50,792 INFO epoch # 2914 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0027-> 0.0027 -loss = 0.008402756655414123
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:50,811 INFO epoch # 2915 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0027-> 0.0027 -loss = 0.008290364174172282
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:50,829 INFO epoch # 2916 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0027-> 0.0027 -loss = 0.008411922684899764
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:50,847 INFO epoch # 2917 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0027-> 0.0027 -loss = 0.00828026387898717
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:50,865 INFO epoch # 2918 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0027-> 0.0027 -loss = 0.008309703567647375
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:50,884 INFO epoch # 2919 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0027-> 0.0027 -loss = 0.00825537788841757
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:50,902 INFO epoch # 2920 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0027-> 0.0027 -loss = 0.008715414740436245
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:50,902 INFO *** epoch 2920, rolling-avg-loss (window=10)= 0.008369207434589044
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:50,920 INFO epoch # 2921 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0027-> 0.0027 -loss = 0.00860226515942486
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:50,939 INFO epoch # 2922 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0027-> 0.0027 -loss = 0.00831715359527152
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:50,957 INFO epoch # 2923 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0027-> 0.0027 -loss = 0.008407391185755841
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:50,975 INFO epoch # 2924 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0027-> 0.0027 -loss = 0.00855401782609988
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:50,993 INFO epoch # 2925 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0027-> 0.0027 -loss = 0.008560253656469285
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:51,012 INFO epoch # 2926 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0027-> 0.0027 -loss = 0.00858179170609219
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:51,030 INFO epoch # 2927 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0027-> 0.0027 -loss = 0.008351208194653736
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:51,048 INFO epoch # 2928 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0027-> 0.0027 -loss = 0.008521001160261221
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:51,067 INFO epoch # 2929 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0027-> 0.0027 -loss = 0.008294664774439298
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:51,085 INFO epoch # 2930 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0027-> 0.0027 -loss = 0.008257465215137927
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:51,085 INFO *** epoch 2930, rolling-avg-loss (window=10)= 0.008444721247360575
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:51,103 INFO epoch # 2931 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0027-> 0.0027 -loss = 0.008218159819080029
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:51,122 INFO epoch # 2932 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0027-> 0.0027 -loss = 0.008293488070194144
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:51,140 INFO epoch # 2933 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0027-> 0.0027 -loss = 0.008245860946772154
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:51,158 INFO epoch # 2934 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0027-> 0.0027 -loss = 0.008268693858553888
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:51,176 INFO epoch # 2935 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0027-> 0.0027 -loss = 0.00849708454188658
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:51,195 INFO epoch # 2936 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0027-> 0.0027 -loss = 0.01056097160835634
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:51,213 INFO epoch # 2937 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0027-> 0.0027 -loss = 0.00838571259737364
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:51,231 INFO epoch # 2938 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0027-> 0.0027 -loss = 0.008394078831770457
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:51,249 INFO epoch # 2939 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0027-> 0.0027 -loss = 0.008258172747446224
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:51,268 INFO epoch # 2940 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0027-> 0.0027 -loss = 0.008310580196848605
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:51,268 INFO *** epoch 2940, rolling-avg-loss (window=10)= 0.008543280321828207
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:51,286 INFO epoch # 2941 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0027-> 0.0027 -loss = 0.008251691775512882
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:51,304 INFO epoch # 2942 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0027-> 0.0027 -loss = 0.008251699429820292
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:51,323 INFO epoch # 2943 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0027-> 0.0027 -loss = 0.008319294152897783
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:51,341 INFO epoch # 2944 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0027-> 0.0027 -loss = 0.008417367356742034
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:51,359 INFO epoch # 2945 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0027-> 0.0027 -loss = 0.00825350914237788
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:51,378 INFO epoch # 2946 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0027-> 0.0027 -loss = 0.008273667743196711
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:51,396 INFO epoch # 2947 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0027-> 0.0027 -loss = 0.008264175994554535
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:51,414 INFO epoch # 2948 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0027-> 0.0027 -loss = 0.00877379175653914
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:51,432 INFO epoch # 2949 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0027-> 0.0027 -loss = 0.008419705911364872
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:51,450 INFO epoch # 2950 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0027-> 0.0027 -loss = 0.008227352325775428
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:51,451 INFO *** epoch 2950, rolling-avg-loss (window=10)= 0.008345225558878155
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:51,469 INFO epoch # 2951 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0027-> 0.0027 -loss = 0.008217924940254306
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:51,487 INFO epoch # 2952 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0027-> 0.0027 -loss = 0.008302633148559835
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:51,505 INFO epoch # 2953 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0027-> 0.0026 -loss = 0.008286378470074851
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:51,524 INFO epoch # 2954 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0026-> 0.0026 -loss = 0.008276046239188872
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:51,542 INFO epoch # 2955 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0026-> 0.0026 -loss = 0.008238670074206311
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:51,561 INFO epoch # 2956 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0026-> 0.0026 -loss = 0.008254664440755732
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:51,579 INFO epoch # 2957 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0026-> 0.0026 -loss = 0.008237752415880095
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:51,597 INFO epoch # 2958 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0026-> 0.0026 -loss = 0.008191596527467482
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:51,615 INFO epoch # 2959 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0026-> 0.0026 -loss = 0.00824294587073382
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:51,634 INFO epoch # 2960 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0026-> 0.0026 -loss = 0.00829907800653018
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:51,634 INFO *** epoch 2960, rolling-avg-loss (window=10)= 0.008254769013365148
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:51,652 INFO epoch # 2961 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0026-> 0.0026 -loss = 0.008191561715648277
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:51,670 INFO epoch # 2962 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0026-> 0.0026 -loss = 0.008194124136934988
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:51,689 INFO epoch # 2963 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0026-> 0.0026 -loss = 0.008251869861851446
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:51,707 INFO epoch # 2964 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0026-> 0.0026 -loss = 0.008632032528112177
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:51,725 INFO epoch # 2965 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0026-> 0.0026 -loss = 0.008286870634037768
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:51,744 INFO epoch # 2966 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0026-> 0.0026 -loss = 0.008243981304985937
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:51,762 INFO epoch # 2967 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0026-> 0.0026 -loss = 0.01065599514549831
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:51,780 INFO epoch # 2968 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0026-> 0.0026 -loss = 0.00822250505007105
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:51,799 INFO epoch # 2969 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0026-> 0.0026 -loss = 0.008511459971487056
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:51,817 INFO epoch # 2970 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0026-> 0.0026 -loss = 0.008415364456595853
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:51,817 INFO *** epoch 2970, rolling-avg-loss (window=10)= 0.008560576480522285
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:51,835 INFO epoch # 2971 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0026-> 0.0026 -loss = 0.008247775193012785
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:51,854 INFO epoch # 2972 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0026-> 0.0026 -loss = 0.008261100188974524
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:51,872 INFO epoch # 2973 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0026-> 0.0026 -loss = 0.01248402138298843
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:51,890 INFO epoch # 2974 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0026-> 0.0026 -loss = 0.008498843075358309
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:51,909 INFO epoch # 2975 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0026-> 0.0026 -loss = 0.008258400612248806
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:51,928 INFO epoch # 2976 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0026-> 0.0026 -loss = 0.008202922817872604
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:51,946 INFO epoch # 2977 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0026-> 0.0026 -loss = 0.008239318303822074
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:51,965 INFO epoch # 2978 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0026-> 0.0026 -loss = 0.008188254625565605
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:51,983 INFO epoch # 2979 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0026-> 0.0026 -loss = 0.008181623117707204
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:52,002 INFO epoch # 2980 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0026-> 0.0026 -loss = 0.008183291669411119
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:52,002 INFO *** epoch 2980, rolling-avg-loss (window=10)= 0.008674555098696145
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:52,020 INFO epoch # 2981 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0026-> 0.0026 -loss = 0.008249849641288165
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:52,038 INFO epoch # 2982 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0026-> 0.0026 -loss = 0.008363998829736374
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:52,056 INFO epoch # 2983 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0026-> 0.0026 -loss = 0.00859899719216628
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:52,075 INFO epoch # 2984 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0026-> 0.0026 -loss = 0.008146129715896677
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:52,093 INFO epoch # 2985 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0026-> 0.0026 -loss = 0.008245509387052152
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:52,112 INFO epoch # 2986 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0026-> 0.0026 -loss = 0.008183659403584898
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:52,130 INFO epoch # 2987 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0026-> 0.0026 -loss = 0.008258884772658348
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:52,148 INFO epoch # 2988 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0026-> 0.0026 -loss = 0.008542331175704021
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:52,166 INFO epoch # 2989 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0026-> 0.0026 -loss = 0.008210224637878127
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:52,185 INFO epoch # 2990 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0026-> 0.0026 -loss = 0.008227700687712058
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:52,185 INFO *** epoch 2990, rolling-avg-loss (window=10)= 0.00830272854436771
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:52,203 INFO epoch # 2991 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0026-> 0.0026 -loss = 0.008200672818929888
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:52,222 INFO epoch # 2992 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0026-> 0.0026 -loss = 0.00833772360056173
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:52,240 INFO epoch # 2993 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0026-> 0.0026 -loss = 0.00813828939863015
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:52,259 INFO epoch # 2994 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0026-> 0.0026 -loss = 0.008179294884030242
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:52,277 INFO epoch # 2995 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0026-> 0.0026 -loss = 0.008239963579399046
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:52,295 INFO epoch # 2996 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0026-> 0.0026 -loss = 0.008236026660597418
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:52,314 INFO epoch # 2997 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0026-> 0.0026 -loss = 0.008186391300114337
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:52,332 INFO epoch # 2998 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0026-> 0.0026 -loss = 0.008236508961999789
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:52,350 INFO epoch # 2999 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0026-> 0.0026 -loss = 0.008263179148343625
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:52,369 INFO epoch # 3000 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0026-> 0.0026 -loss = 0.008185277620214038
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:52,369 INFO *** epoch 3000, rolling-avg-loss (window=10)= 0.008220332797282025
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:52,387 INFO epoch # 3001 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0026-> 0.0026 -loss = 0.008188343155779876
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:52,406 INFO epoch # 3002 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0026-> 0.0026 -loss = 0.008193557070626412
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:52,424 INFO epoch # 3003 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0026-> 0.0026 -loss = 0.008199943978979718
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:52,442 INFO epoch # 3004 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0026-> 0.0026 -loss = 0.008223494383855723
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:52,460 INFO epoch # 3005 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0026-> 0.0026 -loss = 0.008158356111380272
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:52,479 INFO epoch # 3006 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0026-> 0.0026 -loss = 0.008137081684253644
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:52,497 INFO epoch # 3007 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0026-> 0.0026 -loss = 0.008757459509070031
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:52,515 INFO epoch # 3008 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0026-> 0.0026 -loss = 0.008165993363945745
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:52,534 INFO epoch # 3009 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0026-> 0.0026 -loss = 0.0081241568805126
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:52,552 INFO epoch # 3010 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0026-> 0.0026 -loss = 0.008200906180718448
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:52,552 INFO *** epoch 3010, rolling-avg-loss (window=10)= 0.008234929231912247
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:52,571 INFO epoch # 3011 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0026-> 0.0026 -loss = 0.008183376223314553
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:52,590 INFO epoch # 3012 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0026-> 0.0026 -loss = 0.008458204283670057
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:52,608 INFO epoch # 3013 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0026-> 0.0026 -loss = 0.008153062808560207
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:52,626 INFO epoch # 3014 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0026-> 0.0026 -loss = 0.008110790800856194
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:52,645 INFO epoch # 3015 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0026-> 0.0026 -loss = 0.008118619283777662
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:52,663 INFO epoch # 3016 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0026-> 0.0026 -loss = 0.008173586029442959
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:52,681 INFO epoch # 3017 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0026-> 0.0026 -loss = 0.008177643016097136
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:52,700 INFO epoch # 3018 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0026-> 0.0026 -loss = 0.008127238688757643
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:52,718 INFO epoch # 3019 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0026-> 0.0026 -loss = 0.008311805773701053
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:52,737 INFO epoch # 3020 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0026-> 0.0026 -loss = 0.00813352840486914
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:52,737 INFO *** epoch 3020, rolling-avg-loss (window=10)= 0.00819478553130466
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:52,755 INFO epoch # 3021 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0026-> 0.0026 -loss = 0.012602970280568115
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:52,774 INFO epoch # 3022 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0026-> 0.0026 -loss = 0.00851780065568164
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:52,792 INFO epoch # 3023 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0026-> 0.0026 -loss = 0.008272509985545184
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:52,811 INFO epoch # 3024 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0026-> 0.0026 -loss = 0.008219432063924614
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:52,829 INFO epoch # 3025 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0026-> 0.0025 -loss = 0.008704618900083005
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:52,847 INFO epoch # 3026 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.00818286650974187
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:52,866 INFO epoch # 3027 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.008469223699648865
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:52,884 INFO epoch # 3028 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.008168184242094867
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:52,902 INFO epoch # 3029 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.008702535316842841
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:52,921 INFO epoch # 3030 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.008122898205328966
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:52,921 INFO *** epoch 3030, rolling-avg-loss (window=10)= 0.008796303985945997
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:52,939 INFO epoch # 3031 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.008296127649373375
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:52,958 INFO epoch # 3032 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.00882926007034257
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:52,976 INFO epoch # 3033 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.008517545484210132
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:52,994 INFO epoch # 3034 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.008126528839056846
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:53,013 INFO epoch # 3035 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.008425903331954032
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:53,031 INFO epoch # 3036 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.00821839933632873
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:53,049 INFO epoch # 3037 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.008216622278268915
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:53,067 INFO epoch # 3038 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.009253730298951268
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:53,086 INFO epoch # 3039 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.008178235075320117
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:53,104 INFO epoch # 3040 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.00817122792795999
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:53,104 INFO *** epoch 3040, rolling-avg-loss (window=10)= 0.008423358029176597
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:53,122 INFO epoch # 3041 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.008204496421967633
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:53,141 INFO epoch # 3042 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.00809200300500379
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:53,159 INFO epoch # 3043 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.008152393515047152
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:53,178 INFO epoch # 3044 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.008212277934944723
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:53,196 INFO epoch # 3045 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.008205560923670419
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:53,214 INFO epoch # 3046 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.008264123425760772
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:53,233 INFO epoch # 3047 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.008115331911540125
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:53,251 INFO epoch # 3048 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.008238905196776614
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:53,269 INFO epoch # 3049 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.008102253275865223
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:53,287 INFO epoch # 3050 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.008698351222847123
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:53,287 INFO *** epoch 3050, rolling-avg-loss (window=10)= 0.008228569683342356
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:53,306 INFO epoch # 3051 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.008132782048051013
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:53,324 INFO epoch # 3052 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.012353016038105125
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:53,342 INFO epoch # 3053 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.008648318638734054
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:53,361 INFO epoch # 3054 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.008087088339379989
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:53,379 INFO epoch # 3055 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.008109107337077148
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:53,397 INFO epoch # 3056 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.008201204938814044
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:53,416 INFO epoch # 3057 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.008365221590793226
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:53,434 INFO epoch # 3058 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.00816153430059785
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:53,452 INFO epoch # 3059 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.008121674567519221
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:53,471 INFO epoch # 3060 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.008137076350976713
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:53,471 INFO *** epoch 3060, rolling-avg-loss (window=10)= 0.008631702415004838
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:53,489 INFO epoch # 3061 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.008061228014412336
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:53,507 INFO epoch # 3062 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.00809958214085782
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:53,526 INFO epoch # 3063 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.008245287361205555
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:53,544 INFO epoch # 3064 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.008119537589664105
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:53,562 INFO epoch # 3065 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.008088261194643565
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:53,581 INFO epoch # 3066 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.008130433430778794
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:53,599 INFO epoch # 3067 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.008042409310291987
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:53,618 INFO epoch # 3068 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.008134069787047338
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:53,636 INFO epoch # 3069 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.008286292148113716
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:53,654 INFO epoch # 3070 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.008152245682140347
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:53,655 INFO *** epoch 3070, rolling-avg-loss (window=10)= 0.008135934665915556
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:53,673 INFO epoch # 3071 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.008110755337838782
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:53,691 INFO epoch # 3072 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.008042096431381651
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:53,709 INFO epoch # 3073 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.008178859614417888
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:53,728 INFO epoch # 3074 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.008079851704678731
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:53,746 INFO epoch # 3075 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.008100230115815066
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:53,764 INFO epoch # 3076 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.008119024932966568
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:53,783 INFO epoch # 3077 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.008120002843497787
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:53,801 INFO epoch # 3078 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.008103256644972134
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:53,820 INFO epoch # 3079 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.008075724839727627
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:53,838 INFO epoch # 3080 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.008243526383012068
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:53,838 INFO *** epoch 3080, rolling-avg-loss (window=10)= 0.00811733288483083
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:53,856 INFO epoch # 3081 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.008091820651316084
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:53,875 INFO epoch # 3082 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.008051297831116244
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:53,893 INFO epoch # 3083 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.008184940659702988
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:53,911 INFO epoch # 3084 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.00806549836852355
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:53,930 INFO epoch # 3085 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.008050533408095362
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:53,948 INFO epoch # 3086 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.008080005842202809
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:53,966 INFO epoch # 3087 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.008068359165918082
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:53,985 INFO epoch # 3088 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0025 -loss = 0.008159148521372117
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:54,003 INFO epoch # 3089 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0025-> 0.0024 -loss = 0.008101072446152102
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:54,021 INFO epoch # 3090 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.008382961317693116
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:54,021 INFO *** epoch 3090, rolling-avg-loss (window=10)= 0.008123563821209245
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:54,040 INFO epoch # 3091 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.008113433286780491
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:54,058 INFO epoch # 3092 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.008069232881098287
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:54,076 INFO epoch # 3093 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.008169949880539207
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:54,094 INFO epoch # 3094 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.008126780885504559
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:54,113 INFO epoch # 3095 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.008025735411138157
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:54,131 INFO epoch # 3096 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.008023755850445013
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:54,149 INFO epoch # 3097 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.008630515876575373
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:54,168 INFO epoch # 3098 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.008041099485126324
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:54,186 INFO epoch # 3099 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.008061570639256388
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:54,204 INFO epoch # 3100 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.008100310587906279
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:54,204 INFO *** epoch 3100, rolling-avg-loss (window=10)= 0.008136238478437008
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:54,223 INFO epoch # 3101 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.00811569947109092
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:54,241 INFO epoch # 3102 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.00857043432915816
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:54,259 INFO epoch # 3103 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.008041921220865333
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:54,277 INFO epoch # 3104 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.008042067565838806
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:54,296 INFO epoch # 3105 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.008084582990704803
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:54,314 INFO epoch # 3106 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.008056421800574753
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:54,332 INFO epoch # 3107 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.008068331426329678
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:54,351 INFO epoch # 3108 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.008036166425881675
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:54,369 INFO epoch # 3109 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.008041573077207431
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:54,388 INFO epoch # 3110 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.008161244422808522
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:54,388 INFO *** epoch 3110, rolling-avg-loss (window=10)= 0.008121844273046009
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:54,406 INFO epoch # 3111 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.007992987852048827
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:54,425 INFO epoch # 3112 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.008149800531100482
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:54,443 INFO epoch # 3113 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.008038837520871311
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:54,461 INFO epoch # 3114 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.008035263541387394
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:54,480 INFO epoch # 3115 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.008027133604628034
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:54,498 INFO epoch # 3116 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.008117287907225545
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:54,516 INFO epoch # 3117 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.008037474348384421
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:54,534 INFO epoch # 3118 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.008122957457089797
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:54,553 INFO epoch # 3119 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.008485854545142502
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:54,571 INFO epoch # 3120 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.008039461441512685
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:54,571 INFO *** epoch 3120, rolling-avg-loss (window=10)= 0.0081047058749391
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:54,589 INFO epoch # 3121 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.008237534995714668
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:54,608 INFO epoch # 3122 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.00801486320051481
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:54,627 INFO epoch # 3123 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.008217473412514664
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:54,645 INFO epoch # 3124 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.008046853796258802
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:54,663 INFO epoch # 3125 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.008056887287239078
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:54,682 INFO epoch # 3126 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.008337141924130265
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:54,700 INFO epoch # 3127 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.008084584318567067
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:54,718 INFO epoch # 3128 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.00801177821267629
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:54,736 INFO epoch # 3129 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.008027981857594568
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:54,755 INFO epoch # 3130 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.012364496156806126
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:54,755 INFO *** epoch 3130, rolling-avg-loss (window=10)= 0.008539959516201633
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:54,773 INFO epoch # 3131 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.008342861125129275
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:54,791 INFO epoch # 3132 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.00804055876142229
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:54,810 INFO epoch # 3133 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.007954760094435187
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:54,829 INFO epoch # 3134 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.007985999973243452
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:54,847 INFO epoch # 3135 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.008077339116425719
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:54,865 INFO epoch # 3136 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.008019218606932554
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:54,884 INFO epoch # 3137 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.008163481710653286
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:54,902 INFO epoch # 3138 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.008108838395855855
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:54,920 INFO epoch # 3139 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.00799456193271908
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:54,939 INFO epoch # 3140 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.007991810936800903
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:54,939 INFO *** epoch 3140, rolling-avg-loss (window=10)= 0.00806794306536176
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:54,957 INFO epoch # 3141 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.007988710469362559
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:54,976 INFO epoch # 3142 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.008006406300410163
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:54,995 INFO epoch # 3143 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.007935825378808659
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:55,014 INFO epoch # 3144 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.008028995904169278
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:55,033 INFO epoch # 3145 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.008278360324766254
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:55,051 INFO epoch # 3146 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.008558722336601932
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:55,069 INFO epoch # 3147 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.00818911138776457
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:55,088 INFO epoch # 3148 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.008168993132130709
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:55,106 INFO epoch # 3149 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.008246274901466677
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:55,124 INFO epoch # 3150 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.00797776266335859
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:55,125 INFO *** epoch 3150, rolling-avg-loss (window=10)= 0.00813791627988394
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:55,143 INFO epoch # 3151 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.00808931660867529
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:55,162 INFO epoch # 3152 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.008028157870285213
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:55,181 INFO epoch # 3153 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.008168435204424895
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:55,200 INFO epoch # 3154 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.007969341953867115
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:55,218 INFO epoch # 3155 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.008328156574862078
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:55,237 INFO epoch # 3156 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.007995955958904233
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:55,255 INFO epoch # 3157 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.008057950653892476
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:55,273 INFO epoch # 3158 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.008047064737183973
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:55,292 INFO epoch # 3159 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.008057966027990915
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:55,310 INFO epoch # 3160 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.008030911812966224
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:55,310 INFO *** epoch 3160, rolling-avg-loss (window=10)= 0.00807732574030524
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:55,328 INFO epoch # 3161 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.008294099068734795
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:55,346 INFO epoch # 3162 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.007997552373126382
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:55,365 INFO epoch # 3163 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.00800364193491987
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:55,383 INFO epoch # 3164 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.007988110162841622
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:55,401 INFO epoch # 3165 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.007990013400558382
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:55,420 INFO epoch # 3166 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.008176504976290744
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:55,438 INFO epoch # 3167 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.008520543000486214
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:55,456 INFO epoch # 3168 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.008119497586449143
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:55,474 INFO epoch # 3169 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.008105769884423353
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:55,493 INFO epoch # 3170 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.007971715855092043
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:55,493 INFO *** epoch 3170, rolling-avg-loss (window=10)= 0.008116744824292255
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:55,511 INFO epoch # 3171 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.007989554618688999
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:55,529 INFO epoch # 3172 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.008023530008358648
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:55,548 INFO epoch # 3173 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.007941117772134021
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:55,566 INFO epoch # 3174 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.00799274069868261
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:55,585 INFO epoch # 3175 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0024 -loss = 0.008043700443522539
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:55,603 INFO epoch # 3176 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0024-> 0.0023 -loss = 0.008005728530406486
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:55,621 INFO epoch # 3177 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.007960659408126958
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:55,640 INFO epoch # 3178 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.007953832115163095
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:55,658 INFO epoch # 3179 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.00794847065662907
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:55,676 INFO epoch # 3180 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.008001169819181086
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:55,676 INFO *** epoch 3180, rolling-avg-loss (window=10)= 0.007986050407089352
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:55,694 INFO epoch # 3181 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.012349946366157383
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:55,713 INFO epoch # 3182 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.008063493289228063
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:55,731 INFO epoch # 3183 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.007949554761580657
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:55,749 INFO epoch # 3184 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.00796855756198056
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:55,767 INFO epoch # 3185 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.007980122903973097
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:55,786 INFO epoch # 3186 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.007962920943100471
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:55,804 INFO epoch # 3187 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.007958477897773264
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:55,823 INFO epoch # 3188 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.007922413897176739
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:55,841 INFO epoch # 3189 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.007964440519572236
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:55,860 INFO epoch # 3190 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.007990597398020327
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:55,860 INFO *** epoch 3190, rolling-avg-loss (window=10)= 0.008411052553856279
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:55,878 INFO epoch # 3191 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.007964461656229105
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:55,896 INFO epoch # 3192 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.00805174998822622
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:55,914 INFO epoch # 3193 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.007956974313856335
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:55,933 INFO epoch # 3194 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.008057372193434276
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:55,951 INFO epoch # 3195 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.007937510737974662
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:55,970 INFO epoch # 3196 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.007960116476169787
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:55,988 INFO epoch # 3197 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.007981702030519955
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:56,006 INFO epoch # 3198 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.007972779676492792
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:56,025 INFO epoch # 3199 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.007987484204932116
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:56,044 INFO epoch # 3200 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.007984986958035734
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:56,044 INFO *** epoch 3200, rolling-avg-loss (window=10)= 0.007985513823587097
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:56,062 INFO epoch # 3201 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.008080155610514339
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:56,080 INFO epoch # 3202 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.008037238232645905
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:56,098 INFO epoch # 3203 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.007924763151095249
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:56,117 INFO epoch # 3204 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.00792062590335263
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:56,135 INFO epoch # 3205 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.007923827244667336
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:56,153 INFO epoch # 3206 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.008064405417826492
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:56,172 INFO epoch # 3207 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.007938929495139746
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:56,190 INFO epoch # 3208 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.008019757064175792
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:56,208 INFO epoch # 3209 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.008303716153022833
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:56,227 INFO epoch # 3210 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.01075781258259667
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:56,227 INFO *** epoch 3210, rolling-avg-loss (window=10)= 0.0082971230855037
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:56,245 INFO epoch # 3211 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.008020446872251341
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:56,263 INFO epoch # 3212 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.008124509724439122
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:56,282 INFO epoch # 3213 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.007929680490633473
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:56,300 INFO epoch # 3214 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.007918442373920698
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:56,318 INFO epoch # 3215 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.007946171521325596
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:56,337 INFO epoch # 3216 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.008545265853172168
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:56,355 INFO epoch # 3217 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.008003882590855937
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:56,373 INFO epoch # 3218 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.007928451894258615
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:56,392 INFO epoch # 3219 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.00795213279343443
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:56,410 INFO epoch # 3220 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.007952808547997847
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:56,411 INFO *** epoch 3220, rolling-avg-loss (window=10)= 0.008032179266228923
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:56,429 INFO epoch # 3221 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.008121121383737773
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:56,448 INFO epoch # 3222 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.00794323708396405
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:56,466 INFO epoch # 3223 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.007949943741550669
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:56,484 INFO epoch # 3224 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.007891290908446535
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:56,502 INFO epoch # 3225 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.00787489042886591
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:56,521 INFO epoch # 3226 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.007954315093229525
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:56,539 INFO epoch # 3227 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.007927338949230034
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:56,557 INFO epoch # 3228 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.00789874889596831
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:56,576 INFO epoch # 3229 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.008172394846042152
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:56,594 INFO epoch # 3230 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.007942098618514137
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:56,594 INFO *** epoch 3230, rolling-avg-loss (window=10)= 0.00796753799495491
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:56,613 INFO epoch # 3231 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.00799864437431097
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:56,631 INFO epoch # 3232 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.007948622442199849
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:56,650 INFO epoch # 3233 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.007909318344900385
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:56,668 INFO epoch # 3234 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.00791278851829702
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:56,686 INFO epoch # 3235 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.007908868192316731
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:56,705 INFO epoch # 3236 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.00879473129316466
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:56,723 INFO epoch # 3237 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.00811479191906983
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:56,741 INFO epoch # 3238 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.008137973192788195
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:56,759 INFO epoch # 3239 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.007989995785464998
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:56,778 INFO epoch # 3240 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.008014577098947484
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:56,778 INFO *** epoch 3240, rolling-avg-loss (window=10)= 0.008073031116146013
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:56,797 INFO epoch # 3241 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.00792644513421692
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:56,815 INFO epoch # 3242 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.007963994648889638
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:56,834 INFO epoch # 3243 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.007805014567566104
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:56,853 INFO epoch # 3244 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.007903897483629407
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:56,871 INFO epoch # 3245 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.00791091666178545
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:56,889 INFO epoch # 3246 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.00789173050725367
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:56,908 INFO epoch # 3247 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.007933154964121059
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:56,927 INFO epoch # 3248 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.007845103642466711
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:56,946 INFO epoch # 3249 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.007943993150547612
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:56,965 INFO epoch # 3250 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.007914664765849011
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:56,965 INFO *** epoch 3250, rolling-avg-loss (window=10)= 0.007903891552632557
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:56,983 INFO epoch # 3251 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.007911420980235562
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:57,001 INFO epoch # 3252 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.007961477411299711
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:57,020 INFO epoch # 3253 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0023 -loss = 0.007918595030787401
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:57,038 INFO epoch # 3254 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0023-> 0.0022 -loss = 0.008013105507416185
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:57,056 INFO epoch # 3255 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0022-> 0.0022 -loss = 0.0078851837424736
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:57,076 INFO epoch # 3256 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0022-> 0.0022 -loss = 0.007983236995642073
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:57,094 INFO epoch # 3257 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0022-> 0.0022 -loss = 0.008188012077880558
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:57,113 INFO epoch # 3258 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0022-> 0.0022 -loss = 0.007921951815660577
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:57,132 INFO epoch # 3259 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0022-> 0.0022 -loss = 0.007871369907661574
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:57,150 INFO epoch # 3260 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0022-> 0.0022 -loss = 0.007898081115854438
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:57,150 INFO *** epoch 3260, rolling-avg-loss (window=10)= 0.007955243458491168
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:57,169 INFO epoch # 3261 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0022-> 0.0022 -loss = 0.00789907420767122
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:57,187 INFO epoch # 3262 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0022-> 0.0022 -loss = 0.007869238470448181
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:57,205 INFO epoch # 3263 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0022-> 0.0022 -loss = 0.007939723225717898
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:57,224 INFO epoch # 3264 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0022-> 0.0022 -loss = 0.008449177104921546
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:57,243 INFO epoch # 3265 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0022-> 0.0022 -loss = 0.00783123459223134
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:57,261 INFO epoch # 3266 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0022-> 0.0022 -loss = 0.007864738552598283
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:57,279 INFO epoch # 3267 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0022-> 0.0022 -loss = 0.00789880860975245
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:57,298 INFO epoch # 3268 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0022-> 0.0022 -loss = 0.007916609436506405
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:57,316 INFO epoch # 3269 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0022-> 0.0022 -loss = 0.007842280087061226
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:57,334 INFO epoch # 3270 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0022-> 0.0022 -loss = 0.007905069320258917
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:57,334 INFO *** epoch 3270, rolling-avg-loss (window=10)= 0.007941595360716747
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:57,352 INFO epoch # 3271 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0022-> 0.0022 -loss = 0.008356250385986641
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:57,370 INFO epoch # 3272 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0022-> 0.0022 -loss = 0.007951501313073095
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:57,389 INFO epoch # 3273 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0022-> 0.0022 -loss = 0.007862958416808397
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:57,407 INFO epoch # 3274 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0022-> 0.0022 -loss = 0.007885528673796216
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:57,425 INFO epoch # 3275 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0022-> 0.0022 -loss = 0.00825390708996565
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:57,443 INFO epoch # 3276 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0022-> 0.0022 -loss = 0.007981298527738545
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:57,462 INFO epoch # 3277 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0022-> 0.0022 -loss = 0.007886469371442217
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:57,480 INFO epoch # 3278 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0022-> 0.0022 -loss = 0.007880233406467596
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:57,498 INFO epoch # 3279 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0022-> 0.0022 -loss = 0.00785884683864424
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:57,517 INFO epoch # 3280 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0022-> 0.0022 -loss = 0.007857300101022702
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:57,517 INFO *** epoch 3280, rolling-avg-loss (window=10)= 0.00797742941249453
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:57,535 INFO epoch # 3281 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0022-> 0.0022 -loss = 0.007884468061092775
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:57,553 INFO epoch # 3282 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0022-> 0.0022 -loss = 0.00791489020048175
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:57,571 INFO epoch # 3283 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0022-> 0.0022 -loss = 0.007933018801850267
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:57,590 INFO epoch # 3284 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0022-> 0.0022 -loss = 0.007854279698221944
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:57,608 INFO epoch # 3285 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0022-> 0.0022 -loss = 0.008340704978763824
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:57,626 INFO epoch # 3286 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0022-> 0.0022 -loss = 0.008174310336471535
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:57,645 INFO epoch # 3287 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0022-> 0.0022 -loss = 0.007943585616885684
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:57,663 INFO epoch # 3288 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0022-> 0.0022 -loss = 0.008004418494238053
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:57,682 INFO epoch # 3289 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0022-> 0.0022 -loss = 0.007866932333854493
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:57,700 INFO epoch # 3290 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0022-> 0.0022 -loss = 0.00783580846109544
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:57,700 INFO *** epoch 3290, rolling-avg-loss (window=10)= 0.007975241698295577
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:57,718 INFO epoch # 3291 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0022-> 0.0022 -loss = 0.007801662173733348
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:57,736 INFO epoch # 3292 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0022-> 0.0022 -loss = 0.007821897273970535
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:57,755 INFO epoch # 3293 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0022-> 0.0022 -loss = 0.007809988124790834
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:57,773 INFO epoch # 3294 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0022-> 0.0022 -loss = 0.00785359234578209
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:57,791 INFO epoch # 3295 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0022-> 0.0022 -loss = 0.007926656428026035
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:57,809 INFO epoch # 3296 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0022-> 0.0022 -loss = 0.007867026557505596
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:57,828 INFO epoch # 3297 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0022-> 0.0022 -loss = 0.007855225088860607
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:57,846 INFO epoch # 3298 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0022-> 0.0022 -loss = 0.007874612594605424
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:57,865 INFO epoch # 3299 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0022-> 0.0022 -loss = 0.008078964448941406
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:57,884 INFO epoch # 3300 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0022-> 0.0022 -loss = 0.00784909929643618
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:57,884 INFO *** epoch 3300, rolling-avg-loss (window=10)= 0.007873872433265205
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:57,903 INFO epoch # 3301 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0022-> 0.0022 -loss = 0.007848556306271348
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:57,921 INFO epoch # 3302 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0022-> 0.0021 -loss = 0.00996612790186191
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:57,939 INFO epoch # 3303 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.007910225154773798
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:57,958 INFO epoch # 3304 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.007920825977635104
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:57,976 INFO epoch # 3305 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.008258679314167239
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:57,994 INFO epoch # 3306 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.008037871040869504
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:58,013 INFO epoch # 3307 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.007870397148508346
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:58,031 INFO epoch # 3308 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.007917051694676047
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:58,050 INFO epoch # 3309 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.007797403723088792
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:58,069 INFO epoch # 3310 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.008030611727008363
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:58,069 INFO *** epoch 3310, rolling-avg-loss (window=10)= 0.008155774998886044
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:58,088 INFO epoch # 3311 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.00796527358761523
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:58,107 INFO epoch # 3312 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.00783032066465239
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:58,125 INFO epoch # 3313 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.007816762103175279
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:58,143 INFO epoch # 3314 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.00786436213820707
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:58,161 INFO epoch # 3315 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.007809419726982014
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:58,180 INFO epoch # 3316 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.007997651740879519
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:58,198 INFO epoch # 3317 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.007803906712069875
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:58,216 INFO epoch # 3318 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.0079521694824507
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:58,235 INFO epoch # 3319 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.008375861041713506
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:58,253 INFO epoch # 3320 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.00785737036858336
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:58,253 INFO *** epoch 3320, rolling-avg-loss (window=10)= 0.007927309756632894
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:58,271 INFO epoch # 3321 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.008277837827336043
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:58,290 INFO epoch # 3322 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.007875241892179474
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:58,308 INFO epoch # 3323 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.007846942437026883
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:58,326 INFO epoch # 3324 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.007886610728746746
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:58,345 INFO epoch # 3325 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.00779081585642416
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:58,363 INFO epoch # 3326 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.007898692492744885
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:58,381 INFO epoch # 3327 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.00784645776002435
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:58,399 INFO epoch # 3328 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.00784965918137459
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:58,418 INFO epoch # 3329 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.007934378627396654
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:58,436 INFO epoch # 3330 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.007846930668165442
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:58,436 INFO *** epoch 3330, rolling-avg-loss (window=10)= 0.007905356747141924
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:58,455 INFO epoch # 3331 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.007856444892240688
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:58,473 INFO epoch # 3332 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.007879174074332695
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:58,492 INFO epoch # 3333 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.007808437556377612
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:58,510 INFO epoch # 3334 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.00779213191344752
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:58,528 INFO epoch # 3335 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.007792750089720357
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:58,547 INFO epoch # 3336 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.00784717290662229
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:58,565 INFO epoch # 3337 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.007818103338649962
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:58,583 INFO epoch # 3338 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.007798925682436675
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:58,601 INFO epoch # 3339 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.007872053662140388
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:58,620 INFO epoch # 3340 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.007807222988049034
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:58,620 INFO *** epoch 3340, rolling-avg-loss (window=10)= 0.007827241710401722
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:58,638 INFO epoch # 3341 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.007847493106964976
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:58,657 INFO epoch # 3342 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.007802238316799048
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:58,675 INFO epoch # 3343 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.007960255079524359
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:58,694 INFO epoch # 3344 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.007904786347353365
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:58,712 INFO epoch # 3345 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.007755827326036524
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:58,730 INFO epoch # 3346 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.007839096149837133
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:58,749 INFO epoch # 3347 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.0077478838320530485
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:58,767 INFO epoch # 3348 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.007901974153355695
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:58,785 INFO epoch # 3349 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.007861424677685136
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:58,803 INFO epoch # 3350 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.007781864871503785
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:58,803 INFO *** epoch 3350, rolling-avg-loss (window=10)= 0.007840284386111307
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:58,822 INFO epoch # 3351 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.007880452441895613
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:58,840 INFO epoch # 3352 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.008150024677888723
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:58,859 INFO epoch # 3353 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.007860935598728247
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:58,878 INFO epoch # 3354 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.008527566384145757
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:58,897 INFO epoch # 3355 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.007833732550352579
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:58,916 INFO epoch # 3356 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.007799379869538825
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:58,934 INFO epoch # 3357 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.008178402516932692
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:58,952 INFO epoch # 3358 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.007828468136722222
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:58,971 INFO epoch # 3359 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.007756127939501312
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:58,989 INFO epoch # 3360 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.007768988834868651
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:58,989 INFO *** epoch 3360, rolling-avg-loss (window=10)= 0.007958407895057463
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:59,007 INFO epoch # 3361 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.007815778786607552
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:59,026 INFO epoch # 3362 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.007792785072524566
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:59,044 INFO epoch # 3363 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.0077438450571207795
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:59,063 INFO epoch # 3364 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.007806080597219989
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:59,081 INFO epoch # 3365 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.007766187496599741
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:59,100 INFO epoch # 3366 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.008057512579398463
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:59,118 INFO epoch # 3367 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.007875820454501081
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:59,136 INFO epoch # 3368 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.007878222884755814
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:59,155 INFO epoch # 3369 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.007734848883046652
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:59,173 INFO epoch # 3370 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.007920531163108535
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:59,173 INFO *** epoch 3370, rolling-avg-loss (window=10)= 0.007839161297488318
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:59,191 INFO epoch # 3371 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.007861222671635915
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:59,209 INFO epoch # 3372 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.007904211674031103
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:59,228 INFO epoch # 3373 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.0078034465841483325
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:59,246 INFO epoch # 3374 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.007751201782411954
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:59,264 INFO epoch # 3375 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.007813825824996457
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:59,283 INFO epoch # 3376 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.007979872600117233
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:59,301 INFO epoch # 3377 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.00775103825435508
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:59,320 INFO epoch # 3378 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.007835792614059756
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:59,338 INFO epoch # 3379 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.0078024586946412455
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:59,356 INFO epoch # 3380 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.007815565819328185
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:59,356 INFO *** epoch 3380, rolling-avg-loss (window=10)= 0.007831863651972526
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:59,374 INFO epoch # 3381 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.01200899486138951
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:59,393 INFO epoch # 3382 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.007886485356721096
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:59,411 INFO epoch # 3383 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.007792478951159865
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:59,429 INFO epoch # 3384 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.007785093479469651
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:59,448 INFO epoch # 3385 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.007786054102325579
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:59,466 INFO epoch # 3386 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.00791357292473549
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:59,485 INFO epoch # 3387 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.008270014608569909
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:59,504 INFO epoch # 3388 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.007766623544739559
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:59,522 INFO epoch # 3389 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.008008104872715194
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:59,540 INFO epoch # 3390 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.0021 -loss = 0.007765242378809489
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:59,540 INFO *** epoch 3390, rolling-avg-loss (window=10)= 0.008298266508063534
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:59,558 INFO epoch # 3391 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0021-> 0.002 -loss = 0.0077585202670888975
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:59,577 INFO epoch # 3392 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.00984085906020482
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:59,595 INFO epoch # 3393 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.007946615274704527
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:59,613 INFO epoch # 3394 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.007772897872200701
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:59,632 INFO epoch # 3395 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.007849376488593407
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:59,650 INFO epoch # 3396 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.010499913543753792
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:59,668 INFO epoch # 3397 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.007826365450455341
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:59,687 INFO epoch # 3398 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.007814281198079698
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:59,705 INFO epoch # 3399 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.007769002637360245
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:59,724 INFO epoch # 3400 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.007846859451092314
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:59,724 INFO *** epoch 3400, rolling-avg-loss (window=10)= 0.008292469124353375
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:59,742 INFO epoch # 3401 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.007826485423720442
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:59,760 INFO epoch # 3402 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.0077645161873078905
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:59,778 INFO epoch # 3403 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.007906949998869095
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:59,797 INFO epoch # 3404 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.007972686158609577
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:59,815 INFO epoch # 3405 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.007828710509784287
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:59,834 INFO epoch # 3406 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.007802467254805379
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:59,852 INFO epoch # 3407 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.008046059519983828
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:59,871 INFO epoch # 3408 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.007876146581111243
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:59,889 INFO epoch # 3409 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.011832190859422553
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:59,908 INFO epoch # 3410 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.007913873079814948
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:48:59,908 INFO *** epoch 3410, rolling-avg-loss (window=10)= 0.008277008557342924
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:59,926 INFO epoch # 3411 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.007761721848510206
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:59,945 INFO epoch # 3412 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.007741221794276498
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:59,963 INFO epoch # 3413 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.007673936630453682
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:59,981 INFO epoch # 3414 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.00771176326998102
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:48:59,999 INFO epoch # 3415 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.007760639800835634
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:00,018 INFO epoch # 3416 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.007750316486635711
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:00,036 INFO epoch # 3417 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.007893378482549451
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:00,055 INFO epoch # 3418 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.007697433935391018
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:00,073 INFO epoch # 3419 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.007702406099269865
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:00,091 INFO epoch # 3420 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.007779661187669262
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:00,092 INFO *** epoch 3420, rolling-avg-loss (window=10)= 0.0077472479535572345
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:00,110 INFO epoch # 3421 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.007859083081712015
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:00,128 INFO epoch # 3422 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.007825703210983193
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:00,147 INFO epoch # 3423 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.007738810618320713
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:00,165 INFO epoch # 3424 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.007822547740943264
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:00,183 INFO epoch # 3425 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.00782575360062765
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:00,202 INFO epoch # 3426 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.00773159293748904
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:00,220 INFO epoch # 3427 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.007724341943685431
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:00,238 INFO epoch # 3428 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.007716733867709991
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:00,256 INFO epoch # 3429 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.007820039023499703
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:00,275 INFO epoch # 3430 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.007867091666412307
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:00,275 INFO *** epoch 3430, rolling-avg-loss (window=10)= 0.00779316976913833
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:00,293 INFO epoch # 3431 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.007787232403643429
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:00,311 INFO epoch # 3432 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.007717857079114765
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:00,330 INFO epoch # 3433 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.007804778197169071
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:00,348 INFO epoch # 3434 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.007741291385173099
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:00,367 INFO epoch # 3435 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.0077129719575168565
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:00,385 INFO epoch # 3436 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.007802423897373956
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:00,403 INFO epoch # 3437 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.0077372154701151885
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:00,421 INFO epoch # 3438 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.007790311618009582
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:00,440 INFO epoch # 3439 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.008194843278033659
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:00,458 INFO epoch # 3440 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.0077468872696044855
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:00,458 INFO *** epoch 3440, rolling-avg-loss (window=10)= 0.007803581255575409
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:00,476 INFO epoch # 3441 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.007784183391777333
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:00,495 INFO epoch # 3442 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.007813669384631794
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:00,513 INFO epoch # 3443 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.007829079018847551
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:00,531 INFO epoch # 3444 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.007802009775332408
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:00,550 INFO epoch # 3445 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.007675319604459219
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:00,568 INFO epoch # 3446 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.0077339997405942995
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:00,586 INFO epoch # 3447 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.007791095522406977
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:00,605 INFO epoch # 3448 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.007767878312733956
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:00,623 INFO epoch # 3449 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.0076993719703750685
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:00,641 INFO epoch # 3450 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.007807743124430999
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:00,641 INFO *** epoch 3450, rolling-avg-loss (window=10)= 0.00777043498455896
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:00,659 INFO epoch # 3451 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.007724611681624083
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:00,678 INFO epoch # 3452 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.007710894045885652
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:00,696 INFO epoch # 3453 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.008229293744079769
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:00,715 INFO epoch # 3454 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.007789179486280773
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:00,733 INFO epoch # 3455 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.007841581798857078
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:00,752 INFO epoch # 3456 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.007720554622210329
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:00,770 INFO epoch # 3457 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.007667253295949195
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:00,789 INFO epoch # 3458 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.007821291736036073
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:00,807 INFO epoch # 3459 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.007667117341043195
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:00,825 INFO epoch # 3460 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.007751940480375197
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:00,825 INFO *** epoch 3460, rolling-avg-loss (window=10)= 0.007792371823234135
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:00,843 INFO epoch # 3461 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.0077642070391448215
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:00,862 INFO epoch # 3462 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.00777039705280913
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:00,880 INFO epoch # 3463 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.00769526363001205
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:00,899 INFO epoch # 3464 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.007755989325232804
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:00,918 INFO epoch # 3465 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.008044033915211912
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:00,936 INFO epoch # 3466 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.007739517630398041
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:00,954 INFO epoch # 3467 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.002 -loss = 0.00779707649780903
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:00,973 INFO epoch # 3468 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.002-> 0.0019 -loss = 0.007708703160460573
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:00,991 INFO epoch # 3469 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0019 -loss = 0.007709799589065369
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:01,009 INFO epoch # 3470 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0019 -loss = 0.00772795080774813
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:01,009 INFO *** epoch 3470, rolling-avg-loss (window=10)= 0.007771293864789186
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:01,028 INFO epoch # 3471 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0019 -loss = 0.008190052929421654
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:01,046 INFO epoch # 3472 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0019 -loss = 0.00781176926830085
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:01,064 INFO epoch # 3473 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0019 -loss = 0.007652060157852247
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:01,083 INFO epoch # 3474 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0019 -loss = 0.007846384956792463
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:01,101 INFO epoch # 3475 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0019 -loss = 0.007721588652202627
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:01,120 INFO epoch # 3476 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0019 -loss = 0.007743970552837709
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:01,139 INFO epoch # 3477 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0019 -loss = 0.007653964508790523
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:01,158 INFO epoch # 3478 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0019 -loss = 0.007695031668845331
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:01,176 INFO epoch # 3479 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0019 -loss = 0.0076803304873465095
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:01,195 INFO epoch # 3480 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0019 -loss = 0.00777250336977886
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:01,195 INFO *** epoch 3480, rolling-avg-loss (window=10)= 0.007776765655216877
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:01,213 INFO epoch # 3481 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0019 -loss = 0.007694853607972618
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:01,231 INFO epoch # 3482 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0019 -loss = 0.007789046292600688
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:01,249 INFO epoch # 3483 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0019 -loss = 0.009687864432635251
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:01,268 INFO epoch # 3484 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0019 -loss = 0.007841766640922287
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:01,286 INFO epoch # 3485 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0019 -loss = 0.007699819387198659
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:01,304 INFO epoch # 3486 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0019 -loss = 0.007692085728194797
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:01,323 INFO epoch # 3487 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0019 -loss = 0.007686095486860722
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:01,341 INFO epoch # 3488 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0019 -loss = 0.007708117496804334
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:01,359 INFO epoch # 3489 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0019 -loss = 0.007777332088153344
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:01,378 INFO epoch # 3490 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0019 -loss = 0.007785114728903864
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:01,378 INFO *** epoch 3490, rolling-avg-loss (window=10)= 0.007936209589024657
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:01,396 INFO epoch # 3491 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0019 -loss = 0.00769111308909487
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:01,415 INFO epoch # 3492 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0019 -loss = 0.00780714230495505
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:01,433 INFO epoch # 3493 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0019 -loss = 0.007655349974811543
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:01,451 INFO epoch # 3494 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0019 -loss = 0.007735797960776836
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:01,469 INFO epoch # 3495 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0019 -loss = 0.007732325415418018
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:01,488 INFO epoch # 3496 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0019 -loss = 0.007803639906342141
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:01,506 INFO epoch # 3497 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0019 -loss = 0.0076797436086053494
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:01,525 INFO epoch # 3498 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0019 -loss = 0.007783316177665256
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:01,543 INFO epoch # 3499 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0019 -loss = 0.00784912863309728
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:01,561 INFO epoch # 3500 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0019 -loss = 0.007691318645811407
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:01,562 INFO *** epoch 3500, rolling-avg-loss (window=10)= 0.007742887571657775
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:01,580 INFO epoch # 3501 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0019 -loss = 0.0076825024116260465
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:01,599 INFO epoch # 3502 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0019 -loss = 0.0077156048064352944
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:01,617 INFO epoch # 3503 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0019 -loss = 0.007814161068381509
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:01,635 INFO epoch # 3504 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0019 -loss = 0.007658802918740548
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:01,654 INFO epoch # 3505 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0019 -loss = 0.0076941464794799685
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:01,672 INFO epoch # 3506 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0019 -loss = 0.007662636875465978
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:01,690 INFO epoch # 3507 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0019 -loss = 0.0077499154685938265
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:01,709 INFO epoch # 3508 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0019 -loss = 0.007653328229935141
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:01,727 INFO epoch # 3509 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0019 -loss = 0.0077650207676924765
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:01,746 INFO epoch # 3510 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0019 -loss = 0.007706473970756633
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:01,746 INFO *** epoch 3510, rolling-avg-loss (window=10)= 0.007710259299710742
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:01,764 INFO epoch # 3511 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0019 -loss = 0.007770946747768903
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:01,783 INFO epoch # 3512 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0019 -loss = 0.0077281176709220745
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:01,801 INFO epoch # 3513 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0019 -loss = 0.007605576201967779
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:01,820 INFO epoch # 3514 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0019 -loss = 0.007678498528548516
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:01,838 INFO epoch # 3515 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0019 -loss = 0.011790195254434366
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:01,856 INFO epoch # 3516 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0019 -loss = 0.007778880441037472
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:01,875 INFO epoch # 3517 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0019 -loss = 0.007662046424229629
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:01,893 INFO epoch # 3518 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0019 -loss = 0.00779240702468087
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:01,911 INFO epoch # 3519 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0019 -loss = 0.008419884165050462
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:01,930 INFO epoch # 3520 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0019 -loss = 0.007854712584958179
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:01,930 INFO *** epoch 3520, rolling-avg-loss (window=10)= 0.008208126504359824
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:01,948 INFO epoch # 3521 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0019 -loss = 0.007816378478310071
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:01,967 INFO epoch # 3522 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0019 -loss = 0.007795579705998534
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:01,985 INFO epoch # 3523 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0019 -loss = 0.00768465019427822
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:02,004 INFO epoch # 3524 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0019 -loss = 0.007672156829357846
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:02,022 INFO epoch # 3525 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0019 -loss = 0.007649040468095336
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:02,040 INFO epoch # 3526 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0019 -loss = 0.007622584133059718
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:02,059 INFO epoch # 3527 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0019 -loss = 0.007728278418653645
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:02,077 INFO epoch # 3528 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0019 -loss = 0.007641334326763172
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:02,095 INFO epoch # 3529 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0019 -loss = 0.007657327616470866
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:02,114 INFO epoch # 3530 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0019 -loss = 0.007664339689654298
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:02,114 INFO *** epoch 3530, rolling-avg-loss (window=10)= 0.007693166986064171
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:02,132 INFO epoch # 3531 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0019 -loss = 0.007628206087247236
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:02,151 INFO epoch # 3532 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0019 -loss = 0.007802049694873858
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:02,169 INFO epoch # 3533 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0019 -loss = 0.007616800321557093
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:02,188 INFO epoch # 3534 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0019 -loss = 0.007637587877979968
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:02,206 INFO epoch # 3535 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0019-> 0.0018 -loss = 0.007758087223919574
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:02,224 INFO epoch # 3536 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.007707216773269465
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:02,242 INFO epoch # 3537 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.007671192390262149
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:02,261 INFO epoch # 3538 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.00791060147821554
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:02,279 INFO epoch # 3539 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.0076603545967373066
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:02,297 INFO epoch # 3540 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.007691941107623279
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:02,298 INFO *** epoch 3540, rolling-avg-loss (window=10)= 0.007708403755168547
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:02,316 INFO epoch # 3541 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.007696130349359009
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:02,334 INFO epoch # 3542 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.007684320793487132
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:02,353 INFO epoch # 3543 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.007654998888028786
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:02,371 INFO epoch # 3544 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.007685360717005096
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:02,390 INFO epoch # 3545 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.00767349278612528
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:02,408 INFO epoch # 3546 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.007662018724658992
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:02,427 INFO epoch # 3547 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.007799515155056724
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:02,445 INFO epoch # 3548 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.007747615651169326
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:02,463 INFO epoch # 3549 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.0076391925613279454
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:02,481 INFO epoch # 3550 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.007833883588318713
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:02,482 INFO *** epoch 3550, rolling-avg-loss (window=10)= 0.0077076529214537
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:02,500 INFO epoch # 3551 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.007629145082319155
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:02,518 INFO epoch # 3552 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.007895068294601515
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:02,537 INFO epoch # 3553 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.007710708050581161
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:02,555 INFO epoch # 3554 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.007918425275420304
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:02,573 INFO epoch # 3555 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.007692467908782419
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:02,592 INFO epoch # 3556 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.007619073085152195
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:02,610 INFO epoch # 3557 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.00765839184896322
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:02,629 INFO epoch # 3558 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.007598862288432429
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:02,647 INFO epoch # 3559 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.007579561530292267
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:02,665 INFO epoch # 3560 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.007679810427362099
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:02,666 INFO *** epoch 3560, rolling-avg-loss (window=10)= 0.0076981513791906766
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:02,684 INFO epoch # 3561 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.007577696964290226
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:02,702 INFO epoch # 3562 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.007698244364291895
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:02,720 INFO epoch # 3563 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.007589032553369179
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:02,739 INFO epoch # 3564 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.007748368952888995
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:02,757 INFO epoch # 3565 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.0076163569174241275
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:02,776 INFO epoch # 3566 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.007605368140502833
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:02,794 INFO epoch # 3567 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.007609131735080155
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:02,813 INFO epoch # 3568 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.007640440526301973
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:02,831 INFO epoch # 3569 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.007619810436153784
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:02,849 INFO epoch # 3570 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.007670719533052761
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:02,849 INFO *** epoch 3570, rolling-avg-loss (window=10)= 0.0076375170123355925
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:02,868 INFO epoch # 3571 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.007637699614861049
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:02,886 INFO epoch # 3572 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.007619877338584047
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:02,904 INFO epoch # 3573 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.007670692164538195
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:02,923 INFO epoch # 3574 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.007590566878207028
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:02,941 INFO epoch # 3575 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.007616283251991263
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:02,960 INFO epoch # 3576 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.0075927217440039385
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:02,978 INFO epoch # 3577 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.007679426351387519
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:02,997 INFO epoch # 3578 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.007807422251062235
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:03,016 INFO epoch # 3579 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.00763906805877923
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:03,035 INFO epoch # 3580 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.0075979654138791375
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:03,035 INFO *** epoch 3580, rolling-avg-loss (window=10)= 0.0076451723067293646
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:03,053 INFO epoch # 3581 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.007719863562670071
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:03,071 INFO epoch # 3582 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.007595208171551349
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:03,090 INFO epoch # 3583 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.007599262014991837
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:03,108 INFO epoch # 3584 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.00758677253179485
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:03,126 INFO epoch # 3585 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.007625887326867087
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:03,145 INFO epoch # 3586 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.007574001163447974
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:03,163 INFO epoch # 3587 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.007584656359540531
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:03,182 INFO epoch # 3588 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.007552049013611395
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:03,200 INFO epoch # 3589 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.007585482841022895
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:03,219 INFO epoch # 3590 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.007652212661923841
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:03,219 INFO *** epoch 3590, rolling-avg-loss (window=10)= 0.007607539564742183
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:03,237 INFO epoch # 3591 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.007556651558843441
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:03,256 INFO epoch # 3592 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.007628617007867433
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:03,274 INFO epoch # 3593 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.007706480391789228
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:03,292 INFO epoch # 3594 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.0076238994479354005
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:03,310 INFO epoch # 3595 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.0075840132412849925
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:03,329 INFO epoch # 3596 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.007614928959810641
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:03,347 INFO epoch # 3597 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.007581600395496935
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:03,366 INFO epoch # 3598 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.007557608656497905
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:03,386 INFO epoch # 3599 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.007599110929731978
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:03,405 INFO epoch # 3600 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.007564521954918746
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:03,405 INFO *** epoch 3600, rolling-avg-loss (window=10)= 0.00760174325441767
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:03,424 INFO epoch # 3601 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.007608666528540198
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:03,442 INFO epoch # 3602 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.007586117135360837
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:03,460 INFO epoch # 3603 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.007719322657067096
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:03,479 INFO epoch # 3604 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.00759132657549344
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:03,497 INFO epoch # 3605 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.007617715589731233
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:03,515 INFO epoch # 3606 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.00758466807383229
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:03,534 INFO epoch # 3607 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.007596912837470882
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:03,552 INFO epoch # 3608 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.007601440102007473
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:03,571 INFO epoch # 3609 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.007606821920489892
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:03,589 INFO epoch # 3610 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.007543298353994032
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:03,589 INFO *** epoch 3610, rolling-avg-loss (window=10)= 0.007605628977398737
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:03,607 INFO epoch # 3611 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.00760970279952744
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:03,626 INFO epoch # 3612 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.007726519776042551
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:03,644 INFO epoch # 3613 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.007710790599958273
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:03,662 INFO epoch # 3614 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.0076649093243759125
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:03,681 INFO epoch # 3615 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.00781750060923514
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:03,699 INFO epoch # 3616 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.007903906993306009
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:03,717 INFO epoch # 3617 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.008107157049380476
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:03,736 INFO epoch # 3618 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.008075902176642558
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:03,754 INFO epoch # 3619 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.0075960811373079196
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:03,773 INFO epoch # 3620 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0018 -loss = 0.007649369828868657
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:03,773 INFO *** epoch 3620, rolling-avg-loss (window=10)= 0.007786184029464493
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:03,791 INFO epoch # 3621 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0018-> 0.0017 -loss = 0.007750365995889297
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:03,810 INFO epoch # 3622 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.007578797169117024
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:03,828 INFO epoch # 3623 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.0076386460386856925
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:03,847 INFO epoch # 3624 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.007582766040286515
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:03,865 INFO epoch # 3625 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.007563143411971396
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:03,883 INFO epoch # 3626 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.007580157929623965
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:03,901 INFO epoch # 3627 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.007970378959726077
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:03,920 INFO epoch # 3628 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.007611539196659578
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:03,938 INFO epoch # 3629 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.007608992818859406
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:03,957 INFO epoch # 3630 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.007565979452920146
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:03,957 INFO *** epoch 3630, rolling-avg-loss (window=10)= 0.007645076701373909
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:03,975 INFO epoch # 3631 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.007617324066814035
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:03,994 INFO epoch # 3632 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.007566324646177236
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:04,012 INFO epoch # 3633 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.007548868728918023
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:04,031 INFO epoch # 3634 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.007593799011374358
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:04,049 INFO epoch # 3635 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.0076947497473156545
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:04,067 INFO epoch # 3636 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.007574529590783641
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:04,086 INFO epoch # 3637 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.007601321369293146
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:04,104 INFO epoch # 3638 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.007540116843301803
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:04,122 INFO epoch # 3639 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.007893503177911043
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:04,141 INFO epoch # 3640 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.007608331783558242
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:04,141 INFO *** epoch 3640, rolling-avg-loss (window=10)= 0.0076238868965447185
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:04,159 INFO epoch # 3641 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.007587991203763522
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:04,178 INFO epoch # 3642 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.00756217421439942
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:04,196 INFO epoch # 3643 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.007567853052023565
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:04,215 INFO epoch # 3644 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.009551914990879595
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:04,233 INFO epoch # 3645 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.007620899275934789
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:04,252 INFO epoch # 3646 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.009878130334982416
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:04,270 INFO epoch # 3647 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.007577001924801152
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:04,288 INFO epoch # 3648 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.007558619399787858
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:04,307 INFO epoch # 3649 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.007828058609447908
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:04,325 INFO epoch # 3650 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.007571490699774586
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:04,325 INFO *** epoch 3650, rolling-avg-loss (window=10)= 0.00803041337057948
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:04,343 INFO epoch # 3651 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.007716242223978043
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:04,362 INFO epoch # 3652 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.007546374610683415
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:04,380 INFO epoch # 3653 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.007638095466973027
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:04,399 INFO epoch # 3654 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.007568626624561148
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:04,417 INFO epoch # 3655 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.007649334576854017
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:04,436 INFO epoch # 3656 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.0075455409205460455
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:04,454 INFO epoch # 3657 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.007829337278963067
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:04,473 INFO epoch # 3658 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.007528342441219138
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:04,491 INFO epoch # 3659 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.007545116717665223
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:04,509 INFO epoch # 3660 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.007582570695376489
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:04,509 INFO *** epoch 3660, rolling-avg-loss (window=10)= 0.007614958155681961
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:04,527 INFO epoch # 3661 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.0075321077201806474
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:04,546 INFO epoch # 3662 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.007547849945694907
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:04,564 INFO epoch # 3663 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.007541965474956669
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:04,583 INFO epoch # 3664 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.007545202268374851
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:04,602 INFO epoch # 3665 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.007525444380007684
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:04,621 INFO epoch # 3666 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.007580800971481949
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:04,640 INFO epoch # 3667 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.007622091594384983
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:04,659 INFO epoch # 3668 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.0075416890904307365
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:04,677 INFO epoch # 3669 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.008033680198423099
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:04,696 INFO epoch # 3670 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.007664527885935968
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:04,696 INFO *** epoch 3670, rolling-avg-loss (window=10)= 0.0076135359529871495
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:04,714 INFO epoch # 3671 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.007547393128334079
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:04,732 INFO epoch # 3672 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.00763020656813751
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:04,751 INFO epoch # 3673 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.007625168829690665
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:04,769 INFO epoch # 3674 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.007655908528249711
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:04,788 INFO epoch # 3675 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.007575588326290017
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:04,806 INFO epoch # 3676 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.007538538418884855
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:04,825 INFO epoch # 3677 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.007664979977562325
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:04,843 INFO epoch # 3678 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.007605776358104777
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:04,862 INFO epoch # 3679 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.007523679581936449
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:04,880 INFO epoch # 3680 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.007633740413439227
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:04,881 INFO *** epoch 3680, rolling-avg-loss (window=10)= 0.007600098013062962
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:04,899 INFO epoch # 3681 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.007560645055491477
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:04,917 INFO epoch # 3682 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.007590673063532449
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:04,935 INFO epoch # 3683 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.007589345303131267
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:04,954 INFO epoch # 3684 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.007555158510513138
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:04,972 INFO epoch # 3685 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.0075034862020402215
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:04,991 INFO epoch # 3686 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.007507022401114227
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:05,009 INFO epoch # 3687 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.007549951751570916
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:05,028 INFO epoch # 3688 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.007533558236900717
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:05,046 INFO epoch # 3689 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.007537289537140168
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:05,065 INFO epoch # 3690 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.0075030027528555365
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:05,065 INFO *** epoch 3690, rolling-avg-loss (window=10)= 0.0075430132814290115
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:05,083 INFO epoch # 3691 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.007508018134103622
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:05,102 INFO epoch # 3692 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.007554284602520056
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:05,121 INFO epoch # 3693 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.0075875193651882
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:05,140 INFO epoch # 3694 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.007513669588661287
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:05,158 INFO epoch # 3695 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.0076131501627969556
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:05,176 INFO epoch # 3696 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.007813566873664968
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:05,195 INFO epoch # 3697 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.0075457716193341184
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:05,213 INFO epoch # 3698 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.007530766022682656
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:05,232 INFO epoch # 3699 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.007654415629076539
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:05,250 INFO epoch # 3700 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.007575723349873442
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:05,250 INFO *** epoch 3700, rolling-avg-loss (window=10)= 0.007589688534790184
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:05,269 INFO epoch # 3701 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.0074969659399357624
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:05,287 INFO epoch # 3702 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.007725944684352726
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:05,306 INFO epoch # 3703 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.007580377885460621
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:05,324 INFO epoch # 3704 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.007538497524365084
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:05,342 INFO epoch # 3705 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.0075571065754047595
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:05,361 INFO epoch # 3706 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.0075101489055668935
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:05,379 INFO epoch # 3707 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.008046659764659125
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:05,398 INFO epoch # 3708 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.007658575796085643
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:05,416 INFO epoch # 3709 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.0075080041569890454
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:05,434 INFO epoch # 3710 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.007491714921343373
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:05,435 INFO *** epoch 3710, rolling-avg-loss (window=10)= 0.0076113996154163035
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:05,453 INFO epoch # 3711 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.0075400576715765055
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:05,472 INFO epoch # 3712 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.007520063769334229
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:05,490 INFO epoch # 3713 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.0074775235407287255
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:05,508 INFO epoch # 3714 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.007508168007916538
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:05,527 INFO epoch # 3715 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.0077374525790219195
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:05,545 INFO epoch # 3716 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.007435625655489275
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:05,563 INFO epoch # 3717 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.007598635311296675
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:05,582 INFO epoch # 3718 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.0075549439279711805
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:05,600 INFO epoch # 3719 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.007529374481237028
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:05,619 INFO epoch # 3720 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.011452403487055562
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:05,619 INFO *** epoch 3720, rolling-avg-loss (window=10)= 0.007935424843162764
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:05,638 INFO epoch # 3721 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.007634745954419486
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:05,656 INFO epoch # 3722 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.007587465392134618
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:05,675 INFO epoch # 3723 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.007614315658429405
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:05,693 INFO epoch # 3724 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.007814638986019418
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:05,712 INFO epoch # 3725 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.007618453979375772
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:05,730 INFO epoch # 3726 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.007502281776396558
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:05,748 INFO epoch # 3727 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.007481324497348396
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:05,766 INFO epoch # 3728 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.00753400576650165
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:05,785 INFO epoch # 3729 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.007535568169259932
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:05,803 INFO epoch # 3730 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.007489768158848165
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:05,803 INFO *** epoch 3730, rolling-avg-loss (window=10)= 0.00758125683387334
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:05,822 INFO epoch # 3731 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.007520089631725568
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:05,840 INFO epoch # 3732 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.007460121414624155
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:05,859 INFO epoch # 3733 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.007520722909248434
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:05,878 INFO epoch # 3734 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.0075339014365454204
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:05,896 INFO epoch # 3735 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.007544298066932242
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:05,914 INFO epoch # 3736 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.007661399995413376
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:05,933 INFO epoch # 3737 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0017 -loss = 0.007480793981812894
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:05,951 INFO epoch # 3738 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0017-> 0.0016 -loss = 0.007591411711473484
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:05,969 INFO epoch # 3739 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.007648403188795783
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:05,987 INFO epoch # 3740 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.007523377164034173
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:05,987 INFO *** epoch 3740, rolling-avg-loss (window=10)= 0.007548451950060553
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:06,006 INFO epoch # 3741 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.007481933571398258
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:06,025 INFO epoch # 3742 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.007477303388441214
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:06,043 INFO epoch # 3743 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.007510347142670071
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:06,062 INFO epoch # 3744 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.0076159409727551974
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:06,080 INFO epoch # 3745 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.00750188717211131
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:06,099 INFO epoch # 3746 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.00761731682359823
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:06,117 INFO epoch # 3747 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.0075014247704530135
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:06,136 INFO epoch # 3748 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.0074386920568940695
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:06,154 INFO epoch # 3749 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.007532444324169774
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:06,172 INFO epoch # 3750 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.007466880484571448
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:06,172 INFO *** epoch 3750, rolling-avg-loss (window=10)= 0.007514417070706258
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:06,190 INFO epoch # 3751 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.007527042020228691
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:06,209 INFO epoch # 3752 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.007492192409699783
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:06,227 INFO epoch # 3753 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.008127537927066442
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:06,246 INFO epoch # 3754 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.0074833993130596355
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:06,264 INFO epoch # 3755 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.00745532582004671
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:06,283 INFO epoch # 3756 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.007460206648829626
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:06,302 INFO epoch # 3757 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.007448427550116321
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:06,321 INFO epoch # 3758 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.007519433071138337
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:06,339 INFO epoch # 3759 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.00749003145028837
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:06,357 INFO epoch # 3760 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.007507031208660919
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:06,357 INFO *** epoch 3760, rolling-avg-loss (window=10)= 0.007551062741913484
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:06,376 INFO epoch # 3761 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.007470126438420266
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:06,394 INFO epoch # 3762 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.0074722525641846005
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:06,412 INFO epoch # 3763 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.007516855828725966
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:06,431 INFO epoch # 3764 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.007493145625630859
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:06,449 INFO epoch # 3765 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.007453577196429251
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:06,468 INFO epoch # 3766 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.00743342435816885
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:06,486 INFO epoch # 3767 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.007457453710230766
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:06,505 INFO epoch # 3768 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.0074565757167874835
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:06,523 INFO epoch # 3769 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.007653010696230922
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:06,541 INFO epoch # 3770 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.007487288865377195
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:06,541 INFO *** epoch 3770, rolling-avg-loss (window=10)= 0.007489371100018616
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:06,560 INFO epoch # 3771 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.007438276625180151
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:06,578 INFO epoch # 3772 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.007664218850550242
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:06,596 INFO epoch # 3773 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.007463581481715664
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:06,615 INFO epoch # 3774 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.007443766138749197
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:06,634 INFO epoch # 3775 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.007941705196572002
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:06,652 INFO epoch # 3776 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.007492608376196586
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:06,671 INFO epoch # 3777 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.007533079799031839
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:06,689 INFO epoch # 3778 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.00743934935235302
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:06,707 INFO epoch # 3779 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.007698826244450174
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:06,726 INFO epoch # 3780 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.007460753062332515
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:06,726 INFO *** epoch 3780, rolling-avg-loss (window=10)= 0.007557616512713139
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:06,744 INFO epoch # 3781 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.0075456459453562275
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:06,762 INFO epoch # 3782 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.007447615713317646
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:06,780 INFO epoch # 3783 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.007477613384253345
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:06,799 INFO epoch # 3784 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.007535927157732658
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:06,817 INFO epoch # 3785 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.007674837179365568
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:06,836 INFO epoch # 3786 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.007433753555233125
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:06,854 INFO epoch # 3787 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.00748867297443212
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:06,873 INFO epoch # 3788 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.0074723696016008034
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:06,891 INFO epoch # 3789 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.007478802130208351
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:06,910 INFO epoch # 3790 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.007606870116433129
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:06,910 INFO *** epoch 3790, rolling-avg-loss (window=10)= 0.007516210775793297
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:06,928 INFO epoch # 3791 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.007504109471483389
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:06,947 INFO epoch # 3792 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.007482071345293662
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:06,966 INFO epoch # 3793 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.007455186656443402
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:06,984 INFO epoch # 3794 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.007611038898176048
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:07,003 INFO epoch # 3795 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.007591769550344907
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:07,021 INFO epoch # 3796 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.007434170984197408
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:07,040 INFO epoch # 3797 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.007463216330506839
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:07,059 INFO epoch # 3798 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.007469966178177856
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:07,077 INFO epoch # 3799 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.007450007691659266
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:07,096 INFO epoch # 3800 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.007448753516655415
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:07,096 INFO *** epoch 3800, rolling-avg-loss (window=10)= 0.007491029062293819
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:07,114 INFO epoch # 3801 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.007705961183091858
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:07,133 INFO epoch # 3802 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.007696678305364912
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:07,151 INFO epoch # 3803 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.007429636967572151
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:07,169 INFO epoch # 3804 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.007477505343558732
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:07,188 INFO epoch # 3805 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.007466853719961364
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:07,206 INFO epoch # 3806 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.007611902408825699
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:07,224 INFO epoch # 3807 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.00752640406426508
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:07,243 INFO epoch # 3808 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.007752854551654309
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:07,262 INFO epoch # 3809 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.007552395956736291
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:07,280 INFO epoch # 3810 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.007472783079720102
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:07,280 INFO *** epoch 3810, rolling-avg-loss (window=10)= 0.00756929755807505
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:07,299 INFO epoch # 3811 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.007454210637661163
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:07,317 INFO epoch # 3812 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.007484182067855727
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:07,336 INFO epoch # 3813 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0016 -loss = 0.007551404138212092
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:07,354 INFO epoch # 3814 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0016-> 0.0015 -loss = 0.0074840919696725905
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:07,372 INFO epoch # 3815 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.007517555859521963
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:07,391 INFO epoch # 3816 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.007515655393945053
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:07,409 INFO epoch # 3817 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.007515575343859382
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:07,427 INFO epoch # 3818 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.007403211538985488
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:07,446 INFO epoch # 3819 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.007556981770903803
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:07,465 INFO epoch # 3820 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.008079892591922544
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:07,465 INFO *** epoch 3820, rolling-avg-loss (window=10)= 0.0075562761312539806
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:07,483 INFO epoch # 3821 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.00805872507407912
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:07,502 INFO epoch # 3822 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.007581733327242546
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:07,520 INFO epoch # 3823 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.007500329214963131
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:07,538 INFO epoch # 3824 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.007423958151775878
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:07,557 INFO epoch # 3825 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.007515502613387071
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:07,575 INFO epoch # 3826 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.007486329868697794
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:07,593 INFO epoch # 3827 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.007601877077831887
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:07,611 INFO epoch # 3828 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.007456614908733172
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:07,630 INFO epoch # 3829 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.0074881218242808245
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:07,649 INFO epoch # 3830 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.007447366439009784
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:07,649 INFO *** epoch 3830, rolling-avg-loss (window=10)= 0.0075560558500001205
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:07,667 INFO epoch # 3831 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.008042299279622966
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:07,686 INFO epoch # 3832 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.007448953307175543
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:07,704 INFO epoch # 3833 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.007509510018280707
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:07,723 INFO epoch # 3834 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.007432351500028744
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:07,741 INFO epoch # 3835 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.007426315074553713
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:07,760 INFO epoch # 3836 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.007848300796467811
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:07,778 INFO epoch # 3837 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.007477017072233139
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:07,796 INFO epoch # 3838 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.007443346257787198
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:07,814 INFO epoch # 3839 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.007501600084651727
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:07,833 INFO epoch # 3840 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.007464460497430991
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:07,833 INFO *** epoch 3840, rolling-avg-loss (window=10)= 0.007559415388823254
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:07,851 INFO epoch # 3841 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.007452170055330498
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:07,870 INFO epoch # 3842 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.007448701337125385
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:07,888 INFO epoch # 3843 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.007950223036459647
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:07,907 INFO epoch # 3844 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.007420008500048425
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:07,925 INFO epoch # 3845 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.007449387518136064
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:07,944 INFO epoch # 3846 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.007471808487025555
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:07,962 INFO epoch # 3847 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.007396181212243391
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:07,980 INFO epoch # 3848 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.00744349034721381
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:07,998 INFO epoch # 3849 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.007782416407280834
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:08,017 INFO epoch # 3850 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.007414174498990178
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:08,017 INFO *** epoch 3850, rolling-avg-loss (window=10)= 0.007522856139985379
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:08,035 INFO epoch # 3851 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.0074160447729809675
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:08,054 INFO epoch # 3852 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.007518296366470167
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:08,073 INFO epoch # 3853 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.0074775714383577
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:08,091 INFO epoch # 3854 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.00749147601891309
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:08,110 INFO epoch # 3855 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.007423372400808148
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:08,129 INFO epoch # 3856 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.007458895506715635
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:08,147 INFO epoch # 3857 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.007417115939460928
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:08,165 INFO epoch # 3858 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.0074247051488782745
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:08,184 INFO epoch # 3859 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.007403287396300584
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:08,202 INFO epoch # 3860 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.007466871375072515
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:08,202 INFO *** epoch 3860, rolling-avg-loss (window=10)= 0.0074497636363958005
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:08,220 INFO epoch # 3861 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.007414504740154371
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:08,239 INFO epoch # 3862 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.007435184856149135
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:08,257 INFO epoch # 3863 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.011320948786305962
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:08,276 INFO epoch # 3864 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.007504096611228306
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:08,294 INFO epoch # 3865 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.0076742080818803515
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:08,313 INFO epoch # 3866 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.007463520632882137
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:08,331 INFO epoch # 3867 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.007371532261458924
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:08,350 INFO epoch # 3868 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.007394871605356457
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:08,368 INFO epoch # 3869 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.007569390789285535
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:08,386 INFO epoch # 3870 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.007408368255710229
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:08,386 INFO *** epoch 3870, rolling-avg-loss (window=10)= 0.00785566266204114
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:08,405 INFO epoch # 3871 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.007627129285538103
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:08,423 INFO epoch # 3872 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.007520112121710554
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:08,442 INFO epoch # 3873 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.007457089286617702
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:08,460 INFO epoch # 3874 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.0074443104858801235
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:08,479 INFO epoch # 3875 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.007425175321259303
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:08,497 INFO epoch # 3876 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.007450352124578785
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:08,516 INFO epoch # 3877 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.007551218270236859
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:08,534 INFO epoch # 3878 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.007410570477077272
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:08,552 INFO epoch # 3879 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.007443116504873615
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:08,571 INFO epoch # 3880 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.007418180684908293
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:08,571 INFO *** epoch 3880, rolling-avg-loss (window=10)= 0.007474725456268061
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:08,589 INFO epoch # 3881 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.00738040633041237
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:08,607 INFO epoch # 3882 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.007391161612758879
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:08,625 INFO epoch # 3883 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.00736622895419714
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:08,644 INFO epoch # 3884 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.007599232143547852
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:08,662 INFO epoch # 3885 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.007439828488713829
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:08,681 INFO epoch # 3886 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.007386319688521326
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:08,699 INFO epoch # 3887 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.007408886540360982
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:08,718 INFO epoch # 3888 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.007542969615315087
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:08,737 INFO epoch # 3889 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.007401907245366601
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:08,755 INFO epoch # 3890 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.007880120836489368
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:08,755 INFO *** epoch 3890, rolling-avg-loss (window=10)= 0.007479706145568343
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:08,773 INFO epoch # 3891 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.007482356057153083
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:08,791 INFO epoch # 3892 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.00739495680318214
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:08,810 INFO epoch # 3893 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.007475985545170261
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:08,828 INFO epoch # 3894 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.0074721657001646236
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:08,846 INFO epoch # 3895 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.007428451670421055
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:08,865 INFO epoch # 3896 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.009333012258139206
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:08,883 INFO epoch # 3897 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.0074156279806629755
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:08,902 INFO epoch # 3898 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.007439657929353416
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:08,920 INFO epoch # 3899 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.00740978690009797
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:08,939 INFO epoch # 3900 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.00742140416696202
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:08,939 INFO *** epoch 3900, rolling-avg-loss (window=10)= 0.007627340501130675
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:08,958 INFO epoch # 3901 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.007379265800409485
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:08,977 INFO epoch # 3902 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.007390098213363672
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:08,995 INFO epoch # 3903 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.007377991725661559
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:09,013 INFO epoch # 3904 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.00739130482179462
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:09,032 INFO epoch # 3905 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.0073777487996267155
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:09,050 INFO epoch # 3906 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.007386389588646125
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:09,069 INFO epoch # 3907 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.007391005077806767
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:09,087 INFO epoch # 3908 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.007425458788929973
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:09,106 INFO epoch # 3909 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.00755699029105017
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:09,124 INFO epoch # 3910 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.0073827781961881556
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:09,124 INFO *** epoch 3910, rolling-avg-loss (window=10)= 0.007405903130347724
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:09,143 INFO epoch # 3911 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.010093130011227913
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:09,161 INFO epoch # 3912 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.007382906856946647
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:09,179 INFO epoch # 3913 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.007412022503558546
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:09,198 INFO epoch # 3914 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.007374698376224842
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:09,216 INFO epoch # 3915 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.007357801052421564
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:09,234 INFO epoch # 3916 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.0073969678560388274
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:09,253 INFO epoch # 3917 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.007347765455051558
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:09,271 INFO epoch # 3918 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.007382440358924214
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:09,290 INFO epoch # 3919 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.007394797066808678
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:09,308 INFO epoch # 3920 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.007464323225576663
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:09,309 INFO *** epoch 3920, rolling-avg-loss (window=10)= 0.007660685276277945
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:09,327 INFO epoch # 3921 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.0076306472037686035
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:09,346 INFO epoch # 3922 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.0073528980574337766
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:09,364 INFO epoch # 3923 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.00736340962612303
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:09,382 INFO epoch # 3924 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.007390099144686246
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:09,400 INFO epoch # 3925 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.007374472810624866
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:09,419 INFO epoch # 3926 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.007469901094736997
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:09,437 INFO epoch # 3927 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0015 -loss = 0.007403631643683184
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:09,456 INFO epoch # 3928 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0015-> 0.0014 -loss = 0.007421816160785966
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:09,474 INFO epoch # 3929 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.007340648189710919
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:09,493 INFO epoch # 3930 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.0073890538078558166
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:09,493 INFO *** epoch 3930, rolling-avg-loss (window=10)= 0.0074136577739409406
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:09,511 INFO epoch # 3931 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.007375549081189092
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:09,530 INFO epoch # 3932 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.00737670180387795
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:09,548 INFO epoch # 3933 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.007401292503345758
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:09,567 INFO epoch # 3934 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.007368060803855769
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:09,585 INFO epoch # 3935 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.0074301237873442005
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:09,603 INFO epoch # 3936 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.007447788804711308
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:09,622 INFO epoch # 3937 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.007366083347733365
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:09,640 INFO epoch # 3938 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.007337014896620531
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:09,658 INFO epoch # 3939 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.007345838497712975
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:09,677 INFO epoch # 3940 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.007355880559771322
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:09,677 INFO *** epoch 3940, rolling-avg-loss (window=10)= 0.007380433408616227
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:09,695 INFO epoch # 3941 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.00734974297847657
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:09,714 INFO epoch # 3942 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.007364948898612056
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:09,733 INFO epoch # 3943 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.007440938439685851
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:09,751 INFO epoch # 3944 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.007367267808149336
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:09,769 INFO epoch # 3945 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.007431014088069787
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:09,788 INFO epoch # 3946 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.01133532802487025
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:09,806 INFO epoch # 3947 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.007497821839933749
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:09,824 INFO epoch # 3948 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.007467501771316165
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:09,842 INFO epoch # 3949 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.007353878238063771
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:09,861 INFO epoch # 3950 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.007358939059486147
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:09,861 INFO *** epoch 3950, rolling-avg-loss (window=10)= 0.0077967381146663685
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:09,879 INFO epoch # 3951 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.0073797160512185656
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:09,898 INFO epoch # 3952 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.007469344593118876
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:09,917 INFO epoch # 3953 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.007404297844914254
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:09,935 INFO epoch # 3954 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.007633757035364397
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:09,953 INFO epoch # 3955 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.0074170994776068255
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:09,972 INFO epoch # 3956 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.007447008836606983
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:09,990 INFO epoch # 3957 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.007382469204458175
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:10,008 INFO epoch # 3958 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.0073580483403929975
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:10,027 INFO epoch # 3959 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.0074117169533565175
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:10,046 INFO epoch # 3960 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.007335501242778264
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:10,046 INFO *** epoch 3960, rolling-avg-loss (window=10)= 0.007423895957981585
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:10,064 INFO epoch # 3961 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.007529430829890771
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:10,083 INFO epoch # 3962 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.0073579189884185325
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:10,101 INFO epoch # 3963 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.007330045107664773
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:10,120 INFO epoch # 3964 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.007382690022495808
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:10,139 INFO epoch # 3965 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.007347647682763636
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:10,158 INFO epoch # 3966 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.007393767191388179
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:10,177 INFO epoch # 3967 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.007366150246525649
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:10,195 INFO epoch # 3968 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.007421391383104492
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:10,213 INFO epoch # 3969 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.007314990463783033
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:10,231 INFO epoch # 3970 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.007364116034295876
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:10,231 INFO *** epoch 3970, rolling-avg-loss (window=10)= 0.007380814795033075
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:10,250 INFO epoch # 3971 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.011157532710058149
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:10,268 INFO epoch # 3972 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.00763566441310104
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:10,287 INFO epoch # 3973 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.00733391048561316
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:10,305 INFO epoch # 3974 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.007482420547603397
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:10,324 INFO epoch # 3975 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.0076077003323007375
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:10,342 INFO epoch # 3976 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.007361991949437652
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:10,361 INFO epoch # 3977 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.007344707591983024
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:10,379 INFO epoch # 3978 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.007374240361968987
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:10,397 INFO epoch # 3979 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.007495562356780283
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:10,415 INFO epoch # 3980 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.007385426964901853
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:10,416 INFO *** epoch 3980, rolling-avg-loss (window=10)= 0.007817915771374829
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:10,434 INFO epoch # 3981 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.007321209403016837
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:10,452 INFO epoch # 3982 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.007312626730708871
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:10,470 INFO epoch # 3983 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.007356578560575144
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:10,489 INFO epoch # 3984 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.007333906898566056
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:10,507 INFO epoch # 3985 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.007337124508921988
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:10,526 INFO epoch # 3986 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.007307559713808587
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:10,544 INFO epoch # 3987 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.007357351150858449
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:10,563 INFO epoch # 3988 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.008164740924257785
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:10,581 INFO epoch # 3989 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.007401286602544133
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:10,599 INFO epoch # 3990 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.007307039420993533
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:10,600 INFO *** epoch 3990, rolling-avg-loss (window=10)= 0.0074199423914251385
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:10,618 INFO epoch # 3991 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.00731683573758346
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:10,636 INFO epoch # 3992 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.00731846834969474
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:10,654 INFO epoch # 3993 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.007447763193340506
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:10,673 INFO epoch # 3994 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.007317924188100733
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:10,691 INFO epoch # 3995 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.007454543127096258
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:10,709 INFO epoch # 3996 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.007349488041654695
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:10,728 INFO epoch # 3997 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.007549193222075701
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:10,746 INFO epoch # 3998 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.007452906538674142
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:10,765 INFO epoch # 3999 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.007333415789616993
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:10,784 INFO epoch # 4000 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.0073123498768836726
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:10,784 INFO *** epoch 4000, rolling-avg-loss (window=10)= 0.00738528880647209
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:10,802 INFO epoch # 4001 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.0073234106312156655
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:10,821 INFO epoch # 4002 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.007520439197833184
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:10,839 INFO epoch # 4003 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.007341291075135814
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:10,857 INFO epoch # 4004 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.007322017878323095
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:10,875 INFO epoch # 4005 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.0073812585724226665
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:10,894 INFO epoch # 4006 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.007368259888608009
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:10,912 INFO epoch # 4007 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.007890688608313212
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:10,931 INFO epoch # 4008 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.007306356403205427
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:10,949 INFO epoch # 4009 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.0073073387902695686
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:10,968 INFO epoch # 4010 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.007328279200010002
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:10,968 INFO *** epoch 4010, rolling-avg-loss (window=10)= 0.007408934024533664
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:10,986 INFO epoch # 4011 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.007374292355962098
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:11,005 INFO epoch # 4012 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.007315414037293522
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:11,023 INFO epoch # 4013 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.007424933210131712
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:11,041 INFO epoch # 4014 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.007298297452507541
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:11,060 INFO epoch # 4015 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.007375182023679372
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:11,078 INFO epoch # 4016 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.007324869773583487
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:11,096 INFO epoch # 4017 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.0075215840588498395
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:11,115 INFO epoch # 4018 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.007457047264324501
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:11,133 INFO epoch # 4019 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.007474179739801912
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:11,152 INFO epoch # 4020 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.007325342598051066
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:11,152 INFO *** epoch 4020, rolling-avg-loss (window=10)= 0.0073891142514185045
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:11,170 INFO epoch # 4021 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.007283714399818564
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:11,189 INFO epoch # 4022 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.0074630462331697345
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:11,207 INFO epoch # 4023 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.007301300964172697
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:11,225 INFO epoch # 4024 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.007292455789865926
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:11,243 INFO epoch # 4025 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.007307383428269532
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:11,262 INFO epoch # 4026 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.007333455087064067
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:11,280 INFO epoch # 4027 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.007324940008402336
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:11,298 INFO epoch # 4028 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.007738021289696917
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:11,317 INFO epoch # 4029 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.007299619697732851
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:11,335 INFO epoch # 4030 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.007296247047634097
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:11,336 INFO *** epoch 4030, rolling-avg-loss (window=10)= 0.007364018394582672
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:11,354 INFO epoch # 4031 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.007293400158232544
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:11,373 INFO epoch # 4032 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.007287978627573466
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:11,391 INFO epoch # 4033 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.007376824432867579
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:11,409 INFO epoch # 4034 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.007356587339018006
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:11,428 INFO epoch # 4035 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.007310779743420426
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:11,446 INFO epoch # 4036 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.007315863527765032
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:11,464 INFO epoch # 4037 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.007315162325539859
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:11,482 INFO epoch # 4038 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.007276302279933589
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:11,501 INFO epoch # 4039 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.007356594542216044
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:11,519 INFO epoch # 4040 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.007311153312912211
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:11,519 INFO *** epoch 4040, rolling-avg-loss (window=10)= 0.007320064628947876
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:11,538 INFO epoch # 4041 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.0074342916122986935
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:11,556 INFO epoch # 4042 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.007777001621434465
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:11,575 INFO epoch # 4043 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.007326279308472294
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:11,593 INFO epoch # 4044 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.00735976453506737
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:11,612 INFO epoch # 4045 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.007616801289259456
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:11,630 INFO epoch # 4046 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.00733734447567258
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:11,648 INFO epoch # 4047 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.007278507626324426
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:11,667 INFO epoch # 4048 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.007335919086472131
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:11,685 INFO epoch # 4049 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.007288245727977483
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:11,703 INFO epoch # 4050 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.0073242603793914896
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:11,703 INFO *** epoch 4050, rolling-avg-loss (window=10)= 0.007407841566237039
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:11,722 INFO epoch # 4051 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.0073173847267753445
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:11,740 INFO epoch # 4052 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.007269590110809077
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:11,759 INFO epoch # 4053 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.007300599161681021
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:11,777 INFO epoch # 4054 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.007435449231707025
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:11,796 INFO epoch # 4055 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.007333456851483788
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:11,814 INFO epoch # 4056 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.0073034413617278915
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:11,832 INFO epoch # 4057 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.00734857650968479
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:11,850 INFO epoch # 4058 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.00728596900444245
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:11,869 INFO epoch # 4059 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.007319033189560287
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:11,887 INFO epoch # 4060 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.007428636592521798
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:11,887 INFO *** epoch 4060, rolling-avg-loss (window=10)= 0.007334213674039347
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:11,905 INFO epoch # 4061 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.009112824369367445
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:11,924 INFO epoch # 4062 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.007385330805846024
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:11,942 INFO epoch # 4063 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.007298904820345342
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:11,961 INFO epoch # 4064 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.007292136237083469
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:11,979 INFO epoch # 4065 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.007369255727098789
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:11,998 INFO epoch # 4066 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.007353121167398058
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:12,017 INFO epoch # 4067 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.007359696326602716
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:12,035 INFO epoch # 4068 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.0073035284876823425
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:12,053 INFO epoch # 4069 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.007418094195600133
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:12,072 INFO epoch # 4070 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.00730707267211983
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:12,072 INFO *** epoch 4070, rolling-avg-loss (window=10)= 0.007519996480914415
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:12,090 INFO epoch # 4071 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.007367187474301318
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:12,108 INFO epoch # 4072 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.00739058802719228
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:12,127 INFO epoch # 4073 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0014 -loss = 0.007341015094425529
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:12,145 INFO epoch # 4074 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0014-> 0.0013 -loss = 0.007277540244103875
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:12,163 INFO epoch # 4075 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.007306062085262965
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:12,182 INFO epoch # 4076 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.007731682740995893
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:12,200 INFO epoch # 4077 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.007850874400901375
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:12,218 INFO epoch # 4078 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.007330631928198272
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:12,237 INFO epoch # 4079 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.007283453880518209
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:12,255 INFO epoch # 4080 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.0072535860308562405
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:12,255 INFO *** epoch 4080, rolling-avg-loss (window=10)= 0.007413262190675595
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:12,273 INFO epoch # 4081 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.007255923221237026
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:12,292 INFO epoch # 4082 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.007342334967688657
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:12,310 INFO epoch # 4083 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.007293424143426819
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:12,328 INFO epoch # 4084 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.007285605814104201
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:12,347 INFO epoch # 4085 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.007294154645933304
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:12,365 INFO epoch # 4086 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.00727488756456296
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:12,384 INFO epoch # 4087 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.0072850789947551675
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:12,402 INFO epoch # 4088 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.007723820832325146
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:12,421 INFO epoch # 4089 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.007332561101065949
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:12,439 INFO epoch # 4090 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.007240896589792101
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:12,439 INFO *** epoch 4090, rolling-avg-loss (window=10)= 0.007332868787489133
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:12,458 INFO epoch # 4091 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.0098020554651157
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:12,476 INFO epoch # 4092 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.007356192356382962
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:12,494 INFO epoch # 4093 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.007334738838835619
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:12,513 INFO epoch # 4094 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.008057912273216061
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:12,531 INFO epoch # 4095 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.007336993541684933
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:12,550 INFO epoch # 4096 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.007312557558179833
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:12,568 INFO epoch # 4097 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.007294622617337154
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:12,587 INFO epoch # 4098 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.0076341665371728595
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:12,605 INFO epoch # 4099 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.007492643824662082
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:12,624 INFO epoch # 4100 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.007364947552559897
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:12,624 INFO *** epoch 4100, rolling-avg-loss (window=10)= 0.00769868305651471
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:12,642 INFO epoch # 4101 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.0073330746308784
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:12,661 INFO epoch # 4102 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.007276773543708259
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:12,679 INFO epoch # 4103 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.007283278908289503
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:12,697 INFO epoch # 4104 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.007303218888409901
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:12,715 INFO epoch # 4105 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.007243621488669305
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:12,734 INFO epoch # 4106 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.007249376467370894
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:12,752 INFO epoch # 4107 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.011076602968387306
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:12,771 INFO epoch # 4108 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.007350778705585981
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:12,789 INFO epoch # 4109 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.007389071055513341
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:12,808 INFO epoch # 4110 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.007275196905538905
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:12,808 INFO *** epoch 4110, rolling-avg-loss (window=10)= 0.007678099356235179
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:12,827 INFO epoch # 4111 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.007299036369659007
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:12,845 INFO epoch # 4112 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.007880924466007855
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:12,863 INFO epoch # 4113 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.007298916643776465
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:12,882 INFO epoch # 4114 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.007293839851627126
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:12,900 INFO epoch # 4115 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.007860413537855493
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:12,918 INFO epoch # 4116 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.007297165029740427
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:12,937 INFO epoch # 4117 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.00730228450265713
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:12,955 INFO epoch # 4118 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.007810808227077359
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:12,974 INFO epoch # 4119 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.007284193321538623
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:12,992 INFO epoch # 4120 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.007239843380375532
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:12,992 INFO *** epoch 4120, rolling-avg-loss (window=10)= 0.0074567425330315015
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:13,011 INFO epoch # 4121 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.007242886305903085
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:13,030 INFO epoch # 4122 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.007263838251674315
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:13,048 INFO epoch # 4123 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.007244672880915459
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:13,066 INFO epoch # 4124 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.00733022556596552
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:13,085 INFO epoch # 4125 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.007259710837388411
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:13,103 INFO epoch # 4126 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.00725886995496694
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:13,122 INFO epoch # 4127 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.007434265051415423
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:13,141 INFO epoch # 4128 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.0072781884045980405
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:13,160 INFO epoch # 4129 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.007248511548823444
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:13,178 INFO epoch # 4130 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.007372440119070234
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:13,178 INFO *** epoch 4130, rolling-avg-loss (window=10)= 0.007293360892072087
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:13,197 INFO epoch # 4131 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.007268051565915812
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:13,215 INFO epoch # 4132 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.007246697026857873
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:13,234 INFO epoch # 4133 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.007229737828311045
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:13,252 INFO epoch # 4134 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.007269124274898786
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:13,270 INFO epoch # 4135 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.007280293506482849
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:13,289 INFO epoch # 4136 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.007313685211556731
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:13,307 INFO epoch # 4137 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.007308874199225102
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:13,325 INFO epoch # 4138 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.007266609703947324
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:13,344 INFO epoch # 4139 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.007267573495482793
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:13,363 INFO epoch # 4140 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.00978361641682568
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:13,363 INFO *** epoch 4140, rolling-avg-loss (window=10)= 0.0075234263229504
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:13,381 INFO epoch # 4141 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.007361847237916663
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:13,400 INFO epoch # 4142 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.007404425581626128
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:13,419 INFO epoch # 4143 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.007243561471113935
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:13,437 INFO epoch # 4144 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.007340525422478095
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:13,456 INFO epoch # 4145 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.00724132369941799
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:13,474 INFO epoch # 4146 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.007848304208891932
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:13,492 INFO epoch # 4147 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.007259362784679979
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:13,511 INFO epoch # 4148 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.007237603324028896
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:13,529 INFO epoch # 4149 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.0072146352576965
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:13,547 INFO epoch # 4150 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.007309480548428837
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:13,547 INFO *** epoch 4150, rolling-avg-loss (window=10)= 0.007346106953627895
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:13,566 INFO epoch # 4151 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.007278847402631072
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:13,585 INFO epoch # 4152 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.007344092598941643
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:13,603 INFO epoch # 4153 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.007232296877191402
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:13,621 INFO epoch # 4154 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.007250890004797839
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:13,640 INFO epoch # 4155 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.007243004070915049
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:13,658 INFO epoch # 4156 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.007330946551519446
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:13,676 INFO epoch # 4157 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.007256419332406949
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:13,695 INFO epoch # 4158 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.0072229839770443505
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:13,713 INFO epoch # 4159 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.007260626385686919
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:13,731 INFO epoch # 4160 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.007755648563033901
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:13,731 INFO *** epoch 4160, rolling-avg-loss (window=10)= 0.007317575576416857
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:13,750 INFO epoch # 4161 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.007244807573442813
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:13,768 INFO epoch # 4162 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.00725670596875716
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:13,787 INFO epoch # 4163 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.007264591520652175
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:13,805 INFO epoch # 4164 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.007267314365890343
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:13,824 INFO epoch # 4165 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.007268478533660527
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:13,842 INFO epoch # 4166 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.007260150392539799
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:13,860 INFO epoch # 4167 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.007321743119973689
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:13,879 INFO epoch # 4168 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.00724893622827949
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:13,897 INFO epoch # 4169 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.007217065667646239
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:13,915 INFO epoch # 4170 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.0072200604881800245
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:13,915 INFO *** epoch 4170, rolling-avg-loss (window=10)= 0.007256985385902226
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:13,934 INFO epoch # 4171 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.0072864365865825675
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:13,952 INFO epoch # 4172 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.007211689531686716
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:13,970 INFO epoch # 4173 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.007375243032583967
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:13,989 INFO epoch # 4174 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.007238944293931127
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:14,007 INFO epoch # 4175 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.007270020789292175
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:14,026 INFO epoch # 4176 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.007262295614054892
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:14,044 INFO epoch # 4177 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.007306251740374137
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:14,063 INFO epoch # 4178 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.007240452297992306
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:14,081 INFO epoch # 4179 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.007488536419259617
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:14,099 INFO epoch # 4180 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.007415553867758717
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:14,099 INFO *** epoch 4180, rolling-avg-loss (window=10)= 0.0073095424173516225
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:14,118 INFO epoch # 4181 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.007273649454873521
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:14,136 INFO epoch # 4182 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0013 -loss = 0.007220267871161923
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:14,154 INFO epoch # 4183 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0013-> 0.0012 -loss = 0.007248468329635216
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:14,173 INFO epoch # 4184 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.007242554609547369
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:14,191 INFO epoch # 4185 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.007278596502146684
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:14,210 INFO epoch # 4186 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.007501423056964995
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:14,228 INFO epoch # 4187 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.007273188410181319
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:14,247 INFO epoch # 4188 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.007246359680721071
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:14,265 INFO epoch # 4189 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.0072048381734930445
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:14,283 INFO epoch # 4190 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.00723627603292698
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:14,283 INFO *** epoch 4190, rolling-avg-loss (window=10)= 0.007272562212165212
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:14,302 INFO epoch # 4191 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.00723268123329035
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:14,320 INFO epoch # 4192 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.00720086757428362
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:14,338 INFO epoch # 4193 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.007216507721750531
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:14,357 INFO epoch # 4194 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.007209325485746376
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:14,375 INFO epoch # 4195 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.007241939041705336
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:14,394 INFO epoch # 4196 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.007280910995177692
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:14,412 INFO epoch # 4197 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.007272517923411215
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:14,431 INFO epoch # 4198 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.00725978720583953
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:14,449 INFO epoch # 4199 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.007236231522256276
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:14,468 INFO epoch # 4200 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.007247306944918819
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:14,468 INFO *** epoch 4200, rolling-avg-loss (window=10)= 0.007239807564837974
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:14,486 INFO epoch # 4201 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.0073097740387311205
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:14,504 INFO epoch # 4202 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.007262592709594173
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:14,522 INFO epoch # 4203 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.0072093543894879986
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:14,541 INFO epoch # 4204 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.0072173116423073225
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:14,559 INFO epoch # 4205 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.007228917718748562
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:14,578 INFO epoch # 4206 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.007202917357062688
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:14,597 INFO epoch # 4207 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.007190045962488512
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:14,615 INFO epoch # 4208 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.007266752149007516
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:14,634 INFO epoch # 4209 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.0076946370681980625
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:14,652 INFO epoch # 4210 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.007260719503392465
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:14,653 INFO *** epoch 4210, rolling-avg-loss (window=10)= 0.007284302253901842
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:14,671 INFO epoch # 4211 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.007258046658535022
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:14,689 INFO epoch # 4212 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.0071926942855498055
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:14,707 INFO epoch # 4213 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.007389856760710245
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:14,725 INFO epoch # 4214 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.01110783763579093
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:14,744 INFO epoch # 4215 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.007333731595281279
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:14,762 INFO epoch # 4216 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.007152182784921024
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:14,780 INFO epoch # 4217 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.007218614868179429
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:14,799 INFO epoch # 4218 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.007278686553036096
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:14,818 INFO epoch # 4219 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.007188895375293214
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:14,836 INFO epoch # 4220 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.007196705530077452
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:14,836 INFO *** epoch 4220, rolling-avg-loss (window=10)= 0.00763172520473745
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:14,855 INFO epoch # 4221 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.007208658989839023
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:14,873 INFO epoch # 4222 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.007203752753412118
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:14,891 INFO epoch # 4223 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.007173814723500982
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:14,910 INFO epoch # 4224 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.007290709123481065
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:14,928 INFO epoch # 4225 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.00722849153316929
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:14,946 INFO epoch # 4226 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.007271129834407475
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:14,965 INFO epoch # 4227 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.007226794885355048
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:14,983 INFO epoch # 4228 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.007213142380351201
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:15,002 INFO epoch # 4229 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.007258883564645657
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:15,021 INFO epoch # 4230 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.00769355996089871
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:15,021 INFO *** epoch 4230, rolling-avg-loss (window=10)= 0.007276893774906057
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:15,039 INFO epoch # 4231 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.007204422763606999
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:15,058 INFO epoch # 4232 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.007193665951490402
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:15,076 INFO epoch # 4233 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.007213365224743029
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:15,095 INFO epoch # 4234 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.007194674664788181
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:15,113 INFO epoch # 4235 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.007190764643382863
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:15,132 INFO epoch # 4236 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.0071892462838150095
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:15,150 INFO epoch # 4237 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.007201920991064981
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:15,168 INFO epoch # 4238 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.007221030282380525
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:15,187 INFO epoch # 4239 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.007195536920335144
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:15,206 INFO epoch # 4240 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.007336191010836046
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:15,206 INFO *** epoch 4240, rolling-avg-loss (window=10)= 0.007214081873644318
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:15,224 INFO epoch # 4241 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.007211051281046821
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:15,243 INFO epoch # 4242 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.007277369113580789
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:15,262 INFO epoch # 4243 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.007239009901240934
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:15,280 INFO epoch # 4244 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.007533318635978503
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:15,298 INFO epoch # 4245 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.00717115279257996
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:15,317 INFO epoch # 4246 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.007357743561442476
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:15,335 INFO epoch # 4247 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.0072087274747900665
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:15,353 INFO epoch # 4248 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.00720595311577199
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:15,372 INFO epoch # 4249 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.007370015482592862
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:15,390 INFO epoch # 4250 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.007212251777673373
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:15,390 INFO *** epoch 4250, rolling-avg-loss (window=10)= 0.0072786593136697775
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:15,409 INFO epoch # 4251 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.0072007745038717985
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:15,427 INFO epoch # 4252 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.007188961059000576
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:15,446 INFO epoch # 4253 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.007308193071366986
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:15,464 INFO epoch # 4254 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.007359512255789014
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:15,482 INFO epoch # 4255 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.007183284127677325
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:15,501 INFO epoch # 4256 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.007231969284475781
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:15,519 INFO epoch # 4257 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.007275641713931691
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:15,537 INFO epoch # 4258 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.007337280771025689
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:15,556 INFO epoch # 4259 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.007168737614847487
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:15,574 INFO epoch # 4260 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.007235871620650869
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:15,574 INFO *** epoch 4260, rolling-avg-loss (window=10)= 0.0072490226022637215
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:15,593 INFO epoch # 4261 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.007183732355770189
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:15,612 INFO epoch # 4262 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.007194869624072453
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:15,630 INFO epoch # 4263 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.0072444531178916804
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:15,649 INFO epoch # 4264 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.007202782901003957
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:15,667 INFO epoch # 4265 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.007234362612507539
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:15,686 INFO epoch # 4266 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.007207262075098697
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:15,704 INFO epoch # 4267 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.007168515312514501
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:15,722 INFO epoch # 4268 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.007200802760053193
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:15,741 INFO epoch # 4269 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.007176245162554551
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:15,759 INFO epoch # 4270 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.0071869092716951855
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:15,759 INFO *** epoch 4270, rolling-avg-loss (window=10)= 0.007199993519316194
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:15,778 INFO epoch # 4271 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.007207260587165365
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:15,796 INFO epoch # 4272 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.00717617651753244
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:15,815 INFO epoch # 4273 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.00717138566687936
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:15,833 INFO epoch # 4274 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.007202752214652719
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:15,852 INFO epoch # 4275 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.007231799500004854
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:15,870 INFO epoch # 4276 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.007192430326540489
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:15,889 INFO epoch # 4277 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.0072686556886765175
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:15,907 INFO epoch # 4278 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.007211098898551427
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:15,925 INFO epoch # 4279 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.007189937117800582
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:15,943 INFO epoch # 4280 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.0071773445124563295
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:15,944 INFO *** epoch 4280, rolling-avg-loss (window=10)= 0.007202884103026008
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:15,962 INFO epoch # 4281 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.007196350175945554
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:15,980 INFO epoch # 4282 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.007230186580272857
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:15,999 INFO epoch # 4283 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.007207553178886883
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:16,017 INFO epoch # 4284 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.007228219972603256
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:16,036 INFO epoch # 4285 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.007530797585786786
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:16,055 INFO epoch # 4286 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.007241943945700768
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:16,074 INFO epoch # 4287 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.007197579077910632
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:16,092 INFO epoch # 4288 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.007179094114690088
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:16,111 INFO epoch # 4289 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.0071801265148678795
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:16,130 INFO epoch # 4290 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.007171870314778062
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:16,130 INFO *** epoch 4290, rolling-avg-loss (window=10)= 0.007236372146144277
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:16,148 INFO epoch # 4291 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.007176656374213053
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:16,167 INFO epoch # 4292 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.007168722921051085
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:16,186 INFO epoch # 4293 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.007213879875052953
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:16,205 INFO epoch # 4294 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.007188245850556996
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:16,224 INFO epoch # 4295 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.007224672532174736
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:16,243 INFO epoch # 4296 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.007276464079041034
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:16,261 INFO epoch # 4297 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.007278937537193997
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:16,280 INFO epoch # 4298 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.007160183406085707
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:16,298 INFO epoch # 4299 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.007168853342591319
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:16,317 INFO epoch # 4300 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.007218283451948082
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:16,317 INFO *** epoch 4300, rolling-avg-loss (window=10)= 0.007207489936990896
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:16,335 INFO epoch # 4301 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.007519253704231232
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:16,353 INFO epoch # 4302 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.007266723656357499
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:16,372 INFO epoch # 4303 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0012 -loss = 0.007187680868810276
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:16,390 INFO epoch # 4304 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0012-> 0.0011 -loss = 0.007330651478696382
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:16,409 INFO epoch # 4305 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.00737681079772301
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:16,427 INFO epoch # 4306 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.007163197256886633
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:16,446 INFO epoch # 4307 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.007170559383666841
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:16,465 INFO epoch # 4308 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.007204098470538156
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:16,483 INFO epoch # 4309 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.0071870923493406735
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:16,501 INFO epoch # 4310 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.007204978614026913
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:16,501 INFO *** epoch 4310, rolling-avg-loss (window=10)= 0.007261104658027762
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:16,520 INFO epoch # 4311 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.007352434677159181
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:16,538 INFO epoch # 4312 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.0071996973201748915
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:16,556 INFO epoch # 4313 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.007218335464131087
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:16,575 INFO epoch # 4314 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.007153025993829942
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:16,595 INFO epoch # 4315 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.007142511989513878
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:16,614 INFO epoch # 4316 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.007478579704184085
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:16,633 INFO epoch # 4317 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.007208256545709446
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:16,652 INFO epoch # 4318 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.007182502864452545
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:16,670 INFO epoch # 4319 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.007197722596174572
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:16,688 INFO epoch # 4320 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.007142303798900684
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:16,689 INFO *** epoch 4320, rolling-avg-loss (window=10)= 0.0072275370954230315
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:16,707 INFO epoch # 4321 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.007215075485873967
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:16,725 INFO epoch # 4322 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.0071534510534547735
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:16,743 INFO epoch # 4323 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.007212464170152089
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:16,762 INFO epoch # 4324 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.007172451158112381
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:16,780 INFO epoch # 4325 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.007437444182869513
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:16,798 INFO epoch # 4326 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.007709173038165318
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:16,817 INFO epoch # 4327 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.007187824863649439
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:16,835 INFO epoch # 4328 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.007156664854846895
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:16,854 INFO epoch # 4329 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.007194697805971373
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:16,872 INFO epoch # 4330 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.0071440149113186635
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:16,872 INFO *** epoch 4330, rolling-avg-loss (window=10)= 0.007258326152441441
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:16,891 INFO epoch # 4331 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.007242404943099245
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:16,909 INFO epoch # 4332 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.007156489951739786
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:16,928 INFO epoch # 4333 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.0071793495590100065
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:16,946 INFO epoch # 4334 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.007134903073165333
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:16,964 INFO epoch # 4335 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.007139546964026522
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:16,983 INFO epoch # 4336 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.00718779521776014
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:17,001 INFO epoch # 4337 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.007137068314477801
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:17,020 INFO epoch # 4338 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.007145832358219195
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:17,039 INFO epoch # 4339 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.007184611342381686
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:17,057 INFO epoch # 4340 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.007222615422506351
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:17,057 INFO *** epoch 4340, rolling-avg-loss (window=10)= 0.007173061714638607
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:17,076 INFO epoch # 4341 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.007153632890549488
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:17,095 INFO epoch # 4342 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.007133869319659425
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:17,113 INFO epoch # 4343 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.007134146320822765
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:17,132 INFO epoch # 4344 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.007159217093430925
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:17,150 INFO epoch # 4345 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.007150486253522104
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:17,168 INFO epoch # 4346 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.007147374752094038
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:17,187 INFO epoch # 4347 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.0071530263012391515
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:17,205 INFO epoch # 4348 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.007157400395954028
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:17,224 INFO epoch # 4349 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.0071962730144150555
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:17,242 INFO epoch # 4350 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.00712983532139333
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:17,242 INFO *** epoch 4350, rolling-avg-loss (window=10)= 0.007151526166308031
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:17,261 INFO epoch # 4351 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.0071580387448193505
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:17,279 INFO epoch # 4352 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.007187618564785225
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:17,298 INFO epoch # 4353 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.007129918158170767
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:17,316 INFO epoch # 4354 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.007134986590244807
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:17,335 INFO epoch # 4355 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.007122778126358753
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:17,353 INFO epoch # 4356 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.007158948745200178
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:17,371 INFO epoch # 4357 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.0072098639684554655
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:17,390 INFO epoch # 4358 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.007246099612530088
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:17,408 INFO epoch # 4359 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.007300782581296517
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:17,426 INFO epoch # 4360 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.007229522969282698
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:17,427 INFO *** epoch 4360, rolling-avg-loss (window=10)= 0.007187855806114385
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:17,445 INFO epoch # 4361 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.007702862705627922
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:17,463 INFO epoch # 4362 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.007137199983844766
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:17,482 INFO epoch # 4363 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.00741106214991305
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:17,500 INFO epoch # 4364 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.007170539582148194
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:17,518 INFO epoch # 4365 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.0071658200758975
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:17,537 INFO epoch # 4366 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.007202623350167414
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:17,555 INFO epoch # 4367 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.007104427630110877
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:17,573 INFO epoch # 4368 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.00711520866752835
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:17,591 INFO epoch # 4369 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.007187911600340158
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:17,610 INFO epoch # 4370 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.007173549140134128
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:17,610 INFO *** epoch 4370, rolling-avg-loss (window=10)= 0.007237120488571236
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:17,628 INFO epoch # 4371 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.007142963524529478
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:17,647 INFO epoch # 4372 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.007135499661671929
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:17,665 INFO epoch # 4373 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.0071189200280059595
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:17,684 INFO epoch # 4374 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.007228682890854543
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:17,702 INFO epoch # 4375 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.007157879685109947
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:17,720 INFO epoch # 4376 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.007132985014322912
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:17,739 INFO epoch # 4377 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.007249176102050114
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:17,757 INFO epoch # 4378 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.007160915738495532
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:17,775 INFO epoch # 4379 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.007134093648346607
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:17,794 INFO epoch # 4380 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.0071453937562182546
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:17,794 INFO *** epoch 4380, rolling-avg-loss (window=10)= 0.007160651004960527
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:17,812 INFO epoch # 4381 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.007153273225412704
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:17,831 INFO epoch # 4382 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.007243830761581194
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:17,849 INFO epoch # 4383 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.007453801026713336
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:17,868 INFO epoch # 4384 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.007230889401398599
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:17,889 INFO epoch # 4385 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.007144526258343831
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:17,910 INFO epoch # 4386 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.007295086041267496
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:17,932 INFO epoch # 4387 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.007685332711844239
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:17,955 INFO epoch # 4388 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.007174349739216268
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:17,977 INFO epoch # 4389 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.007194314966909587
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:17,999 INFO epoch # 4390 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.007143356808228418
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:17,999 INFO *** epoch 4390, rolling-avg-loss (window=10)= 0.007271876094091567
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:18,022 INFO epoch # 4391 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.007264870320796035
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:18,053 INFO epoch # 4392 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.011357536146533675
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:18,077 INFO epoch # 4393 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.007188583382230718
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:18,102 INFO epoch # 4394 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.007292404097825056
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:18,124 INFO epoch # 4395 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.0071818260330474
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:18,146 INFO epoch # 4396 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.0073090960358968005
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:18,165 INFO epoch # 4397 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.007206892754766159
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:18,185 INFO epoch # 4398 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.007593901133077452
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:18,204 INFO epoch # 4399 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.0071836981041997205
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:18,223 INFO epoch # 4400 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.007131969661713811
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:18,224 INFO *** epoch 4400, rolling-avg-loss (window=10)= 0.007671077767008682
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:18,243 INFO epoch # 4401 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.007137651482480578
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:18,263 INFO epoch # 4402 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.007148067241359968
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:18,283 INFO epoch # 4403 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.007108220670488663
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:18,302 INFO epoch # 4404 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.007172703986725537
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:18,321 INFO epoch # 4405 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.007113371260857093
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:18,339 INFO epoch # 4406 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.007168797303165775
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:18,357 INFO epoch # 4407 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.007185327653132845
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:18,375 INFO epoch # 4408 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.007187017872638535
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:18,394 INFO epoch # 4409 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.007278549783222843
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:18,412 INFO epoch # 4410 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.007099510854459368
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:18,412 INFO *** epoch 4410, rolling-avg-loss (window=10)= 0.00715992181085312
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:18,432 INFO epoch # 4411 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.007139626795833465
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:18,451 INFO epoch # 4412 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.0072203100062324665
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:18,470 INFO epoch # 4413 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.007196265971288085
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:18,488 INFO epoch # 4414 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.007150282326620072
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:18,507 INFO epoch # 4415 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.007122164621250704
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:18,525 INFO epoch # 4416 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.007175135950092226
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:18,544 INFO epoch # 4417 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.007145868265070021
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:18,562 INFO epoch # 4418 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.007283057722816011
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:18,580 INFO epoch # 4419 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.007108077326847706
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:18,599 INFO epoch # 4420 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.007149146265874151
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:18,599 INFO *** epoch 4420, rolling-avg-loss (window=10)= 0.00716899352519249
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:18,617 INFO epoch # 4421 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.007141538208088605
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:18,636 INFO epoch # 4422 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.007143067068682285
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:18,654 INFO epoch # 4423 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.007132392802304821
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:18,673 INFO epoch # 4424 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.007271555477927905
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:18,691 INFO epoch # 4425 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.007114869375072885
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:18,710 INFO epoch # 4426 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.007124846884835279
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:18,728 INFO epoch # 4427 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.007132885228202213
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:18,747 INFO epoch # 4428 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.007123539733584039
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:18,765 INFO epoch # 4429 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.007137914253689814
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:18,783 INFO epoch # 4430 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.007120027945347829
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:18,783 INFO *** epoch 4430, rolling-avg-loss (window=10)= 0.007144263697773568
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:18,801 INFO epoch # 4431 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.0075863419187953696
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:18,820 INFO epoch # 4432 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.007144291757867904
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:18,838 INFO epoch # 4433 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.009573200612067012
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:18,857 INFO epoch # 4434 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.007349684052314842
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:18,875 INFO epoch # 4435 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.0071156159647216555
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:18,894 INFO epoch # 4436 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.007530550035880879
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:18,912 INFO epoch # 4437 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.0071516818352392875
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:18,931 INFO epoch # 4438 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.007080706211127108
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:18,949 INFO epoch # 4439 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.007109229314664844
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:18,967 INFO epoch # 4440 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.007087734047672711
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:18,967 INFO *** epoch 4440, rolling-avg-loss (window=10)= 0.007472903575035161
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:18,986 INFO epoch # 4441 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.007123487015633145
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:19,004 INFO epoch # 4442 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.007242695432069013
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:19,022 INFO epoch # 4443 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.007139669694879558
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:19,041 INFO epoch # 4444 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.00730541319353506
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:19,059 INFO epoch # 4445 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.007698197310674004
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:19,078 INFO epoch # 4446 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.00721369681195938
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:19,096 INFO epoch # 4447 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.007085023966283188
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:19,115 INFO epoch # 4448 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.0071652768419880886
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:19,133 INFO epoch # 4449 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.00720813326552161
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:19,152 INFO epoch # 4450 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.007179742475273088
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:19,152 INFO *** epoch 4450, rolling-avg-loss (window=10)= 0.007236133600781613
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:19,170 INFO epoch # 4451 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.00707576363129192
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:19,188 INFO epoch # 4452 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.007126051299565006
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:19,207 INFO epoch # 4453 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.007121682607248658
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:19,225 INFO epoch # 4454 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.007127183191187214
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:19,245 INFO epoch # 4455 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.00714909649832407
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:19,264 INFO epoch # 4456 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.007290985420695506
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:19,283 INFO epoch # 4457 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.0071710275442455895
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:19,302 INFO epoch # 4458 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.007453641890606377
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:19,320 INFO epoch # 4459 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.007123781317204703
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:19,339 INFO epoch # 4460 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.0074528582372295205
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:19,339 INFO *** epoch 4460, rolling-avg-loss (window=10)= 0.007209207163759857
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:19,357 INFO epoch # 4461 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.0011 -loss = 0.00716251676203683
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:19,376 INFO epoch # 4462 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.0011-> 0.001 -loss = 0.007112204366421793
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:19,394 INFO epoch # 4463 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007270878086274024
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:19,412 INFO epoch # 4464 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007256729746586643
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:19,431 INFO epoch # 4465 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0071391310630133376
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:19,449 INFO epoch # 4466 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007148930642870255
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:19,468 INFO epoch # 4467 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007149241817387519
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:19,487 INFO epoch # 4468 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007123756797227543
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:19,505 INFO epoch # 4469 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0071243711790884845
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:19,524 INFO epoch # 4470 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007099052738340106
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:19,524 INFO *** epoch 4470, rolling-avg-loss (window=10)= 0.007158681319924654
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:19,542 INFO epoch # 4471 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007521551662648562
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:19,560 INFO epoch # 4472 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007168631214881316
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:19,579 INFO epoch # 4473 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00718619404869969
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:19,597 INFO epoch # 4474 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007100543418346206
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:19,616 INFO epoch # 4475 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007117993915016996
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:19,634 INFO epoch # 4476 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00706961122341454
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:19,653 INFO epoch # 4477 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007233921100123553
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:19,671 INFO epoch # 4478 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007098488320480101
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:19,690 INFO epoch # 4479 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007081968375132419
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:19,708 INFO epoch # 4480 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007208718474430498
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:19,709 INFO *** epoch 4480, rolling-avg-loss (window=10)= 0.007178762175317388
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:19,727 INFO epoch # 4481 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007206211797893047
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:19,746 INFO epoch # 4482 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007079669983795611
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:19,764 INFO epoch # 4483 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007079266069922596
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:19,782 INFO epoch # 4484 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007119641824829159
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:19,801 INFO epoch # 4485 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007069336679705884
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:19,819 INFO epoch # 4486 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0071326806137221865
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:19,837 INFO epoch # 4487 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0070981382741592824
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:19,856 INFO epoch # 4488 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00741929379364592
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:19,874 INFO epoch # 4489 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007145349809434265
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:19,893 INFO epoch # 4490 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007083922348101623
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:19,893 INFO *** epoch 4490, rolling-avg-loss (window=10)= 0.007143351119520957
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:19,911 INFO epoch # 4491 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007237851925310679
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:19,930 INFO epoch # 4492 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007072763102769386
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:19,948 INFO epoch # 4493 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00739735658862628
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:19,966 INFO epoch # 4494 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007105530792614445
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:19,985 INFO epoch # 4495 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007169967626396101
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:20,003 INFO epoch # 4496 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007098956506524701
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:20,021 INFO epoch # 4497 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007166125200456008
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:20,040 INFO epoch # 4498 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00706948167498922
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:20,058 INFO epoch # 4499 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007104852782504167
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:20,077 INFO epoch # 4500 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007182222172559705
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:20,077 INFO *** epoch 4500, rolling-avg-loss (window=10)= 0.007160510837275069
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:20,096 INFO epoch # 4501 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007209437415440334
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:20,115 INFO epoch # 4502 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007084340966684977
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:20,134 INFO epoch # 4503 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0071566343467566185
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:20,153 INFO epoch # 4504 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007130849080567714
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:20,171 INFO epoch # 4505 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007065026260534069
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:20,189 INFO epoch # 4506 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007085204946633894
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:20,208 INFO epoch # 4507 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007168751038989285
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:20,226 INFO epoch # 4508 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0070614189535262994
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:20,245 INFO epoch # 4509 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007159666954976274
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:20,263 INFO epoch # 4510 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0070862881002540234
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:20,263 INFO *** epoch 4510, rolling-avg-loss (window=10)= 0.007120761806436349
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:20,282 INFO epoch # 4511 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0071468762507720385
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:20,300 INFO epoch # 4512 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0071083346992963925
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:20,319 INFO epoch # 4513 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007070722222124459
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:20,337 INFO epoch # 4514 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007067722828651313
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:20,356 INFO epoch # 4515 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007162108311604243
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:20,374 INFO epoch # 4516 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007093039279425284
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:20,392 INFO epoch # 4517 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007281795387825696
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:20,411 INFO epoch # 4518 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007395544598693959
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:20,429 INFO epoch # 4519 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007188911709818058
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:20,447 INFO epoch # 4520 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00712817068779259
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:20,448 INFO *** epoch 4520, rolling-avg-loss (window=10)= 0.007164322597600403
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:20,466 INFO epoch # 4521 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0071237104493775405
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:20,485 INFO epoch # 4522 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007068207225529477
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:20,503 INFO epoch # 4523 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0070738254726165906
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:20,522 INFO epoch # 4524 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0070761664283054415
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:20,540 INFO epoch # 4525 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007078328031639103
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:20,559 INFO epoch # 4526 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007076995392708341
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:20,577 INFO epoch # 4527 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007167214636865538
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:20,596 INFO epoch # 4528 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007128660163289169
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:20,614 INFO epoch # 4529 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007075822006299859
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:20,632 INFO epoch # 4530 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007100212584191468
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:20,632 INFO *** epoch 4530, rolling-avg-loss (window=10)= 0.007096914239082252
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:20,650 INFO epoch # 4531 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0071063111354305875
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:20,669 INFO epoch # 4532 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00707340568624204
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:20,687 INFO epoch # 4533 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007164922841184307
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:20,706 INFO epoch # 4534 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0070858946892258245
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:20,724 INFO epoch # 4535 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007112828716344666
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:20,743 INFO epoch # 4536 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007095616925653303
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:20,761 INFO epoch # 4537 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0072172553118434735
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:20,780 INFO epoch # 4538 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007110176913556643
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:20,798 INFO epoch # 4539 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00706839053236763
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:20,816 INFO epoch # 4540 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007102238745574141
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:20,816 INFO *** epoch 4540, rolling-avg-loss (window=10)= 0.007113704149742261
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:20,835 INFO epoch # 4541 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007146212989027845
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:20,853 INFO epoch # 4542 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0070742934112786315
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:20,871 INFO epoch # 4543 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007075583300320432
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:20,890 INFO epoch # 4544 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0071350139514834154
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:20,908 INFO epoch # 4545 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0070712089946027845
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:20,927 INFO epoch # 4546 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007117494191334117
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:20,946 INFO epoch # 4547 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007105984212103067
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:20,964 INFO epoch # 4548 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007078316568367882
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:20,982 INFO epoch # 4549 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.009514289409707999
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:21,000 INFO epoch # 4550 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007175514881964773
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:21,001 INFO *** epoch 4550, rolling-avg-loss (window=10)= 0.007349391191019095
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:21,019 INFO epoch # 4551 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007101866143784719
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:21,037 INFO epoch # 4552 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007181166271038819
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:21,056 INFO epoch # 4553 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007083533309923951
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:21,074 INFO epoch # 4554 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007077996855514357
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:21,093 INFO epoch # 4555 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007151897661969997
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:21,111 INFO epoch # 4556 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00708696968285949
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:21,130 INFO epoch # 4557 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007072771179082338
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:21,148 INFO epoch # 4558 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007627299095474882
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:21,167 INFO epoch # 4559 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0070785969801363535
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:21,185 INFO epoch # 4560 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007073210763337556
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:21,185 INFO *** epoch 4560, rolling-avg-loss (window=10)= 0.007153530794312246
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:21,204 INFO epoch # 4561 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007066823425702751
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:21,222 INFO epoch # 4562 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007041670756734675
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:21,240 INFO epoch # 4563 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007070344570820453
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:21,259 INFO epoch # 4564 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007108248708391329
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:21,277 INFO epoch # 4565 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007057216909743147
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:21,296 INFO epoch # 4566 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007105384509486612
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:21,314 INFO epoch # 4567 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00708255720383022
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:21,332 INFO epoch # 4568 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007069803359627258
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:21,351 INFO epoch # 4569 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007051796508676489
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:21,369 INFO epoch # 4570 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0070641330821672454
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:21,370 INFO *** epoch 4570, rolling-avg-loss (window=10)= 0.007071797903518018
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:21,388 INFO epoch # 4571 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007229980979900574
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:21,406 INFO epoch # 4572 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007094385506206891
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:21,425 INFO epoch # 4573 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007318804146052571
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:21,443 INFO epoch # 4574 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007064754692692077
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:21,461 INFO epoch # 4575 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007236478217237163
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:21,480 INFO epoch # 4576 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007206768925243523
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:21,499 INFO epoch # 4577 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0071277784081758
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:21,517 INFO epoch # 4578 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007048719930025982
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:21,536 INFO epoch # 4579 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007089533155522076
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:21,554 INFO epoch # 4580 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007036058497760678
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:21,554 INFO *** epoch 4580, rolling-avg-loss (window=10)= 0.007145326245881734
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:21,573 INFO epoch # 4581 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007036294264253229
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:21,592 INFO epoch # 4582 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007605102488014381
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:21,610 INFO epoch # 4583 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007111939044989413
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:21,628 INFO epoch # 4584 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007097230653016595
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:21,647 INFO epoch # 4585 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007056063532218104
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:21,665 INFO epoch # 4586 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007061875956424046
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:21,683 INFO epoch # 4587 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007043755133054219
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:21,702 INFO epoch # 4588 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007069313374813646
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:21,721 INFO epoch # 4589 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007032054283627076
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:21,739 INFO epoch # 4590 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0070737679161538836
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:21,739 INFO *** epoch 4590, rolling-avg-loss (window=10)= 0.007118739664656459
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:21,758 INFO epoch # 4591 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007334176443691831
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:21,776 INFO epoch # 4592 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007082336342136841
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:21,795 INFO epoch # 4593 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00704880123885232
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:21,813 INFO epoch # 4594 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0071175712801050395
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:21,831 INFO epoch # 4595 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0076594386555370875
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:21,850 INFO epoch # 4596 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0070685334503650665
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:21,868 INFO epoch # 4597 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007104753258317942
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:21,886 INFO epoch # 4598 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007085498804372037
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:21,905 INFO epoch # 4599 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007038965617539361
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:21,923 INFO epoch # 4600 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007035799637378659
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:21,924 INFO *** epoch 4600, rolling-avg-loss (window=10)= 0.007157587472829618
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:21,942 INFO epoch # 4601 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007099007776560029
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:21,961 INFO epoch # 4602 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007144066250475589
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:21,979 INFO epoch # 4603 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0070316571691364516
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:21,997 INFO epoch # 4604 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007038202245894354
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:22,017 INFO epoch # 4605 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007426797506923322
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:22,036 INFO epoch # 4606 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007092935193213634
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:22,054 INFO epoch # 4607 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.009446413943805965
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:22,072 INFO epoch # 4608 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007077447611663956
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:22,091 INFO epoch # 4609 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007048714101983933
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:22,110 INFO epoch # 4610 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007036745319055626
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:22,110 INFO *** epoch 4610, rolling-avg-loss (window=10)= 0.007344198711871286
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:22,128 INFO epoch # 4611 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007382407602563035
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:22,147 INFO epoch # 4612 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00708137932815589
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:22,165 INFO epoch # 4613 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007112545976269757
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:22,184 INFO epoch # 4614 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007092626052326523
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:22,202 INFO epoch # 4615 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007068267084832769
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:22,220 INFO epoch # 4616 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007040715718176216
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:22,239 INFO epoch # 4617 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00702827734494349
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:22,257 INFO epoch # 4618 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0072226899610541295
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:22,276 INFO epoch # 4619 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00706754440034274
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:22,294 INFO epoch # 4620 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007050234969938174
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:22,294 INFO *** epoch 4620, rolling-avg-loss (window=10)= 0.007114668843860273
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:22,313 INFO epoch # 4621 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007037542854959611
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:22,331 INFO epoch # 4622 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007050681560940575
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:22,350 INFO epoch # 4623 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007872046408010647
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:22,369 INFO epoch # 4624 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007032015932054492
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:22,387 INFO epoch # 4625 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007042622703011148
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:22,405 INFO epoch # 4626 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007198353501735255
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:22,424 INFO epoch # 4627 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007089266073307954
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:22,442 INFO epoch # 4628 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007198518102086382
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:22,460 INFO epoch # 4629 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007457975603756495
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:22,479 INFO epoch # 4630 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007065110919938888
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:22,479 INFO *** epoch 4630, rolling-avg-loss (window=10)= 0.007204413365980144
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:22,497 INFO epoch # 4631 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007040367047011387
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:22,516 INFO epoch # 4632 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007032606892607873
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:22,534 INFO epoch # 4633 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0070136153626663145
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:22,552 INFO epoch # 4634 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007021854573395103
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:22,571 INFO epoch # 4635 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007043166257062694
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:22,589 INFO epoch # 4636 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007050959047774086
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:22,608 INFO epoch # 4637 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007096818448189879
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:22,626 INFO epoch # 4638 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007293438589840662
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:22,644 INFO epoch # 4639 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007316403793083737
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:22,662 INFO epoch # 4640 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0070378609307226725
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:22,662 INFO *** epoch 4640, rolling-avg-loss (window=10)= 0.007094709094235441
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:22,680 INFO epoch # 4641 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007613339043018641
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:22,699 INFO epoch # 4642 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007062344149744604
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:22,717 INFO epoch # 4643 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00714891760435421
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:22,736 INFO epoch # 4644 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0070484995521837845
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:22,754 INFO epoch # 4645 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007036507413431536
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:22,772 INFO epoch # 4646 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006998860493695247
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:22,791 INFO epoch # 4647 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007040932458039606
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:22,809 INFO epoch # 4648 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007050840758893173
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:22,827 INFO epoch # 4649 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007045254882541485
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:22,845 INFO epoch # 4650 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007011899597273441
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:22,846 INFO *** epoch 4650, rolling-avg-loss (window=10)= 0.007105739595317573
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:22,864 INFO epoch # 4651 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007458694613887928
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:22,882 INFO epoch # 4652 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007044215028145118
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:22,901 INFO epoch # 4653 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007495814577850979
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:22,919 INFO epoch # 4654 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007149154131184332
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:22,937 INFO epoch # 4655 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007063077267957851
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:22,956 INFO epoch # 4656 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007014530383457895
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:22,974 INFO epoch # 4657 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007061679716571234
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:22,992 INFO epoch # 4658 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007019361040875083
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:23,011 INFO epoch # 4659 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007261428399942815
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:23,029 INFO epoch # 4660 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007011090801825048
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:23,029 INFO *** epoch 4660, rolling-avg-loss (window=10)= 0.0071579045961698284
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:23,047 INFO epoch # 4661 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007041082342766458
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:23,066 INFO epoch # 4662 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007053353449009592
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:23,084 INFO epoch # 4663 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007020148579613306
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:23,102 INFO epoch # 4664 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00701422512793215
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:23,121 INFO epoch # 4665 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007018848627922125
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:23,139 INFO epoch # 4666 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007124799882149091
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:23,157 INFO epoch # 4667 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007226404737593839
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:23,176 INFO epoch # 4668 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007095425695297308
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:23,194 INFO epoch # 4669 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007071508225635625
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:23,212 INFO epoch # 4670 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007087218764354475
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:23,212 INFO *** epoch 4670, rolling-avg-loss (window=10)= 0.007075301543227397
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:23,230 INFO epoch # 4671 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007096498546161456
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:23,249 INFO epoch # 4672 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007148502052586991
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:23,267 INFO epoch # 4673 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007019462722382741
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:23,286 INFO epoch # 4674 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007004403394603287
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:23,305 INFO epoch # 4675 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007051108550513163
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:23,323 INFO epoch # 4676 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007171270015533082
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:23,342 INFO epoch # 4677 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007064091663778527
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:23,360 INFO epoch # 4678 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007055370955640683
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:23,379 INFO epoch # 4679 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00704392179613933
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:23,397 INFO epoch # 4680 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0072196025466837455
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:23,397 INFO *** epoch 4680, rolling-avg-loss (window=10)= 0.0070874232244023
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:23,416 INFO epoch # 4681 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007063156626827549
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:23,434 INFO epoch # 4682 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007077675109030679
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:23,452 INFO epoch # 4683 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007025778970273677
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:23,471 INFO epoch # 4684 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007146337055019103
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:23,489 INFO epoch # 4685 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007021162109595025
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:23,507 INFO epoch # 4686 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007038281582936179
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:23,525 INFO epoch # 4687 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007025822185823927
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:23,544 INFO epoch # 4688 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007758928546536481
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:23,562 INFO epoch # 4689 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007184507321653655
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:23,581 INFO epoch # 4690 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007069695315294666
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:23,581 INFO *** epoch 4690, rolling-avg-loss (window=10)= 0.007141134482299094
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:23,599 INFO epoch # 4691 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00703983550920384
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:23,618 INFO epoch # 4692 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007052520631987136
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:23,636 INFO epoch # 4693 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007054917557979934
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:23,654 INFO epoch # 4694 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0070205938136496115
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:23,672 INFO epoch # 4695 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0071666936710244045
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:23,690 INFO epoch # 4696 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007043736470222939
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:23,709 INFO epoch # 4697 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00699579690626706
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:23,727 INFO epoch # 4698 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007005791645497084
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:23,746 INFO epoch # 4699 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007093513879226521
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:23,764 INFO epoch # 4700 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006992087388425716
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:23,764 INFO *** epoch 4700, rolling-avg-loss (window=10)= 0.007046548747348424
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:23,783 INFO epoch # 4701 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007073211243550759
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:23,801 INFO epoch # 4702 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006982534399867291
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:23,819 INFO epoch # 4703 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0073271594737889245
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:23,838 INFO epoch # 4704 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007098908754414879
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:23,856 INFO epoch # 4705 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0070210172270890325
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:23,874 INFO epoch # 4706 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007130757374397945
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:23,892 INFO epoch # 4707 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007076496684021549
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:23,911 INFO epoch # 4708 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007016233485046541
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:23,929 INFO epoch # 4709 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0070101196397445165
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:23,948 INFO epoch # 4710 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007002262893365696
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:23,948 INFO *** epoch 4710, rolling-avg-loss (window=10)= 0.007073870117528714
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:23,966 INFO epoch # 4711 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007008213833614718
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:23,985 INFO epoch # 4712 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007046162929327693
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:24,004 INFO epoch # 4713 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007033993384538917
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:24,022 INFO epoch # 4714 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007091378709446872
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:24,040 INFO epoch # 4715 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007051012977171922
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:24,058 INFO epoch # 4716 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007170166602008976
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:24,077 INFO epoch # 4717 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00708179621869931
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:24,095 INFO epoch # 4718 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007128605589969084
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:24,114 INFO epoch # 4719 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006979205376410391
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:24,132 INFO epoch # 4720 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007047383889585035
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:24,132 INFO *** epoch 4720, rolling-avg-loss (window=10)= 0.007063791951077291
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:24,151 INFO epoch # 4721 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007003045320743695
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:24,169 INFO epoch # 4722 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007109615238732658
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:24,188 INFO epoch # 4723 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0069889357164356625
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:24,206 INFO epoch # 4724 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007074318065861007
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:24,224 INFO epoch # 4725 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007012734327872749
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:24,243 INFO epoch # 4726 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007002414316957584
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:24,261 INFO epoch # 4727 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007037011273496319
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:24,279 INFO epoch # 4728 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007011585192230996
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:24,297 INFO epoch # 4729 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007013033304247074
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:24,316 INFO epoch # 4730 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006988730197917903
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:24,316 INFO *** epoch 4730, rolling-avg-loss (window=10)= 0.007024142295449565
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:24,335 INFO epoch # 4731 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00696398355285055
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:24,353 INFO epoch # 4732 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0070461320065078326
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:24,372 INFO epoch # 4733 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006990848436544184
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:24,390 INFO epoch # 4734 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007045077727525495
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:24,408 INFO epoch # 4735 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007141558053262997
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:24,427 INFO epoch # 4736 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007049001291306922
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:24,445 INFO epoch # 4737 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007093618689395953
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:24,463 INFO epoch # 4738 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0070035167846072
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:24,481 INFO epoch # 4739 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006976484120968962
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:24,500 INFO epoch # 4740 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0070521915367862675
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:24,500 INFO *** epoch 4740, rolling-avg-loss (window=10)= 0.007036241219975636
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:24,518 INFO epoch # 4741 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007014445167442318
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:24,536 INFO epoch # 4742 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006975226016948
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:24,555 INFO epoch # 4743 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007230727725982433
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:24,573 INFO epoch # 4744 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007047341401630547
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:24,592 INFO epoch # 4745 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007111309376341524
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:24,610 INFO epoch # 4746 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007351042360824067
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:24,629 INFO epoch # 4747 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007541763443441596
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:24,647 INFO epoch # 4748 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0070091566449264064
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:24,665 INFO epoch # 4749 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007003352919127792
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:24,684 INFO epoch # 4750 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006983439045143314
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:24,684 INFO *** epoch 4750, rolling-avg-loss (window=10)= 0.0071267804101808
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:24,702 INFO epoch # 4751 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0076774725239374675
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:24,721 INFO epoch # 4752 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007027796025795396
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:24,740 INFO epoch # 4753 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006965946940908907
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:24,759 INFO epoch # 4754 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.009711570110084722
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:24,778 INFO epoch # 4755 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0070418837713077664
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:24,797 INFO epoch # 4756 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007079168135533109
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:24,815 INFO epoch # 4757 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00699011048709508
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:24,833 INFO epoch # 4758 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006990986454184167
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:24,852 INFO epoch # 4759 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007020910044957418
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:24,870 INFO epoch # 4760 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.009494851110503078
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:24,870 INFO *** epoch 4760, rolling-avg-loss (window=10)= 0.0076000695604307115
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:24,888 INFO epoch # 4761 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007161637367971707
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:24,906 INFO epoch # 4762 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006977291890507331
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:24,925 INFO epoch # 4763 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0069852204687776975
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:24,943 INFO epoch # 4764 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007001141719229054
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:24,962 INFO epoch # 4765 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007024299928161781
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:24,980 INFO epoch # 4766 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0070171213446883485
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:24,999 INFO epoch # 4767 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006950096054424648
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:25,018 INFO epoch # 4768 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007248305675602751
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:25,037 INFO epoch # 4769 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007057113209157251
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:25,055 INFO epoch # 4770 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007054307869111653
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:25,055 INFO *** epoch 4770, rolling-avg-loss (window=10)= 0.007047653552763222
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:25,074 INFO epoch # 4771 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0087177696514118
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:25,093 INFO epoch # 4772 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007072586740832776
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:25,112 INFO epoch # 4773 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006975377986236708
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:25,133 INFO epoch # 4774 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007074103545164689
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:25,152 INFO epoch # 4775 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006965303768083686
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:25,171 INFO epoch # 4776 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007376927605946548
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:25,190 INFO epoch # 4777 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0069922467664582655
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:25,208 INFO epoch # 4778 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00702833406830905
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:25,227 INFO epoch # 4779 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007028782893030439
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:25,245 INFO epoch # 4780 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0070009904011385515
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:25,245 INFO *** epoch 4780, rolling-avg-loss (window=10)= 0.007223242342661251
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:25,263 INFO epoch # 4781 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007001361213042401
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:25,281 INFO epoch # 4782 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007037223447696306
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:25,300 INFO epoch # 4783 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0069911639802739955
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:25,318 INFO epoch # 4784 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007035561950033298
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:25,336 INFO epoch # 4785 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006956670811632648
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:25,354 INFO epoch # 4786 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007024646383797517
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:25,373 INFO epoch # 4787 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007019083168415818
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:25,391 INFO epoch # 4788 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006948091515369015
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:25,409 INFO epoch # 4789 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007089344762789551
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:25,428 INFO epoch # 4790 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007525970951974159
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:25,428 INFO *** epoch 4790, rolling-avg-loss (window=10)= 0.0070629118185024705
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:25,446 INFO epoch # 4791 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006980303609452676
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:25,464 INFO epoch # 4792 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007024172511592042
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:25,482 INFO epoch # 4793 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006990996589593124
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:25,501 INFO epoch # 4794 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0070300046681950334
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:25,519 INFO epoch # 4795 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006946410441742046
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:25,537 INFO epoch # 4796 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007023919824860059
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:25,556 INFO epoch # 4797 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006985505202464992
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:25,574 INFO epoch # 4798 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006965417542232899
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:25,593 INFO epoch # 4799 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007020181539701298
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:25,611 INFO epoch # 4800 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007115200496627949
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:25,611 INFO *** epoch 4800, rolling-avg-loss (window=10)= 0.007008211242646212
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:25,630 INFO epoch # 4801 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007088170401402749
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:25,648 INFO epoch # 4802 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007011578247329453
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:25,666 INFO epoch # 4803 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006959118749364279
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:25,685 INFO epoch # 4804 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006968371126276907
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:25,703 INFO epoch # 4805 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00695765856289654
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:25,721 INFO epoch # 4806 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006964976702874992
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:25,739 INFO epoch # 4807 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006972018520173151
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:25,758 INFO epoch # 4808 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007095639772160212
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:25,776 INFO epoch # 4809 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006965663877053885
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:25,795 INFO epoch # 4810 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0070151752697711345
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:25,795 INFO *** epoch 4810, rolling-avg-loss (window=10)= 0.00699983712293033
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:25,813 INFO epoch # 4811 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006963070729398169
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:25,831 INFO epoch # 4812 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006968140602111816
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:25,850 INFO epoch # 4813 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007073590113577666
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:25,868 INFO epoch # 4814 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.009326604667876381
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:25,886 INFO epoch # 4815 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007004682407568907
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:25,904 INFO epoch # 4816 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00700007336854469
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:25,923 INFO epoch # 4817 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006952874868147774
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:25,941 INFO epoch # 4818 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006980904083320638
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:25,959 INFO epoch # 4819 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006986343731114175
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:25,978 INFO epoch # 4820 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0071265769365709275
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:25,978 INFO *** epoch 4820, rolling-avg-loss (window=10)= 0.0072382861508231144
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:25,996 INFO epoch # 4821 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00694455851589737
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:26,015 INFO epoch # 4822 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007021265846560709
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:26,033 INFO epoch # 4823 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007030187491182005
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:26,051 INFO epoch # 4824 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007055220994516276
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:26,069 INFO epoch # 4825 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006968942452658666
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:26,087 INFO epoch # 4826 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007036313218122814
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:26,106 INFO epoch # 4827 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007066679321724223
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:26,124 INFO epoch # 4828 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0069461055518331705
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:26,142 INFO epoch # 4829 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006972086419409607
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:26,161 INFO epoch # 4830 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00697043418767862
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:26,161 INFO *** epoch 4830, rolling-avg-loss (window=10)= 0.007001179399958346
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:26,179 INFO epoch # 4831 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006967120421904838
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:26,197 INFO epoch # 4832 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007122387956769671
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:26,216 INFO epoch # 4833 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0069807227337150835
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:26,234 INFO epoch # 4834 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007112375773431268
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:26,253 INFO epoch # 4835 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006995177631324623
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:26,271 INFO epoch # 4836 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006983109360589879
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:26,289 INFO epoch # 4837 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006974665986490436
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:26,307 INFO epoch # 4838 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007005284562183078
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:26,325 INFO epoch # 4839 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0069567995342367794
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:26,344 INFO epoch # 4840 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006946942652575672
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:26,344 INFO *** epoch 4840, rolling-avg-loss (window=10)= 0.007004458661322132
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:26,362 INFO epoch # 4841 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006930856754479464
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:26,381 INFO epoch # 4842 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00692818796778738
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:26,399 INFO epoch # 4843 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006959803227800876
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:26,417 INFO epoch # 4844 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007439231623720843
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:26,436 INFO epoch # 4845 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007363176253420534
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:26,454 INFO epoch # 4846 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006986904045334086
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:26,472 INFO epoch # 4847 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007182319368439494
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:26,490 INFO epoch # 4848 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006987465851125307
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:26,509 INFO epoch # 4849 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007210033840237884
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:26,527 INFO epoch # 4850 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006964389012864558
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:26,527 INFO *** epoch 4850, rolling-avg-loss (window=10)= 0.007095236794521042
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:26,545 INFO epoch # 4851 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006945564671696047
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:26,564 INFO epoch # 4852 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007173986221459927
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:26,582 INFO epoch # 4853 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007601316025102278
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:26,601 INFO epoch # 4854 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007008516702626366
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:26,619 INFO epoch # 4855 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006930245268449653
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:26,638 INFO epoch # 4856 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006940721759747248
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:26,656 INFO epoch # 4857 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0069469117661355995
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:26,675 INFO epoch # 4858 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006966906887100777
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:26,693 INFO epoch # 4859 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0069687881477875635
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:26,711 INFO epoch # 4860 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0069977718812879175
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:26,711 INFO *** epoch 4860, rolling-avg-loss (window=10)= 0.007048072933139337
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:26,729 INFO epoch # 4861 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00693877810772392
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:26,748 INFO epoch # 4862 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006967434517719084
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:26,766 INFO epoch # 4863 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006952619747607969
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:26,785 INFO epoch # 4864 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007681353104999289
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:26,804 INFO epoch # 4865 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007001375674008159
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:26,822 INFO epoch # 4866 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007238610836793669
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:26,840 INFO epoch # 4867 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006986167249124264
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:26,859 INFO epoch # 4868 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006993574635998812
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:26,877 INFO epoch # 4869 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006947814737941371
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:26,895 INFO epoch # 4870 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0069818822157685645
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:26,896 INFO *** epoch 4870, rolling-avg-loss (window=10)= 0.00706896108276851
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:26,914 INFO epoch # 4871 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.010570846876362339
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:26,932 INFO epoch # 4872 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007110467086022254
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:26,951 INFO epoch # 4873 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006995177034696098
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:26,969 INFO epoch # 4874 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006942717296624323
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:26,987 INFO epoch # 4875 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007036611808871385
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:27,006 INFO epoch # 4876 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006936763944395352
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:27,024 INFO epoch # 4877 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007008057116763666
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:27,042 INFO epoch # 4878 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006983743907767348
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:27,061 INFO epoch # 4879 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006968509576836368
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:27,079 INFO epoch # 4880 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0069143454093136825
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:27,079 INFO *** epoch 4880, rolling-avg-loss (window=10)= 0.007346724005765281
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:27,097 INFO epoch # 4881 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007148802364099538
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:27,115 INFO epoch # 4882 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006974126776185585
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:27,134 INFO epoch # 4883 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007257182172907051
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:27,152 INFO epoch # 4884 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007000448305916507
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:27,171 INFO epoch # 4885 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006987890170421451
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:27,189 INFO epoch # 4886 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006932249179953942
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:27,208 INFO epoch # 4887 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006929795217729406
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:27,226 INFO epoch # 4888 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007374736560450401
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:27,245 INFO epoch # 4889 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006953765307116555
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:27,263 INFO epoch # 4890 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00702319482297753
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:27,263 INFO *** epoch 4890, rolling-avg-loss (window=10)= 0.007058219087775796
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:27,281 INFO epoch # 4891 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006928023933141958
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:27,300 INFO epoch # 4892 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0069465757624129765
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:27,318 INFO epoch # 4893 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006957692647119984
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:27,336 INFO epoch # 4894 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006966558561543934
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:27,354 INFO epoch # 4895 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0069298588459787425
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:27,373 INFO epoch # 4896 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0069676991588494275
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:27,391 INFO epoch # 4897 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006935620203876169
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:27,410 INFO epoch # 4898 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006950150291231694
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:27,428 INFO epoch # 4899 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006967112720303703
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:27,447 INFO epoch # 4900 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007021649991656886
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:27,447 INFO *** epoch 4900, rolling-avg-loss (window=10)= 0.006957094211611547
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:27,465 INFO epoch # 4901 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00707101523221354
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:27,483 INFO epoch # 4902 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007004549435805529
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:27,501 INFO epoch # 4903 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007050631451420486
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:27,520 INFO epoch # 4904 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007003388825978618
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:27,538 INFO epoch # 4905 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006919636307429755
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:27,556 INFO epoch # 4906 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006976760178076802
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:27,574 INFO epoch # 4907 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006988029272179119
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:27,593 INFO epoch # 4908 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006926683112396859
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:27,611 INFO epoch # 4909 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0070483998279087245
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:27,630 INFO epoch # 4910 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007123967778170481
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:27,630 INFO *** epoch 4910, rolling-avg-loss (window=10)= 0.007011306142157991
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:27,648 INFO epoch # 4911 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006912023689437774
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:27,666 INFO epoch # 4912 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006919777726579923
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:27,685 INFO epoch # 4913 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00699190646992065
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:27,703 INFO epoch # 4914 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.010716302775108488
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:27,721 INFO epoch # 4915 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007150202487537172
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:27,739 INFO epoch # 4916 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007249687547300709
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:27,758 INFO epoch # 4917 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006924757079104893
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:27,776 INFO epoch # 4918 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007033812154986663
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:27,794 INFO epoch # 4919 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006987504475546302
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:27,813 INFO epoch # 4920 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006950797302124556
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:27,813 INFO *** epoch 4920, rolling-avg-loss (window=10)= 0.007383677170764713
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:27,831 INFO epoch # 4921 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006892798606713768
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:27,849 INFO epoch # 4922 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007015828050498385
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:27,868 INFO epoch # 4923 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007104016334778862
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:27,886 INFO epoch # 4924 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007154822051234078
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:27,904 INFO epoch # 4925 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006960206254007062
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:27,922 INFO epoch # 4926 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0069577883077727165
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:27,941 INFO epoch # 4927 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0069543569115921855
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:27,959 INFO epoch # 4928 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0069455259217647836
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:27,977 INFO epoch # 4929 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006952781463041902
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:27,996 INFO epoch # 4930 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006932414802577114
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:27,996 INFO *** epoch 4930, rolling-avg-loss (window=10)= 0.006987053870398085
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:28,014 INFO epoch # 4931 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006928831804543734
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:28,033 INFO epoch # 4932 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006981386010011192
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:28,051 INFO epoch # 4933 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0070617414530715905
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:28,069 INFO epoch # 4934 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006912558023032034
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:28,087 INFO epoch # 4935 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007039936273940839
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:28,105 INFO epoch # 4936 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007517923815612448
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:28,124 INFO epoch # 4937 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0069834644127695356
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:28,142 INFO epoch # 4938 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.010460435594723094
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:28,161 INFO epoch # 4939 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007014633629296441
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:28,180 INFO epoch # 4940 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006916644069860922
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:28,180 INFO *** epoch 4940, rolling-avg-loss (window=10)= 0.007381755508686183
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:28,199 INFO epoch # 4941 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006988139120949199
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:28,217 INFO epoch # 4942 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00694114507859922
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:28,236 INFO epoch # 4943 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006963306623219978
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:28,254 INFO epoch # 4944 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006936181420314824
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:28,273 INFO epoch # 4945 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006904331021360122
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:28,291 INFO epoch # 4946 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006938855276530376
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:28,309 INFO epoch # 4947 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006953756732400507
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:28,328 INFO epoch # 4948 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0069364278388093226
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:28,346 INFO epoch # 4949 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006923339311470045
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:28,364 INFO epoch # 4950 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00698327153804712
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:28,364 INFO *** epoch 4950, rolling-avg-loss (window=10)= 0.0069468753961700715
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:28,383 INFO epoch # 4951 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0069532532506855205
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:28,402 INFO epoch # 4952 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0070248534611891955
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:28,421 INFO epoch # 4953 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006933301116077928
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:28,439 INFO epoch # 4954 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006966324086533859
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:28,457 INFO epoch # 4955 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007005020022916142
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:28,476 INFO epoch # 4956 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006957479472475825
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:28,494 INFO epoch # 4957 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007251145601912867
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:28,512 INFO epoch # 4958 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0070613527204841375
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:28,530 INFO epoch # 4959 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007012169327936135
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:28,549 INFO epoch # 4960 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006897643252159469
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:28,549 INFO *** epoch 4960, rolling-avg-loss (window=10)= 0.0070062542312371075
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:28,568 INFO epoch # 4961 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007145583895180607
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:28,587 INFO epoch # 4962 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006926269768882776
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:28,606 INFO epoch # 4963 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007114529042155482
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:28,625 INFO epoch # 4964 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006972599869186524
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:28,643 INFO epoch # 4965 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0069227533058437984
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:28,662 INFO epoch # 4966 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006916640290000942
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:28,680 INFO epoch # 4967 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006928591938049067
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:28,698 INFO epoch # 4968 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006962666462641209
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:28,717 INFO epoch # 4969 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006945600001927232
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:28,735 INFO epoch # 4970 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006891812758112792
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:28,735 INFO *** epoch 4970, rolling-avg-loss (window=10)= 0.006972704733198043
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:28,753 INFO epoch # 4971 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007039863725367468
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:28,772 INFO epoch # 4972 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006904589870828204
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:28,790 INFO epoch # 4973 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006894508427649271
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:28,808 INFO epoch # 4974 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006934983714018017
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:28,827 INFO epoch # 4975 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006900802145537455
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:28,845 INFO epoch # 4976 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006947614878299646
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:28,864 INFO epoch # 4977 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00698075677792076
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:28,882 INFO epoch # 4978 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0069331342238001525
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:28,900 INFO epoch # 4979 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00693123995733913
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:28,919 INFO epoch # 4980 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.010917166258877842
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:28,919 INFO *** epoch 4980, rolling-avg-loss (window=10)= 0.007338465997963795
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:28,937 INFO epoch # 4981 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0070302278836607
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:28,955 INFO epoch # 4982 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007227149759273743
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:28,973 INFO epoch # 4983 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007052596331050154
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:28,992 INFO epoch # 4984 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006903615154442377
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:29,010 INFO epoch # 4985 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00690304128875141
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:29,029 INFO epoch # 4986 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007227513833640842
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:29,047 INFO epoch # 4987 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006894733072840609
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:29,066 INFO epoch # 4988 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0069010003717266954
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:29,084 INFO epoch # 4989 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0069194854877423495
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:29,102 INFO epoch # 4990 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006905040467245271
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:29,102 INFO *** epoch 4990, rolling-avg-loss (window=10)= 0.006996440365037415
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:29,121 INFO epoch # 4991 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006930695399205433
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:29,139 INFO epoch # 4992 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00689136763321585
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:29,157 INFO epoch # 4993 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006892860335938167
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:29,176 INFO epoch # 4994 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006874200033053057
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:29,195 INFO epoch # 4995 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006890179640322458
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:29,214 INFO epoch # 4996 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006966366716369521
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:29,232 INFO epoch # 4997 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006916304086189484
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:29,250 INFO epoch # 4998 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006926148260390619
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:29,269 INFO epoch # 4999 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007929545041406527
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:29,287 INFO epoch # 5000 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006987439192016609
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:29,287 INFO *** epoch 5000, rolling-avg-loss (window=10)= 0.007020510633810773
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:29,305 INFO epoch # 5001 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0069297990448831115
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:29,324 INFO epoch # 5002 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0071449800561822485
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:29,342 INFO epoch # 5003 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006959799120522803
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:29,360 INFO epoch # 5004 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007059233757900074
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:29,379 INFO epoch # 5005 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006925829835381592
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:29,397 INFO epoch # 5006 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006971574817725923
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:29,416 INFO epoch # 5007 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006904209054482635
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:29,434 INFO epoch # 5008 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006966561690205708
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:29,453 INFO epoch # 5009 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006881486133352155
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:29,471 INFO epoch # 5010 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.008641443160740891
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:29,471 INFO *** epoch 5010, rolling-avg-loss (window=10)= 0.007138491667137714
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:29,489 INFO epoch # 5011 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006902508404891705
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:29,508 INFO epoch # 5012 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006879106473206775
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:29,527 INFO epoch # 5013 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007018469215836376
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:29,546 INFO epoch # 5014 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007065296522341669
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:29,565 INFO epoch # 5015 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006924878318386618
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:29,583 INFO epoch # 5016 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006887416609970387
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:29,602 INFO epoch # 5017 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006888214200444054
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:29,620 INFO epoch # 5018 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007023273661616258
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:29,639 INFO epoch # 5019 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0070337929064407945
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:29,657 INFO epoch # 5020 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0073606898440630175
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:29,657 INFO *** epoch 5020, rolling-avg-loss (window=10)= 0.006998364615719765
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:29,676 INFO epoch # 5021 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006933468350325711
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:29,694 INFO epoch # 5022 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006995550673309481
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:29,712 INFO epoch # 5023 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00689030912326416
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:29,730 INFO epoch # 5024 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006949588296265574
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:29,748 INFO epoch # 5025 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007006194799032528
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:29,767 INFO epoch # 5026 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006929980751010589
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:29,785 INFO epoch # 5027 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006950403898372315
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:29,803 INFO epoch # 5028 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006879556291096378
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:29,822 INFO epoch # 5029 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006950409457203932
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:29,840 INFO epoch # 5030 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006933632401342038
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:29,840 INFO *** epoch 5030, rolling-avg-loss (window=10)= 0.006941909404122271
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:29,858 INFO epoch # 5031 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.008620856086054118
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:29,877 INFO epoch # 5032 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006943993452296127
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:29,895 INFO epoch # 5033 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0069353469407360535
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:29,913 INFO epoch # 5034 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.009272045623220038
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:29,932 INFO epoch # 5035 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007026696519460529
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:29,950 INFO epoch # 5036 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0069024529730086215
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:29,968 INFO epoch # 5037 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006892753805004759
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:29,987 INFO epoch # 5038 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006901033306348836
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:30,005 INFO epoch # 5039 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006868003063573269
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:30,024 INFO epoch # 5040 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006906557577167405
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:30,024 INFO *** epoch 5040, rolling-avg-loss (window=10)= 0.007326973934686976
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:30,042 INFO epoch # 5041 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0068725761520909145
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:30,060 INFO epoch # 5042 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006966557084524538
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:30,079 INFO epoch # 5043 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006975209507800173
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:30,097 INFO epoch # 5044 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006924132550921058
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:30,115 INFO epoch # 5045 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006872961843328085
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:30,134 INFO epoch # 5046 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006897367627971107
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:30,152 INFO epoch # 5047 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006885808808874572
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:30,170 INFO epoch # 5048 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006892960976983886
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:30,189 INFO epoch # 5049 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006869122553325724
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:30,207 INFO epoch # 5050 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006875223662063945
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:30,207 INFO *** epoch 5050, rolling-avg-loss (window=10)= 0.0069031920767884
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:30,226 INFO epoch # 5051 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00689224160851154
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:30,244 INFO epoch # 5052 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006901004795508925
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:30,263 INFO epoch # 5053 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006889243551995605
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:30,281 INFO epoch # 5054 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006932949625479523
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:30,299 INFO epoch # 5055 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0068934051669202745
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:30,318 INFO epoch # 5056 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006977748420467833
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:30,336 INFO epoch # 5057 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0069180288119241595
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:30,354 INFO epoch # 5058 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0070964487895253114
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:30,372 INFO epoch # 5059 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006920592899405165
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:30,391 INFO epoch # 5060 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006923064738657558
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:30,391 INFO *** epoch 5060, rolling-avg-loss (window=10)= 0.0069344728408395895
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:30,409 INFO epoch # 5061 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006858045788249001
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:30,428 INFO epoch # 5062 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00685614151552727
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:30,446 INFO epoch # 5063 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007009226355876308
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:30,464 INFO epoch # 5064 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006894976741023129
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:30,483 INFO epoch # 5065 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006884212460136041
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:30,501 INFO epoch # 5066 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007333921963436296
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:30,519 INFO epoch # 5067 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0069073031190782785
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:30,538 INFO epoch # 5068 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0068852683070872445
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:30,556 INFO epoch # 5069 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006895219314174028
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:30,574 INFO epoch # 5070 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00750529960350832
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:30,574 INFO *** epoch 5070, rolling-avg-loss (window=10)= 0.007002961516809592
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:30,593 INFO epoch # 5071 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006893409048643662
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:30,611 INFO epoch # 5072 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006900425269122934
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:30,629 INFO epoch # 5073 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00686523423428298
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:30,648 INFO epoch # 5074 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007061278374749236
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:30,666 INFO epoch # 5075 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006856663560029119
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:30,685 INFO epoch # 5076 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0069527355808531865
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:30,703 INFO epoch # 5077 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006939725270058261
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:30,721 INFO epoch # 5078 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006876922518131323
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:30,739 INFO epoch # 5079 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006948846479644999
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:30,757 INFO epoch # 5080 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006885254850203637
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:30,758 INFO *** epoch 5080, rolling-avg-loss (window=10)= 0.0069180495185719336
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:30,776 INFO epoch # 5081 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006882414083520416
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:30,794 INFO epoch # 5082 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006864268729259493
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:30,812 INFO epoch # 5083 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006877786458062474
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:30,831 INFO epoch # 5084 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006874957802210702
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:30,849 INFO epoch # 5085 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0068669229694933165
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:30,868 INFO epoch # 5086 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006887994262797292
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:30,886 INFO epoch # 5087 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006892491932376288
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:30,904 INFO epoch # 5088 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006887053350510541
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:30,923 INFO epoch # 5089 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007161264606111217
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:30,941 INFO epoch # 5090 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006856243608126533
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:30,941 INFO *** epoch 5090, rolling-avg-loss (window=10)= 0.0069051397802468275
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:30,959 INFO epoch # 5091 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006893388934258837
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:30,977 INFO epoch # 5092 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006913141922268551
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:30,996 INFO epoch # 5093 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0072643296953174286
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:31,014 INFO epoch # 5094 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006876028099213727
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:31,033 INFO epoch # 5095 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006875532755657332
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:31,051 INFO epoch # 5096 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006933227759873262
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:31,070 INFO epoch # 5097 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006880856723000761
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:31,088 INFO epoch # 5098 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006859460252599092
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:31,106 INFO epoch # 5099 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00690178589138668
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:31,124 INFO epoch # 5100 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006938048165466171
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:31,124 INFO *** epoch 5100, rolling-avg-loss (window=10)= 0.006933580019904184
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:31,143 INFO epoch # 5101 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0070200976078922395
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:31,161 INFO epoch # 5102 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006879663134895964
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:31,179 INFO epoch # 5103 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006850820353065501
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:31,198 INFO epoch # 5104 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006844565563369542
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:31,216 INFO epoch # 5105 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006879998985823477
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:31,236 INFO epoch # 5106 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006896580060129054
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:31,255 INFO epoch # 5107 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006954234231670853
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:31,274 INFO epoch # 5108 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0071606803066970315
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:31,292 INFO epoch # 5109 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0068860754363413434
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:31,311 INFO epoch # 5110 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0068598503930843435
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:31,311 INFO *** epoch 5110, rolling-avg-loss (window=10)= 0.006923256607296935
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:31,329 INFO epoch # 5111 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006861409958219156
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:31,348 INFO epoch # 5112 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006880876379000256
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:31,366 INFO epoch # 5113 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006968433113797801
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:31,384 INFO epoch # 5114 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00685243408952374
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:31,402 INFO epoch # 5115 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006848037664894946
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:31,421 INFO epoch # 5116 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007043076231639134
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:31,439 INFO epoch # 5117 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006867280200822279
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:31,458 INFO epoch # 5118 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006892131870699814
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:31,476 INFO epoch # 5119 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00698345778073417
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:31,495 INFO epoch # 5120 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006857287866296247
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:31,495 INFO *** epoch 5120, rolling-avg-loss (window=10)= 0.006905442515562754
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:31,513 INFO epoch # 5121 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006913017474289518
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:31,531 INFO epoch # 5122 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007374262597295456
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:31,549 INFO epoch # 5123 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006891873417771421
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:31,568 INFO epoch # 5124 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006862629503302742
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:31,586 INFO epoch # 5125 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006874542617879342
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:31,604 INFO epoch # 5126 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006965498392673908
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:31,623 INFO epoch # 5127 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.008514878936694004
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:31,641 INFO epoch # 5128 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007391552080662223
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:31,660 INFO epoch # 5129 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006882262598082889
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:31,678 INFO epoch # 5130 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006926739348273259
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:31,678 INFO *** epoch 5130, rolling-avg-loss (window=10)= 0.007159725696692476
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:31,697 INFO epoch # 5131 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006857002234028187
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:31,715 INFO epoch # 5132 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006896245871757856
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:31,733 INFO epoch # 5133 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006864487040729728
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:31,751 INFO epoch # 5134 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006940275492524961
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:31,770 INFO epoch # 5135 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006963544772588648
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:31,788 INFO epoch # 5136 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006842259539553197
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:31,806 INFO epoch # 5137 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006901041513629025
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:31,824 INFO epoch # 5138 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006891208635352086
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:31,843 INFO epoch # 5139 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006914579982549185
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:31,861 INFO epoch # 5140 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006832804790974478
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:31,862 INFO *** epoch 5140, rolling-avg-loss (window=10)= 0.006890344987368735
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:31,880 INFO epoch # 5141 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006823780535341939
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:31,898 INFO epoch # 5142 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006897830477100797
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:31,917 INFO epoch # 5143 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00686011587822577
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:31,935 INFO epoch # 5144 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0069783967519470025
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:31,953 INFO epoch # 5145 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006849980025435798
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:31,972 INFO epoch # 5146 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006944175744138192
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:31,990 INFO epoch # 5147 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006884407150209881
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:32,008 INFO epoch # 5148 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006882221863634186
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:32,027 INFO epoch # 5149 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006969954083615448
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:32,045 INFO epoch # 5150 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00683874020978692
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:32,045 INFO *** epoch 5150, rolling-avg-loss (window=10)= 0.006892960271943594
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:32,064 INFO epoch # 5151 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006843258888693526
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:32,082 INFO epoch # 5152 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006975456912186928
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:32,100 INFO epoch # 5153 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006939534687262494
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:32,119 INFO epoch # 5154 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00688007604185259
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:32,137 INFO epoch # 5155 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006829590995039325
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:32,155 INFO epoch # 5156 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006846669490187196
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:32,174 INFO epoch # 5157 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0069978541432647035
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:32,192 INFO epoch # 5158 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006913640387210762
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:32,210 INFO epoch # 5159 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006908324543474009
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:32,229 INFO epoch # 5160 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006912492430274142
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:32,229 INFO *** epoch 5160, rolling-avg-loss (window=10)= 0.006904689851944567
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:32,251 INFO epoch # 5161 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006854247611045139
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:32,269 INFO epoch # 5162 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006904399495397229
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:32,288 INFO epoch # 5163 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006855671217635972
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:32,306 INFO epoch # 5164 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006920697433088208
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:32,325 INFO epoch # 5165 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006854601957456907
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:32,343 INFO epoch # 5166 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006880486260342877
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:32,361 INFO epoch # 5167 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0068596015735238325
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:32,379 INFO epoch # 5168 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007270226422406267
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:32,398 INFO epoch # 5169 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006860703018901404
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:32,416 INFO epoch # 5170 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00690211077380809
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:32,416 INFO *** epoch 5170, rolling-avg-loss (window=10)= 0.006916274576360593
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:32,435 INFO epoch # 5171 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0069244142941897735
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:32,453 INFO epoch # 5172 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006833915420429548
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:32,471 INFO epoch # 5173 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00682252623300883
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:32,490 INFO epoch # 5174 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006863013113616034
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:32,508 INFO epoch # 5175 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006875730985484552
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:32,527 INFO epoch # 5176 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006823886535130441
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:32,545 INFO epoch # 5177 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006881723678816343
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:32,564 INFO epoch # 5178 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006871462057461031
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:32,582 INFO epoch # 5179 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006861510875751264
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:32,600 INFO epoch # 5180 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.009170853576506488
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:32,600 INFO *** epoch 5180, rolling-avg-loss (window=10)= 0.007092903677039431
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:32,618 INFO epoch # 5181 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006858026750705903
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:32,637 INFO epoch # 5182 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0068325422653288115
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:32,655 INFO epoch # 5183 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00748295069206506
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:32,674 INFO epoch # 5184 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006847650140116457
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:32,692 INFO epoch # 5185 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.009146124852122739
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:32,711 INFO epoch # 5186 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006859155564598041
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:32,729 INFO epoch # 5187 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006820009250077419
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:32,748 INFO epoch # 5188 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006912586308317259
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:32,766 INFO epoch # 5189 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006850362566183321
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:32,784 INFO epoch # 5190 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007032482586510014
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:32,784 INFO *** epoch 5190, rolling-avg-loss (window=10)= 0.007164189097602502
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:32,802 INFO epoch # 5191 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0069901387723803055
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:32,821 INFO epoch # 5192 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006848930202977499
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:32,839 INFO epoch # 5193 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006870773133414332
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:32,858 INFO epoch # 5194 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006833392322732834
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:32,876 INFO epoch # 5195 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006836651165940566
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:32,894 INFO epoch # 5196 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006819691181590315
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:32,913 INFO epoch # 5197 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0068381007586140186
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:32,931 INFO epoch # 5198 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006880754150188295
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:32,950 INFO epoch # 5199 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006802344529205584
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:32,968 INFO epoch # 5200 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00689845958549995
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:32,968 INFO *** epoch 5200, rolling-avg-loss (window=10)= 0.0068619235802543695
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:32,986 INFO epoch # 5201 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006857444423076231
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:33,005 INFO epoch # 5202 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006882545396365458
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:33,023 INFO epoch # 5203 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006817428293288685
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:33,041 INFO epoch # 5204 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0068790510995313525
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:33,059 INFO epoch # 5205 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00680914591976034
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:33,078 INFO epoch # 5206 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006839635749201989
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:33,096 INFO epoch # 5207 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006837011027528206
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:33,114 INFO epoch # 5208 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.008936047393945046
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:33,133 INFO epoch # 5209 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006955290162295569
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:33,151 INFO epoch # 5210 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007385788376268465
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:33,151 INFO *** epoch 5210, rolling-avg-loss (window=10)= 0.007119938784126134
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:33,170 INFO epoch # 5211 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006868097410915652
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:33,188 INFO epoch # 5212 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006844263512903126
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:33,206 INFO epoch # 5213 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0068886179687979165
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:33,225 INFO epoch # 5214 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006834914871433284
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:33,243 INFO epoch # 5215 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006946334215172101
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:33,261 INFO epoch # 5216 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006852659120340832
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:33,279 INFO epoch # 5217 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006827069621067494
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:33,298 INFO epoch # 5218 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006855830532003893
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:33,316 INFO epoch # 5219 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006860363188025076
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:33,335 INFO epoch # 5220 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006836843822384253
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:33,335 INFO *** epoch 5220, rolling-avg-loss (window=10)= 0.0068614994263043625
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:33,353 INFO epoch # 5221 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0068790583427471574
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:33,371 INFO epoch # 5222 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006851837068097666
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:33,390 INFO epoch # 5223 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006928272978257155
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:33,408 INFO epoch # 5224 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006816641631303355
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:33,426 INFO epoch # 5225 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006779814741094015
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:33,445 INFO epoch # 5226 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006854763818409992
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:33,463 INFO epoch # 5227 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007047592305752914
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:33,481 INFO epoch # 5228 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007125748641556129
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:33,500 INFO epoch # 5229 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0068645970823126845
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:33,518 INFO epoch # 5230 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006932231484825024
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:33,518 INFO *** epoch 5230, rolling-avg-loss (window=10)= 0.0069080558094356094
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:33,537 INFO epoch # 5231 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00689743083785288
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:33,555 INFO epoch # 5232 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006871184952615295
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:33,573 INFO epoch # 5233 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006876641786220716
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:33,592 INFO epoch # 5234 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006820887276262511
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:33,610 INFO epoch # 5235 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007079630671796622
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:33,629 INFO epoch # 5236 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006840264784841565
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:33,647 INFO epoch # 5237 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007002184411248891
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:33,665 INFO epoch # 5238 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006846878211945295
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:33,684 INFO epoch # 5239 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006876022023789119
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:33,702 INFO epoch # 5240 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00688430755326408
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:33,702 INFO *** epoch 5240, rolling-avg-loss (window=10)= 0.0068995432509836975
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:33,721 INFO epoch # 5241 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006841201429779176
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:33,739 INFO epoch # 5242 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006810427123127738
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:33,758 INFO epoch # 5243 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00710647895175498
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:33,776 INFO epoch # 5244 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006818289162765723
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:33,794 INFO epoch # 5245 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006836484928498976
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:33,813 INFO epoch # 5246 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006826999364420772
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:33,831 INFO epoch # 5247 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00679800055695523
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:33,850 INFO epoch # 5248 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0068693415087182075
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:33,869 INFO epoch # 5249 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006921130079717841
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:33,888 INFO epoch # 5250 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006910295975103509
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:33,888 INFO *** epoch 5250, rolling-avg-loss (window=10)= 0.006873864908084215
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:33,906 INFO epoch # 5251 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006809063277614769
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:33,924 INFO epoch # 5252 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007361117324762745
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:33,943 INFO epoch # 5253 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006807073124946328
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:33,961 INFO epoch # 5254 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006783173364965478
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:33,980 INFO epoch # 5255 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006912298074894352
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:33,999 INFO epoch # 5256 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006817755565862171
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:34,018 INFO epoch # 5257 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006905233847646741
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:34,036 INFO epoch # 5258 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006841529342636932
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:34,055 INFO epoch # 5259 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00680723182449583
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:34,073 INFO epoch # 5260 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006873543206893373
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:34,073 INFO *** epoch 5260, rolling-avg-loss (window=10)= 0.0068918018954718715
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:34,091 INFO epoch # 5261 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00681857523159124
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:34,110 INFO epoch # 5262 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007001689427852398
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:34,128 INFO epoch # 5263 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006831588885688689
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:34,146 INFO epoch # 5264 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006799152499297634
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:34,165 INFO epoch # 5265 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006805433044064557
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:34,183 INFO epoch # 5266 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006919497656781459
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:34,202 INFO epoch # 5267 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006828238292655442
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:34,220 INFO epoch # 5268 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0068918124270567205
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:34,238 INFO epoch # 5269 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.008514997065503849
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:34,256 INFO epoch # 5270 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0068530930584529415
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:34,257 INFO *** epoch 5270, rolling-avg-loss (window=10)= 0.0070264077588944925
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:34,275 INFO epoch # 5271 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007343468958424637
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:34,293 INFO epoch # 5272 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006839816625870299
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:34,312 INFO epoch # 5273 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006808396501583047
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:34,330 INFO epoch # 5274 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006869822973385453
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:34,349 INFO epoch # 5275 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006813462110585533
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:34,367 INFO epoch # 5276 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006787215555959847
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:34,386 INFO epoch # 5277 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006877117975818692
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:34,404 INFO epoch # 5278 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006839101086370647
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:34,422 INFO epoch # 5279 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006824233045335859
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:34,441 INFO epoch # 5280 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006823681280366145
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:34,441 INFO *** epoch 5280, rolling-avg-loss (window=10)= 0.0068826316113700155
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:34,459 INFO epoch # 5281 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006823473882832332
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:34,477 INFO epoch # 5282 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006822078463301295
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:34,495 INFO epoch # 5283 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006793717289838241
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:34,514 INFO epoch # 5284 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006796749781642575
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:34,532 INFO epoch # 5285 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00685226492350921
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:34,551 INFO epoch # 5286 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006966797554923687
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:34,569 INFO epoch # 5287 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0068334900024638046
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:34,587 INFO epoch # 5288 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006830515754700173
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:34,606 INFO epoch # 5289 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006977114928304218
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:34,624 INFO epoch # 5290 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006821628827310633
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:34,624 INFO *** epoch 5290, rolling-avg-loss (window=10)= 0.0068517831408826165
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:34,643 INFO epoch # 5291 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0067861058669222984
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:34,661 INFO epoch # 5292 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006802396725106519
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:34,679 INFO epoch # 5293 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006795440305722877
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:34,697 INFO epoch # 5294 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0068627245746029075
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:34,716 INFO epoch # 5295 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006834969055489637
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:34,734 INFO epoch # 5296 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006783468135836301
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:34,753 INFO epoch # 5297 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006806654069805518
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:34,771 INFO epoch # 5298 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006854839437437477
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:34,789 INFO epoch # 5299 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006848418110166676
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:34,808 INFO epoch # 5300 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006822267416282557
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:34,808 INFO *** epoch 5300, rolling-avg-loss (window=10)= 0.006819728369737277
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:34,826 INFO epoch # 5301 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0069029349469929
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:34,845 INFO epoch # 5302 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006786950401874492
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:34,863 INFO epoch # 5303 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006810013623180566
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:34,881 INFO epoch # 5304 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006812823070504237
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:34,899 INFO epoch # 5305 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006795545050408691
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:34,917 INFO epoch # 5306 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00682546721509425
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:34,936 INFO epoch # 5307 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006803772779676365
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:34,954 INFO epoch # 5308 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00683751469841809
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:34,973 INFO epoch # 5309 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00683095079875784
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:34,991 INFO epoch # 5310 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006910196221724618
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:34,991 INFO *** epoch 5310, rolling-avg-loss (window=10)= 0.006831616880663205
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:35,009 INFO epoch # 5311 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007207862250652397
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:35,028 INFO epoch # 5312 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007211157528217882
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:35,046 INFO epoch # 5313 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006808625701523852
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:35,064 INFO epoch # 5314 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0068674128015118185
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:35,082 INFO epoch # 5315 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006888692663778784
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:35,101 INFO epoch # 5316 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00726448016212089
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:35,119 INFO epoch # 5317 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006824812546255998
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:35,138 INFO epoch # 5318 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006795973517000675
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:35,156 INFO epoch # 5319 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00683010265493067
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:35,175 INFO epoch # 5320 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006826747550803702
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:35,175 INFO *** epoch 5320, rolling-avg-loss (window=10)= 0.006952586737679667
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:35,193 INFO epoch # 5321 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006815400531195337
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:35,212 INFO epoch # 5322 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007234372020320734
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:35,230 INFO epoch # 5323 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006933322765689809
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:35,248 INFO epoch # 5324 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006842076239991002
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:35,266 INFO epoch # 5325 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006909285184519831
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:35,285 INFO epoch # 5326 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006804716897022445
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:35,303 INFO epoch # 5327 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006823333191277925
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:35,322 INFO epoch # 5328 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006811424274928868
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:35,340 INFO epoch # 5329 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006784023207728751
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:35,359 INFO epoch # 5330 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00917674770244048
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:35,359 INFO *** epoch 5330, rolling-avg-loss (window=10)= 0.007113470201511518
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:35,377 INFO epoch # 5331 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006806425913964631
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:35,396 INFO epoch # 5332 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006838562698249007
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:35,414 INFO epoch # 5333 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006768489849491743
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:35,432 INFO epoch # 5334 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006782342486985726
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:35,451 INFO epoch # 5335 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006902655633894028
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:35,469 INFO epoch # 5336 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00705695734359324
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:35,487 INFO epoch # 5337 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.009092785887332866
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:35,505 INFO epoch # 5338 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006791015810449608
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:35,524 INFO epoch # 5339 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006812916690250859
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:35,542 INFO epoch # 5340 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.010261053470458137
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:35,542 INFO *** epoch 5340, rolling-avg-loss (window=10)= 0.007411320578466984
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:35,561 INFO epoch # 5341 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0068769176468777005
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:35,579 INFO epoch # 5342 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006785994246456539
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:35,598 INFO epoch # 5343 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006803360371122835
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:35,617 INFO epoch # 5344 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006771902786567807
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:35,635 INFO epoch # 5345 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006880975583044346
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:35,654 INFO epoch # 5346 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006861810845293803
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:35,672 INFO epoch # 5347 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006779270930564962
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:35,691 INFO epoch # 5348 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006857794593088329
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:35,709 INFO epoch # 5349 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006778836581361247
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:35,727 INFO epoch # 5350 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006836396816652268
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:35,727 INFO *** epoch 5350, rolling-avg-loss (window=10)= 0.006823326040102984
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:35,746 INFO epoch # 5351 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006784571258322103
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:35,764 INFO epoch # 5352 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006769109269953333
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:35,782 INFO epoch # 5353 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006775486341211945
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:35,801 INFO epoch # 5354 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006781960462831194
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:35,819 INFO epoch # 5355 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00678405007784022
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:35,837 INFO epoch # 5356 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00843153583628009
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:35,856 INFO epoch # 5357 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006823971118137706
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:35,874 INFO epoch # 5358 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00687905269296607
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:35,892 INFO epoch # 5359 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006988596291193971
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:35,910 INFO epoch # 5360 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006958210375159979
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:35,910 INFO *** epoch 5360, rolling-avg-loss (window=10)= 0.0069976543723896615
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:35,929 INFO epoch # 5361 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006788816273910925
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:35,947 INFO epoch # 5362 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0067682153967325576
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:35,965 INFO epoch # 5363 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006820147376856767
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:35,984 INFO epoch # 5364 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006763980985851958
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:36,002 INFO epoch # 5365 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006771449247025885
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:36,021 INFO epoch # 5366 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00689054202666739
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:36,039 INFO epoch # 5367 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00680455890687881
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:36,057 INFO epoch # 5368 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.010278098550770665
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:36,076 INFO epoch # 5369 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006855667939817067
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:36,094 INFO epoch # 5370 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006822542960435385
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:36,094 INFO *** epoch 5370, rolling-avg-loss (window=10)= 0.007156401966494741
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:36,112 INFO epoch # 5371 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006953350595722441
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:36,131 INFO epoch # 5372 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006801597151934402
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:36,149 INFO epoch # 5373 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006791638857976068
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:36,168 INFO epoch # 5374 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006810213595599635
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:36,186 INFO epoch # 5375 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006800115086662117
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:36,205 INFO epoch # 5376 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0067987705806444865
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:36,223 INFO epoch # 5377 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0068882123014191166
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:36,241 INFO epoch # 5378 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006922144857526291
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:36,259 INFO epoch # 5379 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00684039435145678
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:36,278 INFO epoch # 5380 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006740099117450882
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:36,278 INFO *** epoch 5380, rolling-avg-loss (window=10)= 0.006834653649639222
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:36,296 INFO epoch # 5381 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006918694776686607
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:36,314 INFO epoch # 5382 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006763603389117634
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:36,333 INFO epoch # 5383 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006833686908066738
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:36,352 INFO epoch # 5384 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006880407781864051
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:36,370 INFO epoch # 5385 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0068139001305098645
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:36,389 INFO epoch # 5386 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006792686162953032
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:36,408 INFO epoch # 5387 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006798977861762978
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:36,427 INFO epoch # 5388 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006769412335415836
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:36,445 INFO epoch # 5389 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006753553436283255
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:36,463 INFO epoch # 5390 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00676520432534744
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:36,463 INFO *** epoch 5390, rolling-avg-loss (window=10)= 0.0068090127108007435
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:36,481 INFO epoch # 5391 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.009057515584572684
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:36,500 INFO epoch # 5392 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006852413465821883
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:36,518 INFO epoch # 5393 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006947105244762497
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:36,536 INFO epoch # 5394 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006774434015824227
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:36,555 INFO epoch # 5395 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006824469557614066
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:36,573 INFO epoch # 5396 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006952002138859825
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:36,592 INFO epoch # 5397 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006755162357876543
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:36,610 INFO epoch # 5398 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006855721992906183
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:36,629 INFO epoch # 5399 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006800402799854055
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:36,647 INFO epoch # 5400 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0067403445009404095
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:36,647 INFO *** epoch 5400, rolling-avg-loss (window=10)= 0.007055957165903237
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:36,665 INFO epoch # 5401 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006775573649065336
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:36,683 INFO epoch # 5402 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006764175148418872
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:36,701 INFO epoch # 5403 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0067557067013694905
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:36,720 INFO epoch # 5404 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006775146222935291
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:36,738 INFO epoch # 5405 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006755830905603943
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:36,757 INFO epoch # 5406 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0068956885006628
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:36,775 INFO epoch # 5407 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006788607257476542
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:36,793 INFO epoch # 5408 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006773590717784828
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:36,812 INFO epoch # 5409 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006838118937594118
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:36,830 INFO epoch # 5410 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006822123519668821
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:36,830 INFO *** epoch 5410, rolling-avg-loss (window=10)= 0.006794456156058004
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:36,848 INFO epoch # 5411 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006776280326448614
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:36,867 INFO epoch # 5412 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006773691722628428
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:36,885 INFO epoch # 5413 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006859597051516175
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:36,903 INFO epoch # 5414 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0067481330333976075
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:36,921 INFO epoch # 5415 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0067783275444526225
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:36,940 INFO epoch # 5416 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006777866008633282
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:36,958 INFO epoch # 5417 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00690276868044748
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:36,977 INFO epoch # 5418 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006751814056769945
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:36,995 INFO epoch # 5419 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006741629029420437
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:37,014 INFO epoch # 5420 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0067627823882503435
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:37,014 INFO *** epoch 5420, rolling-avg-loss (window=10)= 0.006787288984196493
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:37,032 INFO epoch # 5421 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006779424878914142
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:37,051 INFO epoch # 5422 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006753991579898866
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:37,070 INFO epoch # 5423 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006774589954147814
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:37,088 INFO epoch # 5424 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006816539895226015
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:37,106 INFO epoch # 5425 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00677059681765968
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:37,125 INFO epoch # 5426 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007105274133209605
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:37,143 INFO epoch # 5427 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006952595907932846
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:37,162 INFO epoch # 5428 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006827182234701468
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:37,181 INFO epoch # 5429 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006745263694028836
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:37,199 INFO epoch # 5430 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006782166492484976
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:37,199 INFO *** epoch 5430, rolling-avg-loss (window=10)= 0.006830762558820425
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:37,217 INFO epoch # 5431 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0068404851845116355
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:37,236 INFO epoch # 5432 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0067768915396300144
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:37,254 INFO epoch # 5433 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006745307477103779
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:37,272 INFO epoch # 5434 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006830027701653307
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:37,291 INFO epoch # 5435 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0067419776460155845
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:37,309 INFO epoch # 5436 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006764680383639643
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:37,327 INFO epoch # 5437 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006732903131705825
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:37,346 INFO epoch # 5438 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006742197667335859
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:37,364 INFO epoch # 5439 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006746861086867284
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:37,383 INFO epoch # 5440 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006730486926244339
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:37,383 INFO *** epoch 5440, rolling-avg-loss (window=10)= 0.006765181874470727
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:37,401 INFO epoch # 5441 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00678021066414658
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:37,420 INFO epoch # 5442 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006742082336131716
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:37,438 INFO epoch # 5443 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006861827059765346
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:37,457 INFO epoch # 5444 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006784871304262197
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:37,475 INFO epoch # 5445 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0067468535526131745
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:37,493 INFO epoch # 5446 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006866541487397626
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:37,512 INFO epoch # 5447 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006744958856870653
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:37,530 INFO epoch # 5448 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006776726069801953
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:37,548 INFO epoch # 5449 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006889856878842693
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:37,567 INFO epoch # 5450 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006794131295464467
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:37,567 INFO *** epoch 5450, rolling-avg-loss (window=10)= 0.006798805950529641
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:37,585 INFO epoch # 5451 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0068876641962560825
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:37,604 INFO epoch # 5452 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00677057961729588
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:37,622 INFO epoch # 5453 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006772158863896038
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:37,641 INFO epoch # 5454 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006734584032528801
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:37,659 INFO epoch # 5455 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.010771142224257346
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:37,677 INFO epoch # 5456 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007436795705871191
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:37,695 INFO epoch # 5457 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00678827210504096
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:37,714 INFO epoch # 5458 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.009042687346664025
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:37,732 INFO epoch # 5459 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006755986800271785
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:37,750 INFO epoch # 5460 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007017781827016734
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:37,750 INFO *** epoch 5460, rolling-avg-loss (window=10)= 0.007497765271909884
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:37,769 INFO epoch # 5461 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006729008677211823
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:37,787 INFO epoch # 5462 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006987536344240652
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:37,806 INFO epoch # 5463 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006717521711834706
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:37,824 INFO epoch # 5464 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006745529877662193
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:37,842 INFO epoch # 5465 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006748037856596056
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:37,861 INFO epoch # 5466 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006777894752303837
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:37,879 INFO epoch # 5467 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006758204253856093
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:37,897 INFO epoch # 5468 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006782563435990596
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:37,915 INFO epoch # 5469 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006774462864996167
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:37,934 INFO epoch # 5470 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006711298010486644
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:37,934 INFO *** epoch 5470, rolling-avg-loss (window=10)= 0.006773205778517877
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:37,952 INFO epoch # 5471 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006759124695236096
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:37,971 INFO epoch # 5472 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006758663796063047
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:37,989 INFO epoch # 5473 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007069679570122389
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:38,007 INFO epoch # 5474 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006759463518392295
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:38,026 INFO epoch # 5475 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006731422177836066
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:38,044 INFO epoch # 5476 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0067689634051930625
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:38,062 INFO epoch # 5477 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006976387398026418
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:38,081 INFO epoch # 5478 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006722706999426009
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:38,099 INFO epoch # 5479 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00677309583988972
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:38,117 INFO epoch # 5480 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006772644235752523
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:38,117 INFO *** epoch 5480, rolling-avg-loss (window=10)= 0.006809215163593762
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:38,136 INFO epoch # 5481 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00682160315773217
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:38,154 INFO epoch # 5482 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006886448598379502
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:38,173 INFO epoch # 5483 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00672977424619603
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:38,191 INFO epoch # 5484 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006740627140970901
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:38,209 INFO epoch # 5485 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006903825171320932
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:38,228 INFO epoch # 5486 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006714975730574224
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:38,246 INFO epoch # 5487 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0067377421946730465
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:38,265 INFO epoch # 5488 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006758317547792103
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:38,283 INFO epoch # 5489 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006825949894846417
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:38,301 INFO epoch # 5490 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006756100130587583
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:38,301 INFO *** epoch 5490, rolling-avg-loss (window=10)= 0.006787536381307291
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:38,319 INFO epoch # 5491 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006711913165418082
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:38,338 INFO epoch # 5492 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0067321044552954845
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:38,356 INFO epoch # 5493 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00689345409773523
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:38,375 INFO epoch # 5494 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006725378432747675
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:38,393 INFO epoch # 5495 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006734249076544074
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:38,411 INFO epoch # 5496 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006761662531062029
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:38,430 INFO epoch # 5497 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006762903831258882
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:38,448 INFO epoch # 5498 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006766005157260224
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:38,466 INFO epoch # 5499 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006728370641212678
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:38,485 INFO epoch # 5500 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006707719152473146
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:38,485 INFO *** epoch 5500, rolling-avg-loss (window=10)= 0.006752376054100751
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:38,503 INFO epoch # 5501 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0067738765210378915
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:38,521 INFO epoch # 5502 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006754648002242902
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:38,539 INFO epoch # 5503 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006715841449477011
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:38,558 INFO epoch # 5504 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0067318767760298215
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:38,576 INFO epoch # 5505 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006750389562512282
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:38,595 INFO epoch # 5506 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0067877397559641395
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:38,613 INFO epoch # 5507 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006944057306100149
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:38,631 INFO epoch # 5508 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006737227937264834
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:38,650 INFO epoch # 5509 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006743336489307694
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:38,668 INFO epoch # 5510 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006709936988045229
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:38,668 INFO *** epoch 5510, rolling-avg-loss (window=10)= 0.0067648930787981955
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:38,686 INFO epoch # 5511 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006742674726410769
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:38,704 INFO epoch # 5512 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0067796880030073225
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:38,723 INFO epoch # 5513 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006732366317010019
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:38,741 INFO epoch # 5514 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007019086271611741
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:38,759 INFO epoch # 5515 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006695593103358988
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:38,777 INFO epoch # 5516 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006754281177563826
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:38,796 INFO epoch # 5517 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006815253804234089
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:38,816 INFO epoch # 5518 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006750389613443986
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:38,835 INFO epoch # 5519 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006734270511515206
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:38,854 INFO epoch # 5520 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00674285809873254
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:38,854 INFO *** epoch 5520, rolling-avg-loss (window=10)= 0.006776646162688848
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:38,872 INFO epoch # 5521 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006773826618882595
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:38,890 INFO epoch # 5522 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006756899463653099
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:38,909 INFO epoch # 5523 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00679203469917411
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:38,927 INFO epoch # 5524 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006713608869176824
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:38,945 INFO epoch # 5525 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006869778786494862
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:38,964 INFO epoch # 5526 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006723969192535151
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:38,982 INFO epoch # 5527 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006707920983899385
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:39,001 INFO epoch # 5528 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00686384239452309
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:39,019 INFO epoch # 5529 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006748649142537033
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:39,038 INFO epoch # 5530 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0068020092039660085
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:39,038 INFO *** epoch 5530, rolling-avg-loss (window=10)= 0.0067752539354842154
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:39,056 INFO epoch # 5531 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006977926368563203
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:39,075 INFO epoch # 5532 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006813230127590941
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:39,093 INFO epoch # 5533 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006709544173645554
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:39,111 INFO epoch # 5534 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00669577436929103
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:39,129 INFO epoch # 5535 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006741899320331868
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:39,148 INFO epoch # 5536 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006710782763548195
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:39,166 INFO epoch # 5537 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006701060079649324
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:39,185 INFO epoch # 5538 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006723611542838626
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:39,203 INFO epoch # 5539 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006797003032261273
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:39,222 INFO epoch # 5540 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006819813810579944
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:39,222 INFO *** epoch 5540, rolling-avg-loss (window=10)= 0.006769064558829996
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:39,240 INFO epoch # 5541 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.008369227005459834
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:39,259 INFO epoch # 5542 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00678700627759099
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:39,277 INFO epoch # 5543 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007149093751650071
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:39,295 INFO epoch # 5544 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006709536381094949
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:39,314 INFO epoch # 5545 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0070920011021371465
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:39,332 INFO epoch # 5546 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006704214196361136
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:39,350 INFO epoch # 5547 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006677148552626022
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:39,369 INFO epoch # 5548 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006683320902084233
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:39,387 INFO epoch # 5549 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0067202282953076065
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:39,405 INFO epoch # 5550 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006690759408229496
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:39,406 INFO *** epoch 5550, rolling-avg-loss (window=10)= 0.006958253587254148
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:39,424 INFO epoch # 5551 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006826954675489105
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:39,442 INFO epoch # 5552 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006748848798451945
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:39,461 INFO epoch # 5553 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006731126843078528
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:39,479 INFO epoch # 5554 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006857138578197919
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:39,498 INFO epoch # 5555 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00670153727332945
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:39,516 INFO epoch # 5556 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006752746645361185
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:39,534 INFO epoch # 5557 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007270441914442927
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:39,552 INFO epoch # 5558 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0069184844178380445
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:39,571 INFO epoch # 5559 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006724012171616778
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:39,589 INFO epoch # 5560 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006693727802485228
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:39,590 INFO *** epoch 5560, rolling-avg-loss (window=10)= 0.006822501912029111
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:39,608 INFO epoch # 5561 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006694788055028766
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:39,626 INFO epoch # 5562 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006791837877244689
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:39,645 INFO epoch # 5563 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.009056315902853385
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:39,663 INFO epoch # 5564 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006770130850782152
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:39,682 INFO epoch # 5565 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00673672725315555
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:39,700 INFO epoch # 5566 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006976679833314847
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:39,718 INFO epoch # 5567 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006723149537720019
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:39,736 INFO epoch # 5568 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006789666771510383
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:39,755 INFO epoch # 5569 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006746702238160651
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:39,773 INFO epoch # 5570 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006850613692222396
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:39,773 INFO *** epoch 5570, rolling-avg-loss (window=10)= 0.007013661201199284
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:39,791 INFO epoch # 5571 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0067143036612833384
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:39,810 INFO epoch # 5572 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006722441832607728
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:39,828 INFO epoch # 5573 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006683418960165
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:39,846 INFO epoch # 5574 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006697671855363296
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:39,865 INFO epoch # 5575 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006723330840031849
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:39,883 INFO epoch # 5576 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00671901039822842
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:39,901 INFO epoch # 5577 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006903801731823478
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:39,920 INFO epoch # 5578 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006984935393120395
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:39,938 INFO epoch # 5579 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006730893037456553
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:39,956 INFO epoch # 5580 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006693124400044326
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:39,956 INFO *** epoch 5580, rolling-avg-loss (window=10)= 0.006757293211012439
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:39,974 INFO epoch # 5581 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006686963854008354
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:39,993 INFO epoch # 5582 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006737460982549237
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:40,011 INFO epoch # 5583 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006698143628455
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:40,029 INFO epoch # 5584 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006709776065690676
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:40,048 INFO epoch # 5585 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006691551923722727
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:40,066 INFO epoch # 5586 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00667172816429229
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:40,085 INFO epoch # 5587 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006763700170267839
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:40,104 INFO epoch # 5588 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006684293897706084
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:40,123 INFO epoch # 5589 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006716824183968129
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:40,142 INFO epoch # 5590 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006692877555906307
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:40,142 INFO *** epoch 5590, rolling-avg-loss (window=10)= 0.006705332042656664
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:40,161 INFO epoch # 5591 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006865891322377138
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:40,180 INFO epoch # 5592 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006722136065945961
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:40,199 INFO epoch # 5593 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0067048888085992076
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:40,217 INFO epoch # 5594 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006784171579056419
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:40,236 INFO epoch # 5595 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006752119188604411
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:40,255 INFO epoch # 5596 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006830210080806864
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:40,273 INFO epoch # 5597 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00671241289091995
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:40,291 INFO epoch # 5598 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00666629453189671
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:40,310 INFO epoch # 5599 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006715308118145913
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:40,328 INFO epoch # 5600 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00688618611820857
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:40,328 INFO *** epoch 5600, rolling-avg-loss (window=10)= 0.006763961870456114
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:40,346 INFO epoch # 5601 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006694520961900707
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:40,364 INFO epoch # 5602 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006713284525176277
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:40,383 INFO epoch # 5603 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006717083135299617
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:40,401 INFO epoch # 5604 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00668332323039067
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:40,420 INFO epoch # 5605 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0068296089812065475
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:40,438 INFO epoch # 5606 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006673095704172738
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:40,457 INFO epoch # 5607 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006709680190397194
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:40,475 INFO epoch # 5608 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0066725413817039225
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:40,494 INFO epoch # 5609 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006780771342164371
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:40,512 INFO epoch # 5610 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006686159751552623
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:40,512 INFO *** epoch 5610, rolling-avg-loss (window=10)= 0.0067160069203964666
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:40,530 INFO epoch # 5611 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006708686065394431
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:40,548 INFO epoch # 5612 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00668966593730147
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:40,567 INFO epoch # 5613 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006786507696233457
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:40,585 INFO epoch # 5614 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006724744540406391
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:40,604 INFO epoch # 5615 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006733121743309312
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:40,622 INFO epoch # 5616 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006743710902810562
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:40,641 INFO epoch # 5617 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00670820693630958
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:40,659 INFO epoch # 5618 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006883910609758459
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:40,678 INFO epoch # 5619 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007003439131949563
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:40,696 INFO epoch # 5620 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006673852567473659
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:40,696 INFO *** epoch 5620, rolling-avg-loss (window=10)= 0.006765584613094689
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:40,715 INFO epoch # 5621 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006670589042187203
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:40,733 INFO epoch # 5622 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0067940074077341706
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:40,751 INFO epoch # 5623 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006751799017365556
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:40,769 INFO epoch # 5624 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0067670023745449726
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:40,788 INFO epoch # 5625 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006848695946246153
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:40,806 INFO epoch # 5626 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006707758657285012
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:40,825 INFO epoch # 5627 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006666469385891105
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:40,843 INFO epoch # 5628 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006676670731394552
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:40,862 INFO epoch # 5629 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006692084665701259
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:40,880 INFO epoch # 5630 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0069961433473508805
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:40,880 INFO *** epoch 5630, rolling-avg-loss (window=10)= 0.006757122057570087
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:40,899 INFO epoch # 5631 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006700218116748147
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:40,917 INFO epoch # 5632 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007232005129480967
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:40,935 INFO epoch # 5633 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007108863450412173
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:40,953 INFO epoch # 5634 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007662718166102422
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:40,972 INFO epoch # 5635 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006701340291328961
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:40,990 INFO epoch # 5636 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006693905241263565
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:41,008 INFO epoch # 5637 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006668802747299196
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:41,027 INFO epoch # 5638 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006709343615511898
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:41,045 INFO epoch # 5639 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006693718292808626
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:41,064 INFO epoch # 5640 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006674544332781807
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:41,064 INFO *** epoch 5640, rolling-avg-loss (window=10)= 0.006884545938373776
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:41,082 INFO epoch # 5641 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006674852658761665
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:41,100 INFO epoch # 5642 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006706250591378193
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:41,119 INFO epoch # 5643 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006657371282926761
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:41,137 INFO epoch # 5644 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006810549850342795
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:41,155 INFO epoch # 5645 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006725784558511805
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:41,173 INFO epoch # 5646 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006679802150756586
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:41,192 INFO epoch # 5647 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006776642068871297
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:41,210 INFO epoch # 5648 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006694207120744977
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:41,229 INFO epoch # 5649 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006718393000483047
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:41,247 INFO epoch # 5650 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00674238085775869
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:41,247 INFO *** epoch 5650, rolling-avg-loss (window=10)= 0.006718623414053581
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:41,266 INFO epoch # 5651 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0067780722038151
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:41,284 INFO epoch # 5652 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006707279422698775
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:41,302 INFO epoch # 5653 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006714622250001412
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:41,320 INFO epoch # 5654 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006678038047539303
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:41,339 INFO epoch # 5655 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00713261640703422
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:41,357 INFO epoch # 5656 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006705349020194262
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:41,375 INFO epoch # 5657 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006815435612224974
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:41,394 INFO epoch # 5658 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006686355234705843
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:41,412 INFO epoch # 5659 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006697097160213161
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:41,431 INFO epoch # 5660 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006659530994511442
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:41,431 INFO *** epoch 5660, rolling-avg-loss (window=10)= 0.006757439635293849
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:41,449 INFO epoch # 5661 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00670718901528744
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:41,468 INFO epoch # 5662 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0067342586917220615
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:41,486 INFO epoch # 5663 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006660230887064245
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:41,504 INFO epoch # 5664 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006807452769862721
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:41,522 INFO epoch # 5665 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006820552265708102
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:41,541 INFO epoch # 5666 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006669136040727608
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:41,559 INFO epoch # 5667 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006724819959345041
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:41,577 INFO epoch # 5668 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006861551508336561
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:41,596 INFO epoch # 5669 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006773995271942113
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:41,614 INFO epoch # 5670 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00668673379914253
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:41,614 INFO *** epoch 5670, rolling-avg-loss (window=10)= 0.0067445920209138425
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:41,633 INFO epoch # 5671 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006675878255919088
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:41,651 INFO epoch # 5672 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00674062891266658
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:41,670 INFO epoch # 5673 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006699787103570998
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:41,688 INFO epoch # 5674 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006690357709885575
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:41,707 INFO epoch # 5675 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0066539323270262685
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:41,725 INFO epoch # 5676 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006761429784091888
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:41,743 INFO epoch # 5677 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006697297645587241
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:41,761 INFO epoch # 5678 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00669569224191946
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:41,779 INFO epoch # 5679 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006694058713037521
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:41,798 INFO epoch # 5680 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00666945317061618
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:41,798 INFO *** epoch 5680, rolling-avg-loss (window=10)= 0.0066978515864320794
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:41,816 INFO epoch # 5681 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006643977321800776
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:41,835 INFO epoch # 5682 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.008883598595275544
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:41,853 INFO epoch # 5683 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007018239619355882
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:41,872 INFO epoch # 5684 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.008895379065506859
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:41,890 INFO epoch # 5685 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006728917393047595
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:41,909 INFO epoch # 5686 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006666056226094952
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:41,927 INFO epoch # 5687 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006688168759865221
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:41,945 INFO epoch # 5688 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006670319879049202
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:41,963 INFO epoch # 5689 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006823931405961048
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:41,982 INFO epoch # 5690 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0066541292471811175
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:41,982 INFO *** epoch 5690, rolling-avg-loss (window=10)= 0.0071672717513138195
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:42,000 INFO epoch # 5691 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006626856169532402
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:42,019 INFO epoch # 5692 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006740728833392495
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:42,037 INFO epoch # 5693 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0066461930709920125
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:42,056 INFO epoch # 5694 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006713240953104105
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:42,074 INFO epoch # 5695 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006759581388905644
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:42,093 INFO epoch # 5696 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.008942777683841996
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:42,111 INFO epoch # 5697 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006785202927858336
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:42,129 INFO epoch # 5698 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006847198113973718
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:42,148 INFO epoch # 5699 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006800433198804967
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:42,166 INFO epoch # 5700 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0071522129874210805
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:42,166 INFO *** epoch 5700, rolling-avg-loss (window=10)= 0.007001442532782676
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:42,184 INFO epoch # 5701 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007099358437699266
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:42,203 INFO epoch # 5702 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006732870893756626
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:42,221 INFO epoch # 5703 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00668818105259561
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:42,239 INFO epoch # 5704 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0066702876283670776
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:42,258 INFO epoch # 5705 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006702599312120583
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:42,276 INFO epoch # 5706 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006673214198599453
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:42,295 INFO epoch # 5707 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006813404994318262
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:42,313 INFO epoch # 5708 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006654374625213677
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:42,331 INFO epoch # 5709 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006669891288765939
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:42,350 INFO epoch # 5710 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006669157319265651
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:42,350 INFO *** epoch 5710, rolling-avg-loss (window=10)= 0.0067373339750702145
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:42,368 INFO epoch # 5711 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006743346573784947
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:42,386 INFO epoch # 5712 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006685750064207241
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:42,405 INFO epoch # 5713 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0066475117764639435
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:42,423 INFO epoch # 5714 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006898812385770725
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:42,441 INFO epoch # 5715 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006781634183425922
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:42,460 INFO epoch # 5716 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006641798681812361
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:42,478 INFO epoch # 5717 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.010124338030436775
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:42,497 INFO epoch # 5718 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006723888458509464
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:42,515 INFO epoch # 5719 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0066710390310618095
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:42,533 INFO epoch # 5720 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.008932727701903787
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:42,533 INFO *** epoch 5720, rolling-avg-loss (window=10)= 0.007285084688737698
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:42,552 INFO epoch # 5721 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006650449127846514
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:42,570 INFO epoch # 5722 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006828446319559589
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:42,588 INFO epoch # 5723 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006660347422439372
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:42,607 INFO epoch # 5724 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0066615963442018256
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:42,625 INFO epoch # 5725 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006715901068673702
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:42,644 INFO epoch # 5726 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00704088115162449
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:42,662 INFO epoch # 5727 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006650651121162809
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:42,681 INFO epoch # 5728 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006686761451419443
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:42,699 INFO epoch # 5729 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006768221748643555
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:42,718 INFO epoch # 5730 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0066688843617157545
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:42,718 INFO *** epoch 5730, rolling-avg-loss (window=10)= 0.006733214011728705
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:42,736 INFO epoch # 5731 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006971381579205627
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:42,754 INFO epoch # 5732 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007061770786094712
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:42,773 INFO epoch # 5733 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006829955022112699
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:42,791 INFO epoch # 5734 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006664152158919023
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:42,809 INFO epoch # 5735 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006761775843187934
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:42,828 INFO epoch # 5736 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006843378156190738
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:42,847 INFO epoch # 5737 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006663494626991451
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:42,865 INFO epoch # 5738 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006638780319917714
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:42,883 INFO epoch # 5739 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006688037727144547
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:42,902 INFO epoch # 5740 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006682355815428309
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:42,902 INFO *** epoch 5740, rolling-avg-loss (window=10)= 0.006780508203519275
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:42,920 INFO epoch # 5741 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006628671348153148
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:42,938 INFO epoch # 5742 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006652549058344448
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:42,957 INFO epoch # 5743 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006811817285779398
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:42,975 INFO epoch # 5744 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006667704277788289
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:42,993 INFO epoch # 5745 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006661411036475329
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:43,012 INFO epoch # 5746 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006728331616614014
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:43,030 INFO epoch # 5747 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006686177141091321
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:43,049 INFO epoch # 5748 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006689662681310438
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:43,067 INFO epoch # 5749 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006665188528131694
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:43,086 INFO epoch # 5750 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006673650110315066
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:43,086 INFO *** epoch 5750, rolling-avg-loss (window=10)= 0.006686516308400314
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:43,104 INFO epoch # 5751 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006653133812505985
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:43,123 INFO epoch # 5752 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0066484015915193595
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:43,141 INFO epoch # 5753 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006639764855208341
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:43,159 INFO epoch # 5754 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006761124255717732
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:43,177 INFO epoch # 5755 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006643755397817586
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:43,195 INFO epoch # 5756 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006632088359765476
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:43,214 INFO epoch # 5757 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006665272056125104
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:43,232 INFO epoch # 5758 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006654140983300749
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:43,251 INFO epoch # 5759 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0066375788519508205
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:43,269 INFO epoch # 5760 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006677758123259991
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:43,269 INFO *** epoch 5760, rolling-avg-loss (window=10)= 0.006661301828717115
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:43,288 INFO epoch # 5761 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0066206214050907874
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:43,306 INFO epoch # 5762 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006694230789435096
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:43,325 INFO epoch # 5763 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006626425714785
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:43,344 INFO epoch # 5764 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006618814604735235
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:43,362 INFO epoch # 5765 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00663356691802619
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:43,380 INFO epoch # 5766 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006650171493674861
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:43,399 INFO epoch # 5767 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006658415361016523
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:43,417 INFO epoch # 5768 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0066041324607795104
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:43,436 INFO epoch # 5769 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006650539882684825
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:43,454 INFO epoch # 5770 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006721890676999465
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:43,454 INFO *** epoch 5770, rolling-avg-loss (window=10)= 0.006647880930722749
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:43,473 INFO epoch # 5771 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006631848162214737
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:43,491 INFO epoch # 5772 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006721904392179567
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:43,509 INFO epoch # 5773 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006846709569799714
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:43,527 INFO epoch # 5774 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007043156365398318
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:43,546 INFO epoch # 5775 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0066430078841221984
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:43,564 INFO epoch # 5776 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006628946150158299
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:43,582 INFO epoch # 5777 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006631489406572655
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:43,600 INFO epoch # 5778 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006642645057581831
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:43,619 INFO epoch # 5779 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006784046512620989
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:43,637 INFO epoch # 5780 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006807581768953241
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:43,637 INFO *** epoch 5780, rolling-avg-loss (window=10)= 0.006738133526960155
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:43,656 INFO epoch # 5781 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0066354989576211665
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:43,675 INFO epoch # 5782 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0066280920000281185
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:43,694 INFO epoch # 5783 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006628503520914819
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:43,713 INFO epoch # 5784 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00662491548791877
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:43,732 INFO epoch # 5785 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0066220918924955186
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:43,751 INFO epoch # 5786 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006798325473937439
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:43,770 INFO epoch # 5787 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006641940628469456
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:43,789 INFO epoch # 5788 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0066496393010311294
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:43,808 INFO epoch # 5789 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006695743551972555
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:43,826 INFO epoch # 5790 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006824261756264605
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:43,826 INFO *** epoch 5790, rolling-avg-loss (window=10)= 0.006674901257065357
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:43,845 INFO epoch # 5791 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006722034064296167
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:43,863 INFO epoch # 5792 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006658783146122005
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:43,881 INFO epoch # 5793 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006899275824252982
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:43,900 INFO epoch # 5794 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006647562928264961
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:43,918 INFO epoch # 5795 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0066340283083263785
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:43,936 INFO epoch # 5796 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0066633518727030605
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:43,955 INFO epoch # 5797 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006612612956814701
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:43,973 INFO epoch # 5798 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006641147781920154
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:43,991 INFO epoch # 5799 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006638365252001677
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:44,010 INFO epoch # 5800 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0066552479765960015
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:44,010 INFO *** epoch 5800, rolling-avg-loss (window=10)= 0.0066772410111298084
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:44,028 INFO epoch # 5801 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006703351926262258
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:44,047 INFO epoch # 5802 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006643365886702668
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:44,065 INFO epoch # 5803 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0067433989242999814
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:44,083 INFO epoch # 5804 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006651737479842268
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:44,101 INFO epoch # 5805 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00665704292623559
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:44,120 INFO epoch # 5806 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0066040221263392596
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:44,138 INFO epoch # 5807 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006622694672842044
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:44,156 INFO epoch # 5808 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00666241797443945
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:44,175 INFO epoch # 5809 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006627429567743093
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:44,193 INFO epoch # 5810 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0066321531412540935
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:44,193 INFO *** epoch 5810, rolling-avg-loss (window=10)= 0.00665476146259607
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:44,211 INFO epoch # 5811 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0066281959116167855
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:44,230 INFO epoch # 5812 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006627025595662417
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:44,248 INFO epoch # 5813 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0072088644446921535
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:44,266 INFO epoch # 5814 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006615407270146534
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:44,285 INFO epoch # 5815 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006749984622729244
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:44,303 INFO epoch # 5816 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006686458829790354
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:44,322 INFO epoch # 5817 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006626775342738256
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:44,340 INFO epoch # 5818 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0066352557951177005
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:44,358 INFO epoch # 5819 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006604240628803382
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:44,377 INFO epoch # 5820 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006715672305290354
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:44,377 INFO *** epoch 5820, rolling-avg-loss (window=10)= 0.006709788074658718
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:44,395 INFO epoch # 5821 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006749017178663053
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:44,413 INFO epoch # 5822 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006619097395741846
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:44,432 INFO epoch # 5823 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006653136148088379
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:44,450 INFO epoch # 5824 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006650012986938236
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:44,469 INFO epoch # 5825 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006626093840168323
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:44,487 INFO epoch # 5826 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006696379230561433
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:44,506 INFO epoch # 5827 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006608989957385347
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:44,524 INFO epoch # 5828 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00670630366585101
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:44,542 INFO epoch # 5829 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006684602005407214
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:44,561 INFO epoch # 5830 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00659365095452813
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:44,561 INFO *** epoch 5830, rolling-avg-loss (window=10)= 0.006658728336333297
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:44,579 INFO epoch # 5831 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006592560708668316
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:44,597 INFO epoch # 5832 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006642868986091344
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:44,615 INFO epoch # 5833 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006629074057855178
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:44,634 INFO epoch # 5834 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00662996839673724
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:44,652 INFO epoch # 5835 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006617903862206731
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:44,671 INFO epoch # 5836 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006588711263248115
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:44,690 INFO epoch # 5837 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006629636096477043
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:44,708 INFO epoch # 5838 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006617684906814247
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:44,726 INFO epoch # 5839 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006908887640747707
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:44,745 INFO epoch # 5840 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006634843499341514
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:44,745 INFO *** epoch 5840, rolling-avg-loss (window=10)= 0.006649213941818744
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:44,763 INFO epoch # 5841 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006623226126976078
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:44,781 INFO epoch # 5842 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006652945445239311
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:44,799 INFO epoch # 5843 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006686224642180605
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:44,818 INFO epoch # 5844 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006628341674513649
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:44,836 INFO epoch # 5845 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0066481870744610205
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:44,855 INFO epoch # 5846 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006657203030044911
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:44,873 INFO epoch # 5847 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006672228562820237
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:44,892 INFO epoch # 5848 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006596641040232498
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:44,910 INFO epoch # 5849 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006650171359069645
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:44,928 INFO epoch # 5850 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006596606643142877
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:44,928 INFO *** epoch 5850, rolling-avg-loss (window=10)= 0.006641177559868083
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:44,947 INFO epoch # 5851 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0066089268802898005
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:44,965 INFO epoch # 5852 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006704187813738827
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:44,983 INFO epoch # 5853 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006605950751691125
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:45,001 INFO epoch # 5854 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.008253950210928451
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:45,020 INFO epoch # 5855 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006990213991230121
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:45,038 INFO epoch # 5856 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006644527711614501
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:45,056 INFO epoch # 5857 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006598954561923165
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:45,075 INFO epoch # 5858 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006621755284868414
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:45,093 INFO epoch # 5859 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006596453244128497
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:45,112 INFO epoch # 5860 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006597662402782589
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:45,112 INFO *** epoch 5860, rolling-avg-loss (window=10)= 0.006822258285319549
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:45,131 INFO epoch # 5861 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00669649116389337
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:45,150 INFO epoch # 5862 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006721920399286319
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:45,168 INFO epoch # 5863 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006606602881220169
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:45,186 INFO epoch # 5864 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00658737381490937
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:45,204 INFO epoch # 5865 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006634972440224374
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:45,223 INFO epoch # 5866 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006599638472835068
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:45,241 INFO epoch # 5867 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00661277843391872
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:45,260 INFO epoch # 5868 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006702796243189368
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:45,278 INFO epoch # 5869 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0066030766793119255
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:45,297 INFO epoch # 5870 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0067290034421603195
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:45,297 INFO *** epoch 5870, rolling-avg-loss (window=10)= 0.006649465397094901
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:45,315 INFO epoch # 5871 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006619078420044389
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:45,334 INFO epoch # 5872 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006657861755229533
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:45,352 INFO epoch # 5873 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006639340670517413
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:45,370 INFO epoch # 5874 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006787255158997141
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:45,388 INFO epoch # 5875 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006606467319215881
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:45,406 INFO epoch # 5876 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006609559008211363
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:45,425 INFO epoch # 5877 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006599437336262781
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:45,443 INFO epoch # 5878 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006581898596778046
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:45,461 INFO epoch # 5879 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006578251934115542
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:45,480 INFO epoch # 5880 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006586636864085449
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:45,480 INFO *** epoch 5880, rolling-avg-loss (window=10)= 0.006626578706345754
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:45,498 INFO epoch # 5881 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0065698732414603
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:45,516 INFO epoch # 5882 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006648677557677729
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:45,535 INFO epoch # 5883 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006608929616049863
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:45,553 INFO epoch # 5884 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006763752971892245
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:45,571 INFO epoch # 5885 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006675398428342305
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:45,589 INFO epoch # 5886 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006572245165443746
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:45,607 INFO epoch # 5887 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006642668129643425
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:45,626 INFO epoch # 5888 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006758505034667905
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:45,644 INFO epoch # 5889 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006825691601989092
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:45,663 INFO epoch # 5890 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006710323992592748
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:45,663 INFO *** epoch 5890, rolling-avg-loss (window=10)= 0.006677606573975936
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:45,681 INFO epoch # 5891 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006603321086004144
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:45,699 INFO epoch # 5892 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006596102844923735
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:45,718 INFO epoch # 5893 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006625914844335057
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:45,736 INFO epoch # 5894 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0066181189540657215
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:45,754 INFO epoch # 5895 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006588675038074143
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:45,773 INFO epoch # 5896 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006612877499719616
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:45,791 INFO epoch # 5897 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0068571413758036215
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:45,809 INFO epoch # 5898 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0066808611336455215
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:45,827 INFO epoch # 5899 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006610764256038237
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:45,846 INFO epoch # 5900 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0066064315105904825
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:45,846 INFO *** epoch 5900, rolling-avg-loss (window=10)= 0.006640020854320028
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:45,864 INFO epoch # 5901 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0066097802300646435
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:45,883 INFO epoch # 5902 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006776932394132018
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:45,901 INFO epoch # 5903 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006602888031920884
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:45,920 INFO epoch # 5904 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006626138678257121
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:45,938 INFO epoch # 5905 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006616731068788795
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:45,956 INFO epoch # 5906 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006682226510747569
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:45,975 INFO epoch # 5907 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006580359127838165
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:45,993 INFO epoch # 5908 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006701507707475685
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:46,011 INFO epoch # 5909 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007029391596006462
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:46,029 INFO epoch # 5910 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006570453393578646
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:46,029 INFO *** epoch 5910, rolling-avg-loss (window=10)= 0.0066796408738809985
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:46,048 INFO epoch # 5911 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006596023798920214
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:46,066 INFO epoch # 5912 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006639877894485835
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:46,085 INFO epoch # 5913 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006580915021913825
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:46,103 INFO epoch # 5914 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006583276433957508
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:46,122 INFO epoch # 5915 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0065772707894211635
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:46,140 INFO epoch # 5916 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.009911406894389074
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:46,158 INFO epoch # 5917 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006776451358746272
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:46,177 INFO epoch # 5918 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006640604136919137
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:46,195 INFO epoch # 5919 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006576737821887946
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:46,213 INFO epoch # 5920 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006619046933337813
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:46,213 INFO *** epoch 5920, rolling-avg-loss (window=10)= 0.006950161108397879
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:46,231 INFO epoch # 5921 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006586938434338663
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:46,250 INFO epoch # 5922 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006601617129490478
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:46,268 INFO epoch # 5923 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006914580837474205
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:46,287 INFO epoch # 5924 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0066697808433673345
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:46,306 INFO epoch # 5925 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.008766803934122436
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:46,325 INFO epoch # 5926 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0066813833655032795
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:46,344 INFO epoch # 5927 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006613447185372934
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:46,362 INFO epoch # 5928 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006605386752198683
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:46,380 INFO epoch # 5929 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006611354296182981
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:46,399 INFO epoch # 5930 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006582919148058863
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:46,399 INFO *** epoch 5930, rolling-avg-loss (window=10)= 0.006863421192610986
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:46,417 INFO epoch # 5931 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00661219021276338
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:46,435 INFO epoch # 5932 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.008783361816313118
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:46,453 INFO epoch # 5933 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006644283181231003
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:46,472 INFO epoch # 5934 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006565829815372126
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:46,490 INFO epoch # 5935 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006925885048985947
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:46,508 INFO epoch # 5936 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006569303415744798
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:46,527 INFO epoch # 5937 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0066015136981150135
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:46,545 INFO epoch # 5938 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006767261995264562
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:46,563 INFO epoch # 5939 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006577460255357437
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:46,582 INFO epoch # 5940 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006551781661983114
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:46,582 INFO *** epoch 5940, rolling-avg-loss (window=10)= 0.00685988711011305
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:46,600 INFO epoch # 5941 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006644808341661701
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:46,618 INFO epoch # 5942 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0067490835172066
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:46,636 INFO epoch # 5943 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006703791797917802
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:46,655 INFO epoch # 5944 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00656448947302124
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:46,673 INFO epoch # 5945 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0066286427827435546
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:46,692 INFO epoch # 5946 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006574257531610783
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:46,710 INFO epoch # 5947 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006610419732169248
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:46,728 INFO epoch # 5948 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006637461679929402
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:46,747 INFO epoch # 5949 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006557622578839073
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:46,765 INFO epoch # 5950 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006577772004675353
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:46,766 INFO *** epoch 5950, rolling-avg-loss (window=10)= 0.006624834943977476
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:46,784 INFO epoch # 5951 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006557905433510314
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:46,802 INFO epoch # 5952 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006599902320886031
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:46,820 INFO epoch # 5953 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006568799624801613
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:46,838 INFO epoch # 5954 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006580688288522651
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:46,857 INFO epoch # 5955 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00659371499568806
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:46,875 INFO epoch # 5956 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.008234760785853723
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:46,893 INFO epoch # 5957 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006660562812612625
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:46,912 INFO epoch # 5958 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006573309565283125
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:46,930 INFO epoch # 5959 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0066291822149651125
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:46,948 INFO epoch # 5960 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006573315447894856
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:46,949 INFO *** epoch 5960, rolling-avg-loss (window=10)= 0.006757214149001811
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:46,967 INFO epoch # 5961 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006575171995791607
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:46,985 INFO epoch # 5962 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0066228273790329695
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:47,003 INFO epoch # 5963 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006565771149325883
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:47,021 INFO epoch # 5964 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00660812985006487
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:47,040 INFO epoch # 5965 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006636828962655272
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:47,058 INFO epoch # 5966 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006590112952835625
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:47,076 INFO epoch # 5967 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0066055155111826025
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:47,094 INFO epoch # 5968 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0066066891376976855
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:47,113 INFO epoch # 5969 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007119931477063801
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:47,131 INFO epoch # 5970 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00656414431068697
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:47,131 INFO *** epoch 5970, rolling-avg-loss (window=10)= 0.006649512272633729
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:47,150 INFO epoch # 5971 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006710904686769936
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:47,168 INFO epoch # 5972 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006609417156141717
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:47,186 INFO epoch # 5973 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0068594189287978224
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:47,204 INFO epoch # 5974 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006593824269657489
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:47,222 INFO epoch # 5975 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006584622500668047
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:47,241 INFO epoch # 5976 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006660727733105887
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:47,259 INFO epoch # 5977 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006568533823156031
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:47,277 INFO epoch # 5978 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006598277541343123
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:47,296 INFO epoch # 5979 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006575497791345697
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:47,314 INFO epoch # 5980 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006581149442354217
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:47,314 INFO *** epoch 5980, rolling-avg-loss (window=10)= 0.006634237387333997
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:47,333 INFO epoch # 5981 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006609094172745245
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:47,351 INFO epoch # 5982 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006799127670092275
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:47,370 INFO epoch # 5983 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006599545475182822
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:47,388 INFO epoch # 5984 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0065542580450710375
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:47,406 INFO epoch # 5985 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006886343649966875
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:47,424 INFO epoch # 5986 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006715596064168494
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:47,443 INFO epoch # 5987 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0066348134096188005
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:47,461 INFO epoch # 5988 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0069003885037091095
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:47,479 INFO epoch # 5989 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00667623548724805
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:47,498 INFO epoch # 5990 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00660344872449059
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:47,498 INFO *** epoch 5990, rolling-avg-loss (window=10)= 0.00669788512022933
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:47,516 INFO epoch # 5991 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0066720419308694545
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:47,534 INFO epoch # 5992 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006545481097418815
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:47,553 INFO epoch # 5993 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006702951959596248
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:47,571 INFO epoch # 5994 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00658755609401851
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:47,589 INFO epoch # 5995 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00656181908925646
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:47,608 INFO epoch # 5996 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006577902182471007
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:47,626 INFO epoch # 5997 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00672968555954867
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:47,644 INFO epoch # 5998 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006566388052306138
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:47,663 INFO epoch # 5999 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00678481768045458
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:47,681 INFO epoch # 6000 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00663400290068239
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:47,681 INFO *** epoch 6000, rolling-avg-loss (window=10)= 0.006636264654662227
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:47,699 INFO epoch # 6001 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006590449396753684
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:47,718 INFO epoch # 6002 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006581451143574668
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:47,736 INFO epoch # 6003 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006584499991731718
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:47,754 INFO epoch # 6004 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00662382425434771
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:47,772 INFO epoch # 6005 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006585806688235607
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:47,791 INFO epoch # 6006 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006551232578203781
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:47,809 INFO epoch # 6007 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006591554083570372
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:47,827 INFO epoch # 6008 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006544425756146666
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:47,845 INFO epoch # 6009 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006586019400856458
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:47,864 INFO epoch # 6010 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006558509423484793
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:47,864 INFO *** epoch 6010, rolling-avg-loss (window=10)= 0.006579777271690545
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:47,882 INFO epoch # 6011 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006644554323429475
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:47,901 INFO epoch # 6012 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0065462007296446245
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:47,919 INFO epoch # 6013 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0066635089460760355
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:47,937 INFO epoch # 6014 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006603709527553292
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:47,956 INFO epoch # 6015 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00660004462042707
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:47,974 INFO epoch # 6016 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006542313782119891
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:47,992 INFO epoch # 6017 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0066474263658165
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:48,010 INFO epoch # 6018 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006969545051106252
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:48,029 INFO epoch # 6019 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006579602795682149
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:48,047 INFO epoch # 6020 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006941809991985792
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:48,047 INFO *** epoch 6020, rolling-avg-loss (window=10)= 0.006673871613384108
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:48,065 INFO epoch # 6021 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006542991073729354
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:48,084 INFO epoch # 6022 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006611564564082073
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:48,102 INFO epoch # 6023 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006553837763931369
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:48,121 INFO epoch # 6024 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006566344356542686
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:48,139 INFO epoch # 6025 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.009857959248620318
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:48,158 INFO epoch # 6026 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006577519492566353
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:48,176 INFO epoch # 6027 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00653156009138911
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:48,194 INFO epoch # 6028 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006574303395609604
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:48,212 INFO epoch # 6029 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00652868879478774
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:48,231 INFO epoch # 6030 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006546121854626108
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:48,231 INFO *** epoch 6030, rolling-avg-loss (window=10)= 0.0068890890635884714
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:48,249 INFO epoch # 6031 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006944657972780988
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:48,267 INFO epoch # 6032 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006592752371943789
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:48,286 INFO epoch # 6033 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006625335907301633
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:48,304 INFO epoch # 6034 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006618586481636157
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:48,323 INFO epoch # 6035 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006546475124196149
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:48,341 INFO epoch # 6036 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006573568418389186
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:48,359 INFO epoch # 6037 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006590037475689314
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:48,378 INFO epoch # 6038 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006573015900357859
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:48,396 INFO epoch # 6039 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006560234302014578
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:48,414 INFO epoch # 6040 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00661816281353822
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:48,415 INFO *** epoch 6040, rolling-avg-loss (window=10)= 0.0066242826767847875
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:48,433 INFO epoch # 6041 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00654919863154646
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:48,451 INFO epoch # 6042 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006579077402420808
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:48,469 INFO epoch # 6043 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006594174181373091
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:48,488 INFO epoch # 6044 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006542865212395554
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:48,506 INFO epoch # 6045 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006607727318623802
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:48,525 INFO epoch # 6046 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0065200118588109035
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:48,543 INFO epoch # 6047 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006618789699132321
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:48,562 INFO epoch # 6048 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006661913779680617
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:48,580 INFO epoch # 6049 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006819105255999602
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:48,598 INFO epoch # 6050 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006537658446177375
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:48,598 INFO *** epoch 6050, rolling-avg-loss (window=10)= 0.006603052178616053
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:48,617 INFO epoch # 6051 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00655567345165764
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:48,635 INFO epoch # 6052 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006518128770039766
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:48,653 INFO epoch # 6053 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0065232307233600295
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:48,672 INFO epoch # 6054 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0065837965485116
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:48,690 INFO epoch # 6055 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0065378951803722885
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:48,709 INFO epoch # 6056 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006605747286812402
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:48,727 INFO epoch # 6057 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006702678179863142
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:48,746 INFO epoch # 6058 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006558205248438753
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:48,764 INFO epoch # 6059 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006571891964995302
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:48,782 INFO epoch # 6060 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00652751528105
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:48,782 INFO *** epoch 6060, rolling-avg-loss (window=10)= 0.006568476263510092
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:48,800 INFO epoch # 6061 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.009869975645415252
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:48,819 INFO epoch # 6062 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006904646044858964
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:48,837 INFO epoch # 6063 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0065649894895614125
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:48,855 INFO epoch # 6064 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006529871934617404
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:48,874 INFO epoch # 6065 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006516949433716945
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:48,892 INFO epoch # 6066 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00983523104514461
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:48,910 INFO epoch # 6067 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006698530603898689
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:48,929 INFO epoch # 6068 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006576481326192152
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:48,947 INFO epoch # 6069 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0065387292925152
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:48,965 INFO epoch # 6070 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006537308534461772
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:48,966 INFO *** epoch 6070, rolling-avg-loss (window=10)= 0.00725727133503824
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:48,984 INFO epoch # 6071 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006763320219761226
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:49,002 INFO epoch # 6072 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006550243924721144
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:49,020 INFO epoch # 6073 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006662315438006772
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:49,039 INFO epoch # 6074 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006510548162623309
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:49,057 INFO epoch # 6075 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006590320273971884
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:49,076 INFO epoch # 6076 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006632734355662251
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:49,095 INFO epoch # 6077 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006537099219713127
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:49,113 INFO epoch # 6078 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006566186355485115
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:49,132 INFO epoch # 6079 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006522012292407453
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:49,150 INFO epoch # 6080 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0065415598146501
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:49,150 INFO *** epoch 6080, rolling-avg-loss (window=10)= 0.006587634005700238
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:49,169 INFO epoch # 6081 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0065885018157132436
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:49,187 INFO epoch # 6082 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006556945325428387
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:49,205 INFO epoch # 6083 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006839927616965724
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:49,223 INFO epoch # 6084 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006738704389135819
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:49,242 INFO epoch # 6085 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007105543088982813
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:49,260 INFO epoch # 6086 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006929414976184489
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:49,278 INFO epoch # 6087 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0065352286692359485
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:49,297 INFO epoch # 6088 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007114524436474312
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:49,315 INFO epoch # 6089 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006587138352188049
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:49,334 INFO epoch # 6090 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006520384133182233
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:49,334 INFO *** epoch 6090, rolling-avg-loss (window=10)= 0.006751631280349102
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:49,352 INFO epoch # 6091 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006514924854855053
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:49,371 INFO epoch # 6092 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006503451813841821
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:49,390 INFO epoch # 6093 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006521934697957477
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:49,408 INFO epoch # 6094 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006537484747241251
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:49,427 INFO epoch # 6095 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00654605753152282
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:49,445 INFO epoch # 6096 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006726698204147397
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:49,463 INFO epoch # 6097 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006983804258197779
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:49,481 INFO epoch # 6098 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006525141696329229
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:49,500 INFO epoch # 6099 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006549114732479211
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:49,519 INFO epoch # 6100 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006513094438560074
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:49,519 INFO *** epoch 6100, rolling-avg-loss (window=10)= 0.006592170697513211
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:49,537 INFO epoch # 6101 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006521281011373503
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:49,556 INFO epoch # 6102 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006529360092827119
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:49,574 INFO epoch # 6103 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006512936863146024
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:49,592 INFO epoch # 6104 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006598274198040599
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:49,610 INFO epoch # 6105 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006532645369588863
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:49,629 INFO epoch # 6106 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006549511901539518
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:49,647 INFO epoch # 6107 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006544620500790188
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:49,665 INFO epoch # 6108 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00654817061877111
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:49,683 INFO epoch # 6109 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006528762460220605
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:49,702 INFO epoch # 6110 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006527829169499455
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:49,702 INFO *** epoch 6110, rolling-avg-loss (window=10)= 0.0065393392185796985
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:49,720 INFO epoch # 6111 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006598194853722816
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:49,738 INFO epoch # 6112 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006512442785606254
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:49,757 INFO epoch # 6113 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006967067758523626
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:49,775 INFO epoch # 6114 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006517846992210252
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:49,793 INFO epoch # 6115 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006572925365617266
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:49,812 INFO epoch # 6116 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006696131174976472
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:49,830 INFO epoch # 6117 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0066453630570322275
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:49,848 INFO epoch # 6118 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006549057910888223
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:49,866 INFO epoch # 6119 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006522265768580837
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:49,884 INFO epoch # 6120 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0065594059888098855
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:49,885 INFO *** epoch 6120, rolling-avg-loss (window=10)= 0.006614070165596786
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:49,903 INFO epoch # 6121 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006507857771794079
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:49,921 INFO epoch # 6122 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0065153860978171
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:49,939 INFO epoch # 6123 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006543776409671409
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:49,958 INFO epoch # 6124 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0067049949648207985
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:49,976 INFO epoch # 6125 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006600537057238398
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:49,994 INFO epoch # 6126 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006569038403540617
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:50,013 INFO epoch # 6127 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006516091518278699
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:50,031 INFO epoch # 6128 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0065324729766871314
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:50,049 INFO epoch # 6129 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006587592892174143
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:50,067 INFO epoch # 6130 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006497112466604449
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:50,067 INFO *** epoch 6130, rolling-avg-loss (window=10)= 0.006557486055862682
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:50,086 INFO epoch # 6131 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006566992626176216
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:50,104 INFO epoch # 6132 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006585470371646807
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:50,123 INFO epoch # 6133 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006558371926075779
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:50,141 INFO epoch # 6134 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006526819212012924
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:50,160 INFO epoch # 6135 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006598385902179871
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:50,178 INFO epoch # 6136 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006547670236614067
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:50,197 INFO epoch # 6137 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0066362805337121245
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:50,215 INFO epoch # 6138 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006841301776148612
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:50,233 INFO epoch # 6139 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006556003085279372
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:50,251 INFO epoch # 6140 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006486374271844397
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:50,251 INFO *** epoch 6140, rolling-avg-loss (window=10)= 0.0065903669941690165
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:50,270 INFO epoch # 6141 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006539625359437196
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:50,288 INFO epoch # 6142 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006620358173677232
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:50,306 INFO epoch # 6143 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006527184617880266
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:50,325 INFO epoch # 6144 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006603961199289188
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:50,343 INFO epoch # 6145 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007084711764036911
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:50,362 INFO epoch # 6146 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006609360094444128
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:50,380 INFO epoch # 6147 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006478247913037194
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:50,399 INFO epoch # 6148 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006510163129860302
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:50,417 INFO epoch # 6149 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0065174132760148495
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:50,435 INFO epoch # 6150 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006739755430317018
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:50,436 INFO *** epoch 6150, rolling-avg-loss (window=10)= 0.006623078095799428
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:50,454 INFO epoch # 6151 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006560804322361946
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:50,472 INFO epoch # 6152 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006489152126960107
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:50,491 INFO epoch # 6153 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006514703785796883
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:50,509 INFO epoch # 6154 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0065413496777182445
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:50,528 INFO epoch # 6155 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.008685673750733258
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:50,546 INFO epoch # 6156 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006549165242176969
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:50,564 INFO epoch # 6157 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006533497296913993
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:50,583 INFO epoch # 6158 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006528175545099657
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:50,601 INFO epoch # 6159 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006638909257162595
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:50,619 INFO epoch # 6160 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0065316819891449995
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:50,619 INFO *** epoch 6160, rolling-avg-loss (window=10)= 0.006757311299406865
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:50,638 INFO epoch # 6161 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0065484519545861986
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:50,656 INFO epoch # 6162 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006490972433311981
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:50,674 INFO epoch # 6163 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0065677673410391435
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:50,692 INFO epoch # 6164 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006487261636721087
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:50,711 INFO epoch # 6165 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006481673261077958
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:50,729 INFO epoch # 6166 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006525463868456427
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:50,748 INFO epoch # 6167 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006605836882954463
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:50,766 INFO epoch # 6168 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006535532975249225
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:50,784 INFO epoch # 6169 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006561487349244999
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:50,803 INFO epoch # 6170 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006549147125042509
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:50,803 INFO *** epoch 6170, rolling-avg-loss (window=10)= 0.006535359482768399
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:50,821 INFO epoch # 6171 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006494955207017483
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:50,839 INFO epoch # 6172 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006494192508398555
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:50,857 INFO epoch # 6173 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006511036981464713
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:50,875 INFO epoch # 6174 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006491285392257851
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:50,894 INFO epoch # 6175 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006555781430506613
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:50,912 INFO epoch # 6176 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006517615493066842
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:50,930 INFO epoch # 6177 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006488534527306911
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:50,949 INFO epoch # 6178 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006525712276925333
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:50,968 INFO epoch # 6179 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006506147416075692
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:50,986 INFO epoch # 6180 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006468480098192231
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:50,986 INFO *** epoch 6180, rolling-avg-loss (window=10)= 0.006505374133121222
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:51,004 INFO epoch # 6181 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006497206522908527
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:51,022 INFO epoch # 6182 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006533375955768861
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:51,040 INFO epoch # 6183 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0064932635104923975
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:51,059 INFO epoch # 6184 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006777352304197848
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:51,077 INFO epoch # 6185 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006574540089786751
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:51,095 INFO epoch # 6186 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006517349804198602
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:51,114 INFO epoch # 6187 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006526082470372785
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:51,132 INFO epoch # 6188 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00648803108924767
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:51,150 INFO epoch # 6189 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006524901462398702
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:51,169 INFO epoch # 6190 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006644930155744078
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:51,169 INFO *** epoch 6190, rolling-avg-loss (window=10)= 0.006557703336511622
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:51,187 INFO epoch # 6191 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0065185144121642224
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:51,205 INFO epoch # 6192 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006526498305902351
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:51,224 INFO epoch # 6193 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00658391688921256
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:51,242 INFO epoch # 6194 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0064866508000704926
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:51,260 INFO epoch # 6195 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006510805247671669
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:51,278 INFO epoch # 6196 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0064915009861579165
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:51,297 INFO epoch # 6197 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006506946276203962
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:51,315 INFO epoch # 6198 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006523192947497591
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:51,333 INFO epoch # 6199 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006537833905895241
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:51,352 INFO epoch # 6200 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006483373701485107
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:51,352 INFO *** epoch 6200, rolling-avg-loss (window=10)= 0.0065169233472261116
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:51,371 INFO epoch # 6201 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0064968855476763565
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:51,389 INFO epoch # 6202 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006519835274957586
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:51,408 INFO epoch # 6203 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0065292801591567695
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:51,426 INFO epoch # 6204 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00649183302448364
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:51,444 INFO epoch # 6205 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006499409111711429
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:51,462 INFO epoch # 6206 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006479474279331043
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:51,480 INFO epoch # 6207 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006490289651992498
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:51,499 INFO epoch # 6208 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0065168149121745955
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:51,517 INFO epoch # 6209 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0065228652965743095
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:51,536 INFO epoch # 6210 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006535484360938426
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:51,536 INFO *** epoch 6210, rolling-avg-loss (window=10)= 0.006508217161899666
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:51,554 INFO epoch # 6211 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0065528126651770435
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:51,573 INFO epoch # 6212 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006564386061654659
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:51,592 INFO epoch # 6213 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006512026757263811
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:51,610 INFO epoch # 6214 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006515075827337569
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:51,629 INFO epoch # 6215 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0065794122201623395
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:51,647 INFO epoch # 6216 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006606092887523118
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:51,665 INFO epoch # 6217 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0064917048657662235
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:51,684 INFO epoch # 6218 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006492650780273834
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:51,702 INFO epoch # 6219 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006455258883761417
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:51,721 INFO epoch # 6220 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006851446916698478
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:51,721 INFO *** epoch 6220, rolling-avg-loss (window=10)= 0.0065620867865618495
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:51,739 INFO epoch # 6221 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006485965899628354
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:51,758 INFO epoch # 6222 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006526273387862602
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:51,776 INFO epoch # 6223 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006511893803690327
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:51,794 INFO epoch # 6224 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006466409908171045
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:51,812 INFO epoch # 6225 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006465776252298383
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:51,831 INFO epoch # 6226 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006487385424406966
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:51,849 INFO epoch # 6227 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007005771767580882
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:51,867 INFO epoch # 6228 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0064878783923632
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:51,885 INFO epoch # 6229 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00653629668886424
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:51,904 INFO epoch # 6230 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006495574785731151
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:51,904 INFO *** epoch 6230, rolling-avg-loss (window=10)= 0.006546922631059715
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:51,922 INFO epoch # 6231 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006464330872404389
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:51,941 INFO epoch # 6232 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00654769502216368
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:51,959 INFO epoch # 6233 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0069164894048299175
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:51,978 INFO epoch # 6234 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006656856476183748
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:51,996 INFO epoch # 6235 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00651495151760173
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:52,014 INFO epoch # 6236 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006809692164097214
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:52,032 INFO epoch # 6237 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00664020727344905
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:52,051 INFO epoch # 6238 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006494989182101563
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:52,069 INFO epoch # 6239 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006525691132992506
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:52,087 INFO epoch # 6240 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00646053823584225
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:52,087 INFO *** epoch 6240, rolling-avg-loss (window=10)= 0.006603144128166605
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:52,105 INFO epoch # 6241 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0065543326672923286
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:52,124 INFO epoch # 6242 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006475384456280153
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:52,144 INFO epoch # 6243 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006781558426155243
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:52,162 INFO epoch # 6244 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006490339215815766
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:52,181 INFO epoch # 6245 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006468822040915256
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:52,199 INFO epoch # 6246 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006481815082224784
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:52,217 INFO epoch # 6247 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006552558435942046
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:52,236 INFO epoch # 6248 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0064818968712643255
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:52,254 INFO epoch # 6249 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006474195412010886
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:52,272 INFO epoch # 6250 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00655546192501788
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:52,272 INFO *** epoch 6250, rolling-avg-loss (window=10)= 0.006531636453291867
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:52,290 INFO epoch # 6251 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006444284103054088
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:52,309 INFO epoch # 6252 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006511736002721591
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:52,327 INFO epoch # 6253 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006561765167134581
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:52,345 INFO epoch # 6254 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006583959995623445
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:52,364 INFO epoch # 6255 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006524781660118606
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:52,382 INFO epoch # 6256 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0064888560118561145
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:52,400 INFO epoch # 6257 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006571363330294844
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:52,419 INFO epoch # 6258 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006491584899777081
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:52,437 INFO epoch # 6259 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006461167784436839
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:52,455 INFO epoch # 6260 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006494936991657596
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:52,455 INFO *** epoch 6260, rolling-avg-loss (window=10)= 0.006513443594667478
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:52,474 INFO epoch # 6261 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006537819430377567
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:52,492 INFO epoch # 6262 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006562175225553801
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:52,510 INFO epoch # 6263 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006469702158938162
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:52,529 INFO epoch # 6264 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006474700472608674
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:52,547 INFO epoch # 6265 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006448927870223997
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:52,566 INFO epoch # 6266 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006502173338958528
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:52,584 INFO epoch # 6267 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00648967059169081
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:52,603 INFO epoch # 6268 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0065056159546657
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:52,621 INFO epoch # 6269 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006461712830059696
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:52,639 INFO epoch # 6270 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006516633697174257
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:52,639 INFO *** epoch 6270, rolling-avg-loss (window=10)= 0.0064969131570251195
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:52,658 INFO epoch # 6271 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006474191271991003
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:52,676 INFO epoch # 6272 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006507943364340463
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:52,694 INFO epoch # 6273 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0065324482529831585
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:52,713 INFO epoch # 6274 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006496451220300514
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:52,731 INFO epoch # 6275 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.008058925548539264
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:52,750 INFO epoch # 6276 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006490612733614398
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:52,769 INFO epoch # 6277 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006510125152999535
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:52,787 INFO epoch # 6278 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006492319291282911
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:52,806 INFO epoch # 6279 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007013839611317962
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:52,824 INFO epoch # 6280 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006520970589917852
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:52,824 INFO *** epoch 6280, rolling-avg-loss (window=10)= 0.0067097827037287065
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:52,842 INFO epoch # 6281 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006647056481597247
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:52,860 INFO epoch # 6282 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006571483289008029
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:52,879 INFO epoch # 6283 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006483347075118218
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:52,897 INFO epoch # 6284 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006607293078559451
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:52,915 INFO epoch # 6285 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006465236252552131
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:52,934 INFO epoch # 6286 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.01002674994742847
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:52,952 INFO epoch # 6287 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006498365215520607
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:52,971 INFO epoch # 6288 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0064581990882288665
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:52,989 INFO epoch # 6289 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006501689640572295
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:53,007 INFO epoch # 6290 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006580846362339798
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:53,007 INFO *** epoch 6290, rolling-avg-loss (window=10)= 0.006884026643092511
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:53,026 INFO epoch # 6291 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006458081345044775
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:53,044 INFO epoch # 6292 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007086392834025901
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:53,062 INFO epoch # 6293 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006500446146674221
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:53,081 INFO epoch # 6294 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006463819729106035
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:53,099 INFO epoch # 6295 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006545350144733675
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:53,118 INFO epoch # 6296 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.008668522885272978
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:53,137 INFO epoch # 6297 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006496237223473145
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:53,156 INFO epoch # 6298 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006491090713097947
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:53,174 INFO epoch # 6299 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006446014307584846
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:53,193 INFO epoch # 6300 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006448434774938505
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:53,193 INFO *** epoch 6300, rolling-avg-loss (window=10)= 0.006760439010395203
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:53,211 INFO epoch # 6301 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006471114062151173
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:53,230 INFO epoch # 6302 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006467024806624977
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:53,248 INFO epoch # 6303 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006557133183378028
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:53,266 INFO epoch # 6304 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0066425909208192024
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:53,284 INFO epoch # 6305 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006628886574617354
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:53,303 INFO epoch # 6306 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006479166167991934
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:53,321 INFO epoch # 6307 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006440195058530662
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:53,340 INFO epoch # 6308 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006508687954919878
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:53,358 INFO epoch # 6309 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006901108099555131
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:53,377 INFO epoch # 6310 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006442861435061786
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:53,377 INFO *** epoch 6310, rolling-avg-loss (window=10)= 0.006553876826365013
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:53,395 INFO epoch # 6311 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006458661282522371
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:53,413 INFO epoch # 6312 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006476787988503929
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:53,432 INFO epoch # 6313 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006465940707130358
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:53,450 INFO epoch # 6314 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006475547514128266
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:53,468 INFO epoch # 6315 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0065448411005490925
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:53,487 INFO epoch # 6316 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006472835313616088
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:53,505 INFO epoch # 6317 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006467063729360234
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:53,523 INFO epoch # 6318 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0064446043797943275
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:53,541 INFO epoch # 6319 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006482514727395028
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:53,560 INFO epoch # 6320 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006491156505944673
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:53,560 INFO *** epoch 6320, rolling-avg-loss (window=10)= 0.006477995324894436
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:53,578 INFO epoch # 6321 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0064697284396970645
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:53,597 INFO epoch # 6322 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006554285308084218
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:53,615 INFO epoch # 6323 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006484263336460572
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:53,634 INFO epoch # 6324 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006465674443461467
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:53,652 INFO epoch # 6325 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0064587262422719505
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:53,670 INFO epoch # 6326 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006456740982685005
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:53,688 INFO epoch # 6327 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006451963752624579
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:53,706 INFO epoch # 6328 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006449270993471146
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:53,725 INFO epoch # 6329 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0068484489420370664
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:53,743 INFO epoch # 6330 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006638685234065633
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:53,743 INFO *** epoch 6330, rolling-avg-loss (window=10)= 0.00652777876748587
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:53,761 INFO epoch # 6331 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006481308224465465
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:53,780 INFO epoch # 6332 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0064758760563563555
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:53,798 INFO epoch # 6333 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006487175742222462
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:53,817 INFO epoch # 6334 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0067990437582921
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:53,835 INFO epoch # 6335 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006550869165948825
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:53,853 INFO epoch # 6336 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006437442069000099
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:53,871 INFO epoch # 6337 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0064228658402498695
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:53,889 INFO epoch # 6338 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006831213126133662
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:53,908 INFO epoch # 6339 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006459880798502127
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:53,926 INFO epoch # 6340 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006459986445406685
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:53,926 INFO *** epoch 6340, rolling-avg-loss (window=10)= 0.006540566122657765
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:53,944 INFO epoch # 6341 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00643951294478029
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:53,963 INFO epoch # 6342 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006616229671635665
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:53,981 INFO epoch # 6343 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006423921160603641
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:54,000 INFO epoch # 6344 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006505148914584424
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:54,018 INFO epoch # 6345 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006457871331804199
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:54,036 INFO epoch # 6346 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006522988107462879
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:54,055 INFO epoch # 6347 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.009208577263052575
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:54,073 INFO epoch # 6348 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006518323567433981
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:54,091 INFO epoch # 6349 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0064311002224712865
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:54,109 INFO epoch # 6350 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006465039525210159
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:54,109 INFO *** epoch 6350, rolling-avg-loss (window=10)= 0.00675887127090391
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:54,128 INFO epoch # 6351 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006496952773886733
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:54,147 INFO epoch # 6352 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006437786501919618
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:54,165 INFO epoch # 6353 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006478598395915469
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:54,183 INFO epoch # 6354 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006506828354758909
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:54,202 INFO epoch # 6355 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0064499126965529285
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:54,220 INFO epoch # 6356 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006429614695662167
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:54,238 INFO epoch # 6357 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0065185189378098585
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:54,256 INFO epoch # 6358 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006452284796978347
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:54,275 INFO epoch # 6359 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006517999227071414
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:54,293 INFO epoch # 6360 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006493384051282192
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:54,293 INFO *** epoch 6360, rolling-avg-loss (window=10)= 0.006478188043183763
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:54,311 INFO epoch # 6361 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006653065796854207
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:54,329 INFO epoch # 6362 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006870133620395791
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:54,348 INFO epoch # 6363 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00642783745934139
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:54,366 INFO epoch # 6364 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0064595917938277125
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:54,385 INFO epoch # 6365 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0066819587591453455
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:54,403 INFO epoch # 6366 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006905223275680328
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:54,421 INFO epoch # 6367 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006471876797149889
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:54,440 INFO epoch # 6368 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006706391472107498
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:54,458 INFO epoch # 6369 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00647054756336729
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:54,476 INFO epoch # 6370 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006438138512748992
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:54,476 INFO *** epoch 6370, rolling-avg-loss (window=10)= 0.006608476505061844
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:54,495 INFO epoch # 6371 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0064386709018435795
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:54,513 INFO epoch # 6372 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006458683586970437
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:54,531 INFO epoch # 6373 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006472592409409117
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:54,550 INFO epoch # 6374 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0065498654439579695
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:54,568 INFO epoch # 6375 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006425918274544529
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:54,587 INFO epoch # 6376 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006454181588196661
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:54,605 INFO epoch # 6377 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006485988666099729
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:54,623 INFO epoch # 6378 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.009697091816633474
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:54,642 INFO epoch # 6379 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00649557491124142
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:54,660 INFO epoch # 6380 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006464230154961115
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:54,660 INFO *** epoch 6380, rolling-avg-loss (window=10)= 0.006794279775385803
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:54,678 INFO epoch # 6381 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006526845885673538
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:54,696 INFO epoch # 6382 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0064245618450513575
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:54,715 INFO epoch # 6383 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006579041299119126
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:54,733 INFO epoch # 6384 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006938443089893553
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:54,751 INFO epoch # 6385 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006536954213515855
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:54,770 INFO epoch # 6386 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006451689670939231
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:54,788 INFO epoch # 6387 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006513893480587285
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:54,807 INFO epoch # 6388 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006424681683711242
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:54,825 INFO epoch # 6389 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006416741252905922
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:54,843 INFO epoch # 6390 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006460047898144694
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:54,844 INFO *** epoch 6390, rolling-avg-loss (window=10)= 0.0065272900319541804
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:54,862 INFO epoch # 6391 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006427262400393374
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:54,880 INFO epoch # 6392 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006441692341468297
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:54,898 INFO epoch # 6393 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006558527420565952
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:54,916 INFO epoch # 6394 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006556614433065988
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:54,935 INFO epoch # 6395 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006469858548371121
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:54,953 INFO epoch # 6396 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0065495343078509904
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:54,972 INFO epoch # 6397 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006593785452423617
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:54,990 INFO epoch # 6398 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00659760262715281
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:55,008 INFO epoch # 6399 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006499599548988044
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:55,027 INFO epoch # 6400 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006438337120926008
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:55,027 INFO *** epoch 6400, rolling-avg-loss (window=10)= 0.00651328142012062
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:55,045 INFO epoch # 6401 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006514733511721715
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:55,063 INFO epoch # 6402 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0065227487320953514
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:55,082 INFO epoch # 6403 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006493035638413858
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:55,100 INFO epoch # 6404 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006510003775474615
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:55,118 INFO epoch # 6405 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006468238581874175
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:55,137 INFO epoch # 6406 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006527859059133334
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:55,156 INFO epoch # 6407 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007998852714081295
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:55,174 INFO epoch # 6408 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006434500479372218
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:55,193 INFO epoch # 6409 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006546081516717095
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:55,212 INFO epoch # 6410 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006573635197128169
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:55,212 INFO *** epoch 6410, rolling-avg-loss (window=10)= 0.0066589689206011824
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:55,231 INFO epoch # 6411 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006438001750211697
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:55,249 INFO epoch # 6412 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006460680560849141
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:55,268 INFO epoch # 6413 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006424450206395704
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:55,286 INFO epoch # 6414 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006465099981141975
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:55,304 INFO epoch # 6415 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006471773020166438
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:55,322 INFO epoch # 6416 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006420611331122927
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:55,341 INFO epoch # 6417 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006555017847858835
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:55,359 INFO epoch # 6418 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006453862435591873
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:55,378 INFO epoch # 6419 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006410826372302836
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:55,397 INFO epoch # 6420 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0064097860631591175
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:55,397 INFO *** epoch 6420, rolling-avg-loss (window=10)= 0.0064510109568800544
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:55,416 INFO epoch # 6421 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006467215196607867
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:55,434 INFO epoch # 6422 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006992588820139645
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:55,452 INFO epoch # 6423 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006430437690141844
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:55,471 INFO epoch # 6424 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006449074600823224
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:55,489 INFO epoch # 6425 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0064509067160543054
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:55,507 INFO epoch # 6426 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006509164104500087
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:55,525 INFO epoch # 6427 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006444914342864649
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:55,544 INFO epoch # 6428 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006481136966613121
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:55,562 INFO epoch # 6429 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006556488682690542
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:55,581 INFO epoch # 6430 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006851962800283218
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:55,581 INFO *** epoch 6430, rolling-avg-loss (window=10)= 0.00656338899207185
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:55,599 INFO epoch # 6431 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006515107208542759
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:55,618 INFO epoch # 6432 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006406565855286317
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:55,636 INFO epoch # 6433 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006491773881862173
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:55,654 INFO epoch # 6434 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006410661590052769
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:55,673 INFO epoch # 6435 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006892882229294628
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:55,691 INFO epoch # 6436 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006666755933110835
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:55,709 INFO epoch # 6437 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006445082908612676
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:55,727 INFO epoch # 6438 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006475940273958258
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:55,746 INFO epoch # 6439 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006539955276821274
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:55,764 INFO epoch # 6440 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006487654329248471
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:55,764 INFO *** epoch 6440, rolling-avg-loss (window=10)= 0.006533237948679016
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:55,783 INFO epoch # 6441 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006416607782739447
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:55,801 INFO epoch # 6442 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006453575693740277
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:55,820 INFO epoch # 6443 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006474331305071246
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:55,838 INFO epoch # 6444 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006954356485948665
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:55,856 INFO epoch # 6445 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0065360016633349005
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:55,875 INFO epoch # 6446 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006437983349314891
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:55,893 INFO epoch # 6447 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006396050739567727
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:55,911 INFO epoch # 6448 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006427001404517796
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:55,929 INFO epoch # 6449 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006468788473284803
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:55,948 INFO epoch # 6450 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006509751543489983
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:55,948 INFO *** epoch 6450, rolling-avg-loss (window=10)= 0.006507444844100973
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:55,966 INFO epoch # 6451 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006460525699367281
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:55,985 INFO epoch # 6452 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006413340230210451
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:56,003 INFO epoch # 6453 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00642599390266696
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:56,022 INFO epoch # 6454 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006427657677704701
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:56,041 INFO epoch # 6455 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006424471695936518
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:56,059 INFO epoch # 6456 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006438358082959894
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:56,077 INFO epoch # 6457 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00653474581122282
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:56,095 INFO epoch # 6458 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006426398529583821
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:56,114 INFO epoch # 6459 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006571776397322537
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:56,132 INFO epoch # 6460 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006604784521186957
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:56,132 INFO *** epoch 6460, rolling-avg-loss (window=10)= 0.006472805254816194
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:56,150 INFO epoch # 6461 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006748355390300276
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:56,169 INFO epoch # 6462 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006396417174983071
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:56,187 INFO epoch # 6463 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006496942965895869
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:56,205 INFO epoch # 6464 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006505923054646701
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:56,224 INFO epoch # 6465 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006386077734532591
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:56,242 INFO epoch # 6466 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006431978563341545
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:56,260 INFO epoch # 6467 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006611598004383268
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:56,279 INFO epoch # 6468 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0064962917858792935
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:56,297 INFO epoch # 6469 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0064079984185809735
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:56,315 INFO epoch # 6470 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006404559793736553
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:56,315 INFO *** epoch 6470, rolling-avg-loss (window=10)= 0.006488614288628014
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:56,333 INFO epoch # 6471 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006563073366123717
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:56,352 INFO epoch # 6472 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00648300879765884
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:56,370 INFO epoch # 6473 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006520640228700358
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:56,389 INFO epoch # 6474 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006534320862556342
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:56,407 INFO epoch # 6475 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006556634652952198
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:56,425 INFO epoch # 6476 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006422578855563188
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:56,444 INFO epoch # 6477 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006408931512851268
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:56,462 INFO epoch # 6478 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006425524050428066
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:56,481 INFO epoch # 6479 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006416070809791563
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:56,499 INFO epoch # 6480 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0063936364131222945
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:56,499 INFO *** epoch 6480, rolling-avg-loss (window=10)= 0.006472441954974784
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:56,517 INFO epoch # 6481 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00640030133217806
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:56,535 INFO epoch # 6482 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006484721045126207
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:56,554 INFO epoch # 6483 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006635024459683336
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:56,572 INFO epoch # 6484 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006416237069061026
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:56,591 INFO epoch # 6485 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006419560086214915
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:56,609 INFO epoch # 6486 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006386230666976189
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:56,628 INFO epoch # 6487 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006440131950512296
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:56,647 INFO epoch # 6488 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006445028953748988
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:56,665 INFO epoch # 6489 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006413431507098721
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:56,683 INFO epoch # 6490 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006451618719438557
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:56,684 INFO *** epoch 6490, rolling-avg-loss (window=10)= 0.00644922857900383
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:56,702 INFO epoch # 6491 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00642498433808214
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:56,720 INFO epoch # 6492 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006611612425331259
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:56,738 INFO epoch # 6493 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0064234001183649525
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:56,757 INFO epoch # 6494 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006387548404745758
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:56,775 INFO epoch # 6495 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0064552575058769435
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:56,794 INFO epoch # 6496 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006454233440308599
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:56,812 INFO epoch # 6497 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006426381263736403
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:56,831 INFO epoch # 6498 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006402194714610232
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:56,849 INFO epoch # 6499 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00641372278550989
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:56,867 INFO epoch # 6500 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006414341969502857
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:56,867 INFO *** epoch 6500, rolling-avg-loss (window=10)= 0.006441367696606903
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:56,886 INFO epoch # 6501 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006484966732386965
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:56,904 INFO epoch # 6502 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006388636167685036
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:56,922 INFO epoch # 6503 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00805078306075302
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:56,940 INFO epoch # 6504 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006492324639111757
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:56,959 INFO epoch # 6505 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006436161791498307
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:56,977 INFO epoch # 6506 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006437015919800615
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:56,995 INFO epoch # 6507 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006385562159266556
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:57,014 INFO epoch # 6508 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00637119751991122
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:57,032 INFO epoch # 6509 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006379297665262129
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:57,050 INFO epoch # 6510 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0064199410007859115
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:57,051 INFO *** epoch 6510, rolling-avg-loss (window=10)= 0.006584588665646152
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:57,069 INFO epoch # 6511 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006498237176856492
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:57,087 INFO epoch # 6512 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006489421793958172
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:57,105 INFO epoch # 6513 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006406590993719874
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:57,124 INFO epoch # 6514 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007934531437058467
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:57,142 INFO epoch # 6515 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00640692183515057
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:57,160 INFO epoch # 6516 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006392233397491509
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:57,179 INFO epoch # 6517 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006375726659825887
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:57,197 INFO epoch # 6518 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006439668519305997
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:57,216 INFO epoch # 6519 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0064587906817905605
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:57,234 INFO epoch # 6520 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006400001358997542
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:57,234 INFO *** epoch 6520, rolling-avg-loss (window=10)= 0.006580212385415507
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:57,253 INFO epoch # 6521 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006424627244996373
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:57,271 INFO epoch # 6522 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006473446963354945
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:57,289 INFO epoch # 6523 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0064061353223223705
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:57,307 INFO epoch # 6524 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006397621062205872
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:57,326 INFO epoch # 6525 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006563948787515983
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:57,344 INFO epoch # 6526 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006483385423052823
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:57,363 INFO epoch # 6527 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0063952086529752705
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:57,381 INFO epoch # 6528 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0064135917637031525
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:57,400 INFO epoch # 6529 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006478801511548227
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:57,418 INFO epoch # 6530 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006444652870413847
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:57,418 INFO *** epoch 6530, rolling-avg-loss (window=10)= 0.0064481419602088865
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:57,437 INFO epoch # 6531 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007919680087070446
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:57,455 INFO epoch # 6532 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006413624014385277
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:57,474 INFO epoch # 6533 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006584151858987752
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:57,492 INFO epoch # 6534 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006540094895171933
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:57,510 INFO epoch # 6535 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006399553189112339
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:57,528 INFO epoch # 6536 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0063965857079892885
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:57,547 INFO epoch # 6537 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0064311810237995815
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:57,565 INFO epoch # 6538 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006376484259817516
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:57,583 INFO epoch # 6539 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006387209010426886
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:57,602 INFO epoch # 6540 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0064956471615005285
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:57,602 INFO *** epoch 6540, rolling-avg-loss (window=10)= 0.006594421120826155
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:57,620 INFO epoch # 6541 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006380297250871081
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:57,639 INFO epoch # 6542 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.008020898614631733
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:57,657 INFO epoch # 6543 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006454711336118635
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:57,675 INFO epoch # 6544 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006486174177553039
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:57,694 INFO epoch # 6545 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00636176201805938
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:57,712 INFO epoch # 6546 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006415228701371234
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:57,730 INFO epoch # 6547 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006418044911697507
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:57,748 INFO epoch # 6548 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006419426401407691
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:57,767 INFO epoch # 6549 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006606718874536455
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:57,785 INFO epoch # 6550 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006654738004726823
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:57,785 INFO *** epoch 6550, rolling-avg-loss (window=10)= 0.006621800029097358
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:57,804 INFO epoch # 6551 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006399231901013991
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:57,822 INFO epoch # 6552 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006443183454393875
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:57,841 INFO epoch # 6553 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006478310722741298
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:57,859 INFO epoch # 6554 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006373972475557821
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:57,877 INFO epoch # 6555 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006404254701919854
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:57,896 INFO epoch # 6556 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0063715444375702646
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:57,914 INFO epoch # 6557 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006425965751986951
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:57,932 INFO epoch # 6558 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006386354692949681
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:57,950 INFO epoch # 6559 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006399550635251217
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:57,969 INFO epoch # 6560 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006382510746334447
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:57,969 INFO *** epoch 6560, rolling-avg-loss (window=10)= 0.006406487951971939
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:57,987 INFO epoch # 6561 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006372811702021863
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:58,006 INFO epoch # 6562 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0063979217629821505
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:58,024 INFO epoch # 6563 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006405721931514563
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:58,043 INFO epoch # 6564 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00640274360193871
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:58,061 INFO epoch # 6565 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006354575310979271
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:58,079 INFO epoch # 6566 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006425354215025436
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:58,098 INFO epoch # 6567 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006374524458806263
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:58,116 INFO epoch # 6568 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006366668108967133
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:58,134 INFO epoch # 6569 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0063869775585772
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:58,152 INFO epoch # 6570 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006427169108064845
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:58,153 INFO *** epoch 6570, rolling-avg-loss (window=10)= 0.006391446775887743
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:58,171 INFO epoch # 6571 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0063681850624561775
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:58,189 INFO epoch # 6572 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006365444183757063
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:58,208 INFO epoch # 6573 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006486375037638936
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:58,226 INFO epoch # 6574 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0063477311086899135
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:58,245 INFO epoch # 6575 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006555884596309625
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:58,264 INFO epoch # 6576 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006367494450387312
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:58,283 INFO epoch # 6577 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006364919103361899
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:58,301 INFO epoch # 6578 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006360546372889075
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:58,319 INFO epoch # 6579 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006408159224520205
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:58,337 INFO epoch # 6580 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0063867489334370475
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:58,338 INFO *** epoch 6580, rolling-avg-loss (window=10)= 0.0064011488073447255
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:58,356 INFO epoch # 6581 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006395526012056507
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:58,374 INFO epoch # 6582 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006441718876885716
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:58,392 INFO epoch # 6583 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0065354244397894945
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:58,411 INFO epoch # 6584 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0064180366789514665
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:58,429 INFO epoch # 6585 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00641958565756795
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:58,447 INFO epoch # 6586 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006868255210065399
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:58,466 INFO epoch # 6587 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00671849375430611
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:58,484 INFO epoch # 6588 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006420745856303256
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:58,502 INFO epoch # 6589 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0064056152768898755
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:58,520 INFO epoch # 6590 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006355499233904993
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:58,520 INFO *** epoch 6590, rolling-avg-loss (window=10)= 0.006497890099672077
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:58,539 INFO epoch # 6591 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00653578721176018
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:58,557 INFO epoch # 6592 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006368503458361374
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:58,576 INFO epoch # 6593 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006398410187102854
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:58,595 INFO epoch # 6594 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006357920112350257
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:58,614 INFO epoch # 6595 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0063983687323343474
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:58,632 INFO epoch # 6596 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006635517071117647
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:58,651 INFO epoch # 6597 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006377232293743873
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:58,670 INFO epoch # 6598 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00639667206996819
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:58,688 INFO epoch # 6599 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006370362232701154
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:58,706 INFO epoch # 6600 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.008079528724920237
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:58,706 INFO *** epoch 6600, rolling-avg-loss (window=10)= 0.006591830209436012
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:58,724 INFO epoch # 6601 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006358751938023488
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:58,742 INFO epoch # 6602 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006398833658749936
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:58,761 INFO epoch # 6603 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006367675807268824
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:58,779 INFO epoch # 6604 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006575858446012717
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:58,798 INFO epoch # 6605 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00634443869421375
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:58,816 INFO epoch # 6606 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006428834614780499
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:58,834 INFO epoch # 6607 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0065011401602532715
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:58,852 INFO epoch # 6608 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0063526364083372755
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:58,871 INFO epoch # 6609 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006419959714548895
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:58,889 INFO epoch # 6610 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006401474729500478
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:58,889 INFO *** epoch 6610, rolling-avg-loss (window=10)= 0.006414960417168913
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:58,907 INFO epoch # 6611 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006363105079799425
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:58,926 INFO epoch # 6612 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00644632551484392
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:58,944 INFO epoch # 6613 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006386043351085391
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:58,962 INFO epoch # 6614 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006347538888803683
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:58,981 INFO epoch # 6615 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006611471868382068
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:58,999 INFO epoch # 6616 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006348145530864713
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:59,018 INFO epoch # 6617 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006368850656144787
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:59,036 INFO epoch # 6618 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0064037639676826075
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:59,054 INFO epoch # 6619 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006352538572173216
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:59,072 INFO epoch # 6620 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006364396769640734
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:59,073 INFO *** epoch 6620, rolling-avg-loss (window=10)= 0.006399218019942055
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:59,091 INFO epoch # 6621 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006522264033264946
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:59,109 INFO epoch # 6622 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0063665499656053726
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:59,127 INFO epoch # 6623 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0065008338206098415
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:59,146 INFO epoch # 6624 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0063315750576293794
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:59,164 INFO epoch # 6625 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006359319919283735
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:59,182 INFO epoch # 6626 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00639229405351216
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:59,200 INFO epoch # 6627 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006431354660890065
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:59,219 INFO epoch # 6628 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006416837753931759
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:59,237 INFO epoch # 6629 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006625552538025659
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:59,256 INFO epoch # 6630 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006371044564730255
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:59,256 INFO *** epoch 6630, rolling-avg-loss (window=10)= 0.006431762636748317
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:59,274 INFO epoch # 6631 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006352670086926082
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:59,293 INFO epoch # 6632 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006449910237279255
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:59,311 INFO epoch # 6633 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006427423439163249
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:59,329 INFO epoch # 6634 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0064333520422223955
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:59,347 INFO epoch # 6635 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006421302947273944
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:59,366 INFO epoch # 6636 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0063810557512624655
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:59,384 INFO epoch # 6637 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00635325810071663
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:59,402 INFO epoch # 6638 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006424061139114201
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:59,420 INFO epoch # 6639 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0066473829065216705
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:59,439 INFO epoch # 6640 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006437343443394639
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:59,439 INFO *** epoch 6640, rolling-avg-loss (window=10)= 0.006432776009387453
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:59,457 INFO epoch # 6641 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006360018975101411
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:59,476 INFO epoch # 6642 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007892341869592201
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:59,494 INFO epoch # 6643 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006385540167684667
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:59,513 INFO epoch # 6644 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006346676553221187
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:59,531 INFO epoch # 6645 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0063887601645546965
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:59,549 INFO epoch # 6646 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006426873616874218
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:59,567 INFO epoch # 6647 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006759737338143168
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:59,585 INFO epoch # 6648 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006464387028245255
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:59,604 INFO epoch # 6649 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006695715881505748
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:59,622 INFO epoch # 6650 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006347206159261987
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:59,622 INFO *** epoch 6650, rolling-avg-loss (window=10)= 0.006606725775418454
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:59,641 INFO epoch # 6651 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00668801322899526
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:59,659 INFO epoch # 6652 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006343316581478575
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:59,677 INFO epoch # 6653 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006394898853613995
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:59,696 INFO epoch # 6654 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006336555745292571
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:59,714 INFO epoch # 6655 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006335290065180743
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:59,732 INFO epoch # 6656 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006385708074958529
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:59,750 INFO epoch # 6657 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006348661558149615
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:59,769 INFO epoch # 6658 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0063836366425675806
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:59,787 INFO epoch # 6659 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006340636464301497
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:59,805 INFO epoch # 6660 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006373134132445557
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:59,805 INFO *** epoch 6660, rolling-avg-loss (window=10)= 0.0063929851346983925
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:59,824 INFO epoch # 6661 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006346377933368785
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:59,842 INFO epoch # 6662 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006355240140692331
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:59,860 INFO epoch # 6663 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006557045075169299
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:59,879 INFO epoch # 6664 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006347784059471451
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:59,897 INFO epoch # 6665 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006355906978569692
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:59,915 INFO epoch # 6666 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006335277641483117
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:59,933 INFO epoch # 6667 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006375688153639203
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:59,952 INFO epoch # 6668 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006359569699270651
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:59,970 INFO epoch # 6669 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006421459180273814
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:49:59,988 INFO epoch # 6670 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006385079908795888
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:49:59,988 INFO *** epoch 6670, rolling-avg-loss (window=10)= 0.006383942877073423
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:00,007 INFO epoch # 6671 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006410845962818712
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:00,026 INFO epoch # 6672 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006437821197323501
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:00,044 INFO epoch # 6673 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0067078137763019186
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:00,063 INFO epoch # 6674 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006365422625094652
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:00,081 INFO epoch # 6675 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0063596741420042235
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:00,100 INFO epoch # 6676 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0063621700210205745
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:00,118 INFO epoch # 6677 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006337119015370263
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:00,136 INFO epoch # 6678 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0063395319593837485
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:00,155 INFO epoch # 6679 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.008444892650004476
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:00,173 INFO epoch # 6680 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006725279145030072
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:00,173 INFO *** epoch 6680, rolling-avg-loss (window=10)= 0.0066490570494352145
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:00,191 INFO epoch # 6681 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006353133660013555
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:00,210 INFO epoch # 6682 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006420862140657846
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:00,228 INFO epoch # 6683 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006400259604561143
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:00,247 INFO epoch # 6684 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006365131157508586
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:00,265 INFO epoch # 6685 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006457944793510251
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:00,283 INFO epoch # 6686 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006329610674583819
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:00,301 INFO epoch # 6687 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006343573273625225
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:00,320 INFO epoch # 6688 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006383889984135749
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:00,338 INFO epoch # 6689 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006374989454343449
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:00,356 INFO epoch # 6690 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006484014971647412
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:00,356 INFO *** epoch 6690, rolling-avg-loss (window=10)= 0.006391340971458703
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:00,375 INFO epoch # 6691 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006339205207041232
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:00,393 INFO epoch # 6692 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0066267503425478935
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:00,411 INFO epoch # 6693 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006362227679346688
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:00,430 INFO epoch # 6694 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006405539061233867
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:00,448 INFO epoch # 6695 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006417268719815183
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:00,466 INFO epoch # 6696 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0064373200038971845
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:00,485 INFO epoch # 6697 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006903264296852285
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:00,504 INFO epoch # 6698 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006337190028716577
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:00,523 INFO epoch # 6699 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006323267298284918
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:00,541 INFO epoch # 6700 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006547778135427507
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:00,541 INFO *** epoch 6700, rolling-avg-loss (window=10)= 0.0064699810773163335
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:00,560 INFO epoch # 6701 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006402602652087808
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:00,578 INFO epoch # 6702 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006354457662382629
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:00,596 INFO epoch # 6703 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006419785102480091
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:00,615 INFO epoch # 6704 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006749569958628854
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:00,633 INFO epoch # 6705 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006376730001647957
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:00,651 INFO epoch # 6706 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006397720884706359
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:00,670 INFO epoch # 6707 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006345440291624982
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:00,688 INFO epoch # 6708 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006349911476718262
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:00,706 INFO epoch # 6709 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0063543364267388824
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:00,724 INFO epoch # 6710 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006316815259197028
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:00,725 INFO *** epoch 6710, rolling-avg-loss (window=10)= 0.006406736971621285
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:00,743 INFO epoch # 6711 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006330446696665604
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:00,761 INFO epoch # 6712 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00633783127341303
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:00,779 INFO epoch # 6713 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006311418985205819
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:00,797 INFO epoch # 6714 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0063898368025547825
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:00,816 INFO epoch # 6715 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006322051460301736
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:00,834 INFO epoch # 6716 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006404573578038253
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:00,852 INFO epoch # 6717 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006650174651440466
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:00,871 INFO epoch # 6718 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006307356034085387
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:00,889 INFO epoch # 6719 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00638317855191417
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:00,908 INFO epoch # 6720 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006360534316627309
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:00,908 INFO *** epoch 6720, rolling-avg-loss (window=10)= 0.006379740235024656
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:00,926 INFO epoch # 6721 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006369782226101961
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:00,944 INFO epoch # 6722 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0063143256775219925
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:00,962 INFO epoch # 6723 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006306142180619645
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:00,981 INFO epoch # 6724 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0063099507187871495
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:00,999 INFO epoch # 6725 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006345954938296927
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:01,018 INFO epoch # 6726 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006372075444232905
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:01,036 INFO epoch # 6727 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0063223731667676475
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:01,055 INFO epoch # 6728 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006355095723847626
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:01,074 INFO epoch # 6729 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00636936838782276
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:01,093 INFO epoch # 6730 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0063613989696023054
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:01,093 INFO *** epoch 6730, rolling-avg-loss (window=10)= 0.006342646743360092
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:01,111 INFO epoch # 6731 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00630733104844694
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:01,129 INFO epoch # 6732 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006362869968143059
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:01,148 INFO epoch # 6733 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006405471478501568
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:01,166 INFO epoch # 6734 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006513184529467253
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:01,184 INFO epoch # 6735 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0063612484955228865
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:01,203 INFO epoch # 6736 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00632446004965459
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:01,221 INFO epoch # 6737 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006350430128804874
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:01,239 INFO epoch # 6738 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006364832468534587
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:01,258 INFO epoch # 6739 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006331070962914964
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:01,276 INFO epoch # 6740 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006336868831567699
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:01,276 INFO *** epoch 6740, rolling-avg-loss (window=10)= 0.006365776796155842
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:01,294 INFO epoch # 6741 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006306443363428116
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:01,313 INFO epoch # 6742 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006402942646673182
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:01,331 INFO epoch # 6743 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0066130646446254104
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:01,349 INFO epoch # 6744 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0066079296375392005
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:01,368 INFO epoch # 6745 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006362698157317936
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:01,386 INFO epoch # 6746 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0063875372979964595
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:01,404 INFO epoch # 6747 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006367463432980003
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:01,422 INFO epoch # 6748 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006378874859365169
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:01,441 INFO epoch # 6749 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006323961517409771
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:01,459 INFO epoch # 6750 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006324578440398909
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:01,459 INFO *** epoch 6750, rolling-avg-loss (window=10)= 0.006407549399773416
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:01,478 INFO epoch # 6751 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006328827490506228
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:01,496 INFO epoch # 6752 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006345873440295691
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:01,515 INFO epoch # 6753 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006332935041427845
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:01,533 INFO epoch # 6754 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00631475498812506
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:01,552 INFO epoch # 6755 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00635021443667938
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:01,570 INFO epoch # 6756 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0063112844654824585
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:01,588 INFO epoch # 6757 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006303975371338311
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:01,607 INFO epoch # 6758 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006373853757395409
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:01,625 INFO epoch # 6759 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006349754083203152
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:01,644 INFO epoch # 6760 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006404259584087413
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:01,644 INFO *** epoch 6760, rolling-avg-loss (window=10)= 0.0063415732658540945
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:01,662 INFO epoch # 6761 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006393522566213505
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:01,680 INFO epoch # 6762 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00637390019983286
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:01,699 INFO epoch # 6763 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006338252653222298
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:01,717 INFO epoch # 6764 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006362206924677594
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:01,735 INFO epoch # 6765 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006469293046393432
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:01,753 INFO epoch # 6766 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0063044264425116125
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:01,772 INFO epoch # 6767 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0063182798512571026
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:01,790 INFO epoch # 6768 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006346892922010738
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:01,808 INFO epoch # 6769 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006369353959598811
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:01,826 INFO epoch # 6770 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006320091779343784
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:01,826 INFO *** epoch 6770, rolling-avg-loss (window=10)= 0.006359622034506174
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:01,845 INFO epoch # 6771 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006359888560837135
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:01,863 INFO epoch # 6772 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006313252328254748
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:01,881 INFO epoch # 6773 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006361259926052298
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:01,900 INFO epoch # 6774 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006290327673923457
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:01,918 INFO epoch # 6775 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006315380436717533
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:01,936 INFO epoch # 6776 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006309927517577307
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:01,955 INFO epoch # 6777 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006319795604213141
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:01,973 INFO epoch # 6778 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006293538945101318
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:01,991 INFO epoch # 6779 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006304913342319196
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:02,009 INFO epoch # 6780 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006389648893673439
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:02,010 INFO *** epoch 6780, rolling-avg-loss (window=10)= 0.006325793322866957
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:02,028 INFO epoch # 6781 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006287329160841182
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:02,046 INFO epoch # 6782 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006446187020628713
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:02,065 INFO epoch # 6783 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006342721433611587
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:02,083 INFO epoch # 6784 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006353274085995508
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:02,101 INFO epoch # 6785 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006484516634372994
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:02,120 INFO epoch # 6786 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006337863178487169
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:02,138 INFO epoch # 6787 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006299388780462323
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:02,156 INFO epoch # 6788 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00673563473901595
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:02,174 INFO epoch # 6789 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0063450471170654055
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:02,192 INFO epoch # 6790 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006324533464066917
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:02,192 INFO *** epoch 6790, rolling-avg-loss (window=10)= 0.006395649561454775
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:02,211 INFO epoch # 6791 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006329100768198259
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:02,229 INFO epoch # 6792 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0063913676494848914
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:02,247 INFO epoch # 6793 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006329064210149227
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:02,266 INFO epoch # 6794 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00630413581711764
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:02,285 INFO epoch # 6795 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006420754973078147
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:02,303 INFO epoch # 6796 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006328301627945621
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:02,322 INFO epoch # 6797 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00630113945226185
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:02,340 INFO epoch # 6798 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006396309338015271
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:02,358 INFO epoch # 6799 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006972073402721435
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:02,377 INFO epoch # 6800 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006341817032080144
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:02,377 INFO *** epoch 6800, rolling-avg-loss (window=10)= 0.0064114064271052484
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:02,395 INFO epoch # 6801 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006325703234324465
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:02,413 INFO epoch # 6802 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0063314242906926665
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:02,432 INFO epoch # 6803 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0063417880301130936
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:02,450 INFO epoch # 6804 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0063442772152484395
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:02,468 INFO epoch # 6805 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0063338851869048085
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:02,486 INFO epoch # 6806 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006317145420325687
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:02,505 INFO epoch # 6807 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0063098688624450006
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:02,523 INFO epoch # 6808 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.009478055351792136
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:02,542 INFO epoch # 6809 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006372215160808992
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:02,560 INFO epoch # 6810 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006382170569850132
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:02,560 INFO *** epoch 6810, rolling-avg-loss (window=10)= 0.006653653332250542
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:02,579 INFO epoch # 6811 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006420261826860951
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:02,597 INFO epoch # 6812 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006365469522279454
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:02,616 INFO epoch # 6813 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00634479532163823
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:02,635 INFO epoch # 6814 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006641396194027038
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:02,653 INFO epoch # 6815 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006440778208343545
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:02,671 INFO epoch # 6816 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0063471846624452155
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:02,690 INFO epoch # 6817 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006321055436274037
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:02,708 INFO epoch # 6818 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00630407024800661
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:02,727 INFO epoch # 6819 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006673855397821171
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:02,745 INFO epoch # 6820 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006296732146438444
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:02,745 INFO *** epoch 6820, rolling-avg-loss (window=10)= 0.00641555989641347
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:02,764 INFO epoch # 6821 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006315691691270331
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:02,782 INFO epoch # 6822 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006284673108893912
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:02,800 INFO epoch # 6823 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006316309565590927
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:02,818 INFO epoch # 6824 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006291681969742058
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:02,837 INFO epoch # 6825 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006313484642305411
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:02,855 INFO epoch # 6826 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006690094196528662
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:02,874 INFO epoch # 6827 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006319568623439409
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:02,892 INFO epoch # 6828 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006330448501103092
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:02,911 INFO epoch # 6829 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006299052267422667
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:02,929 INFO epoch # 6830 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006315498801996
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:02,929 INFO *** epoch 6830, rolling-avg-loss (window=10)= 0.006347650336829247
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:02,947 INFO epoch # 6831 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006443422276788624
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:02,966 INFO epoch # 6832 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0063301037189376075
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:02,984 INFO epoch # 6833 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00639403385866899
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:03,002 INFO epoch # 6834 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00649065362449619
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:03,021 INFO epoch # 6835 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006346082129311981
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:03,039 INFO epoch # 6836 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006350863019179087
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:03,058 INFO epoch # 6837 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0064865269196161535
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:03,076 INFO epoch # 6838 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006398331785021583
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:03,095 INFO epoch # 6839 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006326711565634469
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:03,113 INFO epoch # 6840 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006321457640297012
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:03,113 INFO *** epoch 6840, rolling-avg-loss (window=10)= 0.00638881865379517
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:03,131 INFO epoch # 6841 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006320578584563918
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:03,149 INFO epoch # 6842 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006312885801889934
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:03,168 INFO epoch # 6843 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006317532355751609
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:03,186 INFO epoch # 6844 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006316432667517802
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:03,204 INFO epoch # 6845 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006303750527877128
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:03,222 INFO epoch # 6846 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006295889499597251
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:03,241 INFO epoch # 6847 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0062941086252976675
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:03,259 INFO epoch # 6848 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006311298224318307
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:03,278 INFO epoch # 6849 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006290671663009562
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:03,296 INFO epoch # 6850 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006340375417494215
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:03,296 INFO *** epoch 6850, rolling-avg-loss (window=10)= 0.00631035233673174
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:03,314 INFO epoch # 6851 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006312298432021635
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:03,333 INFO epoch # 6852 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006279355715378188
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:03,351 INFO epoch # 6853 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006433279915654566
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:03,369 INFO epoch # 6854 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006314029647910502
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:03,387 INFO epoch # 6855 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006295445116847986
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:03,406 INFO epoch # 6856 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006298659362073522
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:03,424 INFO epoch # 6857 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006307679803285282
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:03,442 INFO epoch # 6858 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0063116350283962674
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:03,461 INFO epoch # 6859 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006345139729091898
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:03,479 INFO epoch # 6860 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006380152921337867
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:03,479 INFO *** epoch 6860, rolling-avg-loss (window=10)= 0.006327767567199771
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:03,498 INFO epoch # 6861 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006437667656427948
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:03,516 INFO epoch # 6862 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006410687168681761
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:03,535 INFO epoch # 6863 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006279140354308765
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:03,553 INFO epoch # 6864 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006352953980240272
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:03,571 INFO epoch # 6865 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006283929858909687
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:03,590 INFO epoch # 6866 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006489359395345673
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:03,608 INFO epoch # 6867 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006766903854440898
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:03,626 INFO epoch # 6868 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00628250071167713
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:03,644 INFO epoch # 6869 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006296176044997992
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:03,663 INFO epoch # 6870 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00635723737286753
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:03,663 INFO *** epoch 6870, rolling-avg-loss (window=10)= 0.0063956556397897655
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:03,681 INFO epoch # 6871 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0062943155608081724
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:03,699 INFO epoch # 6872 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006274743864196353
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:03,718 INFO epoch # 6873 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00630208823713474
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:03,736 INFO epoch # 6874 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00625757803209126
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:03,755 INFO epoch # 6875 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006302601013885578
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:03,773 INFO epoch # 6876 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006299733715422917
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:03,791 INFO epoch # 6877 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006371553950884845
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:03,810 INFO epoch # 6878 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0064179540968325455
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:03,828 INFO epoch # 6879 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006313883925031405
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:03,847 INFO epoch # 6880 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006292998808930861
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:03,847 INFO *** epoch 6880, rolling-avg-loss (window=10)= 0.0063127451205218675
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:03,866 INFO epoch # 6881 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006282159400143428
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:03,884 INFO epoch # 6882 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006284021495957859
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:03,902 INFO epoch # 6883 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006281566860707244
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:03,920 INFO epoch # 6884 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006322346365777776
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:03,939 INFO epoch # 6885 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006383044110407354
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:03,957 INFO epoch # 6886 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006307613322860561
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:03,975 INFO epoch # 6887 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006772725002520019
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:03,994 INFO epoch # 6888 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006315626211289782
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:04,012 INFO epoch # 6889 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0062697571102035
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:04,030 INFO epoch # 6890 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0065733501069189515
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:04,030 INFO *** epoch 6890, rolling-avg-loss (window=10)= 0.006379220998678647
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:04,049 INFO epoch # 6891 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007777453647577204
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:04,067 INFO epoch # 6892 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006272491287745652
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:04,086 INFO epoch # 6893 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006312039891781751
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:04,105 INFO epoch # 6894 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006271698413911508
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:04,124 INFO epoch # 6895 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006310620559816016
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:04,142 INFO epoch # 6896 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006255180120206205
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:04,161 INFO epoch # 6897 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006542977407661965
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:04,179 INFO epoch # 6898 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0063286814984166995
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:04,197 INFO epoch # 6899 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0066483689661254175
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:04,215 INFO epoch # 6900 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006257538789213868
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:04,215 INFO *** epoch 6900, rolling-avg-loss (window=10)= 0.006497705058245628
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:04,234 INFO epoch # 6901 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006290125234954758
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:04,252 INFO epoch # 6902 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006660367045697058
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:04,271 INFO epoch # 6903 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006378162463079207
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:04,289 INFO epoch # 6904 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006301476711087162
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:04,307 INFO epoch # 6905 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006355512628942961
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:04,326 INFO epoch # 6906 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00628840743956971
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:04,344 INFO epoch # 6907 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00625722335462342
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:04,362 INFO epoch # 6908 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006385115411831066
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:04,381 INFO epoch # 6909 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006535023028845899
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:04,399 INFO epoch # 6910 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006379052181728184
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:04,399 INFO *** epoch 6910, rolling-avg-loss (window=10)= 0.006383046550035942
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:04,418 INFO epoch # 6911 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006701142141537275
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:04,436 INFO epoch # 6912 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006271438756812131
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:04,454 INFO epoch # 6913 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006271754638873972
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:04,473 INFO epoch # 6914 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006323000710835913
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:04,491 INFO epoch # 6915 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0062809774426568765
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:04,510 INFO epoch # 6916 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0062577098615292925
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:04,528 INFO epoch # 6917 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006404375748388702
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:04,546 INFO epoch # 6918 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00624441322270286
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:04,565 INFO epoch # 6919 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006295220027823234
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:04,583 INFO epoch # 6920 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00658364089395036
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:04,583 INFO *** epoch 6920, rolling-avg-loss (window=10)= 0.006363367344511062
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:04,601 INFO epoch # 6921 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006377545025316067
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:04,620 INFO epoch # 6922 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006363646880345186
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:04,638 INFO epoch # 6923 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006261890834139194
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:04,657 INFO epoch # 6924 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00628725185742951
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:04,675 INFO epoch # 6925 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00634082690521609
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:04,694 INFO epoch # 6926 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006276904579863185
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:04,712 INFO epoch # 6927 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006264159095735522
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:04,731 INFO epoch # 6928 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006281415910052601
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:04,749 INFO epoch # 6929 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006269641049584607
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:04,768 INFO epoch # 6930 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006256360164115904
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:04,768 INFO *** epoch 6930, rolling-avg-loss (window=10)= 0.006297964230179786
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:04,786 INFO epoch # 6931 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0065488949621794745
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:04,804 INFO epoch # 6932 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006285142961132806
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:04,822 INFO epoch # 6933 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006309812364634126
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:04,841 INFO epoch # 6934 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0065365013397240546
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:04,859 INFO epoch # 6935 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006250370126508642
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:04,877 INFO epoch # 6936 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006267383596423315
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:04,896 INFO epoch # 6937 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006244772617719718
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:04,914 INFO epoch # 6938 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006651558534940705
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:04,933 INFO epoch # 6939 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006386209679476451
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:04,951 INFO epoch # 6940 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006265794156206539
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:04,951 INFO *** epoch 6940, rolling-avg-loss (window=10)= 0.006374644033894583
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:04,969 INFO epoch # 6941 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006296767227468081
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:04,988 INFO epoch # 6942 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0062726651231059805
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:05,006 INFO epoch # 6943 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00629517118431977
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:05,024 INFO epoch # 6944 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006273060695093591
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:05,042 INFO epoch # 6945 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006245793425478041
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:05,061 INFO epoch # 6946 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006292591693636496
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:05,079 INFO epoch # 6947 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006356927438901039
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:05,097 INFO epoch # 6948 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0062822013460390735
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:05,116 INFO epoch # 6949 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00635638267340255
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:05,135 INFO epoch # 6950 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006299921817117138
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:05,135 INFO *** epoch 6950, rolling-avg-loss (window=10)= 0.0062971482624561755
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:05,153 INFO epoch # 6951 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0063114970580500085
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:05,172 INFO epoch # 6952 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006361021725751925
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:05,190 INFO epoch # 6953 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006360875420796219
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:05,209 INFO epoch # 6954 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006309992535534548
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:05,227 INFO epoch # 6955 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006323058736597886
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:05,245 INFO epoch # 6956 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0062668293940078
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:05,263 INFO epoch # 6957 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006273270715610124
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:05,282 INFO epoch # 6958 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006265357005759142
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:05,301 INFO epoch # 6959 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006250929487578105
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:05,319 INFO epoch # 6960 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006501007719634799
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:05,319 INFO *** epoch 6960, rolling-avg-loss (window=10)= 0.006322383979932056
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:05,338 INFO epoch # 6961 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006270179957937216
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:05,356 INFO epoch # 6962 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00629219708207529
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:05,374 INFO epoch # 6963 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006512491716421209
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:05,392 INFO epoch # 6964 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006623172383115161
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:05,411 INFO epoch # 6965 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006266914180741878
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:05,429 INFO epoch # 6966 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006317779567325488
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:05,447 INFO epoch # 6967 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006330685871944297
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:05,465 INFO epoch # 6968 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006238886684514
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:05,484 INFO epoch # 6969 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006287238567892928
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:05,503 INFO epoch # 6970 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006224864513569628
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:05,503 INFO *** epoch 6970, rolling-avg-loss (window=10)= 0.00633644105255371
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:05,521 INFO epoch # 6971 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006337675262329867
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:05,540 INFO epoch # 6972 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006247606637771241
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:05,558 INFO epoch # 6973 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006278558379563037
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:05,576 INFO epoch # 6974 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006295211729593575
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:05,594 INFO epoch # 6975 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006460082629928365
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:05,613 INFO epoch # 6976 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006282879676291486
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:05,631 INFO epoch # 6977 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006217386206117226
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:05,649 INFO epoch # 6978 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006283515082031954
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:05,668 INFO epoch # 6979 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006520730072224978
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:05,686 INFO epoch # 6980 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00628509278249112
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:05,687 INFO *** epoch 6980, rolling-avg-loss (window=10)= 0.006320873845834285
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:05,705 INFO epoch # 6981 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006230319644600968
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:05,724 INFO epoch # 6982 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006266001411859179
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:05,742 INFO epoch # 6983 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0062883595637686085
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:05,760 INFO epoch # 6984 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0062451879821310285
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:05,779 INFO epoch # 6985 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006243133913812926
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:05,797 INFO epoch # 6986 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006367577509081457
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:05,815 INFO epoch # 6987 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006433991380617954
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:05,833 INFO epoch # 6988 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.009410401642526267
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:05,852 INFO epoch # 6989 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006337478174827993
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:05,870 INFO epoch # 6990 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0062723601986363064
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:05,870 INFO *** epoch 6990, rolling-avg-loss (window=10)= 0.006609481142186268
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:05,889 INFO epoch # 6991 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006353789303830126
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:05,907 INFO epoch # 6992 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006251966671698028
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:05,926 INFO epoch # 6993 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006235937344172271
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:05,944 INFO epoch # 6994 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006257031171116978
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:05,963 INFO epoch # 6995 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006310259232122917
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:05,981 INFO epoch # 6996 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006248056608455954
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:05,999 INFO epoch # 6997 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006224234348337632
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:06,017 INFO epoch # 6998 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00624727136164438
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:06,035 INFO epoch # 6999 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006392369275999954
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:06,054 INFO epoch # 7000 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006237217759917257
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:06,054 INFO *** epoch 7000, rolling-avg-loss (window=10)= 0.00627581330772955
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:06,072 INFO epoch # 7001 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006325857822957914
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:06,091 INFO epoch # 7002 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0062659685863764025
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:06,109 INFO epoch # 7003 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006285497325734468
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:06,127 INFO epoch # 7004 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006349986790155526
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:06,146 INFO epoch # 7005 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006280032786889933
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:06,164 INFO epoch # 7006 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006213501721504144
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:06,182 INFO epoch # 7007 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0063846375269349664
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:06,200 INFO epoch # 7008 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006284167226112913
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:06,219 INFO epoch # 7009 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006282080434175441
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:06,237 INFO epoch # 7010 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.009347074152174173
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:06,237 INFO *** epoch 7010, rolling-avg-loss (window=10)= 0.006601880437301588
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:06,255 INFO epoch # 7011 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006275180894590449
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:06,274 INFO epoch # 7012 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006254658412217395
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:06,292 INFO epoch # 7013 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006254101266677026
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:06,310 INFO epoch # 7014 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00637782162084477
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:06,329 INFO epoch # 7015 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006425874245906016
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:06,347 INFO epoch # 7016 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006252300656342413
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:06,366 INFO epoch # 7017 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0062537905178032815
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:06,384 INFO epoch # 7018 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0064098137081600726
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:06,403 INFO epoch # 7019 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006239065834961366
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:06,421 INFO epoch # 7020 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006287441316089826
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:06,421 INFO *** epoch 7020, rolling-avg-loss (window=10)= 0.006303004847359262
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:06,439 INFO epoch # 7021 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006241096896701492
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:06,457 INFO epoch # 7022 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006286039737460669
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:06,475 INFO epoch # 7023 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0062408068115473725
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:06,494 INFO epoch # 7024 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0062317714036908
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:06,513 INFO epoch # 7025 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006249890575418249
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:06,531 INFO epoch # 7026 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006529986407258548
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:06,550 INFO epoch # 7027 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006299786804447649
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:06,568 INFO epoch # 7028 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006244595471798675
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:06,587 INFO epoch # 7029 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00628397367472644
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:06,606 INFO epoch # 7030 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006289489105256507
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:06,606 INFO *** epoch 7030, rolling-avg-loss (window=10)= 0.0062897436888306405
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:06,625 INFO epoch # 7031 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00621813595535059
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:06,643 INFO epoch # 7032 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006234493062947877
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:06,661 INFO epoch # 7033 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006229550675925566
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:06,679 INFO epoch # 7034 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006425876890716609
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:06,698 INFO epoch # 7035 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006254721913137473
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:06,717 INFO epoch # 7036 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0062555756921938155
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:06,735 INFO epoch # 7037 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006296478703006869
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:06,754 INFO epoch # 7038 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006221015690243803
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:06,772 INFO epoch # 7039 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006224359131010715
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:06,790 INFO epoch # 7040 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006239784048375441
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:06,791 INFO *** epoch 7040, rolling-avg-loss (window=10)= 0.006259999176290876
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:06,809 INFO epoch # 7041 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006190948608491453
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:06,827 INFO epoch # 7042 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006218177641130751
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:06,845 INFO epoch # 7043 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006228122543689096
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:06,864 INFO epoch # 7044 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006217777499841759
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:06,882 INFO epoch # 7045 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006218495593202533
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:06,900 INFO epoch # 7046 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006473898531112354
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:06,918 INFO epoch # 7047 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006311672241281485
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:06,937 INFO epoch # 7048 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006230050592421321
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:06,955 INFO epoch # 7049 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0062918528674345
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:06,974 INFO epoch # 7050 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006343708126223646
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:06,974 INFO *** epoch 7050, rolling-avg-loss (window=10)= 0.00627247042448289
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:06,992 INFO epoch # 7051 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006292952351941494
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:07,010 INFO epoch # 7052 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0062141850739863
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:07,029 INFO epoch # 7053 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006215962192072766
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:07,047 INFO epoch # 7054 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006225881606951589
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:07,065 INFO epoch # 7055 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006292695881711552
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:07,083 INFO epoch # 7056 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006283867460297188
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:07,102 INFO epoch # 7057 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006226634319318691
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:07,120 INFO epoch # 7058 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006277656473685056
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:07,138 INFO epoch # 7059 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006382256469805725
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:07,157 INFO epoch # 7060 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006237558402062859
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:07,157 INFO *** epoch 7060, rolling-avg-loss (window=10)= 0.006264965023183322
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:07,177 INFO epoch # 7061 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006221225001354469
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:07,196 INFO epoch # 7062 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006214629505848279
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:07,214 INFO epoch # 7063 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006252752471482381
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:07,232 INFO epoch # 7064 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0062459629771183245
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:07,251 INFO epoch # 7065 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006304307782556862
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:07,269 INFO epoch # 7066 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006265811498451512
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:07,287 INFO epoch # 7067 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006315899154287763
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:07,306 INFO epoch # 7068 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006262555165449157
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:07,324 INFO epoch # 7069 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006215223063918529
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:07,343 INFO epoch # 7070 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0062898384931031615
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:07,343 INFO *** epoch 7070, rolling-avg-loss (window=10)= 0.0062588205113570435
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:07,361 INFO epoch # 7071 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006215869198058499
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:07,380 INFO epoch # 7072 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0065509428350196686
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:07,399 INFO epoch # 7073 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006314519912848482
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:07,417 INFO epoch # 7074 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006214051605638815
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:07,436 INFO epoch # 7075 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006334871122817276
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:07,454 INFO epoch # 7076 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006423656890547136
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:07,472 INFO epoch # 7077 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0062444285795209
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:07,491 INFO epoch # 7078 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006238793375814566
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:07,509 INFO epoch # 7079 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006264893418119755
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:07,528 INFO epoch # 7080 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007700359881710028
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:07,528 INFO *** epoch 7080, rolling-avg-loss (window=10)= 0.006450238682009513
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:07,546 INFO epoch # 7081 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006535648732096888
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:07,565 INFO epoch # 7082 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00621565489564091
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:07,584 INFO epoch # 7083 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006230551487533376
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:07,603 INFO epoch # 7084 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006208091064763721
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:07,621 INFO epoch # 7085 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006235317548998864
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:07,639 INFO epoch # 7086 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006204706676726346
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:07,658 INFO epoch # 7087 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006276535976212472
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:07,676 INFO epoch # 7088 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006207001621078234
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:07,694 INFO epoch # 7089 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0062880291989131365
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:07,713 INFO epoch # 7090 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0062466480521834455
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:07,713 INFO *** epoch 7090, rolling-avg-loss (window=10)= 0.00626481852541474
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:07,731 INFO epoch # 7091 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0063382481966982596
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:07,750 INFO epoch # 7092 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006279102137341397
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:07,768 INFO epoch # 7093 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006500117771793157
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:07,787 INFO epoch # 7094 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00631531789622386
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:07,805 INFO epoch # 7095 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006224250981176738
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:07,824 INFO epoch # 7096 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.008287348719022702
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:07,842 INFO epoch # 7097 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00625202168157557
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:07,860 INFO epoch # 7098 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006217776317498647
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:07,878 INFO epoch # 7099 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006215078967215959
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:07,897 INFO epoch # 7100 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006277868222241523
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:07,897 INFO *** epoch 7100, rolling-avg-loss (window=10)= 0.006490713089078781
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:07,915 INFO epoch # 7101 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006315291429928038
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:07,934 INFO epoch # 7102 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006299930435488932
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:07,953 INFO epoch # 7103 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00623539697699016
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:07,971 INFO epoch # 7104 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006226670106116217
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:07,989 INFO epoch # 7105 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006201343589054886
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:08,008 INFO epoch # 7106 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0061957617981533986
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:08,026 INFO epoch # 7107 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006203998746059369
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:08,045 INFO epoch # 7108 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006190939613588853
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:08,063 INFO epoch # 7109 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006237896617676597
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:08,081 INFO epoch # 7110 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006186589322169311
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:08,081 INFO *** epoch 7110, rolling-avg-loss (window=10)= 0.006229381863522576
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:08,100 INFO epoch # 7111 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006220864088390954
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:08,118 INFO epoch # 7112 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006222660107596312
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:08,136 INFO epoch # 7113 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006183006331411889
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:08,155 INFO epoch # 7114 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006286155872658128
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:08,174 INFO epoch # 7115 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0065720676939236
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:08,192 INFO epoch # 7116 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0062091117979434785
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:08,210 INFO epoch # 7117 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006226873836567393
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:08,228 INFO epoch # 7118 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006242373543500435
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:08,247 INFO epoch # 7119 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006307840067165671
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:08,265 INFO epoch # 7120 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0062079356430331245
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:08,265 INFO *** epoch 7120, rolling-avg-loss (window=10)= 0.006267888898219098
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:08,283 INFO epoch # 7121 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006207068650837755
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:08,302 INFO epoch # 7122 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006196449594426667
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:08,320 INFO epoch # 7123 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006412649127014447
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:08,339 INFO epoch # 7124 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006253819388803095
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:08,357 INFO epoch # 7125 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006199475428729784
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:08,376 INFO epoch # 7126 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006200431576871779
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:08,394 INFO epoch # 7127 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006251850376429502
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:08,413 INFO epoch # 7128 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006243863150302786
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:08,431 INFO epoch # 7129 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006208981401869096
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:08,449 INFO epoch # 7130 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006233519088709727
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:08,449 INFO *** epoch 7130, rolling-avg-loss (window=10)= 0.006240810778399464
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:08,467 INFO epoch # 7131 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006185181824548636
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:08,486 INFO epoch # 7132 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006249470119655598
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:08,504 INFO epoch # 7133 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006204853878443828
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:08,523 INFO epoch # 7134 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006229426257050363
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:08,541 INFO epoch # 7135 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0062650415748066735
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:08,560 INFO epoch # 7136 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006185578804434044
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:08,579 INFO epoch # 7137 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006229898546735058
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:08,598 INFO epoch # 7138 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006220763556484599
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:08,617 INFO epoch # 7139 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006213624572410481
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:08,635 INFO epoch # 7140 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0061898292442492675
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:08,635 INFO *** epoch 7140, rolling-avg-loss (window=10)= 0.006217366837881854
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:08,653 INFO epoch # 7141 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006229342536244076
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:08,672 INFO epoch # 7142 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006500286548543954
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:08,690 INFO epoch # 7143 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006193375927978195
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:08,708 INFO epoch # 7144 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006459579293732531
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:08,727 INFO epoch # 7145 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006249393903999589
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:08,745 INFO epoch # 7146 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006183415138366399
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:08,764 INFO epoch # 7147 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006212400308868382
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:08,782 INFO epoch # 7148 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0061972469848115
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:08,801 INFO epoch # 7149 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006219345774297835
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:08,820 INFO epoch # 7150 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006185922586155357
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:08,820 INFO *** epoch 7150, rolling-avg-loss (window=10)= 0.006263030900299782
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:08,838 INFO epoch # 7151 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0062712816361454315
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:08,856 INFO epoch # 7152 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006197786708071362
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:08,875 INFO epoch # 7153 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006213451011717552
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:08,893 INFO epoch # 7154 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0061773909928888315
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:08,911 INFO epoch # 7155 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0062760792243352626
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:08,930 INFO epoch # 7156 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006203688200912438
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:08,948 INFO epoch # 7157 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.009329301505204057
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:08,967 INFO epoch # 7158 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006217123467649799
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:08,986 INFO epoch # 7159 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0062220919789979234
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:09,004 INFO epoch # 7160 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006256864020542707
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:09,004 INFO *** epoch 7160, rolling-avg-loss (window=10)= 0.006536505874646536
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:09,023 INFO epoch # 7161 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006259664773097029
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:09,042 INFO epoch # 7162 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006196056572662201
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:09,060 INFO epoch # 7163 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006226364741451107
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:09,078 INFO epoch # 7164 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006236108765733661
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:09,097 INFO epoch # 7165 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006184076362842461
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:09,115 INFO epoch # 7166 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006219519098522142
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:09,133 INFO epoch # 7167 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006230259026779095
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:09,152 INFO epoch # 7168 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006205929181305692
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:09,171 INFO epoch # 7169 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006204006942425622
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:09,189 INFO epoch # 7170 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006195804453454912
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:09,189 INFO *** epoch 7170, rolling-avg-loss (window=10)= 0.006215778991827392
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:09,208 INFO epoch # 7171 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006170443522933056
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:09,226 INFO epoch # 7172 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006258596109546488
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:09,245 INFO epoch # 7173 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006243090516363736
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:09,263 INFO epoch # 7174 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0061998219025554135
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:09,281 INFO epoch # 7175 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006191734537424054
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:09,299 INFO epoch # 7176 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006210361112607643
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:09,318 INFO epoch # 7177 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006220726099854801
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:09,336 INFO epoch # 7178 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0066536955200717784
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:09,355 INFO epoch # 7179 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006353857203066582
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:09,373 INFO epoch # 7180 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0062555262738897
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:09,373 INFO *** epoch 7180, rolling-avg-loss (window=10)= 0.0062757852798313255
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:09,392 INFO epoch # 7181 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006311843215371482
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:09,410 INFO epoch # 7182 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006278791744989576
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:09,429 INFO epoch # 7183 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0061897473606222775
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:09,447 INFO epoch # 7184 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006287644733674824
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:09,465 INFO epoch # 7185 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006474266676377738
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:09,484 INFO epoch # 7186 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006218596641701879
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:09,502 INFO epoch # 7187 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0061607039297086885
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:09,520 INFO epoch # 7188 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006186245867866091
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:09,538 INFO epoch # 7189 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006230726303328993
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:09,557 INFO epoch # 7190 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006161016626720084
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:09,557 INFO *** epoch 7190, rolling-avg-loss (window=10)= 0.006249958310036163
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:09,576 INFO epoch # 7191 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0069392587793117855
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:09,594 INFO epoch # 7192 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006206377594935475
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:09,613 INFO epoch # 7193 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006248928344575688
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:09,632 INFO epoch # 7194 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006258433604671154
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:09,650 INFO epoch # 7195 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006189135401655221
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:09,668 INFO epoch # 7196 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006193244924361352
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:09,687 INFO epoch # 7197 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006371815095917555
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:09,705 INFO epoch # 7198 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006192335240484681
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:09,723 INFO epoch # 7199 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006241905899514677
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:09,742 INFO epoch # 7200 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006189367955812486
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:09,742 INFO *** epoch 7200, rolling-avg-loss (window=10)= 0.006303080284124007
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:09,760 INFO epoch # 7201 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006168444315335364
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:09,779 INFO epoch # 7202 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006519399234093726
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:09,798 INFO epoch # 7203 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006166078914247919
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:09,816 INFO epoch # 7204 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00826404798499425
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:09,835 INFO epoch # 7205 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006201307436640491
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:09,853 INFO epoch # 7206 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0061841103561164346
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:09,871 INFO epoch # 7207 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006302906680502929
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:09,889 INFO epoch # 7208 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006181867753184633
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:09,908 INFO epoch # 7209 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0061965819731995
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:09,926 INFO epoch # 7210 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006218679569428787
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:09,926 INFO *** epoch 7210, rolling-avg-loss (window=10)= 0.0064403424217744035
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:09,945 INFO epoch # 7211 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006215065448486712
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:09,963 INFO epoch # 7212 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006188204944919562
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:09,982 INFO epoch # 7213 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006587477630091598
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:10,001 INFO epoch # 7214 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006174140264192829
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:10,019 INFO epoch # 7215 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00617122947005555
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:10,039 INFO epoch # 7216 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006220519564521965
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:10,058 INFO epoch # 7217 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006193478729983326
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:10,076 INFO epoch # 7218 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006201608852279605
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:10,095 INFO epoch # 7219 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006238152236619499
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:10,113 INFO epoch # 7220 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006155611165013397
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:10,113 INFO *** epoch 7220, rolling-avg-loss (window=10)= 0.006234548830616404
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:10,132 INFO epoch # 7221 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0062038056312303524
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:10,151 INFO epoch # 7222 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006239500162337208
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:10,170 INFO epoch # 7223 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006165211398183601
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:10,189 INFO epoch # 7224 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006179104599141283
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:10,208 INFO epoch # 7225 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006188240939081879
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:10,226 INFO epoch # 7226 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006261093520151917
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:10,246 INFO epoch # 7227 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006174509311676957
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:10,265 INFO epoch # 7228 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00620737149802153
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:10,283 INFO epoch # 7229 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006203867465956137
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:10,301 INFO epoch # 7230 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0061687290071859024
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:10,301 INFO *** epoch 7230, rolling-avg-loss (window=10)= 0.0061991433532966765
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:10,320 INFO epoch # 7231 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0062080224124656525
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:10,338 INFO epoch # 7232 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006169230840896489
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:10,357 INFO epoch # 7233 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006176367391162785
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:10,376 INFO epoch # 7234 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006353183172905119
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:10,394 INFO epoch # 7235 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006465833375841612
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:10,413 INFO epoch # 7236 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006274643619690323
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:10,431 INFO epoch # 7237 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006510114599223016
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:10,450 INFO epoch # 7238 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006228083791938843
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:10,468 INFO epoch # 7239 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006183062909258297
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:10,487 INFO epoch # 7240 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00616397140402114
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:10,487 INFO *** epoch 7240, rolling-avg-loss (window=10)= 0.0062732513517403275
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:10,505 INFO epoch # 7241 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00615597632349818
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:10,523 INFO epoch # 7242 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006202481250511482
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:10,541 INFO epoch # 7243 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006154178045107983
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:10,561 INFO epoch # 7244 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006339837946143234
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:10,580 INFO epoch # 7245 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006189177853229921
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:10,599 INFO epoch # 7246 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006197573060489958
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:10,618 INFO epoch # 7247 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006177551644213963
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:10,637 INFO epoch # 7248 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006197698145115282
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:10,656 INFO epoch # 7249 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006162240180856315
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:10,674 INFO epoch # 7250 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006331888995191548
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:10,674 INFO *** epoch 7250, rolling-avg-loss (window=10)= 0.006210860344435787
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:10,692 INFO epoch # 7251 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006180475360451965
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:10,710 INFO epoch # 7252 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0061708132379862946
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:10,729 INFO epoch # 7253 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006423622697184328
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:10,747 INFO epoch # 7254 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006279935099883005
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:10,766 INFO epoch # 7255 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006184500565723283
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:10,784 INFO epoch # 7256 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006165908736875281
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:10,803 INFO epoch # 7257 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006332105422188761
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:10,821 INFO epoch # 7258 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006211792086105561
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:10,840 INFO epoch # 7259 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00618062313151313
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:10,859 INFO epoch # 7260 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006316702267213259
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:10,859 INFO *** epoch 7260, rolling-avg-loss (window=10)= 0.006244647860512487
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:10,877 INFO epoch # 7261 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006173260699142702
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:10,895 INFO epoch # 7262 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006185645084769931
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:10,913 INFO epoch # 7263 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006167664541862905
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:10,932 INFO epoch # 7264 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006266736407269491
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:10,950 INFO epoch # 7265 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006196773330884753
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:10,969 INFO epoch # 7266 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006503495191282127
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:10,987 INFO epoch # 7267 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00616777989489492
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:11,006 INFO epoch # 7268 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006149103344796458
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:11,025 INFO epoch # 7269 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006158342948765494
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:11,043 INFO epoch # 7270 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0062746660187258385
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:11,043 INFO *** epoch 7270, rolling-avg-loss (window=10)= 0.006224346746239462
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:11,062 INFO epoch # 7271 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006169382402731571
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:11,080 INFO epoch # 7272 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006160390228615142
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:11,099 INFO epoch # 7273 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0063257480069296435
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:11,117 INFO epoch # 7274 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006177095252496656
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:11,135 INFO epoch # 7275 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006204597142641433
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:11,153 INFO epoch # 7276 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0062390924722421914
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:11,172 INFO epoch # 7277 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006340741954772966
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:11,190 INFO epoch # 7278 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0065363161484128796
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:11,209 INFO epoch # 7279 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.009226036014297279
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:11,227 INFO epoch # 7280 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006195199261128437
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:11,227 INFO *** epoch 7280, rolling-avg-loss (window=10)= 0.00655745988842682
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:11,246 INFO epoch # 7281 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006193270375661086
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:11,265 INFO epoch # 7282 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006217899092007428
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:11,283 INFO epoch # 7283 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006512220945296576
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:11,302 INFO epoch # 7284 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006285563576966524
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:11,320 INFO epoch # 7285 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006172946727019735
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:11,338 INFO epoch # 7286 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006187240345752798
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:11,356 INFO epoch # 7287 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00620691587755573
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:11,375 INFO epoch # 7288 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006201994820003165
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:11,393 INFO epoch # 7289 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00615851252223365
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:11,412 INFO epoch # 7290 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006201219053764362
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:11,412 INFO *** epoch 7290, rolling-avg-loss (window=10)= 0.006233778333626106
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:11,430 INFO epoch # 7291 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006171333065140061
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:11,449 INFO epoch # 7292 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006159289452625671
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:11,467 INFO epoch # 7293 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006192577668116428
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:11,486 INFO epoch # 7294 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006160106440802338
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:11,504 INFO epoch # 7295 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006184657511767
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:11,522 INFO epoch # 7296 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006153606616862817
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:11,540 INFO epoch # 7297 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006130181165644899
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:11,558 INFO epoch # 7298 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006232181363884592
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:11,577 INFO epoch # 7299 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006143238020740682
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:11,596 INFO epoch # 7300 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0066980803676415235
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:11,596 INFO *** epoch 7300, rolling-avg-loss (window=10)= 0.0062225251673226015
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:11,614 INFO epoch # 7301 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006181928722071461
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:11,633 INFO epoch # 7302 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0061730341403745115
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:11,652 INFO epoch # 7303 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006168605828861473
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:11,670 INFO epoch # 7304 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00622009122162126
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:11,688 INFO epoch # 7305 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006222167859959882
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:11,707 INFO epoch # 7306 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006139729852293385
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:11,725 INFO epoch # 7307 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006130735255283071
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:11,743 INFO epoch # 7308 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0064924096295726486
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:11,761 INFO epoch # 7309 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006186376365803881
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:11,780 INFO epoch # 7310 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006128553601229214
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:11,780 INFO *** epoch 7310, rolling-avg-loss (window=10)= 0.006204363247707079
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:11,798 INFO epoch # 7311 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006136950349173276
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:11,817 INFO epoch # 7312 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006199997893418185
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:11,836 INFO epoch # 7313 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006175528771564132
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:11,854 INFO epoch # 7314 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006136308358691167
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:11,872 INFO epoch # 7315 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00627040196195594
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:11,891 INFO epoch # 7316 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006148660930193728
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:11,909 INFO epoch # 7317 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006206409980222816
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:11,927 INFO epoch # 7318 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006277795779169537
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:11,946 INFO epoch # 7319 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006217818379809614
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:11,964 INFO epoch # 7320 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006196002894284902
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:11,964 INFO *** epoch 7320, rolling-avg-loss (window=10)= 0.00619658752984833
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:11,982 INFO epoch # 7321 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006168883708596695
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:12,001 INFO epoch # 7322 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006168213785713306
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:12,020 INFO epoch # 7323 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006229897597222589
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:12,039 INFO epoch # 7324 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006209877028595656
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:12,057 INFO epoch # 7325 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006127611643023556
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:12,075 INFO epoch # 7326 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006130942205345491
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:12,094 INFO epoch # 7327 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006173108697112184
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:12,112 INFO epoch # 7328 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0061453151574824005
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:12,130 INFO epoch # 7329 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006253063227632083
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:12,149 INFO epoch # 7330 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006145536804979201
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:12,149 INFO *** epoch 7330, rolling-avg-loss (window=10)= 0.006175244985570316
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:12,167 INFO epoch # 7331 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006140239889646182
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:12,185 INFO epoch # 7332 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006349951163429068
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:12,204 INFO epoch # 7333 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006197560578584671
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:12,222 INFO epoch # 7334 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006176683513331227
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:12,241 INFO epoch # 7335 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0061632978067791555
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:12,259 INFO epoch # 7336 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006130995221610647
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:12,278 INFO epoch # 7337 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006133957376732724
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:12,296 INFO epoch # 7338 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006221952746273018
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:12,314 INFO epoch # 7339 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006143243157566758
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:12,332 INFO epoch # 7340 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006142959329736186
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:12,332 INFO *** epoch 7340, rolling-avg-loss (window=10)= 0.006180084078368964
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:12,351 INFO epoch # 7341 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006195326870511053
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:12,369 INFO epoch # 7342 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006134585626568878
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:12,388 INFO epoch # 7343 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006141357520391466
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:12,406 INFO epoch # 7344 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0061441544312401675
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:12,425 INFO epoch # 7345 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006133607868832769
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:12,443 INFO epoch # 7346 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006174654812639346
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:12,462 INFO epoch # 7347 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0062180592758522835
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:12,480 INFO epoch # 7348 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0062055578564468306
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:12,498 INFO epoch # 7349 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006155847146146698
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:12,517 INFO epoch # 7350 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006240779915970052
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:12,517 INFO *** epoch 7350, rolling-avg-loss (window=10)= 0.006174393132459955
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:12,535 INFO epoch # 7351 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006377439945936203
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:12,553 INFO epoch # 7352 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006208552764292108
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:12,571 INFO epoch # 7353 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006180843156471383
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:12,590 INFO epoch # 7354 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006268750559684122
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:12,608 INFO epoch # 7355 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006332344582915539
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:12,627 INFO epoch # 7356 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006156845767691266
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:12,646 INFO epoch # 7357 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006495263627584791
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:12,664 INFO epoch # 7358 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006170941222080728
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:12,683 INFO epoch # 7359 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006181413078593323
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:12,701 INFO epoch # 7360 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006151317673356971
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:12,701 INFO *** epoch 7360, rolling-avg-loss (window=10)= 0.006252371237860643
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:12,719 INFO epoch # 7361 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.008201481108699227
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:12,737 INFO epoch # 7362 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006160273263958516
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:12,756 INFO epoch # 7363 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006190036052430514
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:12,774 INFO epoch # 7364 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006131747519248165
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:12,792 INFO epoch # 7365 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00619200929577346
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:12,811 INFO epoch # 7366 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006255115913518239
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:12,829 INFO epoch # 7367 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006147486528789159
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:12,848 INFO epoch # 7368 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006116376378486166
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:12,866 INFO epoch # 7369 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006139447690657107
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:12,885 INFO epoch # 7370 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006108220595706371
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:12,885 INFO *** epoch 7370, rolling-avg-loss (window=10)= 0.006364219434726692
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:12,903 INFO epoch # 7371 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006123135912275757
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:12,921 INFO epoch # 7372 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006196046848344849
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:12,939 INFO epoch # 7373 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0061367614653136116
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:12,957 INFO epoch # 7374 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006274552306422265
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:12,976 INFO epoch # 7375 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006192054315761197
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:12,994 INFO epoch # 7376 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006114006775533198
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:13,014 INFO epoch # 7377 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006117199007348972
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:13,033 INFO epoch # 7378 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006184204001328908
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:13,052 INFO epoch # 7379 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006142478738183854
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:13,070 INFO epoch # 7380 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006202115077030612
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:13,070 INFO *** epoch 7380, rolling-avg-loss (window=10)= 0.006168255444754323
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:13,089 INFO epoch # 7381 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006144617131212726
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:13,107 INFO epoch # 7382 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0061301532841753215
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:13,125 INFO epoch # 7383 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006131015317805577
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:13,143 INFO epoch # 7384 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006185938880662434
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:13,161 INFO epoch # 7385 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006100991005951073
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:13,180 INFO epoch # 7386 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006110170026659034
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:13,198 INFO epoch # 7387 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.008148394408635795
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:13,217 INFO epoch # 7388 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006150722299935296
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:13,235 INFO epoch # 7389 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006141825931990752
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:13,254 INFO epoch # 7390 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006459831860411214
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:13,254 INFO *** epoch 7390, rolling-avg-loss (window=10)= 0.006370366014743922
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:13,272 INFO epoch # 7391 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006253271032619523
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:13,291 INFO epoch # 7392 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00623801277106395
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:13,309 INFO epoch # 7393 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00611977690277854
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:13,327 INFO epoch # 7394 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006190267456986476
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:13,345 INFO epoch # 7395 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00621140865405323
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:13,364 INFO epoch # 7396 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006119457473687362
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:13,382 INFO epoch # 7397 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006205873403814621
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:13,400 INFO epoch # 7398 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006218579215783393
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:13,419 INFO epoch # 7399 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006138843062217347
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:13,437 INFO epoch # 7400 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006114203781180549
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:13,437 INFO *** epoch 7400, rolling-avg-loss (window=10)= 0.006180969375418499
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:13,456 INFO epoch # 7401 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006145174713310553
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:13,475 INFO epoch # 7402 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006201397656695917
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:13,493 INFO epoch # 7403 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006161600547784474
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:13,511 INFO epoch # 7404 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006193401521159103
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:13,530 INFO epoch # 7405 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006121847436588723
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:13,549 INFO epoch # 7406 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006297454921877943
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:13,567 INFO epoch # 7407 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006123948034655768
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:13,585 INFO epoch # 7408 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006170727872813586
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:13,604 INFO epoch # 7409 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006134854778792942
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:13,622 INFO epoch # 7410 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006204690205777297
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:13,622 INFO *** epoch 7410, rolling-avg-loss (window=10)= 0.00617550976894563
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:13,641 INFO epoch # 7411 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006119567882706178
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:13,659 INFO epoch # 7412 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006086828112529474
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:13,678 INFO epoch # 7413 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0061490717707783915
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:13,697 INFO epoch # 7414 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0061274263316590805
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:13,715 INFO epoch # 7415 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006111859023803845
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:13,733 INFO epoch # 7416 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006232774001546204
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:13,751 INFO epoch # 7417 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006292161357123405
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:13,770 INFO epoch # 7418 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006265135420107981
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:13,788 INFO epoch # 7419 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0061441242942237295
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:13,807 INFO epoch # 7420 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006200906394951744
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:13,807 INFO *** epoch 7420, rolling-avg-loss (window=10)= 0.006172985458943003
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:13,825 INFO epoch # 7421 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0062585007362940814
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:13,844 INFO epoch # 7422 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006128825971245533
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:13,862 INFO epoch # 7423 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0062959597271401435
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:13,881 INFO epoch # 7424 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00615189882228151
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:13,899 INFO epoch # 7425 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0061500339761551
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:13,917 INFO epoch # 7426 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0061030917677271646
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:13,936 INFO epoch # 7427 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006156777180876816
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:13,954 INFO epoch # 7428 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006249794529139763
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:13,972 INFO epoch # 7429 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006136144060292281
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:13,990 INFO epoch # 7430 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006111337206675671
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:13,991 INFO *** epoch 7430, rolling-avg-loss (window=10)= 0.006174236397782806
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:14,009 INFO epoch # 7431 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006108831159508554
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:14,028 INFO epoch # 7432 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006096470948250499
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:14,046 INFO epoch # 7433 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00664693109865766
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:14,065 INFO epoch # 7434 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006259687012061477
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:14,083 INFO epoch # 7435 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006189122534124181
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:14,102 INFO epoch # 7436 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006122313945525093
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:14,120 INFO epoch # 7437 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0065320521644025575
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:14,138 INFO epoch # 7438 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006141458190541016
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:14,156 INFO epoch # 7439 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0061458324489649385
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:14,175 INFO epoch # 7440 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00655166575597832
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:14,175 INFO *** epoch 7440, rolling-avg-loss (window=10)= 0.0062794365258014295
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:14,193 INFO epoch # 7441 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006134421102615306
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:14,212 INFO epoch # 7442 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006115107447840273
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:14,230 INFO epoch # 7443 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006123784914962016
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:14,249 INFO epoch # 7444 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006144378992757993
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:14,268 INFO epoch # 7445 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00621155061526224
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:14,287 INFO epoch # 7446 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006113620169344358
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:14,305 INFO epoch # 7447 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0060931731859454885
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:14,323 INFO epoch # 7448 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006204118071764242
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:14,341 INFO epoch # 7449 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0064099169612745754
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:14,360 INFO epoch # 7450 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006142969516076846
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:14,360 INFO *** epoch 7450, rolling-avg-loss (window=10)= 0.006169304097784334
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:14,378 INFO epoch # 7451 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006117218883446185
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:14,396 INFO epoch # 7452 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006172975692606997
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:14,415 INFO epoch # 7453 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006329237701720558
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:14,433 INFO epoch # 7454 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006301314599113539
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:14,452 INFO epoch # 7455 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006114699801401002
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:14,470 INFO epoch # 7456 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006108593250246486
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:14,489 INFO epoch # 7457 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006369008533511078
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:14,507 INFO epoch # 7458 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006117126846220344
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:14,525 INFO epoch # 7459 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006110584628913784
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:14,544 INFO epoch # 7460 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006114090690971352
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:14,544 INFO *** epoch 7460, rolling-avg-loss (window=10)= 0.0061854850628151326
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:14,562 INFO epoch # 7461 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006173908979690168
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:14,580 INFO epoch # 7462 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006384819069353398
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:14,598 INFO epoch # 7463 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006229553015145939
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:14,617 INFO epoch # 7464 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006134265990112908
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:14,636 INFO epoch # 7465 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006100002196035348
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:14,654 INFO epoch # 7466 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006124929372163024
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:14,673 INFO epoch # 7467 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006300977176579181
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:14,692 INFO epoch # 7468 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006457219977164641
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:14,710 INFO epoch # 7469 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0061759601630910765
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:14,728 INFO epoch # 7470 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006099188296502689
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:14,728 INFO *** epoch 7470, rolling-avg-loss (window=10)= 0.006218082423583837
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:14,747 INFO epoch # 7471 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006574446928425459
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:14,765 INFO epoch # 7472 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006123815801402088
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:14,783 INFO epoch # 7473 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006114775758760516
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:14,801 INFO epoch # 7474 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.009371264895889908
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:14,820 INFO epoch # 7475 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006158660882647382
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:14,838 INFO epoch # 7476 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006135372750577517
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:14,857 INFO epoch # 7477 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006093990185036091
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:14,875 INFO epoch # 7478 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006178337356686825
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:14,894 INFO epoch # 7479 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006128268265456427
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:14,913 INFO epoch # 7480 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006237612993572839
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:14,913 INFO *** epoch 7480, rolling-avg-loss (window=10)= 0.006511654581845505
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:14,931 INFO epoch # 7481 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006096231772971805
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:14,949 INFO epoch # 7482 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006200422671099659
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:14,967 INFO epoch # 7483 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006108321718784282
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:14,986 INFO epoch # 7484 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006079753991798498
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:15,004 INFO epoch # 7485 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006157975036330754
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:15,023 INFO epoch # 7486 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006093034000514308
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:15,041 INFO epoch # 7487 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006139982131571742
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:15,060 INFO epoch # 7488 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0061186294187791646
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:15,078 INFO epoch # 7489 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006090725719332113
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:15,097 INFO epoch # 7490 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006121172609709902
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:15,097 INFO *** epoch 7490, rolling-avg-loss (window=10)= 0.006120624907089223
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:15,115 INFO epoch # 7491 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006105717086029472
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:15,134 INFO epoch # 7492 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006073407726944424
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:15,153 INFO epoch # 7493 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006201818490808364
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:15,171 INFO epoch # 7494 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006169338670588331
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:15,189 INFO epoch # 7495 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00609918740883586
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:15,207 INFO epoch # 7496 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006104543026594911
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:15,226 INFO epoch # 7497 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006166624458273873
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:15,245 INFO epoch # 7498 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006133260703791166
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:15,263 INFO epoch # 7499 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006091062801715452
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:15,282 INFO epoch # 7500 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006092916511988733
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:15,282 INFO *** epoch 7500, rolling-avg-loss (window=10)= 0.006123787688557059
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:15,300 INFO epoch # 7501 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006103328756580595
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:15,319 INFO epoch # 7502 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006133810438768705
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:15,337 INFO epoch # 7503 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006138061347883195
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:15,355 INFO epoch # 7504 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006073428114177659
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:15,374 INFO epoch # 7505 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006138564604043495
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:15,392 INFO epoch # 7506 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0061185469894553535
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:15,410 INFO epoch # 7507 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006117155302490573
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:15,429 INFO epoch # 7508 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006100201146182371
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:15,447 INFO epoch # 7509 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006078871516365325
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:15,466 INFO epoch # 7510 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006104089698055759
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:15,466 INFO *** epoch 7510, rolling-avg-loss (window=10)= 0.006110605791400303
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:15,485 INFO epoch # 7511 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006079036966184503
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:15,503 INFO epoch # 7512 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006172692126710899
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:15,522 INFO epoch # 7513 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006121950140368426
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:15,540 INFO epoch # 7514 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006153399031973095
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:15,558 INFO epoch # 7515 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006085142013034783
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:15,577 INFO epoch # 7516 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006135108127637068
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:15,595 INFO epoch # 7517 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006083205767936306
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:15,613 INFO epoch # 7518 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006082092339056544
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:15,631 INFO epoch # 7519 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006111159498686902
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:15,650 INFO epoch # 7520 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006152943169581704
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:15,650 INFO *** epoch 7520, rolling-avg-loss (window=10)= 0.006117672918117023
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:15,669 INFO epoch # 7521 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006115857911936473
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:15,688 INFO epoch # 7522 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006294904327660333
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:15,706 INFO epoch # 7523 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006109519687015563
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:15,725 INFO epoch # 7524 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006100061069446383
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:15,743 INFO epoch # 7525 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006217976238986012
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:15,761 INFO epoch # 7526 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006194254434376489
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:15,780 INFO epoch # 7527 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006137721615232294
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:15,798 INFO epoch # 7528 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006078467016777722
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:15,816 INFO epoch # 7529 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00608889339491725
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:15,835 INFO epoch # 7530 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006130457390099764
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:15,835 INFO *** epoch 7530, rolling-avg-loss (window=10)= 0.006146811308644829
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:15,853 INFO epoch # 7531 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00613403094757814
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:15,871 INFO epoch # 7532 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006111073420470348
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:15,890 INFO epoch # 7533 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0060955084445595276
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:15,909 INFO epoch # 7534 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00609881263517309
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:15,927 INFO epoch # 7535 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006090437440434471
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:15,946 INFO epoch # 7536 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006108174737164518
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:15,964 INFO epoch # 7537 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0060770325326302554
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:15,982 INFO epoch # 7538 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00611803776700981
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:16,000 INFO epoch # 7539 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0060702665487042395
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:16,018 INFO epoch # 7540 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006096179920859868
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:16,019 INFO *** epoch 7540, rolling-avg-loss (window=10)= 0.006099955439458427
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:16,037 INFO epoch # 7541 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0061185369559098035
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:16,055 INFO epoch # 7542 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006354836925311247
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:16,075 INFO epoch # 7543 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0060663449239655165
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:16,094 INFO epoch # 7544 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00608005834146752
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:16,113 INFO epoch # 7545 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006118010769569082
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:16,132 INFO epoch # 7546 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006079318038246129
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:16,150 INFO epoch # 7547 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006170956839923747
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:16,168 INFO epoch # 7548 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006067099358915584
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:16,187 INFO epoch # 7549 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00609780008380767
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:16,205 INFO epoch # 7550 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006062876433134079
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:16,205 INFO *** epoch 7550, rolling-avg-loss (window=10)= 0.006121583867025038
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:16,223 INFO epoch # 7551 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006070173571060877
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:16,242 INFO epoch # 7552 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006088307585741859
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:16,260 INFO epoch # 7553 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006055035912140738
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:16,278 INFO epoch # 7554 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006083175696403487
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:16,297 INFO epoch # 7555 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006179908392368816
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:16,316 INFO epoch # 7556 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006118987439549528
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:16,334 INFO epoch # 7557 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0060560685851669405
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:16,353 INFO epoch # 7558 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00608477118294104
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:16,371 INFO epoch # 7559 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006251659975532675
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:16,389 INFO epoch # 7560 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006081211446144152
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:16,389 INFO *** epoch 7560, rolling-avg-loss (window=10)= 0.006106929978705012
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:16,407 INFO epoch # 7561 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00622050079255132
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:16,426 INFO epoch # 7562 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0060683314040943515
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:16,444 INFO epoch # 7563 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006078519942093408
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:16,462 INFO epoch # 7564 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006124595969595248
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:16,481 INFO epoch # 7565 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0063153768169286195
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:16,500 INFO epoch # 7566 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0061621355525858235
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:16,518 INFO epoch # 7567 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006053216762666125
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:16,537 INFO epoch # 7568 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006109182468208019
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:16,555 INFO epoch # 7569 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006102513907535467
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:16,574 INFO epoch # 7570 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006087920650315937
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:16,574 INFO *** epoch 7570, rolling-avg-loss (window=10)= 0.006132229426657432
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:16,592 INFO epoch # 7571 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00606523968235706
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:16,610 INFO epoch # 7572 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006093544623581693
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:16,628 INFO epoch # 7573 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006064103148673894
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:16,647 INFO epoch # 7574 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006515232133097015
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:16,665 INFO epoch # 7575 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006102906510932371
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:16,684 INFO epoch # 7576 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0075671006306947675
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:16,703 INFO epoch # 7577 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006092550960602239
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:16,721 INFO epoch # 7578 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006047675907211669
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:16,740 INFO epoch # 7579 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006224439264769899
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:16,758 INFO epoch # 7580 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006076859575841809
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:16,759 INFO *** epoch 7580, rolling-avg-loss (window=10)= 0.006284965243776241
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:16,777 INFO epoch # 7581 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006081328370783012
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:16,795 INFO epoch # 7582 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006126092379417969
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:16,813 INFO epoch # 7583 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006121272912423592
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:16,832 INFO epoch # 7584 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0061635506244783755
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:16,850 INFO epoch # 7585 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006066501337045338
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:16,868 INFO epoch # 7586 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006262225586397108
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:16,887 INFO epoch # 7587 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007554169660579646
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:16,906 INFO epoch # 7588 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006131214264314622
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:16,924 INFO epoch # 7589 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006108026493166108
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:16,943 INFO epoch # 7590 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00609715708924341
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:16,943 INFO *** epoch 7590, rolling-avg-loss (window=10)= 0.006271153871784918
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:16,961 INFO epoch # 7591 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006091109517001314
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:16,979 INFO epoch # 7592 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006085698692913866
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:16,998 INFO epoch # 7593 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006116372966062045
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:17,016 INFO epoch # 7594 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006041121019734419
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:17,034 INFO epoch # 7595 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006048122215361218
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:17,052 INFO epoch # 7596 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006146710948087275
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:17,071 INFO epoch # 7597 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0061529859995062
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:17,089 INFO epoch # 7598 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006103328167228028
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:17,108 INFO epoch # 7599 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006326368969894247
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:17,126 INFO epoch # 7600 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006108454759669257
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:17,126 INFO *** epoch 7600, rolling-avg-loss (window=10)= 0.006122027325545787
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:17,145 INFO epoch # 7601 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007487160408345517
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:17,163 INFO epoch # 7602 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006092370673286496
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:17,182 INFO epoch # 7603 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006079668950405903
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:17,200 INFO epoch # 7604 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0060624885118159
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:17,218 INFO epoch # 7605 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006103853105742019
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:17,236 INFO epoch # 7606 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006123552735516569
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:17,255 INFO epoch # 7607 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006122078113548923
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:17,273 INFO epoch # 7608 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006174089081468992
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:17,291 INFO epoch # 7609 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006109330806793878
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:17,310 INFO epoch # 7610 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0061992180890229065
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:17,310 INFO *** epoch 7610, rolling-avg-loss (window=10)= 0.00625538104759471
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:17,329 INFO epoch # 7611 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006536249831697205
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:17,347 INFO epoch # 7612 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006486428130301647
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:17,366 INFO epoch # 7613 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0060469131349236704
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:17,384 INFO epoch # 7614 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00606581097599701
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:17,402 INFO epoch # 7615 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006064769626391353
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:17,420 INFO epoch # 7616 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0064667091028240975
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:17,439 INFO epoch # 7617 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006108010857133195
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:17,457 INFO epoch # 7618 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006069672119338065
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:17,475 INFO epoch # 7619 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006071287647500867
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:17,494 INFO epoch # 7620 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0060584511229535565
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:17,494 INFO *** epoch 7620, rolling-avg-loss (window=10)= 0.006197430254906067
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:17,512 INFO epoch # 7621 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006114128944318509
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:17,531 INFO epoch # 7622 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0061475696093111765
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:17,549 INFO epoch # 7623 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0060976581371505745
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:17,568 INFO epoch # 7624 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006054671433957992
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:17,586 INFO epoch # 7625 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0060936316185689066
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:17,604 INFO epoch # 7626 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00607483477142523
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:17,622 INFO epoch # 7627 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006122158840298653
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:17,641 INFO epoch # 7628 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006326910584903089
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:17,659 INFO epoch # 7629 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0060793065204052255
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:17,677 INFO epoch # 7630 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006058808750822209
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:17,678 INFO *** epoch 7630, rolling-avg-loss (window=10)= 0.0061169679211161565
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:17,696 INFO epoch # 7631 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006064145571144763
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:17,715 INFO epoch # 7632 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006071159572456963
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:17,733 INFO epoch # 7633 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00607180248334771
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:17,752 INFO epoch # 7634 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006060004452592693
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:17,770 INFO epoch # 7635 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006098857171309646
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:17,789 INFO epoch # 7636 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006046186117600882
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:17,807 INFO epoch # 7637 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006073615724744741
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:17,825 INFO epoch # 7638 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00605722145337495
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:17,843 INFO epoch # 7639 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006051828364434186
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:17,862 INFO epoch # 7640 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006045883594197221
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:17,862 INFO *** epoch 7640, rolling-avg-loss (window=10)= 0.006064070450520376
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:17,880 INFO epoch # 7641 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006050771495210938
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:17,899 INFO epoch # 7642 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0061141327387304045
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:17,917 INFO epoch # 7643 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0061342211010924075
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:17,936 INFO epoch # 7644 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006046620625056676
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:17,954 INFO epoch # 7645 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006077128171455115
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:17,973 INFO epoch # 7646 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006035322119714692
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:17,991 INFO epoch # 7647 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006055600500985747
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:18,010 INFO epoch # 7648 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006172246008645743
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:18,028 INFO epoch # 7649 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006102958981500706
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:18,046 INFO epoch # 7650 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006044011668564053
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:18,046 INFO *** epoch 7650, rolling-avg-loss (window=10)= 0.006083301341095648
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:18,064 INFO epoch # 7651 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006042869685188634
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:18,083 INFO epoch # 7652 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006042447421350516
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:18,101 INFO epoch # 7653 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006036269727701438
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:18,120 INFO epoch # 7654 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006045242473192047
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:18,139 INFO epoch # 7655 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006247806300962111
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:18,157 INFO epoch # 7656 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006099153968534665
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:18,176 INFO epoch # 7657 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006052171058399836
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:18,194 INFO epoch # 7658 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0061113456831662916
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:18,212 INFO epoch # 7659 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0060599043463298585
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:18,230 INFO epoch # 7660 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00605149078546674
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:18,230 INFO *** epoch 7660, rolling-avg-loss (window=10)= 0.006078870145029214
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:18,249 INFO epoch # 7661 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006055665537132882
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:18,267 INFO epoch # 7662 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00608640382415615
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:18,285 INFO epoch # 7663 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006052593966160202
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:18,304 INFO epoch # 7664 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0060435926061472856
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:18,322 INFO epoch # 7665 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0060564992963918485
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:18,341 INFO epoch # 7666 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006046999104000861
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:18,359 INFO epoch # 7667 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006117782286310103
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:18,378 INFO epoch # 7668 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0060220788946026005
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:18,396 INFO epoch # 7669 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006027089159033494
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:18,414 INFO epoch # 7670 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006087358124204911
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:18,415 INFO *** epoch 7670, rolling-avg-loss (window=10)= 0.006059606279814033
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:18,433 INFO epoch # 7671 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007463574896974023
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:18,451 INFO epoch # 7672 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0061138409037084784
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:18,469 INFO epoch # 7673 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0060974120133323595
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:18,488 INFO epoch # 7674 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006135204788733972
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:18,506 INFO epoch # 7675 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0060281103069428355
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:18,525 INFO epoch # 7676 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006124064151663333
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:18,544 INFO epoch # 7677 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006079887494706782
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:18,562 INFO epoch # 7678 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006137402391686919
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:18,581 INFO epoch # 7679 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006161870031064609
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:18,599 INFO epoch # 7680 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006124554754933342
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:18,599 INFO *** epoch 7680, rolling-avg-loss (window=10)= 0.006246592173374666
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:18,617 INFO epoch # 7681 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00663388667817344
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:18,635 INFO epoch # 7682 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006051763935829513
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:18,654 INFO epoch # 7683 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006078398644604022
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:18,672 INFO epoch # 7684 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0060909074381925166
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:18,691 INFO epoch # 7685 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006105858308728784
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:18,709 INFO epoch # 7686 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006033035155269317
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:18,728 INFO epoch # 7687 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006153245209134184
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:18,746 INFO epoch # 7688 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006085479282774031
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:18,765 INFO epoch # 7689 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006057018093997613
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:18,783 INFO epoch # 7690 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00604699007817544
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:18,784 INFO *** epoch 7690, rolling-avg-loss (window=10)= 0.006133658282487886
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:18,802 INFO epoch # 7691 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006322810822894098
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:18,820 INFO epoch # 7692 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006063094489945797
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:18,839 INFO epoch # 7693 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006135879251814913
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:18,857 INFO epoch # 7694 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006043821282219142
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:18,876 INFO epoch # 7695 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006296045427006902
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:18,894 INFO epoch # 7696 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006027518011251232
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:18,913 INFO epoch # 7697 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006085482549679
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:18,931 INFO epoch # 7698 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0060256102988205384
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:18,950 INFO epoch # 7699 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006022244826453971
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:18,968 INFO epoch # 7700 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006074618755519623
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:18,968 INFO *** epoch 7700, rolling-avg-loss (window=10)= 0.006109712571560522
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:18,987 INFO epoch # 7701 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00604057902819477
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:19,005 INFO epoch # 7702 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0060657500580418855
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:19,024 INFO epoch # 7703 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006032458244590089
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:19,042 INFO epoch # 7704 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006059081366402097
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:19,060 INFO epoch # 7705 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006105829110310879
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:19,078 INFO epoch # 7706 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006068585207685828
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:19,097 INFO epoch # 7707 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0060166235471115215
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:19,115 INFO epoch # 7708 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006488438808446517
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:19,134 INFO epoch # 7709 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00601668774652353
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:19,153 INFO epoch # 7710 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006039030075044138
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:19,153 INFO *** epoch 7710, rolling-avg-loss (window=10)= 0.006093306319235126
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:19,172 INFO epoch # 7711 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0060943838689127006
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:19,191 INFO epoch # 7712 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006066549449315062
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:19,209 INFO epoch # 7713 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0059991733614879195
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:19,227 INFO epoch # 7714 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006022638350259513
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:19,246 INFO epoch # 7715 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006101189072069246
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:19,264 INFO epoch # 7716 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006081209721742198
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:19,282 INFO epoch # 7717 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006109952308179345
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:19,300 INFO epoch # 7718 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006036832022800809
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:19,319 INFO epoch # 7719 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006121554390119854
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:19,338 INFO epoch # 7720 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0061834939260734245
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:19,338 INFO *** epoch 7720, rolling-avg-loss (window=10)= 0.0060816976470960075
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:19,356 INFO epoch # 7721 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006035693848389201
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:19,375 INFO epoch # 7722 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006059512554202229
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:19,393 INFO epoch # 7723 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006052874960005283
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:19,411 INFO epoch # 7724 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006112126178777544
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:19,430 INFO epoch # 7725 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006028585816238774
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:19,448 INFO epoch # 7726 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006087865636800416
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:19,466 INFO epoch # 7727 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006076993377064355
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:19,484 INFO epoch # 7728 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006045341116987402
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:19,503 INFO epoch # 7729 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00603668825715431
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:19,522 INFO epoch # 7730 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006048662293324014
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:19,522 INFO *** epoch 7730, rolling-avg-loss (window=10)= 0.0060584344038943526
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:19,540 INFO epoch # 7731 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006072917822166346
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:19,559 INFO epoch # 7732 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006030924429069273
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:19,578 INFO epoch # 7733 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006057998507458251
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:19,596 INFO epoch # 7734 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0060327333958412055
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:19,614 INFO epoch # 7735 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006116123637184501
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:19,633 INFO epoch # 7736 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00617475519538857
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:19,651 INFO epoch # 7737 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006036036644218257
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:19,669 INFO epoch # 7738 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006065178193239262
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:19,687 INFO epoch # 7739 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006070866278605536
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:19,706 INFO epoch # 7740 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006017328771122266
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:19,706 INFO *** epoch 7740, rolling-avg-loss (window=10)= 0.006067486287429346
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:19,724 INFO epoch # 7741 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006045066278602462
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:19,743 INFO epoch # 7742 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006353025415592128
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:19,762 INFO epoch # 7743 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006146693554910598
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:19,780 INFO epoch # 7744 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006066103414923418
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:19,799 INFO epoch # 7745 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006072054638934787
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:19,817 INFO epoch # 7746 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006032849323673872
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:19,835 INFO epoch # 7747 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006066954869311303
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:19,853 INFO epoch # 7748 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0060174354366608895
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:19,871 INFO epoch # 7749 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006072043932363158
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:19,890 INFO epoch # 7750 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0060084551078034565
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:19,890 INFO *** epoch 7750, rolling-avg-loss (window=10)= 0.006088068197277608
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:19,908 INFO epoch # 7751 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006192599386849906
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:19,927 INFO epoch # 7752 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006075806380977156
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:19,945 INFO epoch # 7753 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006005159648339031
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:19,963 INFO epoch # 7754 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006060570874979021
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:19,982 INFO epoch # 7755 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006036342056177091
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:20,000 INFO epoch # 7756 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006012844172801124
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:20,019 INFO epoch # 7757 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006007210682582809
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:20,037 INFO epoch # 7758 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006070070125133498
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:20,055 INFO epoch # 7759 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006014655267790658
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:20,073 INFO epoch # 7760 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005998720083880471
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:20,074 INFO *** epoch 7760, rolling-avg-loss (window=10)= 0.006047397867951077
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:20,092 INFO epoch # 7761 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006034277408616617
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:20,110 INFO epoch # 7762 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006060704112314852
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:20,130 INFO epoch # 7763 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006024258458637632
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:20,148 INFO epoch # 7764 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006000877125188708
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:20,167 INFO epoch # 7765 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0060291891677479725
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:20,185 INFO epoch # 7766 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006000394216243876
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:20,204 INFO epoch # 7767 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006012125535562518
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:20,222 INFO epoch # 7768 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006066211077268235
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:20,240 INFO epoch # 7769 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006029133321135305
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:20,259 INFO epoch # 7770 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005998781427479116
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:20,259 INFO *** epoch 7770, rolling-avg-loss (window=10)= 0.006025595185019483
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:20,277 INFO epoch # 7771 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006045189129508799
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:20,295 INFO epoch # 7772 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006047164675692329
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:20,313 INFO epoch # 7773 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00602131040795939
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:20,332 INFO epoch # 7774 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006112874176324112
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:20,350 INFO epoch # 7775 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006084137301513692
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:20,369 INFO epoch # 7776 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006105967480834806
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:20,387 INFO epoch # 7777 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006117842141975416
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:20,405 INFO epoch # 7778 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006410165457054973
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:20,424 INFO epoch # 7779 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005995187666485435
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:20,442 INFO epoch # 7780 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006091545095841866
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:20,443 INFO *** epoch 7780, rolling-avg-loss (window=10)= 0.006103138353319082
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:20,461 INFO epoch # 7781 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005995014424115652
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:20,479 INFO epoch # 7782 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006055542387912283
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:20,497 INFO epoch # 7783 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005998298724080087
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:20,515 INFO epoch # 7784 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006116086700785672
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:20,534 INFO epoch # 7785 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0060631956985162105
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:20,552 INFO epoch # 7786 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006040917152859038
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:20,571 INFO epoch # 7787 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006028265164786717
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:20,589 INFO epoch # 7788 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006059259980247589
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:20,608 INFO epoch # 7789 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006328263152681757
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:20,627 INFO epoch # 7790 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0059845692758244695
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:20,627 INFO *** epoch 7790, rolling-avg-loss (window=10)= 0.006066941266180947
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:20,645 INFO epoch # 7791 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005995292685838649
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:20,663 INFO epoch # 7792 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006078425576561131
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:20,682 INFO epoch # 7793 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0074874939273286145
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:20,700 INFO epoch # 7794 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006009371269101393
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:20,718 INFO epoch # 7795 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006007703665090958
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:20,737 INFO epoch # 7796 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00606668544060085
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:20,755 INFO epoch # 7797 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006030343953170814
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:20,774 INFO epoch # 7798 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006005552451824769
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:20,793 INFO epoch # 7799 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006438179279939504
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:20,812 INFO epoch # 7800 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006139591867395211
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:20,812 INFO *** epoch 7800, rolling-avg-loss (window=10)= 0.0062258640116851895
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:20,831 INFO epoch # 7801 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006364471049892018
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:20,849 INFO epoch # 7802 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0060339807605487294
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:20,867 INFO epoch # 7803 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006011290362948785
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:20,886 INFO epoch # 7804 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006035064168827375
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:20,904 INFO epoch # 7805 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006045047110092128
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:20,922 INFO epoch # 7806 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006012187372107292
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:20,940 INFO epoch # 7807 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006023226414981764
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:20,959 INFO epoch # 7808 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006030858370650094
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:20,977 INFO epoch # 7809 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006101088802097365
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:20,996 INFO epoch # 7810 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005997634936647955
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:20,996 INFO *** epoch 7810, rolling-avg-loss (window=10)= 0.0060654849348793505
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:21,015 INFO epoch # 7811 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006067228328902274
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:21,033 INFO epoch # 7812 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006193062836246099
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:21,051 INFO epoch # 7813 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0060435675259213895
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:21,069 INFO epoch # 7814 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006055098961951444
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:21,088 INFO epoch # 7815 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005980708951028646
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:21,106 INFO epoch # 7816 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005997374013531953
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:21,124 INFO epoch # 7817 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006073368836950976
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:21,143 INFO epoch # 7818 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006019802214723313
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:21,162 INFO epoch # 7819 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00601766781983315
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:21,181 INFO epoch # 7820 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00598646681100945
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:21,181 INFO *** epoch 7820, rolling-avg-loss (window=10)= 0.006043434630009869
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:21,200 INFO epoch # 7821 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0060170999422552995
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:21,219 INFO epoch # 7822 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006017330841132207
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:21,237 INFO epoch # 7823 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006357885868055746
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:21,256 INFO epoch # 7824 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006084418950194959
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:21,274 INFO epoch # 7825 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005999414872349007
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:21,292 INFO epoch # 7826 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006235288808966288
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:21,310 INFO epoch # 7827 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006150794160930673
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:21,329 INFO epoch # 7828 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0061179188669484574
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:21,347 INFO epoch # 7829 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006027009221725166
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:21,366 INFO epoch # 7830 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005988466868075193
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:21,366 INFO *** epoch 7830, rolling-avg-loss (window=10)= 0.0060995628400632995
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:21,384 INFO epoch # 7831 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006011546185618499
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:21,403 INFO epoch # 7832 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00603096191844088
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:21,421 INFO epoch # 7833 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006136860298283864
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:21,440 INFO epoch # 7834 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006057741335098399
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:21,459 INFO epoch # 7835 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006048380510037532
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:21,477 INFO epoch # 7836 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006023670455761021
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:21,495 INFO epoch # 7837 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0059656772937159985
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:21,513 INFO epoch # 7838 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006011484390910482
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:21,532 INFO epoch # 7839 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006068059514291235
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:21,550 INFO epoch # 7840 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006015736635163194
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:21,550 INFO *** epoch 7840, rolling-avg-loss (window=10)= 0.00603701185373211
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:21,569 INFO epoch # 7841 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005992053418594878
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:21,587 INFO epoch # 7842 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005975027090244112
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:21,606 INFO epoch # 7843 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006041723558155354
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:21,625 INFO epoch # 7844 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006020523524057353
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:21,644 INFO epoch # 7845 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006352100546791917
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:21,662 INFO epoch # 7846 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0073746159177972
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:21,680 INFO epoch # 7847 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006039427244104445
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:21,699 INFO epoch # 7848 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006173195753945038
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:21,717 INFO epoch # 7849 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006038776067725848
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:21,735 INFO epoch # 7850 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006034913265466457
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:21,735 INFO *** epoch 7850, rolling-avg-loss (window=10)= 0.00620423563868826
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:21,753 INFO epoch # 7851 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006043302248144755
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:21,772 INFO epoch # 7852 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006010087428876432
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:21,791 INFO epoch # 7853 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006104312189563643
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:21,810 INFO epoch # 7854 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0061380106599244755
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:21,829 INFO epoch # 7855 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006231595092685893
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:21,848 INFO epoch # 7856 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00604186068449053
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:21,867 INFO epoch # 7857 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007404956213576952
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:21,885 INFO epoch # 7858 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006032765471900348
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:21,904 INFO epoch # 7859 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006047348331776448
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:21,922 INFO epoch # 7860 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005999813201924553
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:21,922 INFO *** epoch 7860, rolling-avg-loss (window=10)= 0.006205405152286403
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:21,940 INFO epoch # 7861 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006008333373756614
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:21,958 INFO epoch # 7862 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005968386054519215
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:21,977 INFO epoch # 7863 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0060341189564496744
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:21,995 INFO epoch # 7864 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006079822913306998
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:22,014 INFO epoch # 7865 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006004641942126909
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:22,033 INFO epoch # 7866 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006061941294319695
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:22,051 INFO epoch # 7867 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006149591332359705
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:22,070 INFO epoch # 7868 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006212370990397176
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:22,089 INFO epoch # 7869 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006568952343513956
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:22,107 INFO epoch # 7870 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006100992592109833
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:22,107 INFO *** epoch 7870, rolling-avg-loss (window=10)= 0.0061189151792859775
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:22,125 INFO epoch # 7871 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006105616092099808
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:22,143 INFO epoch # 7872 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006021903645887505
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:22,162 INFO epoch # 7873 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005968075100099668
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:22,180 INFO epoch # 7874 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005992604408675106
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:22,199 INFO epoch # 7875 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005982027778372867
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:22,219 INFO epoch # 7876 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005960950787994079
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:22,238 INFO epoch # 7877 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005990170360746561
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:22,257 INFO epoch # 7878 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006023851230565924
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:22,276 INFO epoch # 7879 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006003421411151066
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:22,294 INFO epoch # 7880 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00601048910539248
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:22,294 INFO *** epoch 7880, rolling-avg-loss (window=10)= 0.006005910992098506
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:22,312 INFO epoch # 7881 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005994358594762161
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:22,331 INFO epoch # 7882 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005990787267364794
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:22,349 INFO epoch # 7883 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00893904127224232
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:22,367 INFO epoch # 7884 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006020637691108277
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:22,386 INFO epoch # 7885 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006083394975576084
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:22,404 INFO epoch # 7886 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005984352515952196
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:22,423 INFO epoch # 7887 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005996907861117506
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:22,443 INFO epoch # 7888 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0059989225992467254
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:22,462 INFO epoch # 7889 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006142901354905916
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:22,481 INFO epoch # 7890 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00603853760912898
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:22,481 INFO *** epoch 7890, rolling-avg-loss (window=10)= 0.006318984174140496
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:22,499 INFO epoch # 7891 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006085061781050172
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:22,518 INFO epoch # 7892 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006006319876178168
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:22,536 INFO epoch # 7893 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0059665977641998325
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:22,554 INFO epoch # 7894 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006083564687287435
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:22,572 INFO epoch # 7895 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00602156170134549
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:22,591 INFO epoch # 7896 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005971546866931021
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:22,610 INFO epoch # 7897 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006105248310632305
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:22,629 INFO epoch # 7898 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005983657571050571
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:22,648 INFO epoch # 7899 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006074960394471418
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:22,667 INFO epoch # 7900 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006013920035911724
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:22,667 INFO *** epoch 7900, rolling-avg-loss (window=10)= 0.006031243898905814
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:22,686 INFO epoch # 7901 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0060658567963400856
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:22,704 INFO epoch # 7902 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00598327401894494
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:22,722 INFO epoch # 7903 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005995961219014134
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:22,741 INFO epoch # 7904 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00609298324707197
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:22,759 INFO epoch # 7905 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005983687977277441
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:22,777 INFO epoch # 7906 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005989854194922373
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:22,796 INFO epoch # 7907 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006025354628945934
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:22,815 INFO epoch # 7908 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0060350948115228675
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:22,834 INFO epoch # 7909 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006121632053691428
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:22,852 INFO epoch # 7910 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0060283794191491324
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:22,853 INFO *** epoch 7910, rolling-avg-loss (window=10)= 0.006032207836688031
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:22,872 INFO epoch # 7911 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005974756903015077
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:22,890 INFO epoch # 7912 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006072038428101223
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:22,909 INFO epoch # 7913 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00600537934951717
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:22,927 INFO epoch # 7914 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006026725979609182
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:22,946 INFO epoch # 7915 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005993405295157572
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:22,965 INFO epoch # 7916 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005981229347526096
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:22,984 INFO epoch # 7917 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0059871141966141295
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:23,002 INFO epoch # 7918 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006159666845633183
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:23,021 INFO epoch # 7919 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0059845970827154815
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:23,039 INFO epoch # 7920 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0059687243519874755
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:23,039 INFO *** epoch 7920, rolling-avg-loss (window=10)= 0.006015363777987659
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:23,058 INFO epoch # 7921 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005990203655528603
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:23,077 INFO epoch # 7922 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006246053751965519
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:23,096 INFO epoch # 7923 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005981429883831879
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:23,115 INFO epoch # 7924 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007447036561643472
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:23,133 INFO epoch # 7925 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006038172916305484
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:23,152 INFO epoch # 7926 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006065894052881049
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:23,170 INFO epoch # 7927 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006072491207305575
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:23,188 INFO epoch # 7928 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005994753413688159
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:23,207 INFO epoch # 7929 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005970274683932075
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:23,225 INFO epoch # 7930 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00625284924171865
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:23,225 INFO *** epoch 7930, rolling-avg-loss (window=10)= 0.006205915936880047
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:23,243 INFO epoch # 7931 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006003014845191501
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:23,262 INFO epoch # 7932 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005946761033555958
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:23,280 INFO epoch # 7933 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006032671310094884
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:23,299 INFO epoch # 7934 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006056800571968779
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:23,317 INFO epoch # 7935 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006216011544893263
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:23,335 INFO epoch # 7936 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006028831739968155
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:23,354 INFO epoch # 7937 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005972048831608845
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:23,372 INFO epoch # 7938 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005968567918898771
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:23,390 INFO epoch # 7939 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006059900031686993
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:23,409 INFO epoch # 7940 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006023017718689516
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:23,409 INFO *** epoch 7940, rolling-avg-loss (window=10)= 0.006030762554655666
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:23,427 INFO epoch # 7941 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.008901793349650688
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:23,446 INFO epoch # 7942 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006004724942613393
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:23,465 INFO epoch # 7943 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006026108909281902
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:23,484 INFO epoch # 7944 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005964292806311278
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:23,502 INFO epoch # 7945 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00599980232436792
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:23,520 INFO epoch # 7946 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006038569492375245
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:23,538 INFO epoch # 7947 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005994827995891683
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:23,557 INFO epoch # 7948 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005960173926723655
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:23,575 INFO epoch # 7949 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005967649856756907
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:23,593 INFO epoch # 7950 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005989644676446915
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:23,593 INFO *** epoch 7950, rolling-avg-loss (window=10)= 0.0062847588280419584
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:23,612 INFO epoch # 7951 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005962985669611953
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:23,631 INFO epoch # 7952 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005958492485660827
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:23,649 INFO epoch # 7953 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005960729769867612
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:23,667 INFO epoch # 7954 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006004676848533563
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:23,686 INFO epoch # 7955 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006064288383640815
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:23,704 INFO epoch # 7956 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0059770322404801846
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:23,722 INFO epoch # 7957 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005990216173813678
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:23,741 INFO epoch # 7958 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005992856873490382
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:23,760 INFO epoch # 7959 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0059585843882814515
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:23,779 INFO epoch # 7960 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005988491800962947
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:23,779 INFO *** epoch 7960, rolling-avg-loss (window=10)= 0.005985835463434341
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:23,797 INFO epoch # 7961 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006100224651163444
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:23,815 INFO epoch # 7962 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.008931598298659083
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:23,834 INFO epoch # 7963 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006077599158743396
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:23,852 INFO epoch # 7964 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006424711438739905
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:23,871 INFO epoch # 7965 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005965865537291393
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:23,890 INFO epoch # 7966 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00595080986386165
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:23,909 INFO epoch # 7967 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005980636633466929
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:23,927 INFO epoch # 7968 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0059588365656964015
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:23,945 INFO epoch # 7969 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006008131698763464
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:23,964 INFO epoch # 7970 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0059799727678182535
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:23,964 INFO *** epoch 7970, rolling-avg-loss (window=10)= 0.006337838661420392
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:23,982 INFO epoch # 7971 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006298385102127213
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:24,000 INFO epoch # 7972 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005978544584650081
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:24,019 INFO epoch # 7973 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005986892403598176
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:24,037 INFO epoch # 7974 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005941819657891756
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:24,055 INFO epoch # 7975 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005983764214761322
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:24,074 INFO epoch # 7976 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006016666942741722
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:24,092 INFO epoch # 7977 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006090202092309482
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:24,110 INFO epoch # 7978 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005935483743087389
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:24,129 INFO epoch # 7979 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005971720016532345
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:24,147 INFO epoch # 7980 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006025065766152693
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:24,147 INFO *** epoch 7980, rolling-avg-loss (window=10)= 0.006022854452385218
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:24,165 INFO epoch # 7981 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006061748626962071
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:24,183 INFO epoch # 7982 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005974999105092138
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:24,202 INFO epoch # 7983 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006470575081038987
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:24,220 INFO epoch # 7984 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00596240251979907
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:24,238 INFO epoch # 7985 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00597499754439923
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:24,257 INFO epoch # 7986 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005978427554509835
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:24,275 INFO epoch # 7987 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006002789079502691
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:24,293 INFO epoch # 7988 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005988968896417646
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:24,312 INFO epoch # 7989 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005940756032941863
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:24,330 INFO epoch # 7990 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006137836018751841
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:24,330 INFO *** epoch 7990, rolling-avg-loss (window=10)= 0.006049350045941537
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:24,349 INFO epoch # 7991 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006029114843840944
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:24,367 INFO epoch # 7992 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005989511224470334
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:24,385 INFO epoch # 7993 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006009586613799911
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:24,403 INFO epoch # 7994 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005931035808316665
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:24,421 INFO epoch # 7995 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00598808630820713
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:24,440 INFO epoch # 7996 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005991488818835933
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:24,458 INFO epoch # 7997 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005926128285864252
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:24,476 INFO epoch # 7998 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005983790710160974
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:24,495 INFO epoch # 7999 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007362679782090709
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:24,513 INFO epoch # 8000 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006007437077641953
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:24,513 INFO *** epoch 8000, rolling-avg-loss (window=10)= 0.00612188594732288
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:24,531 INFO epoch # 8001 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006104900519858347
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:24,550 INFO epoch # 8002 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005982801831123652
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:24,568 INFO epoch # 8003 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005925094053964131
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:24,586 INFO epoch # 8004 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005933750420808792
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:24,604 INFO epoch # 8005 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006085167602577712
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:24,624 INFO epoch # 8006 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005996676900394959
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:24,643 INFO epoch # 8007 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005941921896010172
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:24,662 INFO epoch # 8008 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00613251114191371
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:24,680 INFO epoch # 8009 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005992579957819544
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:24,699 INFO epoch # 8010 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005974973519187188
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:24,699 INFO *** epoch 8010, rolling-avg-loss (window=10)= 0.00600703778436582
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:24,717 INFO epoch # 8011 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0059466584607434925
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:24,737 INFO epoch # 8012 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0059392609691713005
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:24,756 INFO epoch # 8013 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005942806041275617
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:24,775 INFO epoch # 8014 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00597605367511278
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:24,793 INFO epoch # 8015 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005935392702667741
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:24,812 INFO epoch # 8016 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005953454528935254
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:24,830 INFO epoch # 8017 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005954130258032819
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:24,848 INFO epoch # 8018 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006076641984691378
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:24,866 INFO epoch # 8019 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005967976958345389
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:24,885 INFO epoch # 8020 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005975608561129775
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:24,885 INFO *** epoch 8020, rolling-avg-loss (window=10)= 0.005966798414010555
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:24,903 INFO epoch # 8021 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0059649064496625215
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:24,922 INFO epoch # 8022 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00597228562401142
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:24,940 INFO epoch # 8023 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005983584851492196
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:24,958 INFO epoch # 8024 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006020264703693101
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:24,977 INFO epoch # 8025 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005942428473645123
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:24,995 INFO epoch # 8026 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005950505121290917
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:25,013 INFO epoch # 8027 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0062752883532084525
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:25,032 INFO epoch # 8028 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006026007620675955
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:25,050 INFO epoch # 8029 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005960698130365927
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:25,068 INFO epoch # 8030 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005959814618108794
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:25,068 INFO *** epoch 8030, rolling-avg-loss (window=10)= 0.00600557839461544
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:25,087 INFO epoch # 8031 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005962561888736673
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:25,105 INFO epoch # 8032 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006056727241229964
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:25,125 INFO epoch # 8033 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005939111473708181
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:25,144 INFO epoch # 8034 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00880994518956868
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:25,162 INFO epoch # 8035 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00600431495331577
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:25,181 INFO epoch # 8036 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005932683710852871
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:25,199 INFO epoch # 8037 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005954212083452148
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:25,217 INFO epoch # 8038 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0059194785899308044
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:25,235 INFO epoch # 8039 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005987440719763981
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:25,254 INFO epoch # 8040 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006060783340217313
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:25,254 INFO *** epoch 8040, rolling-avg-loss (window=10)= 0.006262725919077639
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:25,272 INFO epoch # 8041 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005930142262513982
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:25,291 INFO epoch # 8042 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006019169726641849
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:25,310 INFO epoch # 8043 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006014130056428257
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:25,329 INFO epoch # 8044 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005954367010417627
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:25,348 INFO epoch # 8045 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006290154818998417
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:25,367 INFO epoch # 8046 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005965841071883915
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:25,385 INFO epoch # 8047 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005955056163656991
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:25,403 INFO epoch # 8048 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005990841724269558
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:25,421 INFO epoch # 8049 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005998861444822978
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:25,440 INFO epoch # 8050 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005942899537330959
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:25,440 INFO *** epoch 8050, rolling-avg-loss (window=10)= 0.0060061463816964535
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:25,458 INFO epoch # 8051 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00606451572093647
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:25,476 INFO epoch # 8052 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005940215265582083
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:25,495 INFO epoch # 8053 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005930615872784983
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:25,513 INFO epoch # 8054 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005928284230321879
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:25,532 INFO epoch # 8055 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006011991321429377
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:25,550 INFO epoch # 8056 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005957923032838153
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:25,569 INFO epoch # 8057 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0059929760682280175
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:25,587 INFO epoch # 8058 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005983871003991226
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:25,605 INFO epoch # 8059 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005961860377283301
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:25,623 INFO epoch # 8060 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005925697394559393
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:25,624 INFO *** epoch 8060, rolling-avg-loss (window=10)= 0.0059697950287954885
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:25,642 INFO epoch # 8061 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0059877007988689
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:25,660 INFO epoch # 8062 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0059655330078385305
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:25,678 INFO epoch # 8063 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005928613525611581
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:25,696 INFO epoch # 8064 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005985435695038177
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:25,715 INFO epoch # 8065 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005938304595474619
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:25,733 INFO epoch # 8066 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0059249291371088475
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:25,752 INFO epoch # 8067 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0062104493808874395
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:25,770 INFO epoch # 8068 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0059272040125506464
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:25,789 INFO epoch # 8069 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006188785388076212
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:25,808 INFO epoch # 8070 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005989982175378827
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:25,808 INFO *** epoch 8070, rolling-avg-loss (window=10)= 0.006004693771683378
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:25,827 INFO epoch # 8071 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0059564992698142305
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:25,845 INFO epoch # 8072 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005958533391094534
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:25,863 INFO epoch # 8073 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00591866412651143
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:25,881 INFO epoch # 8074 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005929472928983159
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:25,900 INFO epoch # 8075 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005904926154471468
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:25,918 INFO epoch # 8076 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006482247459643986
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:25,937 INFO epoch # 8077 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005935145880357595
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:25,955 INFO epoch # 8078 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005964116335235303
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:25,974 INFO epoch # 8079 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0059997594289598055
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:25,992 INFO epoch # 8080 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005995826673824922
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:25,992 INFO *** epoch 8080, rolling-avg-loss (window=10)= 0.0060045191648896434
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:26,010 INFO epoch # 8081 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00592095241881907
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:26,029 INFO epoch # 8082 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006026653070875909
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:26,047 INFO epoch # 8083 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005979119501716923
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:26,065 INFO epoch # 8084 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005942968080489663
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:26,084 INFO epoch # 8085 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006120340371126076
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:26,102 INFO epoch # 8086 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006111039456300205
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:26,120 INFO epoch # 8087 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005954284741164884
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:26,139 INFO epoch # 8088 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005928506448981352
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:26,157 INFO epoch # 8089 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005980113903206075
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:26,175 INFO epoch # 8090 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005929371811362216
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:26,175 INFO *** epoch 8090, rolling-avg-loss (window=10)= 0.005989334980404238
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:26,194 INFO epoch # 8091 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005904569425183581
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:26,212 INFO epoch # 8092 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006024128564604325
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:26,231 INFO epoch # 8093 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005937177054875065
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:26,249 INFO epoch # 8094 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0059346805937821046
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:26,267 INFO epoch # 8095 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005935103861702373
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:26,285 INFO epoch # 8096 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0059348114737076685
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:26,303 INFO epoch # 8097 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005906492249778239
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:26,322 INFO epoch # 8098 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005909201359827421
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:26,340 INFO epoch # 8099 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005944189611909678
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:26,359 INFO epoch # 8100 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0059759596770163625
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:26,359 INFO *** epoch 8100, rolling-avg-loss (window=10)= 0.005940631387238682
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:26,377 INFO epoch # 8101 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006005768667819211
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:26,396 INFO epoch # 8102 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00594875331807998
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:26,414 INFO epoch # 8103 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006030053205904551
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:26,432 INFO epoch # 8104 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005937849509791704
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:26,450 INFO epoch # 8105 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005910998726903927
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:26,469 INFO epoch # 8106 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005914781308092643
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:26,487 INFO epoch # 8107 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006003705850162078
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:26,505 INFO epoch # 8108 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005995952764351387
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:26,523 INFO epoch # 8109 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005934238655754598
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:26,542 INFO epoch # 8110 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005912984364840668
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:26,542 INFO *** epoch 8110, rolling-avg-loss (window=10)= 0.005959508637170074
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:26,560 INFO epoch # 8111 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005925758352532284
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:26,578 INFO epoch # 8112 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005945286135101924
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:26,597 INFO epoch # 8113 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006081224757508608
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:26,615 INFO epoch # 8114 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005912667962547857
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:26,634 INFO epoch # 8115 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005964358355413424
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:26,652 INFO epoch # 8116 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005937690399150597
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:26,671 INFO epoch # 8117 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0061117598379496485
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:26,689 INFO epoch # 8118 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005952848063316196
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:26,707 INFO epoch # 8119 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005911115771596087
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:26,725 INFO epoch # 8120 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005913780896662502
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:26,725 INFO *** epoch 8120, rolling-avg-loss (window=10)= 0.0059656490531779125
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:26,744 INFO epoch # 8121 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00589908965775976
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:26,762 INFO epoch # 8122 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006388375866663409
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:26,781 INFO epoch # 8123 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006035813741618767
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:26,800 INFO epoch # 8124 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0059241516537440475
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:26,818 INFO epoch # 8125 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0060020445052941795
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:26,837 INFO epoch # 8126 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005938906364463037
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:26,855 INFO epoch # 8127 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0059278856751916464
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:26,874 INFO epoch # 8128 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0059213398380961735
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:26,892 INFO epoch # 8129 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006238010260858573
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:26,910 INFO epoch # 8130 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00595451485060039
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:26,910 INFO *** epoch 8130, rolling-avg-loss (window=10)= 0.006023013241428998
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:26,928 INFO epoch # 8131 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005915983929298818
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:26,946 INFO epoch # 8132 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005903098212002078
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:26,965 INFO epoch # 8133 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.008845744963764446
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:26,984 INFO epoch # 8134 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005940248864135356
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:27,002 INFO epoch # 8135 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005938395763223525
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:27,020 INFO epoch # 8136 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005895800055441214
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:27,039 INFO epoch # 8137 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005958700050541665
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:27,057 INFO epoch # 8138 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005909401566896122
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:27,075 INFO epoch # 8139 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0059130008521606214
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:27,094 INFO epoch # 8140 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005891516213523573
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:27,094 INFO *** epoch 8140, rolling-avg-loss (window=10)= 0.006211189047098742
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:27,112 INFO epoch # 8141 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005907224767724983
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:27,130 INFO epoch # 8142 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005917490223509958
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:27,148 INFO epoch # 8143 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005908427516260417
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:27,167 INFO epoch # 8144 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005986972686514491
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:27,185 INFO epoch # 8145 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005906231850531185
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:27,203 INFO epoch # 8146 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005922541498875944
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:27,222 INFO epoch # 8147 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005920539617363829
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:27,240 INFO epoch # 8148 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005996694613713771
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:27,258 INFO epoch # 8149 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005908161296247272
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:27,277 INFO epoch # 8150 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005912868477025768
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:27,277 INFO *** epoch 8150, rolling-avg-loss (window=10)= 0.0059287152547767615
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:27,295 INFO epoch # 8151 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005992295507894596
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:27,313 INFO epoch # 8152 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005934504053584533
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:27,332 INFO epoch # 8153 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005910781346756266
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:27,350 INFO epoch # 8154 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0059189493986195885
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:27,368 INFO epoch # 8155 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005905879625061061
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:27,386 INFO epoch # 8156 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0060097922578279395
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:27,405 INFO epoch # 8157 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005904922218178399
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:27,423 INFO epoch # 8158 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005958459674729966
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:27,442 INFO epoch # 8159 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005925921148445923
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:27,460 INFO epoch # 8160 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005908855917368783
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:27,460 INFO *** epoch 8160, rolling-avg-loss (window=10)= 0.005937036114846706
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:27,479 INFO epoch # 8161 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005903126715566032
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:27,497 INFO epoch # 8162 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00589989418949699
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:27,515 INFO epoch # 8163 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005914772304095095
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:27,534 INFO epoch # 8164 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00789609232742805
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:27,552 INFO epoch # 8165 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0059273168226354755
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:27,570 INFO epoch # 8166 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005884754817088833
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:27,588 INFO epoch # 8167 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005922501968598226
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:27,607 INFO epoch # 8168 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005902915057959035
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:27,625 INFO epoch # 8169 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00596559738914948
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:27,644 INFO epoch # 8170 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005904357134568272
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:27,644 INFO *** epoch 8170, rolling-avg-loss (window=10)= 0.006112132872658549
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:27,665 INFO epoch # 8171 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005952487095782999
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:27,684 INFO epoch # 8172 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006485368965513771
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:27,703 INFO epoch # 8173 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005914743156608893
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:27,721 INFO epoch # 8174 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006022327765094815
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:27,740 INFO epoch # 8175 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005954940999799874
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:27,758 INFO epoch # 8176 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005918176386330742
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:27,776 INFO epoch # 8177 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0073581869328336325
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:27,795 INFO epoch # 8178 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006393859952368075
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:27,813 INFO epoch # 8179 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005920339885051362
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:27,832 INFO epoch # 8180 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005974475214316044
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:27,832 INFO *** epoch 8180, rolling-avg-loss (window=10)= 0.006189490635370021
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:27,851 INFO epoch # 8181 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005924215703998925
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:27,870 INFO epoch # 8182 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005893557350646006
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:27,888 INFO epoch # 8183 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005916244281252148
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:27,907 INFO epoch # 8184 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006372491090587573
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:27,925 INFO epoch # 8185 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0059399046513135545
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:27,943 INFO epoch # 8186 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0060142620823171455
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:27,961 INFO epoch # 8187 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006022138692060253
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:27,979 INFO epoch # 8188 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005901963791984599
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:27,998 INFO epoch # 8189 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0058940100607287604
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:28,016 INFO epoch # 8190 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005954129181191092
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:28,016 INFO *** epoch 8190, rolling-avg-loss (window=10)= 0.005983291688608006
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:28,034 INFO epoch # 8191 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005887112230993807
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:28,053 INFO epoch # 8192 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00592151166711119
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:28,072 INFO epoch # 8193 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005908692255616188
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:28,091 INFO epoch # 8194 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0059717456315411255
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:28,110 INFO epoch # 8195 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0058816274686250836
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:28,128 INFO epoch # 8196 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005903350005610264
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:28,146 INFO epoch # 8197 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005889677369850688
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:28,164 INFO epoch # 8198 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005899914351175539
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:28,183 INFO epoch # 8199 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005914188644965179
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:28,201 INFO epoch # 8200 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006295232833508635
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:28,201 INFO *** epoch 8200, rolling-avg-loss (window=10)= 0.00594730524589977
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:28,219 INFO epoch # 8201 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005955959979473846
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:28,237 INFO epoch # 8202 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005978752538794652
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:28,256 INFO epoch # 8203 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00591590298427036
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:28,274 INFO epoch # 8204 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0063717615194036625
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:28,293 INFO epoch # 8205 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005965560023469152
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:28,311 INFO epoch # 8206 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006110726608312689
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:28,329 INFO epoch # 8207 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005900901560380589
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:28,348 INFO epoch # 8208 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005879232474399032
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:28,366 INFO epoch # 8209 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005908283834287431
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:28,384 INFO epoch # 8210 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006088599839131348
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:28,384 INFO *** epoch 8210, rolling-avg-loss (window=10)= 0.006007568136192276
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:28,402 INFO epoch # 8211 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005909316478209803
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:28,421 INFO epoch # 8212 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0059165787606616504
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:28,439 INFO epoch # 8213 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00627997988340212
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:28,457 INFO epoch # 8214 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005884580714337062
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:28,476 INFO epoch # 8215 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005936006997217191
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:28,494 INFO epoch # 8216 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005887646380870137
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:28,512 INFO epoch # 8217 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005936826360994019
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:28,531 INFO epoch # 8218 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005892379154829541
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:28,549 INFO epoch # 8219 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005881737335585058
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:28,568 INFO epoch # 8220 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005877320872968994
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:28,568 INFO *** epoch 8220, rolling-avg-loss (window=10)= 0.005940237293907557
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:28,587 INFO epoch # 8221 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005897469112824183
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:28,606 INFO epoch # 8222 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0059990711670252495
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:28,624 INFO epoch # 8223 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005991048368741758
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:28,643 INFO epoch # 8224 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005999038607114926
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:28,662 INFO epoch # 8225 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005902613393118372
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:28,680 INFO epoch # 8226 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005876025214092806
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:28,699 INFO epoch # 8227 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006019470198225463
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:28,717 INFO epoch # 8228 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005948149617324816
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:28,736 INFO epoch # 8229 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005888374013011344
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:28,754 INFO epoch # 8230 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0062284219966386445
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:28,754 INFO *** epoch 8230, rolling-avg-loss (window=10)= 0.005974968168811756
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:28,772 INFO epoch # 8231 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00590603879027185
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:28,790 INFO epoch # 8232 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005936443241807865
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:28,809 INFO epoch # 8233 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005921447664150037
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:28,827 INFO epoch # 8234 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005936663183092605
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:28,845 INFO epoch # 8235 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00587572688164073
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:28,864 INFO epoch # 8236 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006149944139906438
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:28,882 INFO epoch # 8237 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005950124410446733
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:28,900 INFO epoch # 8238 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005945331940893084
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:28,919 INFO epoch # 8239 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00590020379240741
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:28,937 INFO epoch # 8240 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0059376120116212405
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:28,937 INFO *** epoch 8240, rolling-avg-loss (window=10)= 0.0059459536056238
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:28,955 INFO epoch # 8241 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005915070567425573
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:28,974 INFO epoch # 8242 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005872523772268323
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:28,992 INFO epoch # 8243 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00594824704239727
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:29,010 INFO epoch # 8244 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006037848783307709
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:29,028 INFO epoch # 8245 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005953764750302071
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:29,046 INFO epoch # 8246 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005882712252059719
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:29,065 INFO epoch # 8247 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005973157301923493
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:29,083 INFO epoch # 8248 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005993495149596129
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:29,102 INFO epoch # 8249 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00586641721019987
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:29,120 INFO epoch # 8250 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005887670416996116
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:29,120 INFO *** epoch 8250, rolling-avg-loss (window=10)= 0.005933090724647627
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:29,138 INFO epoch # 8251 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005880724620510591
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:29,157 INFO epoch # 8252 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005916077916481299
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:29,176 INFO epoch # 8253 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005930511302722152
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:29,194 INFO epoch # 8254 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0061147570158937015
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:29,212 INFO epoch # 8255 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006032386467268225
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:29,231 INFO epoch # 8256 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0059949874703306705
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:29,249 INFO epoch # 8257 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0059234888503851835
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:29,267 INFO epoch # 8258 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00599021168454783
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:29,286 INFO epoch # 8259 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005854699347764836
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:29,304 INFO epoch # 8260 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005913526183576323
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:29,304 INFO *** epoch 8260, rolling-avg-loss (window=10)= 0.005955137085948081
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:29,322 INFO epoch # 8261 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005894368008739548
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:29,341 INFO epoch # 8262 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0058766776164702605
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:29,359 INFO epoch # 8263 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0059189017229073215
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:29,377 INFO epoch # 8264 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005861412380909314
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:29,395 INFO epoch # 8265 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005895404363400303
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:29,414 INFO epoch # 8266 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005878511008631904
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:29,432 INFO epoch # 8267 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00589143065008102
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:29,450 INFO epoch # 8268 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005884088284801692
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:29,469 INFO epoch # 8269 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005907283295528032
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:29,487 INFO epoch # 8270 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005965833039226709
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:29,487 INFO *** epoch 8270, rolling-avg-loss (window=10)= 0.0058973910370696105
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:29,505 INFO epoch # 8271 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005895365888136439
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:29,524 INFO epoch # 8272 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005870916447747732
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:29,542 INFO epoch # 8273 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005877335592231248
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:29,560 INFO epoch # 8274 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005872443569387542
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:29,579 INFO epoch # 8275 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005889294076041551
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:29,597 INFO epoch # 8276 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007886573395808227
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:29,615 INFO epoch # 8277 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005910565665544709
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:29,633 INFO epoch # 8278 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005904607271077111
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:29,652 INFO epoch # 8279 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006293645972618833
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:29,670 INFO epoch # 8280 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005869600285222987
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:29,670 INFO *** epoch 8280, rolling-avg-loss (window=10)= 0.006127034816381638
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:29,688 INFO epoch # 8281 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005862528596480843
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:29,707 INFO epoch # 8282 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005970896225335309
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:29,725 INFO epoch # 8283 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005910337098612217
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:29,744 INFO epoch # 8284 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005971693415631307
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:29,762 INFO epoch # 8285 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005940401257248595
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:29,780 INFO epoch # 8286 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00591809365505469
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:29,798 INFO epoch # 8287 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00588488373614382
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:29,817 INFO epoch # 8288 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00587604578686296
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:29,835 INFO epoch # 8289 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005884746933588758
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:29,853 INFO epoch # 8290 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0059031742239312734
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:29,853 INFO *** epoch 8290, rolling-avg-loss (window=10)= 0.0059122800928889776
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:29,872 INFO epoch # 8291 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005858245363924652
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:29,890 INFO epoch # 8292 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0058526915818220004
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:29,908 INFO epoch # 8293 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005875622049643425
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:29,927 INFO epoch # 8294 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005942597683315398
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:29,945 INFO epoch # 8295 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006030017728335224
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:29,964 INFO epoch # 8296 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005917856968153501
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:29,982 INFO epoch # 8297 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0058724768095999025
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:30,000 INFO epoch # 8298 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006063876300686388
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:30,018 INFO epoch # 8299 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0061149200846557505
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:30,036 INFO epoch # 8300 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0059862392336071935
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:30,037 INFO *** epoch 8300, rolling-avg-loss (window=10)= 0.005951454380374343
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:30,055 INFO epoch # 8301 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005841724363563117
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:30,073 INFO epoch # 8302 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005879111686226679
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:30,092 INFO epoch # 8303 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005863841673999559
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:30,110 INFO epoch # 8304 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005896458416827954
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:30,129 INFO epoch # 8305 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0059297501466062386
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:30,147 INFO epoch # 8306 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0059029065996583086
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:30,166 INFO epoch # 8307 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005863786744157551
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:30,184 INFO epoch # 8308 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005900913693039911
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:30,202 INFO epoch # 8309 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005863287700776709
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:30,221 INFO epoch # 8310 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.008749749289563624
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:30,221 INFO *** epoch 8310, rolling-avg-loss (window=10)= 0.0061691530314419655
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:30,239 INFO epoch # 8311 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005929899958573515
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:30,257 INFO epoch # 8312 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005880899985641008
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:30,276 INFO epoch # 8313 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005860694986040471
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:30,294 INFO epoch # 8314 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005909180814342108
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:30,313 INFO epoch # 8315 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006184360558108892
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:30,332 INFO epoch # 8316 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005942986921581905
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:30,350 INFO epoch # 8317 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0058479834769968875
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:30,368 INFO epoch # 8318 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005854342201928375
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:30,387 INFO epoch # 8319 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00587346966858604
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:30,405 INFO epoch # 8320 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005839242192450911
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:30,405 INFO *** epoch 8320, rolling-avg-loss (window=10)= 0.005912306076425011
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:30,423 INFO epoch # 8321 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00589926571410615
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:30,441 INFO epoch # 8322 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005858881802851101
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:30,460 INFO epoch # 8323 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005864989667315967
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:30,478 INFO epoch # 8324 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005904149311390938
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:30,496 INFO epoch # 8325 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006009810269461013
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:30,515 INFO epoch # 8326 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005831056346778496
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:30,533 INFO epoch # 8327 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005838036006025504
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:30,552 INFO epoch # 8328 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005871704197488725
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:30,570 INFO epoch # 8329 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005938360354775796
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:30,588 INFO epoch # 8330 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005977512100798776
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:30,588 INFO *** epoch 8330, rolling-avg-loss (window=10)= 0.0058993765770992464
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:30,606 INFO epoch # 8331 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005850140725669917
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:30,625 INFO epoch # 8332 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005868069023563294
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:30,643 INFO epoch # 8333 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005840501102284179
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:30,661 INFO epoch # 8334 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005851807993167313
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:30,679 INFO epoch # 8335 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005917463749938179
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:30,698 INFO epoch # 8336 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005848438868270023
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:30,716 INFO epoch # 8337 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00584534602239728
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:30,735 INFO epoch # 8338 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005857129483047174
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:30,753 INFO epoch # 8339 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005881831420992967
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:30,771 INFO epoch # 8340 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005843595226906473
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:30,771 INFO *** epoch 8340, rolling-avg-loss (window=10)= 0.005860432361623679
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:30,790 INFO epoch # 8341 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005885544880584348
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:30,808 INFO epoch # 8342 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005875530809134943
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:30,826 INFO epoch # 8343 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00732175995290163
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:30,845 INFO epoch # 8344 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0058552576119836885
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:30,863 INFO epoch # 8345 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005907344042498153
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:30,881 INFO epoch # 8346 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005957563400443178
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:30,899 INFO epoch # 8347 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005838674605911365
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:30,918 INFO epoch # 8348 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005928079262957908
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:30,937 INFO epoch # 8349 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.008760117922065547
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:30,956 INFO epoch # 8350 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005942446950939484
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:30,956 INFO *** epoch 8350, rolling-avg-loss (window=10)= 0.006327231943942024
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:30,975 INFO epoch # 8351 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0060594130045501515
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:30,993 INFO epoch # 8352 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005841761307237903
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:31,011 INFO epoch # 8353 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005874682097783079
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:31,030 INFO epoch # 8354 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005857949989149347
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:31,048 INFO epoch # 8355 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005926813275436871
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:31,066 INFO epoch # 8356 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0061570004509121645
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:31,084 INFO epoch # 8357 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005864561768248677
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:31,103 INFO epoch # 8358 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0058642429394240025
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:31,122 INFO epoch # 8359 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005963981871900614
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:31,140 INFO epoch # 8360 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005932019863394089
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:31,140 INFO *** epoch 8360, rolling-avg-loss (window=10)= 0.00593424265680369
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:31,159 INFO epoch # 8361 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005882447381736711
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:31,178 INFO epoch # 8362 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0058384866097185295
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:31,196 INFO epoch # 8363 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005841492074978305
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:31,214 INFO epoch # 8364 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005867117346497253
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:31,232 INFO epoch # 8365 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005827188422699692
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:31,251 INFO epoch # 8366 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005848131240782095
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:31,269 INFO epoch # 8367 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005942854506429285
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:31,287 INFO epoch # 8368 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00586248212857754
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:31,306 INFO epoch # 8369 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0058459836363908835
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:31,324 INFO epoch # 8370 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0058619926567189395
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:31,324 INFO *** epoch 8370, rolling-avg-loss (window=10)= 0.0058618176004529236
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:31,342 INFO epoch # 8371 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005905693011300173
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:31,361 INFO epoch # 8372 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.008783566245256225
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:31,379 INFO epoch # 8373 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0058745408641698305
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:31,398 INFO epoch # 8374 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005853527793078683
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:31,416 INFO epoch # 8375 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005868622600246454
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:31,434 INFO epoch # 8376 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006182493227242958
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:31,453 INFO epoch # 8377 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005839471446961397
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:31,471 INFO epoch # 8378 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005858545737282839
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:31,489 INFO epoch # 8379 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005981806461932138
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:31,508 INFO epoch # 8380 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006086965771828545
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:31,508 INFO *** epoch 8380, rolling-avg-loss (window=10)= 0.0062235233159299245
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:31,526 INFO epoch # 8381 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005920351584791206
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:31,544 INFO epoch # 8382 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0058731447570608
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:31,563 INFO epoch # 8383 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005829932837514207
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:31,581 INFO epoch # 8384 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005862256617547246
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:31,600 INFO epoch # 8385 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0058514194424788
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:31,618 INFO epoch # 8386 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0058656129040173255
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:31,637 INFO epoch # 8387 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005847928779985523
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:31,655 INFO epoch # 8388 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0062119994254317135
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:31,673 INFO epoch # 8389 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006032208795659244
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:31,691 INFO epoch # 8390 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005835225369082764
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:31,691 INFO *** epoch 8390, rolling-avg-loss (window=10)= 0.005913008051356883
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:31,710 INFO epoch # 8391 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0058558255004754756
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:31,729 INFO epoch # 8392 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006068962000426836
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:31,748 INFO epoch # 8393 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005955816333880648
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:31,767 INFO epoch # 8394 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005842106944328407
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:31,785 INFO epoch # 8395 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005874488102563191
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:31,804 INFO epoch # 8396 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00588562129996717
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:31,822 INFO epoch # 8397 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005979535522783408
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:31,840 INFO epoch # 8398 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005834299998241477
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:31,859 INFO epoch # 8399 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005827380209666444
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:31,877 INFO epoch # 8400 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005852577822224703
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:31,877 INFO *** epoch 8400, rolling-avg-loss (window=10)= 0.005897661373455776
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:31,895 INFO epoch # 8401 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005914913577726111
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:31,914 INFO epoch # 8402 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005836127093061805
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:31,932 INFO epoch # 8403 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005926657951931702
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:31,951 INFO epoch # 8404 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005833382998389425
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:31,969 INFO epoch # 8405 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005849586177646415
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:31,988 INFO epoch # 8406 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005837327491462929
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:32,006 INFO epoch # 8407 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005802408917588764
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:32,024 INFO epoch # 8408 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005834829647938022
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:32,042 INFO epoch # 8409 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005880637912923703
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:32,061 INFO epoch # 8410 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005838039858645061
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:32,061 INFO *** epoch 8410, rolling-avg-loss (window=10)= 0.005855391162731394
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:32,079 INFO epoch # 8411 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0059511209510674234
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:32,097 INFO epoch # 8412 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0060526328124979045
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:32,115 INFO epoch # 8413 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005819380920002004
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:32,134 INFO epoch # 8414 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0061564475545310415
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:32,152 INFO epoch # 8415 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0058781964326044545
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:32,170 INFO epoch # 8416 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006045906600775197
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:32,189 INFO epoch # 8417 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0061419298908731434
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:32,207 INFO epoch # 8418 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005865136492502643
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:32,225 INFO epoch # 8419 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005819639714900404
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:32,243 INFO epoch # 8420 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005854609560628887
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:32,243 INFO *** epoch 8420, rolling-avg-loss (window=10)= 0.00595850009303831
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:32,262 INFO epoch # 8421 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005817579405629658
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:32,280 INFO epoch # 8422 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005825849086249946
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:32,298 INFO epoch # 8423 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005826552787766559
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:32,317 INFO epoch # 8424 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005849502136697993
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:32,335 INFO epoch # 8425 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005832976432429859
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:32,353 INFO epoch # 8426 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005813977593788877
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:32,372 INFO epoch # 8427 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005874959904758725
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:32,390 INFO epoch # 8428 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006109551639383426
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:32,409 INFO epoch # 8429 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005863827864232007
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:32,427 INFO epoch # 8430 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005832937793456949
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:32,427 INFO *** epoch 8430, rolling-avg-loss (window=10)= 0.0058647714644394
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:32,445 INFO epoch # 8431 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0058383010218676645
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:32,464 INFO epoch # 8432 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005794378866994521
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:32,483 INFO epoch # 8433 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006134783314337255
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:32,503 INFO epoch # 8434 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005885160095203901
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:32,523 INFO epoch # 8435 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00585999310715124
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:32,542 INFO epoch # 8436 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005825065793032991
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:32,560 INFO epoch # 8437 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005825783264299389
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:32,579 INFO epoch # 8438 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005854737551999278
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:32,598 INFO epoch # 8439 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0058528736990410835
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:32,617 INFO epoch # 8440 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005847094547789311
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:32,617 INFO *** epoch 8440, rolling-avg-loss (window=10)= 0.005871817126171663
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:32,636 INFO epoch # 8441 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005814087602630025
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:32,655 INFO epoch # 8442 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005815447384520667
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:32,673 INFO epoch # 8443 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005823548730404582
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:32,691 INFO epoch # 8444 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005895150643482339
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:32,709 INFO epoch # 8445 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005895273468922824
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:32,728 INFO epoch # 8446 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0058569673892634455
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:32,746 INFO epoch # 8447 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006027055209415266
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:32,765 INFO epoch # 8448 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.009020996738399845
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:32,783 INFO epoch # 8449 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005880004599021049
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:32,801 INFO epoch # 8450 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005848410550242988
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:32,801 INFO *** epoch 8450, rolling-avg-loss (window=10)= 0.006187694231630303
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:32,820 INFO epoch # 8451 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005828316407132661
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:32,838 INFO epoch # 8452 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005842332637257641
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:32,857 INFO epoch # 8453 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005903020646655932
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:32,875 INFO epoch # 8454 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005819215963128954
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:32,893 INFO epoch # 8455 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005819143647386227
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:32,912 INFO epoch # 8456 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005895598202187102
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:32,930 INFO epoch # 8457 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005818249210278736
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:32,949 INFO epoch # 8458 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0060899976451764815
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:32,967 INFO epoch # 8459 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00581116526882397
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:32,986 INFO epoch # 8460 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006183680656249635
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:32,986 INFO *** epoch 8460, rolling-avg-loss (window=10)= 0.005901072028427734
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:33,004 INFO epoch # 8461 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005838357930770144
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:33,023 INFO epoch # 8462 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00579144862240355
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:33,041 INFO epoch # 8463 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00580984232146875
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:33,059 INFO epoch # 8464 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005840849720698316
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:33,077 INFO epoch # 8465 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006102617197029758
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:33,096 INFO epoch # 8466 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005924640168814221
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:33,114 INFO epoch # 8467 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005864245573320659
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:33,132 INFO epoch # 8468 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005800193614049931
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:33,151 INFO epoch # 8469 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0058126569565501995
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:33,169 INFO epoch # 8470 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005824151743581751
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:33,169 INFO *** epoch 8470, rolling-avg-loss (window=10)= 0.005860900384868728
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:33,188 INFO epoch # 8471 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005837289754708763
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:33,207 INFO epoch # 8472 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00580250349958078
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:33,226 INFO epoch # 8473 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005812721985421376
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:33,245 INFO epoch # 8474 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005964735115412623
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:33,263 INFO epoch # 8475 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005829314821312437
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:33,281 INFO epoch # 8476 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005801460369184497
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:33,300 INFO epoch # 8477 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0059635850266204216
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:33,318 INFO epoch # 8478 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005844346029334702
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:33,337 INFO epoch # 8479 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005801194358355133
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:33,355 INFO epoch # 8480 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006147652675281279
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:33,356 INFO *** epoch 8480, rolling-avg-loss (window=10)= 0.005880480363521201
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:33,374 INFO epoch # 8481 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005985767864331137
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:33,393 INFO epoch # 8482 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005825075939355884
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:33,411 INFO epoch # 8483 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005809245081763947
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:33,429 INFO epoch # 8484 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0058442354638827965
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:33,447 INFO epoch # 8485 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005814413547341246
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:33,465 INFO epoch # 8486 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005809001628222177
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:33,484 INFO epoch # 8487 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006063278389774496
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:33,502 INFO epoch # 8488 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005836746975546703
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:33,520 INFO epoch # 8489 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005813228020997485
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:33,539 INFO epoch # 8490 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005813417323224712
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:33,539 INFO *** epoch 8490, rolling-avg-loss (window=10)= 0.0058614410234440585
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:33,557 INFO epoch # 8491 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005791283783764811
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:33,576 INFO epoch # 8492 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005824630101415096
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:33,594 INFO epoch # 8493 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0058649205493566114
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:33,613 INFO epoch # 8494 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005821796326927142
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:33,631 INFO epoch # 8495 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005950766699243104
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:33,649 INFO epoch # 8496 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005967714951111702
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:33,668 INFO epoch # 8497 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005906675567530328
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:33,686 INFO epoch # 8498 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005812110706756357
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:33,704 INFO epoch # 8499 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0058023676901939325
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:33,722 INFO epoch # 8500 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0058186860114801675
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:33,722 INFO *** epoch 8500, rolling-avg-loss (window=10)= 0.005856095238777925
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:33,741 INFO epoch # 8501 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005805956494441489
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:33,759 INFO epoch # 8502 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005886987921257969
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:33,777 INFO epoch # 8503 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005910003266762942
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:33,796 INFO epoch # 8504 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005896864884562092
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:33,814 INFO epoch # 8505 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0058023245983349625
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:33,833 INFO epoch # 8506 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005802955482067773
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:33,851 INFO epoch # 8507 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005828810324601363
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:33,869 INFO epoch # 8508 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005810359674796928
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:33,887 INFO epoch # 8509 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005933526670560241
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:33,906 INFO epoch # 8510 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005822315124532906
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:33,906 INFO *** epoch 8510, rolling-avg-loss (window=10)= 0.0058500104441918666
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:33,924 INFO epoch # 8511 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005921783682424575
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:33,942 INFO epoch # 8512 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005809568563563516
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:33,961 INFO epoch # 8513 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0059894724618061446
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:33,979 INFO epoch # 8514 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0058234824318788014
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:33,998 INFO epoch # 8515 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005872919595276471
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:34,016 INFO epoch # 8516 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005790364662971115
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:34,034 INFO epoch # 8517 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005838121294800658
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:34,053 INFO epoch # 8518 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005827410575875547
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:34,071 INFO epoch # 8519 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005801356652227696
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:34,089 INFO epoch # 8520 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0058429900600458495
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:34,089 INFO *** epoch 8520, rolling-avg-loss (window=10)= 0.005851746998087037
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:34,107 INFO epoch # 8521 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0058517432007647585
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:34,126 INFO epoch # 8522 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005804409345728345
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:34,144 INFO epoch # 8523 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005816137643705588
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:34,163 INFO epoch # 8524 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00582481730816653
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:34,181 INFO epoch # 8525 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005802779855002882
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:34,200 INFO epoch # 8526 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005801396015158389
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:34,218 INFO epoch # 8527 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0057849494987749495
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:34,237 INFO epoch # 8528 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005804451851872727
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:34,255 INFO epoch # 8529 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005892825047340011
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:34,274 INFO epoch # 8530 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005834510968270479
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:34,274 INFO *** epoch 8530, rolling-avg-loss (window=10)= 0.0058218020734784656
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:34,292 INFO epoch # 8531 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005795475510240067
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:34,310 INFO epoch # 8532 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005834198971570004
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:34,329 INFO epoch # 8533 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005807971589092631
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:34,347 INFO epoch # 8534 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005877205869182944
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:34,365 INFO epoch # 8535 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006003778256854275
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:34,384 INFO epoch # 8536 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005955040702247061
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:34,402 INFO epoch # 8537 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005841956644871971
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:34,421 INFO epoch # 8538 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005838888930156827
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:34,439 INFO epoch # 8539 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005961105904134456
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:34,457 INFO epoch # 8540 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005812763993162662
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:34,457 INFO *** epoch 8540, rolling-avg-loss (window=10)= 0.00587283863715129
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:34,476 INFO epoch # 8541 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006132040860393317
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:34,494 INFO epoch # 8542 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006072483334719436
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:34,512 INFO epoch # 8543 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005880211105250055
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:34,530 INFO epoch # 8544 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006182949375215685
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:34,549 INFO epoch # 8545 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0057961861730291275
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:34,567 INFO epoch # 8546 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005874632010090863
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:34,586 INFO epoch # 8547 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005836568376253126
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:34,604 INFO epoch # 8548 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007746779428998707
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:34,623 INFO epoch # 8549 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0059004118738812394
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:34,641 INFO epoch # 8550 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0058058282993442845
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:34,641 INFO *** epoch 8550, rolling-avg-loss (window=10)= 0.006122809083717584
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:34,659 INFO epoch # 8551 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005827341894473648
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:34,678 INFO epoch # 8552 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005805397962831194
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:34,696 INFO epoch # 8553 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005839974124683067
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:34,714 INFO epoch # 8554 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005790181432530517
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:34,732 INFO epoch # 8555 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005808257952594431
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:34,751 INFO epoch # 8556 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005808542471640976
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:34,769 INFO epoch # 8557 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005785063216535491
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:34,788 INFO epoch # 8558 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005832633843965596
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:34,806 INFO epoch # 8559 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0059783715987578034
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:34,824 INFO epoch # 8560 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005829083165735938
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:34,824 INFO *** epoch 8560, rolling-avg-loss (window=10)= 0.005830484766374866
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:34,843 INFO epoch # 8561 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005782628031738568
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:34,861 INFO epoch # 8562 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005950504102656851
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:34,879 INFO epoch # 8563 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005763786193710985
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:34,897 INFO epoch # 8564 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005921062129345955
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:34,916 INFO epoch # 8565 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005782670443295501
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:34,934 INFO epoch # 8566 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005900438107346417
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:34,952 INFO epoch # 8567 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005794925182271982
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:34,970 INFO epoch # 8568 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005925989455136005
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:34,989 INFO epoch # 8569 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005843960701895412
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:35,007 INFO epoch # 8570 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00588778619930963
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:35,007 INFO *** epoch 8570, rolling-avg-loss (window=10)= 0.005855375054670731
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:35,026 INFO epoch # 8571 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005805121665616753
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:35,044 INFO epoch # 8572 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005835068684973521
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:35,063 INFO epoch # 8573 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005762624646195036
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:35,081 INFO epoch # 8574 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005779155962954974
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:35,099 INFO epoch # 8575 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0058133161037403625
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:35,117 INFO epoch # 8576 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005782687600003555
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:35,136 INFO epoch # 8577 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0061065303125360515
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:35,155 INFO epoch # 8578 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005825984891998814
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:35,173 INFO epoch # 8579 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005773974717158126
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:35,191 INFO epoch # 8580 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005832337195897708
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:35,192 INFO *** epoch 8580, rolling-avg-loss (window=10)= 0.00583168017810749
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:35,210 INFO epoch # 8581 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005827395809319569
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:35,228 INFO epoch # 8582 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005783158187114168
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:35,246 INFO epoch # 8583 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005770064686657861
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:35,265 INFO epoch # 8584 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005864855171239469
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:35,283 INFO epoch # 8585 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00577297602831095
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:35,301 INFO epoch # 8586 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006276329699176131
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:35,320 INFO epoch # 8587 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005792488278530072
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:35,338 INFO epoch # 8588 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005792707270302344
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:35,356 INFO epoch # 8589 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005790779305243632
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:35,375 INFO epoch # 8590 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0057815025611489546
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:35,375 INFO *** epoch 8590, rolling-avg-loss (window=10)= 0.005845225699704315
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:35,393 INFO epoch # 8591 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005836585860379273
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:35,411 INFO epoch # 8592 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005796276142064016
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:35,429 INFO epoch # 8593 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00581288824105286
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:35,448 INFO epoch # 8594 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005776736281404737
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:35,466 INFO epoch # 8595 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005885194939764915
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:35,485 INFO epoch # 8596 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00579733695849427
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:35,503 INFO epoch # 8597 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005790598163002869
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:35,521 INFO epoch # 8598 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005790603867353639
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:35,539 INFO epoch # 8599 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005821236700285226
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:35,557 INFO epoch # 8600 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005811326580442255
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:35,558 INFO *** epoch 8600, rolling-avg-loss (window=10)= 0.005811878373424406
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:35,576 INFO epoch # 8601 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.008660487274028128
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:35,594 INFO epoch # 8602 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005823434956255369
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:35,613 INFO epoch # 8603 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005814426360302605
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:35,631 INFO epoch # 8604 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005818258145154687
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:35,649 INFO epoch # 8605 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007686768698476953
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:35,668 INFO epoch # 8606 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00604375776310917
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:35,686 INFO epoch # 8607 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005883723453735001
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:35,704 INFO epoch # 8608 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005798835714813322
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:35,722 INFO epoch # 8609 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005945350414549466
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:35,741 INFO epoch # 8610 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00576594278390985
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:35,741 INFO *** epoch 8610, rolling-avg-loss (window=10)= 0.006324098556433455
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:35,759 INFO epoch # 8611 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.008574386913096532
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:35,777 INFO epoch # 8612 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0058444368551135994
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:35,796 INFO epoch # 8613 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00612323638779344
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:35,814 INFO epoch # 8614 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005765017627709312
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:35,833 INFO epoch # 8615 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005801054492621915
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:35,851 INFO epoch # 8616 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005771629814262269
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:35,869 INFO epoch # 8617 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006219893959496403
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:35,888 INFO epoch # 8618 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00615745797767886
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:35,906 INFO epoch # 8619 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005773754328401992
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:35,925 INFO epoch # 8620 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005861499779712176
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:35,925 INFO *** epoch 8620, rolling-avg-loss (window=10)= 0.00618923681358865
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:35,943 INFO epoch # 8621 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0058610018277249765
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:35,961 INFO epoch # 8622 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005752161690907087
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:35,980 INFO epoch # 8623 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00578748380576144
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:35,998 INFO epoch # 8624 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0057861339882947505
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:36,017 INFO epoch # 8625 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005781693434983026
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:36,035 INFO epoch # 8626 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0058817271565203555
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:36,054 INFO epoch # 8627 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005762092074292013
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:36,072 INFO epoch # 8628 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0057681224279804155
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:36,090 INFO epoch # 8629 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005751209068876051
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:36,109 INFO epoch # 8630 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00576909391747904
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:36,109 INFO *** epoch 8630, rolling-avg-loss (window=10)= 0.005790071939281915
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:36,127 INFO epoch # 8631 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005862394398718607
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:36,145 INFO epoch # 8632 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0057720575568964705
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:36,163 INFO epoch # 8633 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005784897162811831
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:36,182 INFO epoch # 8634 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005776946261903504
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:36,200 INFO epoch # 8635 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005826345870445948
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:36,218 INFO epoch # 8636 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005949630060058553
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:36,237 INFO epoch # 8637 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005755362868512748
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:36,255 INFO epoch # 8638 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005799605649372097
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:36,274 INFO epoch # 8639 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005795675500849029
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:36,292 INFO epoch # 8640 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005749134643338039
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:36,292 INFO *** epoch 8640, rolling-avg-loss (window=10)= 0.005807204997290682
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:36,310 INFO epoch # 8641 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005780994670203654
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:36,328 INFO epoch # 8642 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005902622753637843
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:36,347 INFO epoch # 8643 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005787147591036046
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:36,365 INFO epoch # 8644 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005773809938546037
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:36,383 INFO epoch # 8645 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005757795477620675
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:36,402 INFO epoch # 8646 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00616812929729349
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:36,420 INFO epoch # 8647 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005829075660585659
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:36,438 INFO epoch # 8648 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005787604262877721
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:36,456 INFO epoch # 8649 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005902435619645985
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:36,475 INFO epoch # 8650 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005929323750024196
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:36,475 INFO *** epoch 8650, rolling-avg-loss (window=10)= 0.00586189390214713
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:36,493 INFO epoch # 8651 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005784528431831859
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:36,511 INFO epoch # 8652 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005771685002400773
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:36,530 INFO epoch # 8653 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005886914612347027
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:36,548 INFO epoch # 8654 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005812484276248142
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:36,566 INFO epoch # 8655 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005755647191108437
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:36,585 INFO epoch # 8656 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005770909589045914
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:36,603 INFO epoch # 8657 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005781756037322339
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:36,622 INFO epoch # 8658 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005876342831470538
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:36,641 INFO epoch # 8659 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005779640843684319
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:36,660 INFO epoch # 8660 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005752177177782869
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:36,660 INFO *** epoch 8660, rolling-avg-loss (window=10)= 0.005797208599324222
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:36,679 INFO epoch # 8661 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0058347932499600574
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:36,698 INFO epoch # 8662 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00579832923176582
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:36,717 INFO epoch # 8663 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00580268175326637
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:36,735 INFO epoch # 8664 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005802642401249614
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:36,753 INFO epoch # 8665 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005820965994644212
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:36,772 INFO epoch # 8666 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005754631809395505
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:36,790 INFO epoch # 8667 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005747726681875065
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:36,808 INFO epoch # 8668 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005853277227288345
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:36,826 INFO epoch # 8669 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005815464865008835
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:36,845 INFO epoch # 8670 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005744849442635314
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:36,845 INFO *** epoch 8670, rolling-avg-loss (window=10)= 0.005797536265708914
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:36,863 INFO epoch # 8671 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005774408407887677
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:36,882 INFO epoch # 8672 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005859159100509714
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:36,900 INFO epoch # 8673 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005745958031184273
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:36,919 INFO epoch # 8674 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005777263890195172
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:36,938 INFO epoch # 8675 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005764535650087055
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:36,956 INFO epoch # 8676 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005957524354016641
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:36,974 INFO epoch # 8677 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005790393781353487
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:36,993 INFO epoch # 8678 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.008663794160383986
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:37,011 INFO epoch # 8679 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00577574363705935
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:37,029 INFO epoch # 8680 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005793210893898504
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:37,030 INFO *** epoch 8680, rolling-avg-loss (window=10)= 0.006090199190657586
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:37,048 INFO epoch # 8681 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005764461755461525
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:37,067 INFO epoch # 8682 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005771314645244274
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:37,085 INFO epoch # 8683 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005776299924036721
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:37,103 INFO epoch # 8684 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007694073476159247
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:37,122 INFO epoch # 8685 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005975719082925934
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:37,140 INFO epoch # 8686 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005898051989788655
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:37,158 INFO epoch # 8687 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0057684656349010766
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:37,177 INFO epoch # 8688 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005941121700743679
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:37,195 INFO epoch # 8689 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0060372382795321755
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:37,213 INFO epoch # 8690 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005751710892582196
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:37,213 INFO *** epoch 8690, rolling-avg-loss (window=10)= 0.0060378457381375485
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:37,232 INFO epoch # 8691 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005773560216766782
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:37,250 INFO epoch # 8692 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007622288376296638
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:37,269 INFO epoch # 8693 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005816917568154167
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:37,288 INFO epoch # 8694 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005785470177215757
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:37,307 INFO epoch # 8695 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0057682227561599575
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:37,326 INFO epoch # 8696 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005806916542496765
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:37,349 INFO epoch # 8697 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005837057789904065
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:37,369 INFO epoch # 8698 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005760429001384182
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:37,389 INFO epoch # 8699 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0057849267177516595
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:37,408 INFO epoch # 8700 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005752405635575997
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:37,408 INFO *** epoch 8700, rolling-avg-loss (window=10)= 0.005970819478170597
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:37,427 INFO epoch # 8701 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005811911974888062
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:37,445 INFO epoch # 8702 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005733543337555602
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:37,464 INFO epoch # 8703 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005871345125342486
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:37,483 INFO epoch # 8704 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005771216096036369
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:37,502 INFO epoch # 8705 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0057456538306723814
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:37,521 INFO epoch # 8706 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005771024392743129
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:37,540 INFO epoch # 8707 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005824071329698199
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:37,558 INFO epoch # 8708 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005789957067463547
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:37,577 INFO epoch # 8709 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005756650796683971
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:37,596 INFO epoch # 8710 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005749031832237961
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:37,596 INFO *** epoch 8710, rolling-avg-loss (window=10)= 0.005782440578332171
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:37,614 INFO epoch # 8711 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005785331260995008
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:37,632 INFO epoch # 8712 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005730065748139168
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:37,651 INFO epoch # 8713 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005770494128228165
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:37,669 INFO epoch # 8714 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005737299976317445
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:37,688 INFO epoch # 8715 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006197629227244761
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:37,706 INFO epoch # 8716 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005745874488638947
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:37,725 INFO epoch # 8717 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005753729546995601
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:37,743 INFO epoch # 8718 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00579462226232863
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:37,762 INFO epoch # 8719 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005772897657152498
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:37,780 INFO epoch # 8720 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00574577823135769
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:37,781 INFO *** epoch 8720, rolling-avg-loss (window=10)= 0.005803372252739791
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:37,799 INFO epoch # 8721 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005871718763955869
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:37,818 INFO epoch # 8722 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005742884852224961
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:37,836 INFO epoch # 8723 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005732530542445602
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:37,854 INFO epoch # 8724 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005771138829004485
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:37,873 INFO epoch # 8725 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005887316972803092
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:37,891 INFO epoch # 8726 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005803944273793604
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:37,909 INFO epoch # 8727 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005766425449110102
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:37,928 INFO epoch # 8728 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005728799511416582
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:37,947 INFO epoch # 8729 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007096772478689672
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:37,965 INFO epoch # 8730 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0058626725658541545
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:37,965 INFO *** epoch 8730, rolling-avg-loss (window=10)= 0.005926420423929812
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:37,984 INFO epoch # 8731 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006298180800513364
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:38,002 INFO epoch # 8732 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005783305921795545
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:38,020 INFO epoch # 8733 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005751672346377745
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:38,039 INFO epoch # 8734 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005809166334074689
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:38,057 INFO epoch # 8735 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005788620292150881
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:38,075 INFO epoch # 8736 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0057446049140708055
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:38,093 INFO epoch # 8737 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005759975410910556
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:38,112 INFO epoch # 8738 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005764865967648802
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:38,130 INFO epoch # 8739 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005871369958185824
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:38,149 INFO epoch # 8740 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006041064207238378
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:38,149 INFO *** epoch 8740, rolling-avg-loss (window=10)= 0.005861282615296659
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:38,167 INFO epoch # 8741 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007652162041267729
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:38,186 INFO epoch # 8742 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0057441617573203985
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:38,204 INFO epoch # 8743 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005776447858806932
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:38,222 INFO epoch # 8744 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005752748831582721
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:38,241 INFO epoch # 8745 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005736028011597227
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:38,259 INFO epoch # 8746 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005883099518541712
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:38,277 INFO epoch # 8747 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005740254564443603
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:38,296 INFO epoch # 8748 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006077279456803808
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:38,314 INFO epoch # 8749 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00578161767043639
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:38,332 INFO epoch # 8750 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005824811487400439
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:38,333 INFO *** epoch 8750, rolling-avg-loss (window=10)= 0.005996861119820096
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:38,351 INFO epoch # 8751 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005749545231083175
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:38,370 INFO epoch # 8752 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0057462891381874215
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:38,388 INFO epoch # 8753 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005763351855421206
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:38,406 INFO epoch # 8754 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0057773638363869395
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:38,425 INFO epoch # 8755 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005797531728603644
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:38,443 INFO epoch # 8756 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007621821354405256
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:38,461 INFO epoch # 8757 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005928726939600892
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:38,480 INFO epoch # 8758 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005779374761914369
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:38,498 INFO epoch # 8759 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0057865657545335125
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:38,516 INFO epoch # 8760 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005754634956247173
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:38,516 INFO *** epoch 8760, rolling-avg-loss (window=10)= 0.005970520555638359
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:38,534 INFO epoch # 8761 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005731148892664351
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:38,553 INFO epoch # 8762 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005740734140999848
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:38,571 INFO epoch # 8763 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005809462185425218
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:38,590 INFO epoch # 8764 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005793838168756338
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:38,608 INFO epoch # 8765 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0058246761400369
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:38,627 INFO epoch # 8766 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005813832231069682
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:38,646 INFO epoch # 8767 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005721491783333477
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:38,664 INFO epoch # 8768 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00572102135993191
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:38,682 INFO epoch # 8769 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005743956307924236
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:38,701 INFO epoch # 8770 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005743223100580508
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:38,701 INFO *** epoch 8770, rolling-avg-loss (window=10)= 0.005764338431072246
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:38,719 INFO epoch # 8771 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005721818706660997
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:38,737 INFO epoch # 8772 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005722160285586142
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:38,756 INFO epoch # 8773 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0058184282534057274
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:38,774 INFO epoch # 8774 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0057424738370173145
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:38,793 INFO epoch # 8775 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0057925537912524305
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:38,811 INFO epoch # 8776 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00572969725180883
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:38,830 INFO epoch # 8777 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0057803298586804885
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:38,848 INFO epoch # 8778 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005837992233864497
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:38,866 INFO epoch # 8779 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005727226072849589
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:38,884 INFO epoch # 8780 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0058557414486131165
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:38,885 INFO *** epoch 8780, rolling-avg-loss (window=10)= 0.005772842173973914
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:38,903 INFO epoch # 8781 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005716409763408592
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:38,921 INFO epoch # 8782 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005709844845114276
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:38,940 INFO epoch # 8783 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005743974554206943
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:38,958 INFO epoch # 8784 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005739164091210114
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:38,977 INFO epoch # 8785 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005761745058407541
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:38,995 INFO epoch # 8786 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005744654601585353
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:39,014 INFO epoch # 8787 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005784576638689032
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:39,032 INFO epoch # 8788 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005898911262192996
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:39,051 INFO epoch # 8789 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005873430192878004
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:39,069 INFO epoch # 8790 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005781912685051793
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:39,069 INFO *** epoch 8790, rolling-avg-loss (window=10)= 0.005775462369274465
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:39,087 INFO epoch # 8791 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005746909024310298
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:39,106 INFO epoch # 8792 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005997182932333089
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:39,124 INFO epoch # 8793 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005765788169810548
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:39,142 INFO epoch # 8794 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005761939577496378
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:39,161 INFO epoch # 8795 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005740573033108376
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:39,179 INFO epoch # 8796 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005774646855570609
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:39,198 INFO epoch # 8797 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005728217223804677
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:39,216 INFO epoch # 8798 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005982026654237416
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:39,235 INFO epoch # 8799 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005916353773500305
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:39,253 INFO epoch # 8800 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005931359824899118
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:39,253 INFO *** epoch 8800, rolling-avg-loss (window=10)= 0.005834499706907081
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:39,271 INFO epoch # 8801 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005728347932745237
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:39,289 INFO epoch # 8802 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005723034119000658
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:39,308 INFO epoch # 8803 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00576002169327694
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:39,326 INFO epoch # 8804 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005751724605943309
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:39,344 INFO epoch # 8805 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00572184276097687
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:39,363 INFO epoch # 8806 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006060775780497352
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:39,381 INFO epoch # 8807 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005737482395488769
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:39,400 INFO epoch # 8808 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005791606439743191
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:39,418 INFO epoch # 8809 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005720426579500781
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:39,436 INFO epoch # 8810 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005742851069953758
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:39,437 INFO *** epoch 8810, rolling-avg-loss (window=10)= 0.005773811337712686
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:39,455 INFO epoch # 8811 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00571852303983178
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:39,473 INFO epoch # 8812 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005795124616270186
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:39,492 INFO epoch # 8813 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005903852932533482
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:39,510 INFO epoch # 8814 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005738557261793176
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:39,528 INFO epoch # 8815 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005712188863981282
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:39,546 INFO epoch # 8816 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005886025399377104
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:39,565 INFO epoch # 8817 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0057638241451059
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:39,584 INFO epoch # 8818 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005710245777663658
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:39,602 INFO epoch # 8819 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0058225896282237954
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:39,620 INFO epoch # 8820 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005777187780040549
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:39,621 INFO *** epoch 8820, rolling-avg-loss (window=10)= 0.005782811944482091
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:39,639 INFO epoch # 8821 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005773342189058894
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:39,657 INFO epoch # 8822 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0057088544072030345
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:39,675 INFO epoch # 8823 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005719872446206864
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:39,694 INFO epoch # 8824 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0057646931636554655
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:39,712 INFO epoch # 8825 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005695347934306483
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:39,730 INFO epoch # 8826 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005741017241234658
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:39,749 INFO epoch # 8827 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0058269263863621745
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:39,767 INFO epoch # 8828 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005706806568923639
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:39,786 INFO epoch # 8829 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006210581996128894
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:39,804 INFO epoch # 8830 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006001490528433351
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:39,804 INFO *** epoch 8830, rolling-avg-loss (window=10)= 0.0058148932861513455
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:39,823 INFO epoch # 8831 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005735257695050677
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:39,841 INFO epoch # 8832 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0057250847821705975
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:39,859 INFO epoch # 8833 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005737277700973209
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:39,878 INFO epoch # 8834 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0057681889993546065
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:39,896 INFO epoch # 8835 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005728763062506914
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:39,914 INFO epoch # 8836 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005719761986256344
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:39,932 INFO epoch # 8837 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005890380336495582
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:39,950 INFO epoch # 8838 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005766293452325044
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:39,969 INFO epoch # 8839 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005716269541153451
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:39,987 INFO epoch # 8840 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005725661794713233
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:39,987 INFO *** epoch 8840, rolling-avg-loss (window=10)= 0.0057512939350999655
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:40,006 INFO epoch # 8841 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005828157572977943
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:40,024 INFO epoch # 8842 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005720015979022719
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:40,043 INFO epoch # 8843 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0060945942386751994
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:40,063 INFO epoch # 8844 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005731828761781799
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:40,081 INFO epoch # 8845 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005765089084889041
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:40,099 INFO epoch # 8846 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005759826563007664
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:40,118 INFO epoch # 8847 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005834574985783547
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:40,137 INFO epoch # 8848 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005847048756550066
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:40,155 INFO epoch # 8849 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005753580819146009
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:40,174 INFO epoch # 8850 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005702397324057529
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:40,174 INFO *** epoch 8850, rolling-avg-loss (window=10)= 0.005803711408589152
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:40,193 INFO epoch # 8851 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005734181933803484
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:40,211 INFO epoch # 8852 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005738459622079972
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:40,230 INFO epoch # 8853 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005809486963698873
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:40,248 INFO epoch # 8854 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005729835484089563
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:40,267 INFO epoch # 8855 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005742681645642733
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:40,285 INFO epoch # 8856 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005723446349293226
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:40,303 INFO epoch # 8857 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005737144689192064
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:40,321 INFO epoch # 8858 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005697287360817427
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:40,340 INFO epoch # 8859 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005713137834391091
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:40,358 INFO epoch # 8860 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006104173186031403
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:40,358 INFO *** epoch 8860, rolling-avg-loss (window=10)= 0.005772983506903984
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:40,376 INFO epoch # 8861 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005850681078300113
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:40,395 INFO epoch # 8862 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005885138663870748
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:40,413 INFO epoch # 8863 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005726819679694017
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:40,432 INFO epoch # 8864 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0057939751459343825
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:40,451 INFO epoch # 8865 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005702436286810553
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:40,469 INFO epoch # 8866 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005760747564636404
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:40,488 INFO epoch # 8867 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005708224063710077
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:40,506 INFO epoch # 8868 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005707051586796297
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:40,524 INFO epoch # 8869 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005713230839319294
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:40,543 INFO epoch # 8870 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005693643586710095
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:40,543 INFO *** epoch 8870, rolling-avg-loss (window=10)= 0.005754194849578198
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:40,561 INFO epoch # 8871 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0058088350560865365
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:40,579 INFO epoch # 8872 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005703604974769405
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:40,598 INFO epoch # 8873 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005767290957010118
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:40,616 INFO epoch # 8874 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005700999561668141
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:40,635 INFO epoch # 8875 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005741441400459735
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:40,653 INFO epoch # 8876 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005736724240705371
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:40,672 INFO epoch # 8877 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005707709136913763
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:40,691 INFO epoch # 8878 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005768858714873204
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:40,709 INFO epoch # 8879 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005724034115701215
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:40,727 INFO epoch # 8880 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006007569518260425
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:40,727 INFO *** epoch 8880, rolling-avg-loss (window=10)= 0.005766706767644791
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:40,745 INFO epoch # 8881 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007561194473964861
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:40,764 INFO epoch # 8882 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005750665866798954
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:40,782 INFO epoch # 8883 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005743070261814864
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:40,800 INFO epoch # 8884 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005772607666585827
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:40,819 INFO epoch # 8885 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005706264204491163
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:40,837 INFO epoch # 8886 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00569990079748095
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:40,856 INFO epoch # 8887 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005809815524116857
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:40,875 INFO epoch # 8888 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005716552648664219
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:40,894 INFO epoch # 8889 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0057146418730553705
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:40,913 INFO epoch # 8890 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006164790778711904
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:40,913 INFO *** epoch 8890, rolling-avg-loss (window=10)= 0.005963950409568497
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:40,931 INFO epoch # 8891 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005700665144104278
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:40,949 INFO epoch # 8892 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00569239171272784
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:40,968 INFO epoch # 8893 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005781176914751995
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:40,986 INFO epoch # 8894 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005707131713279523
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:41,005 INFO epoch # 8895 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005784218770713778
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:41,024 INFO epoch # 8896 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005675595729371707
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:41,043 INFO epoch # 8897 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005712497411877848
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:41,062 INFO epoch # 8898 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0057267895608674735
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:41,081 INFO epoch # 8899 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005823045870783972
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:41,100 INFO epoch # 8900 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0057053278214880265
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:41,100 INFO *** epoch 8900, rolling-avg-loss (window=10)= 0.005730884064996644
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:41,118 INFO epoch # 8901 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0057136901923513506
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:41,137 INFO epoch # 8902 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005704844748834148
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:41,155 INFO epoch # 8903 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005703500957679353
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:41,173 INFO epoch # 8904 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00574404095459613
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:41,192 INFO epoch # 8905 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005719891352782724
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:41,210 INFO epoch # 8906 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005768267008534167
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:41,230 INFO epoch # 8907 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005692683036613744
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:41,249 INFO epoch # 8908 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006095911550801247
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:41,268 INFO epoch # 8909 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0057235901258536614
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:41,287 INFO epoch # 8910 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005729644817620283
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:41,287 INFO *** epoch 8910, rolling-avg-loss (window=10)= 0.005759606474566681
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:41,306 INFO epoch # 8911 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005686286167474464
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:41,324 INFO epoch # 8912 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005696382489986718
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:41,342 INFO epoch # 8913 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005766466740169562
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:41,360 INFO epoch # 8914 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00573362406794331
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:41,379 INFO epoch # 8915 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0058002431942441035
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:41,397 INFO epoch # 8916 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005695977819414111
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:41,416 INFO epoch # 8917 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005708082691853633
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:41,434 INFO epoch # 8918 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005698834709619405
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:41,453 INFO epoch # 8919 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005707735850592144
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:41,473 INFO epoch # 8920 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00568847941030981
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:41,473 INFO *** epoch 8920, rolling-avg-loss (window=10)= 0.005718211314160726
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:41,491 INFO epoch # 8921 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005720820416172501
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:41,510 INFO epoch # 8922 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005725177554268157
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:41,528 INFO epoch # 8923 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005717077183362562
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:41,547 INFO epoch # 8924 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005762323857197771
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:41,565 INFO epoch # 8925 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005699529250705382
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:41,583 INFO epoch # 8926 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0056870628795877565
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:41,602 INFO epoch # 8927 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005747550774685806
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:41,620 INFO epoch # 8928 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005717324969737092
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:41,639 INFO epoch # 8929 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005701779107766924
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:41,658 INFO epoch # 8930 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005750946671469137
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:41,658 INFO *** epoch 8930, rolling-avg-loss (window=10)= 0.005722959266495309
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:41,677 INFO epoch # 8931 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00572605859633768
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:41,697 INFO epoch # 8932 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005792502732219873
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:41,715 INFO epoch # 8933 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00568241153996496
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:41,733 INFO epoch # 8934 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0056861487464630045
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:41,751 INFO epoch # 8935 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005671692195392097
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:41,770 INFO epoch # 8936 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0057085086264123674
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:41,788 INFO epoch # 8937 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005698000662960112
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:41,806 INFO epoch # 8938 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005813606716401409
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:41,824 INFO epoch # 8939 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005718474370951299
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:41,843 INFO epoch # 8940 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005707455522497185
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:41,843 INFO *** epoch 8940, rolling-avg-loss (window=10)= 0.005720485970959999
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:41,862 INFO epoch # 8941 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00846725868541398
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:41,880 INFO epoch # 8942 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005735741360695101
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:41,899 INFO epoch # 8943 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005706562951672822
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:41,917 INFO epoch # 8944 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005703431997972075
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:41,936 INFO epoch # 8945 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005729866581532406
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:41,954 INFO epoch # 8946 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005777868656878127
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:41,972 INFO epoch # 8947 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005739904652728001
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:41,991 INFO epoch # 8948 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005801886863991967
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:42,009 INFO epoch # 8949 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005707345833798172
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:42,027 INFO epoch # 8950 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005879597567400197
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:42,027 INFO *** epoch 8950, rolling-avg-loss (window=10)= 0.006024946515208285
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:42,046 INFO epoch # 8951 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005694592415238731
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:42,064 INFO epoch # 8952 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005706170340999961
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:42,083 INFO epoch # 8953 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005705564297386445
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:42,101 INFO epoch # 8954 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005755717771535274
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:42,120 INFO epoch # 8955 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005675729416907416
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:42,139 INFO epoch # 8956 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005781200728961267
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:42,157 INFO epoch # 8957 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005709874116291758
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:42,175 INFO epoch # 8958 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005671573499057558
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:42,193 INFO epoch # 8959 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005728721767809475
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:42,212 INFO epoch # 8960 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005673782674421091
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:42,212 INFO *** epoch 8960, rolling-avg-loss (window=10)= 0.005710292702860898
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:42,230 INFO epoch # 8961 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005699340381397633
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:42,248 INFO epoch # 8962 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00568037853736314
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:42,267 INFO epoch # 8963 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005702184771507746
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:42,285 INFO epoch # 8964 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005874159891391173
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:42,304 INFO epoch # 8965 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005750828724558232
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:42,322 INFO epoch # 8966 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005696281197742792
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:42,341 INFO epoch # 8967 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006101190076151397
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:42,359 INFO epoch # 8968 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00569145976260188
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:42,378 INFO epoch # 8969 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005768793533206917
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:42,396 INFO epoch # 8970 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0056654719865036895
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:42,396 INFO *** epoch 8970, rolling-avg-loss (window=10)= 0.00576300888624246
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:42,414 INFO epoch # 8971 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0056610116280353395
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:42,432 INFO epoch # 8972 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0056817655568011105
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:42,451 INFO epoch # 8973 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005678710003849119
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:42,469 INFO epoch # 8974 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005826136904943269
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:42,488 INFO epoch # 8975 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00566725851240335
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:42,506 INFO epoch # 8976 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005715486942790449
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:42,525 INFO epoch # 8977 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005761103737313533
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:42,543 INFO epoch # 8978 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0056596579488541465
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:42,562 INFO epoch # 8979 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005701065994799137
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:42,580 INFO epoch # 8980 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005802557476272341
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:42,580 INFO *** epoch 8980, rolling-avg-loss (window=10)= 0.005715475470606179
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:42,598 INFO epoch # 8981 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006229791179066524
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:42,617 INFO epoch # 8982 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0057221052556997165
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:42,635 INFO epoch # 8983 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005672552848409396
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:42,653 INFO epoch # 8984 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005663762118274462
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:42,672 INFO epoch # 8985 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0056815481548255775
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:42,690 INFO epoch # 8986 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005827608834806597
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:42,709 INFO epoch # 8987 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005672322331520263
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:42,727 INFO epoch # 8988 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0056525356476413435
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:42,745 INFO epoch # 8989 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0058676454464148264
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:42,764 INFO epoch # 8990 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005685608619387494
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:42,764 INFO *** epoch 8990, rolling-avg-loss (window=10)= 0.00576754804360462
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:42,782 INFO epoch # 8991 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00565390994597692
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:42,801 INFO epoch # 8992 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005756385278800735
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:42,819 INFO epoch # 8993 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005735340244427789
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:42,837 INFO epoch # 8994 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005686525342753157
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:42,855 INFO epoch # 8995 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005866464314749464
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:42,874 INFO epoch # 8996 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0058696026098914444
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:42,892 INFO epoch # 8997 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0057195860499632545
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:42,911 INFO epoch # 8998 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005686324380803853
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:42,929 INFO epoch # 8999 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0058626882564567495
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:42,947 INFO epoch # 9000 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005672431416314794
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:42,948 INFO *** epoch 9000, rolling-avg-loss (window=10)= 0.005750925784013816
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:42,966 INFO epoch # 9001 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005707546959456522
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:42,985 INFO epoch # 9002 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005737191193475155
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:43,004 INFO epoch # 9003 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005711025540222181
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:43,022 INFO epoch # 9004 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005712377998861484
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:43,041 INFO epoch # 9005 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005683416744432179
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:43,059 INFO epoch # 9006 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0056779289843689185
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:43,077 INFO epoch # 9007 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005733822505135322
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:43,096 INFO epoch # 9008 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005670095175446477
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:43,114 INFO epoch # 9009 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0056679226327105425
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:43,133 INFO epoch # 9010 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0056622576994413976
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:43,133 INFO *** epoch 9010, rolling-avg-loss (window=10)= 0.0056963585433550176
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:43,152 INFO epoch # 9011 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005669832949934062
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:43,170 INFO epoch # 9012 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005661982570018154
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:43,189 INFO epoch # 9013 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005669018340995535
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:43,207 INFO epoch # 9014 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005853834773006383
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:43,225 INFO epoch # 9015 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005696121108485386
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:43,243 INFO epoch # 9016 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005656601402733941
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:43,262 INFO epoch # 9017 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005846535390446661
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:43,280 INFO epoch # 9018 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005693854502169415
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:43,299 INFO epoch # 9019 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005748910865804646
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:43,317 INFO epoch # 9020 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005692828344763257
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:43,317 INFO *** epoch 9020, rolling-avg-loss (window=10)= 0.005718952024835744
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:43,336 INFO epoch # 9021 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0057915345787478145
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:43,355 INFO epoch # 9022 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00566818671177316
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:43,374 INFO epoch # 9023 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005669036985636922
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:43,392 INFO epoch # 9024 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005652229207044002
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:43,410 INFO epoch # 9025 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005800459493912058
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:43,429 INFO epoch # 9026 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00595944915767177
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:43,447 INFO epoch # 9027 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005727338069846155
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:43,465 INFO epoch # 9028 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005702977690816624
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:43,483 INFO epoch # 9029 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0057106191270577256
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:43,502 INFO epoch # 9030 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005671543625794584
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:43,502 INFO *** epoch 9030, rolling-avg-loss (window=10)= 0.005735337464830082
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:43,520 INFO epoch # 9031 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005668311521731084
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:43,539 INFO epoch # 9032 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005687137625500327
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:43,557 INFO epoch # 9033 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005706138173991349
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:43,576 INFO epoch # 9034 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00566503405207186
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:43,594 INFO epoch # 9035 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00569249735417543
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:43,613 INFO epoch # 9036 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005705775063688634
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:43,631 INFO epoch # 9037 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006020361906848848
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:43,649 INFO epoch # 9038 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005661874482029816
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:43,668 INFO epoch # 9039 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005946796285570599
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:43,686 INFO epoch # 9040 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005654458618664648
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:43,686 INFO *** epoch 9040, rolling-avg-loss (window=10)= 0.005740838508427259
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:43,704 INFO epoch # 9041 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005647176090860739
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:43,723 INFO epoch # 9042 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005711129793780856
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:43,741 INFO epoch # 9043 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00565218511474086
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:43,759 INFO epoch # 9044 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0057212175997847226
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:43,778 INFO epoch # 9045 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005681900525814854
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:43,796 INFO epoch # 9046 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005635919673295575
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:43,814 INFO epoch # 9047 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005710995712433942
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:43,832 INFO epoch # 9048 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005793982130853692
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:43,851 INFO epoch # 9049 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005677875298715662
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:43,869 INFO epoch # 9050 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0056653585816093255
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:43,869 INFO *** epoch 9050, rolling-avg-loss (window=10)= 0.005689774052189023
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:43,887 INFO epoch # 9051 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005660523354890756
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:43,906 INFO epoch # 9052 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005651447376294527
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:43,924 INFO epoch # 9053 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0056758419414109085
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:43,943 INFO epoch # 9054 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005657878427882679
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:43,961 INFO epoch # 9055 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005665062773914542
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:43,979 INFO epoch # 9056 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005679486654116772
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:43,998 INFO epoch # 9057 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005910940599278547
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:44,017 INFO epoch # 9058 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005665934029821074
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:44,036 INFO epoch # 9059 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0056895341840572655
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:44,054 INFO epoch # 9060 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005670225345966173
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:44,054 INFO *** epoch 9060, rolling-avg-loss (window=10)= 0.005692687468763324
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:44,072 INFO epoch # 9061 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005689560079190414
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:44,091 INFO epoch # 9062 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005644798864523182
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:44,109 INFO epoch # 9063 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005655869492329657
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:44,128 INFO epoch # 9064 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005715667037293315
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:44,146 INFO epoch # 9065 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005690565423719818
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:44,164 INFO epoch # 9066 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005665300770488102
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:44,183 INFO epoch # 9067 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005690497815521667
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:44,201 INFO epoch # 9068 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005721880923374556
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:44,220 INFO epoch # 9069 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005666113702318398
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:44,238 INFO epoch # 9070 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00569613454354112
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:44,238 INFO *** epoch 9070, rolling-avg-loss (window=10)= 0.005683638865230023
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:44,256 INFO epoch # 9071 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0056477763573639095
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:44,274 INFO epoch # 9072 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005671667593560414
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:44,292 INFO epoch # 9073 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005842598158778856
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:44,311 INFO epoch # 9074 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005664627587975701
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:44,329 INFO epoch # 9075 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005671121667546686
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:44,348 INFO epoch # 9076 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005675513049936853
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:44,366 INFO epoch # 9077 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005946012235654052
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:44,384 INFO epoch # 9078 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0057409995861235075
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:44,403 INFO epoch # 9079 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005654404667438939
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:44,421 INFO epoch # 9080 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005699001503671752
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:44,421 INFO *** epoch 9080, rolling-avg-loss (window=10)= 0.0057213722408050675
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:44,439 INFO epoch # 9081 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005688699191523483
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:44,458 INFO epoch # 9082 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0057072897943726275
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:44,476 INFO epoch # 9083 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0056405305076623335
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:44,494 INFO epoch # 9084 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005638376806018641
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:44,512 INFO epoch # 9085 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0056843214042601176
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:44,531 INFO epoch # 9086 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005668004319886677
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:44,549 INFO epoch # 9087 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005643455293466104
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:44,568 INFO epoch # 9088 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007513050757552264
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:44,586 INFO epoch # 9089 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005707798729417846
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:44,605 INFO epoch # 9090 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00608688576539862
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:44,605 INFO *** epoch 9090, rolling-avg-loss (window=10)= 0.0058978412569558715
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:44,624 INFO epoch # 9091 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0058734014455694705
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:44,642 INFO epoch # 9092 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005658771475282265
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:44,660 INFO epoch # 9093 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005635420500766486
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:44,679 INFO epoch # 9094 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0056359259942837525
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:44,697 INFO epoch # 9095 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005627964459563373
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:44,715 INFO epoch # 9096 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005649745660775807
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:44,733 INFO epoch # 9097 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0056594161906105
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:44,752 INFO epoch # 9098 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005824558185850037
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:44,770 INFO epoch # 9099 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005667503683071118
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:44,789 INFO epoch # 9100 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005690198751835851
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:44,789 INFO *** epoch 9100, rolling-avg-loss (window=10)= 0.005692290634760866
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:44,807 INFO epoch # 9101 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005801378054457018
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:44,825 INFO epoch # 9102 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006127796914370265
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:44,844 INFO epoch # 9103 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005686639226041734
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:44,862 INFO epoch # 9104 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0059436119372549
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:44,880 INFO epoch # 9105 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00567292742562131
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:44,898 INFO epoch # 9106 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005732759711463586
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:44,917 INFO epoch # 9107 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005692756480129901
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:44,935 INFO epoch # 9108 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005665274420607602
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:44,953 INFO epoch # 9109 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0058285297636757605
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:44,971 INFO epoch # 9110 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005688092951459112
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:44,972 INFO *** epoch 9110, rolling-avg-loss (window=10)= 0.005783976688508119
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:44,990 INFO epoch # 9111 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005678092475136509
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:45,009 INFO epoch # 9112 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005642216492560692
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:45,028 INFO epoch # 9113 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005721820140024647
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:45,046 INFO epoch # 9114 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005639816581606283
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:45,065 INFO epoch # 9115 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005660770479153143
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:45,083 INFO epoch # 9116 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005829050329339225
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:45,101 INFO epoch # 9117 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005623938706776244
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:45,120 INFO epoch # 9118 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005633720451442059
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:45,138 INFO epoch # 9119 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00569686884409748
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:45,156 INFO epoch # 9120 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005653377471389831
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:45,156 INFO *** epoch 9120, rolling-avg-loss (window=10)= 0.005677967197152611
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:45,175 INFO epoch # 9121 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005656420911691384
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:45,193 INFO epoch # 9122 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005633100758132059
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:45,211 INFO epoch # 9123 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005674623096638243
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:45,230 INFO epoch # 9124 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005689498073479626
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:45,249 INFO epoch # 9125 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005686587104719365
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:45,267 INFO epoch # 9126 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005642942356644198
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:45,285 INFO epoch # 9127 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007555464380857302
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:45,304 INFO epoch # 9128 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005988879638607614
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:45,322 INFO epoch # 9129 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005742814588302281
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:45,340 INFO epoch # 9130 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005646628462272929
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:45,340 INFO *** epoch 9130, rolling-avg-loss (window=10)= 0.0058916959371345
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:45,359 INFO epoch # 9131 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005636634798065643
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:45,377 INFO epoch # 9132 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005638390237436397
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:45,396 INFO epoch # 9133 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005740798253100365
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:45,414 INFO epoch # 9134 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005636599738863879
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:45,433 INFO epoch # 9135 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005832760196426534
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:45,451 INFO epoch # 9136 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005634367640595883
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:45,470 INFO epoch # 9137 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005675203348801006
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:45,488 INFO epoch # 9138 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005635161674945266
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:45,506 INFO epoch # 9139 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005689917892595986
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:45,524 INFO epoch # 9140 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005623394496069523
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:45,524 INFO *** epoch 9140, rolling-avg-loss (window=10)= 0.005674322827690048
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:45,543 INFO epoch # 9141 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005638661052216776
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:45,561 INFO epoch # 9142 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006979706093261484
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:45,579 INFO epoch # 9143 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005629327475617174
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:45,598 INFO epoch # 9144 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0057206008495995775
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:45,617 INFO epoch # 9145 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005703070764866425
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:45,635 INFO epoch # 9146 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00564973040309269
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:45,654 INFO epoch # 9147 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0056785772867442574
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:45,673 INFO epoch # 9148 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005614393758150982
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:45,691 INFO epoch # 9149 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005641610980092082
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:45,710 INFO epoch # 9150 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0056294018650078215
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:45,710 INFO *** epoch 9150, rolling-avg-loss (window=10)= 0.005788508052864927
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:45,728 INFO epoch # 9151 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005619948178718914
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:45,747 INFO epoch # 9152 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005633652097458253
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:45,766 INFO epoch # 9153 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0057430917586316355
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:45,786 INFO epoch # 9154 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005652984335029032
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:45,805 INFO epoch # 9155 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005633096445308183
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:45,823 INFO epoch # 9156 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0056513062590966
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:45,842 INFO epoch # 9157 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005655158096487867
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:45,861 INFO epoch # 9158 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00564814423705684
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:45,880 INFO epoch # 9159 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00566210554461577
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:45,899 INFO epoch # 9160 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0056198117599706165
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:45,899 INFO *** epoch 9160, rolling-avg-loss (window=10)= 0.005651929871237371
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:45,918 INFO epoch # 9161 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005638253340293886
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:45,936 INFO epoch # 9162 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0056628068050486036
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:45,954 INFO epoch # 9163 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005621571024676086
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:45,972 INFO epoch # 9164 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005612389832094777
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:45,991 INFO epoch # 9165 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005645082455885131
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:46,011 INFO epoch # 9166 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005663143852871144
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:46,030 INFO epoch # 9167 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005779460781923262
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:46,049 INFO epoch # 9168 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005654250384395709
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:46,067 INFO epoch # 9169 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00561482273042202
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:46,086 INFO epoch # 9170 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005635127825371455
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:46,086 INFO *** epoch 9170, rolling-avg-loss (window=10)= 0.005652690903298207
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:46,105 INFO epoch # 9171 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005664249023539014
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:46,124 INFO epoch # 9172 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005619796076643979
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:46,142 INFO epoch # 9173 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0056289671556442045
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:46,160 INFO epoch # 9174 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00561285447111004
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:46,179 INFO epoch # 9175 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005632186104776338
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:46,199 INFO epoch # 9176 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005622435545774351
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:46,218 INFO epoch # 9177 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006939391616469948
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:46,237 INFO epoch # 9178 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0056934261083370075
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:46,256 INFO epoch # 9179 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005925402485445375
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:46,275 INFO epoch # 9180 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005660582224663813
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:46,275 INFO *** epoch 9180, rolling-avg-loss (window=10)= 0.005799929081240407
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:46,293 INFO epoch # 9181 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005637732181639876
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:46,312 INFO epoch # 9182 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0056197305930254515
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:46,330 INFO epoch # 9183 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005694280356692616
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:46,349 INFO epoch # 9184 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00562084827106446
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:46,367 INFO epoch # 9185 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005596657138084993
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:46,385 INFO epoch # 9186 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005805684719234705
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:46,403 INFO epoch # 9187 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0056395256287942175
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:46,422 INFO epoch # 9188 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0056995285412995145
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:46,441 INFO epoch # 9189 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005625800436973805
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:46,460 INFO epoch # 9190 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0057387921879126225
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:46,460 INFO *** epoch 9190, rolling-avg-loss (window=10)= 0.005667858005472226
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:46,479 INFO epoch # 9191 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0056471584939572494
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:46,497 INFO epoch # 9192 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00565683305831044
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:46,516 INFO epoch # 9193 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005639557759423042
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:46,534 INFO epoch # 9194 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005689675665053073
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:46,552 INFO epoch # 9195 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005630458301311592
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:46,570 INFO epoch # 9196 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005648568469041493
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:46,589 INFO epoch # 9197 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005828015724546276
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:46,607 INFO epoch # 9198 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005901045362406876
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:46,625 INFO epoch # 9199 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005763924837083323
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:46,644 INFO epoch # 9200 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005648436592309736
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:46,644 INFO *** epoch 9200, rolling-avg-loss (window=10)= 0.00570536742634431
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:46,662 INFO epoch # 9201 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005664111715304898
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:46,681 INFO epoch # 9202 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0056283622470800765
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:46,699 INFO epoch # 9203 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005653841097227996
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:46,718 INFO epoch # 9204 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005669162590493215
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:46,736 INFO epoch # 9205 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005614294575934764
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:46,754 INFO epoch # 9206 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005663763124175603
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:46,772 INFO epoch # 9207 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0064174874023592565
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:46,791 INFO epoch # 9208 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0056645389086043
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:46,809 INFO epoch # 9209 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0055896466265039635
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:46,827 INFO epoch # 9210 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00562404707306996
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:46,827 INFO *** epoch 9210, rolling-avg-loss (window=10)= 0.005718925536075403
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:46,846 INFO epoch # 9211 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0056659422916709445
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:46,864 INFO epoch # 9212 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005649967861245386
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:46,882 INFO epoch # 9213 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005621923424769193
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:46,901 INFO epoch # 9214 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005649488084600307
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:46,919 INFO epoch # 9215 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0055994444046518765
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:46,938 INFO epoch # 9216 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0056111881422111765
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:46,956 INFO epoch # 9217 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005618225568468915
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:46,974 INFO epoch # 9218 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0056824434468580876
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:46,993 INFO epoch # 9219 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00749221016667434
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:47,011 INFO epoch # 9220 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005683375584339956
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:47,011 INFO *** epoch 9220, rolling-avg-loss (window=10)= 0.0058274208975490184
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:47,029 INFO epoch # 9221 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005677285327692516
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:47,048 INFO epoch # 9222 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005628493941912893
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:47,066 INFO epoch # 9223 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0056205703476734925
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:47,085 INFO epoch # 9224 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005633186687191483
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:47,103 INFO epoch # 9225 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005655518323692377
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:47,122 INFO epoch # 9226 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005624945999443298
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:47,140 INFO epoch # 9227 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005615931619104231
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:47,158 INFO epoch # 9228 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005644213131745346
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:47,176 INFO epoch # 9229 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005659381695295451
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:47,195 INFO epoch # 9230 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005660505616106093
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:47,195 INFO *** epoch 9230, rolling-avg-loss (window=10)= 0.005642003268985718
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:47,213 INFO epoch # 9231 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005711618603527313
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:47,231 INFO epoch # 9232 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00561261300026672
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:47,249 INFO epoch # 9233 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005623440199997276
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:47,268 INFO epoch # 9234 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0056771362615108956
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:47,286 INFO epoch # 9235 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005924272212723736
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:47,304 INFO epoch # 9236 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005611592936475063
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:47,323 INFO epoch # 9237 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005644255499646533
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:47,341 INFO epoch # 9238 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005649978385918075
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:47,359 INFO epoch # 9239 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005658767378918128
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:47,378 INFO epoch # 9240 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.008334082056535408
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:47,378 INFO *** epoch 9240, rolling-avg-loss (window=10)= 0.005944775653551915
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:47,396 INFO epoch # 9241 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005726051116653252
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:47,414 INFO epoch # 9242 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005622067335934844
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:47,432 INFO epoch # 9243 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005771600572188618
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:47,451 INFO epoch # 9244 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005606441944109974
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:47,469 INFO epoch # 9245 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007448283573467052
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:47,487 INFO epoch # 9246 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005690691679774318
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:47,506 INFO epoch # 9247 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005629022758512292
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:47,524 INFO epoch # 9248 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006935650195373455
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:47,543 INFO epoch # 9249 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005653139680362074
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:47,561 INFO epoch # 9250 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005648086880682968
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:47,561 INFO *** epoch 9250, rolling-avg-loss (window=10)= 0.0059731035737058845
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:47,579 INFO epoch # 9251 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005824552074045641
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:47,597 INFO epoch # 9252 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005744350110035157
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:47,615 INFO epoch # 9253 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005655547716742149
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:47,634 INFO epoch # 9254 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005632263961160788
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:47,652 INFO epoch # 9255 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005737942668929463
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:47,670 INFO epoch # 9256 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005595463930148981
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:47,689 INFO epoch # 9257 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005650549825077178
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:47,707 INFO epoch # 9258 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005680517409928143
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:47,725 INFO epoch # 9259 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005619659557851264
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:47,744 INFO epoch # 9260 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005785061974165728
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:47,744 INFO *** epoch 9260, rolling-avg-loss (window=10)= 0.005692590922808449
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:47,762 INFO epoch # 9261 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005833577564771986
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:47,781 INFO epoch # 9262 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005665844480972737
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:47,799 INFO epoch # 9263 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005606134753179504
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:47,817 INFO epoch # 9264 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005610178195638582
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:47,835 INFO epoch # 9265 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005675498196069384
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:47,854 INFO epoch # 9266 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0057131256435241085
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:47,872 INFO epoch # 9267 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006001719732012134
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:47,891 INFO epoch # 9268 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005617524813715136
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:47,910 INFO epoch # 9269 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005605329759418964
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:47,929 INFO epoch # 9270 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005675511241861386
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:47,929 INFO *** epoch 9270, rolling-avg-loss (window=10)= 0.005700444438116392
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:47,947 INFO epoch # 9271 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0057561914836696815
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:47,965 INFO epoch # 9272 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0057363102459930815
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:47,984 INFO epoch # 9273 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0055942894286999945
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:48,002 INFO epoch # 9274 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005647873764246469
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:48,020 INFO epoch # 9275 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005620942665700568
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:48,038 INFO epoch # 9276 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0056038914699456654
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:48,057 INFO epoch # 9277 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005625980968034128
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:48,075 INFO epoch # 9278 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005652591764373938
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:48,093 INFO epoch # 9279 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005597176481387578
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:48,112 INFO epoch # 9280 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005601044409559108
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:48,112 INFO *** epoch 9280, rolling-avg-loss (window=10)= 0.005643629268161021
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:48,130 INFO epoch # 9281 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005618909719487419
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:48,149 INFO epoch # 9282 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00563030679768417
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:48,168 INFO epoch # 9283 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005907185779506108
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:48,186 INFO epoch # 9284 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005605913433100795
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:48,204 INFO epoch # 9285 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005874495240277611
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:48,223 INFO epoch # 9286 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005639481627440546
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:48,241 INFO epoch # 9287 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005598728072072845
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:48,259 INFO epoch # 9288 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0056224780637421645
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:48,277 INFO epoch # 9289 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005619772891805042
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:48,296 INFO epoch # 9290 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005630583887977991
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:48,296 INFO *** epoch 9290, rolling-avg-loss (window=10)= 0.005674785551309469
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:48,314 INFO epoch # 9291 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005659680457029026
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:48,333 INFO epoch # 9292 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0055867407681944314
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:48,351 INFO epoch # 9293 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005694324307114584
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:48,370 INFO epoch # 9294 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005690371908713132
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:48,388 INFO epoch # 9295 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005596260831225663
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:48,406 INFO epoch # 9296 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00694326371740317
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:48,424 INFO epoch # 9297 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005837404234625865
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:48,443 INFO epoch # 9298 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005594305315753445
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:48,461 INFO epoch # 9299 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005607625837001251
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:48,479 INFO epoch # 9300 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005669878781191073
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:48,479 INFO *** epoch 9300, rolling-avg-loss (window=10)= 0.005787985615825164
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:48,498 INFO epoch # 9301 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00560454490914708
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:48,516 INFO epoch # 9302 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005855859646544559
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:48,535 INFO epoch # 9303 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0055948494155018125
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:48,553 INFO epoch # 9304 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005683533316187095
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:48,572 INFO epoch # 9305 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005785971123259515
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:48,590 INFO epoch # 9306 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005636698497255566
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:48,609 INFO epoch # 9307 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005765258003521012
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:48,627 INFO epoch # 9308 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005580203596764477
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:48,645 INFO epoch # 9309 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005591525507043116
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:48,663 INFO epoch # 9310 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005611192958895117
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:48,664 INFO *** epoch 9310, rolling-avg-loss (window=10)= 0.005670963697411935
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:48,682 INFO epoch # 9311 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0056628247984917834
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:48,700 INFO epoch # 9312 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006875707746075932
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:48,718 INFO epoch # 9313 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005605173057119828
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:48,737 INFO epoch # 9314 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005585765709838597
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:48,755 INFO epoch # 9315 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005628432983940002
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:48,773 INFO epoch # 9316 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005597761301032733
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:48,792 INFO epoch # 9317 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005616019898297964
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:48,810 INFO epoch # 9318 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005646954523399472
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:48,828 INFO epoch # 9319 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005607205679552862
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:48,847 INFO epoch # 9320 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005625438530842075
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:48,847 INFO *** epoch 9320, rolling-avg-loss (window=10)= 0.005745128422859125
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:48,865 INFO epoch # 9321 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005594489000941394
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:48,883 INFO epoch # 9322 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006021963319653878
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:48,901 INFO epoch # 9323 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005607016348221805
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:48,920 INFO epoch # 9324 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005859853190486319
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:48,938 INFO epoch # 9325 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005695459283742821
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:48,957 INFO epoch # 9326 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005622777985990979
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:48,975 INFO epoch # 9327 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0055859114036138635
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:48,994 INFO epoch # 9328 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007414931851599249
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:49,013 INFO epoch # 9329 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005609578736766707
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:49,031 INFO epoch # 9330 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00560357172798831
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:49,031 INFO *** epoch 9330, rolling-avg-loss (window=10)= 0.005861555284900533
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:49,050 INFO epoch # 9331 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005602953497145791
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:49,069 INFO epoch # 9332 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006913313380209729
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:49,087 INFO epoch # 9333 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005725165672629373
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:49,106 INFO epoch # 9334 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005649592956615379
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:49,125 INFO epoch # 9335 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005618960443825927
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:49,143 INFO epoch # 9336 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006045328944310313
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:49,162 INFO epoch # 9337 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00559686556152883
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:49,180 INFO epoch # 9338 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005615794041659683
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:49,199 INFO epoch # 9339 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00558586106490111
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:49,217 INFO epoch # 9340 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005577896166869323
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:49,217 INFO *** epoch 9340, rolling-avg-loss (window=10)= 0.005793173172969545
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:49,236 INFO epoch # 9341 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00592640303511871
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:49,254 INFO epoch # 9342 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005976137221296085
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:49,273 INFO epoch # 9343 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005592403744230978
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:49,291 INFO epoch # 9344 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005569009941609693
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:49,309 INFO epoch # 9345 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005989452125504613
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:49,328 INFO epoch # 9346 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005571444784436608
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:49,346 INFO epoch # 9347 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005599715626885882
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:49,365 INFO epoch # 9348 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00562415207241429
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:49,383 INFO epoch # 9349 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005729245131078642
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:49,401 INFO epoch # 9350 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005602236818958772
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:49,401 INFO *** epoch 9350, rolling-avg-loss (window=10)= 0.005718020050153427
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:49,420 INFO epoch # 9351 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005581426466960693
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:49,438 INFO epoch # 9352 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007368163358478341
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:49,456 INFO epoch # 9353 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005808358953800052
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:49,474 INFO epoch # 9354 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005606117418210488
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:49,492 INFO epoch # 9355 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005582334961218294
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:49,511 INFO epoch # 9356 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005563120686929324
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:49,529 INFO epoch # 9357 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005603027673714678
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:49,547 INFO epoch # 9358 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005731004312110599
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:49,566 INFO epoch # 9359 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005668283469276503
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:49,584 INFO epoch # 9360 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005591857185208937
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:49,584 INFO *** epoch 9360, rolling-avg-loss (window=10)= 0.0058103694485907905
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:49,603 INFO epoch # 9361 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005680542315531056
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:49,621 INFO epoch # 9362 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005606091923255008
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:49,639 INFO epoch # 9363 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005619243554974673
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:49,658 INFO epoch # 9364 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0056293734633072745
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:49,676 INFO epoch # 9365 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005631697251374135
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:49,694 INFO epoch # 9366 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005779048202384729
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:49,713 INFO epoch # 9367 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005621947246254422
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:49,731 INFO epoch # 9368 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00560324953039526
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:49,749 INFO epoch # 9369 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005603515601251274
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:49,768 INFO epoch # 9370 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005650590774166631
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:49,768 INFO *** epoch 9370, rolling-avg-loss (window=10)= 0.005642529986289446
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:49,786 INFO epoch # 9371 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0055816053463786375
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:49,805 INFO epoch # 9372 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0056055100649246015
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:49,823 INFO epoch # 9373 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005580853423452936
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:49,841 INFO epoch # 9374 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005690335434337612
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:49,860 INFO epoch # 9375 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005627991246001329
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:49,878 INFO epoch # 9376 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005581704368523788
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:49,897 INFO epoch # 9377 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005678351826645667
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:49,915 INFO epoch # 9378 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005578868316661101
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:49,933 INFO epoch # 9379 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005579879289143719
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:49,951 INFO epoch # 9380 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005586158411460929
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:49,952 INFO *** epoch 9380, rolling-avg-loss (window=10)= 0.005609125772753032
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:49,970 INFO epoch # 9381 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005587369792920072
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:49,988 INFO epoch # 9382 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005616362970613409
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:50,007 INFO epoch # 9383 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005886733652005205
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:50,025 INFO epoch # 9384 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005737295414292021
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:50,043 INFO epoch # 9385 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005703289560187841
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:50,062 INFO epoch # 9386 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005562110414757626
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:50,080 INFO epoch # 9387 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00557734348330996
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:50,099 INFO epoch # 9388 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005930207691562828
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:50,117 INFO epoch # 9389 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005575810155278305
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:50,135 INFO epoch # 9390 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005718738575524185
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:50,135 INFO *** epoch 9390, rolling-avg-loss (window=10)= 0.005689526171045145
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:50,154 INFO epoch # 9391 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005599175994575489
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:50,172 INFO epoch # 9392 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005642257736326428
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:50,190 INFO epoch # 9393 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005554736280828365
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:50,209 INFO epoch # 9394 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005705465162463952
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:50,227 INFO epoch # 9395 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00564001658858615
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:50,245 INFO epoch # 9396 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005637228336127009
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:50,264 INFO epoch # 9397 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005576454572292278
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:50,282 INFO epoch # 9398 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005572368110733805
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:50,300 INFO epoch # 9399 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005610208918369608
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:50,319 INFO epoch # 9400 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005571864308876684
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:50,319 INFO *** epoch 9400, rolling-avg-loss (window=10)= 0.0056109776009179765
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:50,337 INFO epoch # 9401 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005569744411332067
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:50,355 INFO epoch # 9402 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005570183155214181
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:50,374 INFO epoch # 9403 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006170520526211476
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:50,392 INFO epoch # 9404 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005597054445388494
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:50,411 INFO epoch # 9405 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00557727998966584
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:50,429 INFO epoch # 9406 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005955146705673542
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:50,447 INFO epoch # 9407 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0055720543932693545
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:50,466 INFO epoch # 9408 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005546977441554191
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:50,484 INFO epoch # 9409 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005591211374849081
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:50,502 INFO epoch # 9410 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0055835785969975404
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:50,502 INFO *** epoch 9410, rolling-avg-loss (window=10)= 0.005673375104015577
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:50,520 INFO epoch # 9411 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0055680254045000765
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:50,539 INFO epoch # 9412 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005590751999989152
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:50,557 INFO epoch # 9413 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005564803588640643
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:50,575 INFO epoch # 9414 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005554951028898358
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:50,594 INFO epoch # 9415 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00829453070400632
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:50,613 INFO epoch # 9416 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0056334045257244725
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:50,632 INFO epoch # 9417 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005579787324677454
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:50,651 INFO epoch # 9418 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00560999775188975
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:50,670 INFO epoch # 9419 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005557371368922759
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:50,689 INFO epoch # 9420 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005574222719587851
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:50,689 INFO *** epoch 9420, rolling-avg-loss (window=10)= 0.005852784641683683
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:50,707 INFO epoch # 9421 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005646593835990643
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:50,725 INFO epoch # 9422 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005979906090942677
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:50,744 INFO epoch # 9423 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0056806068369041895
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:50,762 INFO epoch # 9424 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005600328771834029
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:50,781 INFO epoch # 9425 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005624012857879279
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:50,800 INFO epoch # 9426 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00564221570675727
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:50,819 INFO epoch # 9427 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005566816071223002
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:50,837 INFO epoch # 9428 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005560073570450186
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:50,855 INFO epoch # 9429 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005604021953331539
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:50,874 INFO epoch # 9430 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005617198876279872
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:50,874 INFO *** epoch 9430, rolling-avg-loss (window=10)= 0.005652177457159268
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:50,892 INFO epoch # 9431 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0055533929480588995
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:50,910 INFO epoch # 9432 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005564087892707903
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:50,929 INFO epoch # 9433 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005596888546278933
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:50,947 INFO epoch # 9434 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00567730538386968
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:50,965 INFO epoch # 9435 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005551353915507207
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:50,984 INFO epoch # 9436 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005595141999947373
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:51,002 INFO epoch # 9437 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005638619612000184
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:51,021 INFO epoch # 9438 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00555081496713683
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:51,039 INFO epoch # 9439 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005564992326981155
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:51,058 INFO epoch # 9440 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005594339734670939
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:51,058 INFO *** epoch 9440, rolling-avg-loss (window=10)= 0.00558869373271591
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:51,077 INFO epoch # 9441 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0055612513788219076
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:51,095 INFO epoch # 9442 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005554612856940366
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:51,113 INFO epoch # 9443 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006158016894914908
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:51,132 INFO epoch # 9444 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005604595549812075
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:51,150 INFO epoch # 9445 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005590508104432956
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:51,168 INFO epoch # 9446 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005612968379864469
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:51,186 INFO epoch # 9447 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005677414061210584
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:51,205 INFO epoch # 9448 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005620339721644996
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:51,223 INFO epoch # 9449 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005583530837611761
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:51,242 INFO epoch # 9450 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005606271155556897
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:51,242 INFO *** epoch 9450, rolling-avg-loss (window=10)= 0.005656950894081092
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:51,260 INFO epoch # 9451 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005598445630312199
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:51,278 INFO epoch # 9452 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005569990993535612
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:51,297 INFO epoch # 9453 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005575790914008394
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:51,315 INFO epoch # 9454 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005572511345235398
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:51,333 INFO epoch # 9455 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005883726033061976
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:51,351 INFO epoch # 9456 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005601062606729101
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:51,370 INFO epoch # 9457 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0056141588975151535
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:51,388 INFO epoch # 9458 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005600598557066405
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:51,407 INFO epoch # 9459 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005572475318331271
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:51,426 INFO epoch # 9460 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005553867198614171
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:51,426 INFO *** epoch 9460, rolling-avg-loss (window=10)= 0.005614262749440968
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:51,444 INFO epoch # 9461 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005595307869953103
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:51,462 INFO epoch # 9462 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0055628574154980015
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:51,480 INFO epoch # 9463 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005546837895963108
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:51,499 INFO epoch # 9464 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005616089070827002
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:51,517 INFO epoch # 9465 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005591455825197045
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:51,535 INFO epoch # 9466 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005586984840192599
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:51,553 INFO epoch # 9467 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005559181336138863
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:51,572 INFO epoch # 9468 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005618241393676726
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:51,590 INFO epoch # 9469 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00560201801272342
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:51,608 INFO epoch # 9470 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00554703093439457
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:51,609 INFO *** epoch 9470, rolling-avg-loss (window=10)= 0.0055826004594564434
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:51,627 INFO epoch # 9471 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005646407324093161
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:51,646 INFO epoch # 9472 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005578796266490826
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:51,665 INFO epoch # 9473 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005554610550461803
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:51,683 INFO epoch # 9474 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005558524851949187
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:51,701 INFO epoch # 9475 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005570649347646395
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:51,719 INFO epoch # 9476 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0060189251707924996
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:51,738 INFO epoch # 9477 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0059355073171900585
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:51,756 INFO epoch # 9478 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005561312696954701
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:51,775 INFO epoch # 9479 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005657528283336433
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:51,793 INFO epoch # 9480 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005562980652030092
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:51,793 INFO *** epoch 9480, rolling-avg-loss (window=10)= 0.005664524246094515
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:51,812 INFO epoch # 9481 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005536982283956604
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:51,830 INFO epoch # 9482 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005562077552895062
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:51,849 INFO epoch # 9483 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005696579024515813
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:51,868 INFO epoch # 9484 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005540421399928164
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:51,887 INFO epoch # 9485 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0055277842984651215
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:51,905 INFO epoch # 9486 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005559083274420118
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:51,923 INFO epoch # 9487 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005641396142891608
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:51,942 INFO epoch # 9488 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005538246208743658
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:51,960 INFO epoch # 9489 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005539321697142441
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:51,978 INFO epoch # 9490 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005591338987869676
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:51,979 INFO *** epoch 9490, rolling-avg-loss (window=10)= 0.005573323087082827
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:51,997 INFO epoch # 9491 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0055311325850198045
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:52,016 INFO epoch # 9492 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005820702685014112
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:52,034 INFO epoch # 9493 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005544858275243314
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:52,052 INFO epoch # 9494 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005603222303761868
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:52,071 INFO epoch # 9495 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0056908297519839834
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:52,090 INFO epoch # 9496 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005544857514905743
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:52,108 INFO epoch # 9497 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005580539072980173
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:52,126 INFO epoch # 9498 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005539729147130856
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:52,144 INFO epoch # 9499 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005548076464037877
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:52,163 INFO epoch # 9500 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0055596170932403766
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:52,163 INFO *** epoch 9500, rolling-avg-loss (window=10)= 0.0055963564893318106
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:52,181 INFO epoch # 9501 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005614740279270336
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:52,200 INFO epoch # 9502 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005575505379965762
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:52,218 INFO epoch # 9503 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005548676461330615
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:52,236 INFO epoch # 9504 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005520588918443536
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:52,255 INFO epoch # 9505 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005548921169975074
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:52,273 INFO epoch # 9506 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005578103911830112
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:52,291 INFO epoch # 9507 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005736747836635914
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:52,310 INFO epoch # 9508 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0055511357059003785
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:52,328 INFO epoch # 9509 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006837886639914359
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:52,347 INFO epoch # 9510 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0056219321268144995
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:52,347 INFO *** epoch 9510, rolling-avg-loss (window=10)= 0.005713423843008059
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:52,365 INFO epoch # 9511 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005560214191064006
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:52,384 INFO epoch # 9512 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005587392683082726
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:52,402 INFO epoch # 9513 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005641513234877493
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:52,421 INFO epoch # 9514 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005539235382457264
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:52,439 INFO epoch # 9515 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0055280881497310475
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:52,457 INFO epoch # 9516 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005557243963266956
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:52,476 INFO epoch # 9517 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005549631387111731
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:52,494 INFO epoch # 9518 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005734084730647737
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:52,512 INFO epoch # 9519 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0055487792124040425
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:52,531 INFO epoch # 9520 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005581939018156845
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:52,531 INFO *** epoch 9520, rolling-avg-loss (window=10)= 0.005582812195279984
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:52,549 INFO epoch # 9521 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005595906764938263
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:52,567 INFO epoch # 9522 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0055458090791944414
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:52,585 INFO epoch # 9523 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005536007640330354
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:52,604 INFO epoch # 9524 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005528665671590716
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:52,622 INFO epoch # 9525 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005660134094796376
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:52,641 INFO epoch # 9526 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005538183479075087
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:52,659 INFO epoch # 9527 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005549890440306626
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:52,677 INFO epoch # 9528 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005532624909392325
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:52,696 INFO epoch # 9529 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005546427750232397
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:52,714 INFO epoch # 9530 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0055504680167359766
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:52,714 INFO *** epoch 9530, rolling-avg-loss (window=10)= 0.005558411784659256
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:52,733 INFO epoch # 9531 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005575856979703531
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:52,751 INFO epoch # 9532 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005543593855691142
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:52,769 INFO epoch # 9533 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005516117076695082
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:52,787 INFO epoch # 9534 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005586680221313145
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:52,806 INFO epoch # 9535 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005631494332192233
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:52,824 INFO epoch # 9536 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005557823369599646
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:52,843 INFO epoch # 9537 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005865201474080095
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:52,862 INFO epoch # 9538 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005576503779593622
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:52,881 INFO epoch # 9539 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00557964696054114
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:52,899 INFO epoch # 9540 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005537922987059574
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:52,899 INFO *** epoch 9540, rolling-avg-loss (window=10)= 0.005597084103646921
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:52,918 INFO epoch # 9541 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005625876467092894
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:52,936 INFO epoch # 9542 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0055870880678412504
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:52,954 INFO epoch # 9543 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005703447706764564
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:52,972 INFO epoch # 9544 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005588814430666389
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:52,991 INFO epoch # 9545 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005531077811610885
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:53,009 INFO epoch # 9546 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005547904369450407
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:53,027 INFO epoch # 9547 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005542545004573185
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:53,045 INFO epoch # 9548 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0055134899712356855
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:53,064 INFO epoch # 9549 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.010067128188893548
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:53,083 INFO epoch # 9550 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0055856553226476535
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:53,083 INFO *** epoch 9550, rolling-avg-loss (window=10)= 0.006029302734077646
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:53,102 INFO epoch # 9551 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005532450068130856
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:53,121 INFO epoch # 9552 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005617249516944867
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:53,139 INFO epoch # 9553 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005559397894103313
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:53,157 INFO epoch # 9554 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005646817615343025
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:53,176 INFO epoch # 9555 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005662683812261093
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:53,194 INFO epoch # 9556 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005518476157703844
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:53,212 INFO epoch # 9557 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005608381798083428
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:53,231 INFO epoch # 9558 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005515844788533286
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:53,249 INFO epoch # 9559 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005628421906294534
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:53,267 INFO epoch # 9560 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00554571866086917
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:53,268 INFO *** epoch 9560, rolling-avg-loss (window=10)= 0.005583544221826742
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:53,286 INFO epoch # 9561 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005515176449989667
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:53,304 INFO epoch # 9562 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005577249794441741
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:53,323 INFO epoch # 9563 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00554504312822246
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:53,341 INFO epoch # 9564 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005766912468970986
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:53,359 INFO epoch # 9565 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005507953632331919
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:53,378 INFO epoch # 9566 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00571629022306297
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:53,396 INFO epoch # 9567 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005533929219382117
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:53,414 INFO epoch # 9568 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005532104030862683
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:53,432 INFO epoch # 9569 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005543311570363585
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:53,451 INFO epoch # 9570 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005601359447609866
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:53,451 INFO *** epoch 9570, rolling-avg-loss (window=10)= 0.005583932996523799
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:53,469 INFO epoch # 9571 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005558441112953005
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:53,488 INFO epoch # 9572 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005538458972296212
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:53,506 INFO epoch # 9573 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005643183860229328
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:53,525 INFO epoch # 9574 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005569589524384355
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:53,543 INFO epoch # 9575 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00559506247373065
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:53,561 INFO epoch # 9576 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005533921166716027
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:53,579 INFO epoch # 9577 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005564859980950132
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:53,598 INFO epoch # 9578 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005520932474610163
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:53,616 INFO epoch # 9579 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005507757145096548
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:53,634 INFO epoch # 9580 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005499430133568239
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:53,634 INFO *** epoch 9580, rolling-avg-loss (window=10)= 0.005553163684453466
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:53,652 INFO epoch # 9581 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005599688051006524
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:53,671 INFO epoch # 9582 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005516891671504709
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:53,690 INFO epoch # 9583 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005543151357414899
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:53,708 INFO epoch # 9584 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005845508821948897
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:53,727 INFO epoch # 9585 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005578433454502374
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:53,745 INFO epoch # 9586 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00599845723627368
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:53,764 INFO epoch # 9587 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005881635675905272
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:53,782 INFO epoch # 9588 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0055254465878533665
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:53,800 INFO epoch # 9589 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005512038187589496
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:53,818 INFO epoch # 9590 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005601697503152536
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:53,818 INFO *** epoch 9590, rolling-avg-loss (window=10)= 0.005660294854715175
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:53,837 INFO epoch # 9591 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005603071411314886
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:53,855 INFO epoch # 9592 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005514762757229619
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:53,874 INFO epoch # 9593 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005532377130293753
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:53,892 INFO epoch # 9594 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00560824815693195
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:53,911 INFO epoch # 9595 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005516871577128768
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:53,929 INFO epoch # 9596 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0055239394278032705
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:53,947 INFO epoch # 9597 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00554343808471458
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:53,966 INFO epoch # 9598 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005504107150045456
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:53,984 INFO epoch # 9599 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005518547224710346
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:54,002 INFO epoch # 9600 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005601933000434656
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:54,002 INFO *** epoch 9600, rolling-avg-loss (window=10)= 0.005546729592060729
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:54,020 INFO epoch # 9601 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005532276289159199
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:54,039 INFO epoch # 9602 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005508292029844597
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:54,057 INFO epoch # 9603 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0056298560739378445
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:54,076 INFO epoch # 9604 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007578018045023782
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:54,094 INFO epoch # 9605 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005627416368952254
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:54,113 INFO epoch # 9606 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005524197953491239
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:54,132 INFO epoch # 9607 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005535859749215888
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:54,150 INFO epoch # 9608 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005548128625378013
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:54,168 INFO epoch # 9609 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005511294104508124
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:54,187 INFO epoch # 9610 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005493838201800827
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:54,187 INFO *** epoch 9610, rolling-avg-loss (window=10)= 0.005748917744131177
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:54,205 INFO epoch # 9611 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005929810417001136
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:54,223 INFO epoch # 9612 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005540802860195981
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:54,242 INFO epoch # 9613 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005521405004401458
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:54,260 INFO epoch # 9614 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005539963523915503
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:54,279 INFO epoch # 9615 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005605636626569321
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:54,297 INFO epoch # 9616 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005509052654815605
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:54,316 INFO epoch # 9617 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005823835657793097
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:54,334 INFO epoch # 9618 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005550145055167377
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:54,352 INFO epoch # 9619 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005533535033464432
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:54,371 INFO epoch # 9620 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005530250960873673
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:54,371 INFO *** epoch 9620, rolling-avg-loss (window=10)= 0.005608443779419758
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:54,389 INFO epoch # 9621 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005498843764144112
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:54,407 INFO epoch # 9622 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005494368129802751
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:54,426 INFO epoch # 9623 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005606288785202196
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:54,444 INFO epoch # 9624 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005523151910892921
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:54,462 INFO epoch # 9625 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005685601674485952
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:54,481 INFO epoch # 9626 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0055179367955133785
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:54,499 INFO epoch # 9627 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0055915483317221515
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:54,518 INFO epoch # 9628 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005529153841052903
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:54,536 INFO epoch # 9629 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00560331253655022
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:54,555 INFO epoch # 9630 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0055011262174957665
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:54,555 INFO *** epoch 9630, rolling-avg-loss (window=10)= 0.005555133198686235
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:54,573 INFO epoch # 9631 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005525996653886978
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:54,592 INFO epoch # 9632 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005539924426557263
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:54,610 INFO epoch # 9633 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0055258959509956185
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:54,628 INFO epoch # 9634 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005527306104340823
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:54,646 INFO epoch # 9635 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005516280081792502
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:54,665 INFO epoch # 9636 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005506533216248499
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:54,683 INFO epoch # 9637 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005504478856892092
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:54,701 INFO epoch # 9638 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005687946424586698
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:54,720 INFO epoch # 9639 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00550408689014148
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:54,738 INFO epoch # 9640 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005624581386655336
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:54,739 INFO *** epoch 9640, rolling-avg-loss (window=10)= 0.005546302999209729
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:54,757 INFO epoch # 9641 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005503286487510195
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:54,775 INFO epoch # 9642 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006064025123123429
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:54,793 INFO epoch # 9643 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005594360234681517
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:54,812 INFO epoch # 9644 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005508712059963727
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:54,830 INFO epoch # 9645 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005529826426936779
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:54,848 INFO epoch # 9646 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005527013745449949
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:54,867 INFO epoch # 9647 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005521951483387966
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:54,885 INFO epoch # 9648 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005525817960005952
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:54,903 INFO epoch # 9649 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005549993453314528
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:54,922 INFO epoch # 9650 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005518919300811831
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:54,922 INFO *** epoch 9650, rolling-avg-loss (window=10)= 0.005584390627518587
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:54,940 INFO epoch # 9651 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0057578909618314356
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:54,959 INFO epoch # 9652 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005551341182581382
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:54,977 INFO epoch # 9653 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005565119783568662
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:54,996 INFO epoch # 9654 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005491712974617258
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:55,014 INFO epoch # 9655 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005527983928914182
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:55,032 INFO epoch # 9656 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0055396012066921685
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:55,050 INFO epoch # 9657 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0054935863809078
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:55,069 INFO epoch # 9658 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005512393026947393
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:55,088 INFO epoch # 9659 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005513609165063826
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:55,107 INFO epoch # 9660 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005536329048482003
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:55,107 INFO *** epoch 9660, rolling-avg-loss (window=10)= 0.005548956765960611
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:55,126 INFO epoch # 9661 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005522973580809776
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:55,145 INFO epoch # 9662 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0054916461631364655
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:55,164 INFO epoch # 9663 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005596223505563103
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:55,183 INFO epoch # 9664 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005485780437084031
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:55,201 INFO epoch # 9665 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005504206168552628
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:55,220 INFO epoch # 9666 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00551073569295113
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:55,238 INFO epoch # 9667 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0054987797266221605
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:55,256 INFO epoch # 9668 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005483424645717605
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:55,275 INFO epoch # 9669 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005485668105393415
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:55,293 INFO epoch # 9670 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005531661292479839
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:55,293 INFO *** epoch 9670, rolling-avg-loss (window=10)= 0.005511109931831015
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:55,312 INFO epoch # 9671 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0057926272638724186
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:55,330 INFO epoch # 9672 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005541651666135294
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:55,349 INFO epoch # 9673 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005563594073464628
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:55,367 INFO epoch # 9674 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005485946909175254
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:55,386 INFO epoch # 9675 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005537808585359016
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:55,404 INFO epoch # 9676 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005579435819527134
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:55,422 INFO epoch # 9677 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005540305992326466
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:55,440 INFO epoch # 9678 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005514609623787692
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:55,459 INFO epoch # 9679 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005793318028736394
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:55,477 INFO epoch # 9680 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005525909418793162
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:55,477 INFO *** epoch 9680, rolling-avg-loss (window=10)= 0.005587520738117746
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:55,495 INFO epoch # 9681 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005516703859029803
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:55,514 INFO epoch # 9682 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0055540838693559635
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:55,533 INFO epoch # 9683 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005483565004396951
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:55,552 INFO epoch # 9684 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005506253186467802
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:55,570 INFO epoch # 9685 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005581481676927069
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:55,589 INFO epoch # 9686 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005649607821396785
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:55,607 INFO epoch # 9687 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005724672180804191
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:55,626 INFO epoch # 9688 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005522540173842572
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:55,644 INFO epoch # 9689 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005548098535655299
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:55,662 INFO epoch # 9690 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0054797385728306836
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:55,662 INFO *** epoch 9690, rolling-avg-loss (window=10)= 0.005556674488070712
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:55,680 INFO epoch # 9691 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005553033093747217
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:55,699 INFO epoch # 9692 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005566171428654343
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:55,717 INFO epoch # 9693 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005493992644915124
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:55,736 INFO epoch # 9694 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005509829526999965
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:55,754 INFO epoch # 9695 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005525702003069455
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:55,773 INFO epoch # 9696 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005481882033564034
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:55,791 INFO epoch # 9697 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005520503062143689
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:55,810 INFO epoch # 9698 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005500246581505053
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:55,828 INFO epoch # 9699 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005528477886400651
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:55,846 INFO epoch # 9700 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00550287436999497
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:55,846 INFO *** epoch 9700, rolling-avg-loss (window=10)= 0.00551827126309945
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:55,864 INFO epoch # 9701 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005572441488766344
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:55,883 INFO epoch # 9702 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005493435077369213
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:55,901 INFO epoch # 9703 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005594400397967547
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:55,919 INFO epoch # 9704 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005542002356378362
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:55,938 INFO epoch # 9705 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005508376969373785
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:55,956 INFO epoch # 9706 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005592962501395959
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:55,975 INFO epoch # 9707 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005575719907938037
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:55,993 INFO epoch # 9708 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005471427319207578
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:56,012 INFO epoch # 9709 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0055039976177795324
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:56,030 INFO epoch # 9710 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005539308167499257
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:56,030 INFO *** epoch 9710, rolling-avg-loss (window=10)= 0.005539407180367562
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:56,049 INFO epoch # 9711 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005501246247149538
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:56,067 INFO epoch # 9712 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005510198017873336
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:56,085 INFO epoch # 9713 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005514341486559715
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:56,103 INFO epoch # 9714 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005740231317759026
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:56,122 INFO epoch # 9715 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005488154012709856
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:56,141 INFO epoch # 9716 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005554998726438498
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:56,160 INFO epoch # 9717 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0055362014354614075
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:56,179 INFO epoch # 9718 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005518801692232955
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:56,197 INFO epoch # 9719 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005527617566258414
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:56,215 INFO epoch # 9720 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005536849759664619
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:56,216 INFO *** epoch 9720, rolling-avg-loss (window=10)= 0.0055428640262107365
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:56,234 INFO epoch # 9721 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005479750321683241
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:56,252 INFO epoch # 9722 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005511141898750793
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:56,270 INFO epoch # 9723 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005481813022925053
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:56,289 INFO epoch # 9724 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005493621338246157
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:56,307 INFO epoch # 9725 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005491674823133508
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:56,325 INFO epoch # 9726 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00549486812815303
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:56,343 INFO epoch # 9727 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005542805021832464
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:56,362 INFO epoch # 9728 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005517202702321811
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:56,380 INFO epoch # 9729 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005497608355653938
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:56,399 INFO epoch # 9730 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005496381596458377
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:56,399 INFO *** epoch 9730, rolling-avg-loss (window=10)= 0.005500686720915837
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:56,417 INFO epoch # 9731 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005579155938903568
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:56,435 INFO epoch # 9732 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0055323270898952615
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:56,454 INFO epoch # 9733 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005495530807820614
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:56,472 INFO epoch # 9734 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005505403369170381
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:56,491 INFO epoch # 9735 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0055338697784463875
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:56,511 INFO epoch # 9736 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005680219685018528
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:56,529 INFO epoch # 9737 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005553639904974261
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:56,548 INFO epoch # 9738 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005564009476074716
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:56,566 INFO epoch # 9739 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005483988672494888
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:56,585 INFO epoch # 9740 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0055146415943454485
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:56,585 INFO *** epoch 9740, rolling-avg-loss (window=10)= 0.005544278631714405
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:56,604 INFO epoch # 9741 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0055185764213092625
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:56,623 INFO epoch # 9742 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005500066417880589
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:56,641 INFO epoch # 9743 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005724043679947499
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:56,659 INFO epoch # 9744 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005509662751137512
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:56,677 INFO epoch # 9745 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005503765201865463
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:56,696 INFO epoch # 9746 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005594707879936323
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:56,714 INFO epoch # 9747 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005472318665852072
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:56,733 INFO epoch # 9748 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00548045937466668
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:56,751 INFO epoch # 9749 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005481399828568101
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:56,770 INFO epoch # 9750 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005501381161593599
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:56,770 INFO *** epoch 9750, rolling-avg-loss (window=10)= 0.00552863813827571
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:56,788 INFO epoch # 9751 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005493538068549242
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:56,807 INFO epoch # 9752 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005545053463720251
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:56,826 INFO epoch # 9753 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0055068218971428
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:56,844 INFO epoch # 9754 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005561643203691347
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:56,862 INFO epoch # 9755 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005806705426948611
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:56,881 INFO epoch # 9756 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005542486898775678
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:56,899 INFO epoch # 9757 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005490837953402661
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:56,918 INFO epoch # 9758 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005486317237227922
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:56,936 INFO epoch # 9759 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005501033148902934
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:56,955 INFO epoch # 9760 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00556949164456455
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:56,955 INFO *** epoch 9760, rolling-avg-loss (window=10)= 0.0055503928942925995
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:56,973 INFO epoch # 9761 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005576362349529518
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:56,992 INFO epoch # 9762 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005486223326442996
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:57,011 INFO epoch # 9763 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005496119203598937
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:57,029 INFO epoch # 9764 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005484312736371066
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:57,048 INFO epoch # 9765 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005529395828489214
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:57,066 INFO epoch # 9766 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0054940120862738695
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:57,084 INFO epoch # 9767 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0054811462650832254
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:57,103 INFO epoch # 9768 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005462376535433577
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:57,121 INFO epoch # 9769 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005470050084113609
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:57,139 INFO epoch # 9770 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005498657697899034
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:57,139 INFO *** epoch 9770, rolling-avg-loss (window=10)= 0.005497865611323505
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:57,158 INFO epoch # 9771 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005660351896949578
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:57,176 INFO epoch # 9772 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005516872122825589
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:57,195 INFO epoch # 9773 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005569954868406057
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:57,214 INFO epoch # 9774 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005488342747412389
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:57,232 INFO epoch # 9775 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005491486306709703
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:57,250 INFO epoch # 9776 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00547503598863841
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:57,269 INFO epoch # 9777 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0054669591154379304
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:57,287 INFO epoch # 9778 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005467106329888338
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:57,305 INFO epoch # 9779 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005460882448460325
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:57,323 INFO epoch # 9780 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005464254158141557
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:57,323 INFO *** epoch 9780, rolling-avg-loss (window=10)= 0.005506124598286988
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:57,342 INFO epoch # 9781 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00548694873941713
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:57,360 INFO epoch # 9782 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005555455642024754
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:57,379 INFO epoch # 9783 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005461157994432142
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:57,397 INFO epoch # 9784 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005492589461937314
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:57,416 INFO epoch # 9785 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0055053063842933625
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:57,434 INFO epoch # 9786 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0054872220498509705
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:57,452 INFO epoch # 9787 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005467997885716613
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:57,471 INFO epoch # 9788 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005658684589434415
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:57,489 INFO epoch # 9789 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.008210352203604998
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:57,507 INFO epoch # 9790 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005830926367707434
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:57,507 INFO *** epoch 9790, rolling-avg-loss (window=10)= 0.005815664131841913
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:57,526 INFO epoch # 9791 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005526652792468667
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:57,544 INFO epoch # 9792 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005555597439524718
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:57,562 INFO epoch # 9793 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005488808772497578
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:57,581 INFO epoch # 9794 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0054600802177446894
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:57,599 INFO epoch # 9795 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005543976236367598
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:57,618 INFO epoch # 9796 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005466885409987299
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:57,636 INFO epoch # 9797 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005459115891426336
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:57,654 INFO epoch # 9798 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005494873836141778
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:57,673 INFO epoch # 9799 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00832676863137749
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:57,691 INFO epoch # 9800 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005863526817847742
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:57,691 INFO *** epoch 9800, rolling-avg-loss (window=10)= 0.005818628604538389
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:57,709 INFO epoch # 9801 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005482352895342046
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:57,727 INFO epoch # 9802 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005470225816679886
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:57,746 INFO epoch # 9803 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005456009677800466
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:57,764 INFO epoch # 9804 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005463762514409609
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:57,782 INFO epoch # 9805 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005742194625781849
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:57,801 INFO epoch # 9806 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005496734353073407
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:57,819 INFO epoch # 9807 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006059967909095576
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:57,838 INFO epoch # 9808 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005472337899846025
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:57,856 INFO epoch # 9809 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0054632449136988726
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:57,874 INFO epoch # 9810 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005462932964292122
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:57,874 INFO *** epoch 9810, rolling-avg-loss (window=10)= 0.005556976357001986
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:57,893 INFO epoch # 9811 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005471747572300956
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:57,911 INFO epoch # 9812 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0056276187460753135
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:57,929 INFO epoch # 9813 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005548392986383988
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:57,947 INFO epoch # 9814 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005487822749273619
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:57,966 INFO epoch # 9815 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00553240943554556
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:57,984 INFO epoch # 9816 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0054661223766743205
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:58,002 INFO epoch # 9817 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0054654230443702545
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:58,020 INFO epoch # 9818 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007255876393173821
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:58,039 INFO epoch # 9819 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005507202375156339
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:58,057 INFO epoch # 9820 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005482709930220153
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:58,057 INFO *** epoch 9820, rolling-avg-loss (window=10)= 0.005684532560917432
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:58,076 INFO epoch # 9821 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005712551017495571
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:58,094 INFO epoch # 9822 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005551443860895233
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:58,112 INFO epoch # 9823 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005516704124602256
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:58,130 INFO epoch # 9824 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005506622626853641
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:58,149 INFO epoch # 9825 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005479306997585809
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:58,168 INFO epoch # 9826 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005447971514513483
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:58,186 INFO epoch # 9827 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.006716094398143468
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:58,205 INFO epoch # 9828 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005467060047521954
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:58,223 INFO epoch # 9829 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00544512685155496
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:58,241 INFO epoch # 9830 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005528964964469196
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:58,241 INFO *** epoch 9830, rolling-avg-loss (window=10)= 0.005637184640363557
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:58,260 INFO epoch # 9831 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005484730430907803
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:58,278 INFO epoch # 9832 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0055622703657718375
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:58,297 INFO epoch # 9833 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005484221117512789
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:58,315 INFO epoch # 9834 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005451238886962528
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:58,333 INFO epoch # 9835 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.007284359668119578
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:58,351 INFO epoch # 9836 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005473100092785899
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:58,370 INFO epoch # 9837 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005463029028760502
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:58,388 INFO epoch # 9838 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005514682306966279
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:58,406 INFO epoch # 9839 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005484798180987127
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:58,424 INFO epoch # 9840 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005534300380531931
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:58,425 INFO *** epoch 9840, rolling-avg-loss (window=10)= 0.005673673045930627
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:58,443 INFO epoch # 9841 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005527472007088363
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:58,461 INFO epoch # 9842 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005546732416405575
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:58,480 INFO epoch # 9843 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005466751903441036
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:58,498 INFO epoch # 9844 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005566151809034636
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:58,517 INFO epoch # 9845 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0054643202056468
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:58,535 INFO epoch # 9846 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00546655189464218
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:58,554 INFO epoch # 9847 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0054668654811393935
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:58,572 INFO epoch # 9848 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005745149555878015
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:58,590 INFO epoch # 9849 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005503728134499397
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:58,608 INFO epoch # 9850 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005486423844558885
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:58,609 INFO *** epoch 9850, rolling-avg-loss (window=10)= 0.005524014725233428
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:58,627 INFO epoch # 9851 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005466172751766862
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:58,645 INFO epoch # 9852 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005454220969113521
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:58,664 INFO epoch # 9853 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005472863471368328
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:58,682 INFO epoch # 9854 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005582708807196468
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:58,701 INFO epoch # 9855 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0054616801426163875
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:58,719 INFO epoch # 9856 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005438408428744879
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:58,737 INFO epoch # 9857 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005757400118454825
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:58,756 INFO epoch # 9858 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005500628187292023
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:58,774 INFO epoch # 9859 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005461402945002192
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:58,792 INFO epoch # 9860 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005542134738789173
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:58,792 INFO *** epoch 9860, rolling-avg-loss (window=10)= 0.0055137620560344654
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:58,810 INFO epoch # 9861 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005571059340581996
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:58,829 INFO epoch # 9862 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00549705553567037
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:58,847 INFO epoch # 9863 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005494776731211459
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:58,865 INFO epoch # 9864 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005576323364948621
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:58,884 INFO epoch # 9865 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005448607817015727
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:58,903 INFO epoch # 9866 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00567596129985759
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:58,921 INFO epoch # 9867 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005502147203515051
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:58,939 INFO epoch # 9868 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005505472498043673
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:58,958 INFO epoch # 9869 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005504064592969371
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:58,976 INFO epoch # 9870 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005446712424600264
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:58,976 INFO *** epoch 9870, rolling-avg-loss (window=10)= 0.005522218080841412
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:58,995 INFO epoch # 9871 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005455681406601798
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:59,014 INFO epoch # 9872 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005617280996375484
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:59,032 INFO epoch # 9873 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0057205551929655485
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:59,051 INFO epoch # 9874 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005470917709317291
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:59,069 INFO epoch # 9875 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00547331515190308
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:59,087 INFO epoch # 9876 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005554065341129899
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:59,106 INFO epoch # 9877 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005439547767309705
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:59,124 INFO epoch # 9878 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005459787349536782
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:59,143 INFO epoch # 9879 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005896912323805736
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:59,161 INFO epoch # 9880 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0054851149034220725
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:59,161 INFO *** epoch 9880, rolling-avg-loss (window=10)= 0.00555731781423674
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:59,180 INFO epoch # 9881 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005822243991133291
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:59,198 INFO epoch # 9882 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005484163739311043
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:59,216 INFO epoch # 9883 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005498792330399738
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:59,235 INFO epoch # 9884 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005451741839351598
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:59,253 INFO epoch # 9885 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005710287397960201
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:59,272 INFO epoch # 9886 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005473367862578016
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:59,290 INFO epoch # 9887 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005440198458018131
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:59,309 INFO epoch # 9888 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0056002148921834305
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:59,327 INFO epoch # 9889 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005551198380999267
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:59,346 INFO epoch # 9890 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005625231020530919
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:59,346 INFO *** epoch 9890, rolling-avg-loss (window=10)= 0.005565743991246564
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:59,364 INFO epoch # 9891 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005470416952448431
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:59,382 INFO epoch # 9892 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005469461553730071
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:59,400 INFO epoch # 9893 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005429632874438539
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:59,419 INFO epoch # 9894 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005772022606834071
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:59,437 INFO epoch # 9895 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005452219702419825
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:59,456 INFO epoch # 9896 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005452608682389837
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:59,474 INFO epoch # 9897 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005556586762395455
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:59,493 INFO epoch # 9898 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005482324930198956
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:59,511 INFO epoch # 9899 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005457849321828689
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:59,529 INFO epoch # 9900 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005791008854430402
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:59,529 INFO *** epoch 9900, rolling-avg-loss (window=10)= 0.005533413224111427
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:59,548 INFO epoch # 9901 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005754732101195259
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:59,566 INFO epoch # 9902 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0055149961153802
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:59,584 INFO epoch # 9903 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005449576312457793
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:59,602 INFO epoch # 9904 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005498783561051823
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:59,620 INFO epoch # 9905 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005523012448975351
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:59,639 INFO epoch # 9906 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005447002646178589
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:59,657 INFO epoch # 9907 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0054243999111349694
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:59,675 INFO epoch # 9908 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0054872086038812995
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:59,694 INFO epoch # 9909 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005746503951741033
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:59,712 INFO epoch # 9910 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005725187496864237
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:59,712 INFO *** epoch 9910, rolling-avg-loss (window=10)= 0.005557140314886055
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:59,730 INFO epoch # 9911 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005465507430926664
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:59,749 INFO epoch # 9912 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005454181929962942
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:59,767 INFO epoch # 9913 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005463488751047407
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:59,785 INFO epoch # 9914 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005428849186500884
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:59,803 INFO epoch # 9915 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005538051362236729
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:59,822 INFO epoch # 9916 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005432338351965882
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:59,840 INFO epoch # 9917 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0058560584984661546
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:59,859 INFO epoch # 9918 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005436410159745719
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:59,877 INFO epoch # 9919 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0054521719976037275
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:59,895 INFO epoch # 9920 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005418092207037262
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:50:59,895 INFO *** epoch 9920, rolling-avg-loss (window=10)= 0.005494514987549337
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:59,914 INFO epoch # 9921 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005475837497215252
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:59,932 INFO epoch # 9922 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005445886716188397
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:59,950 INFO epoch # 9923 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005508961337909568
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:59,969 INFO epoch # 9924 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005549099823838333
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:50:59,987 INFO epoch # 9925 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0059626924885378685
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:51:00,005 INFO epoch # 9926 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005542250893995515
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:51:00,023 INFO epoch # 9927 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005445187871373491
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:51:00,042 INFO epoch # 9928 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0054675700957886875
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:51:00,061 INFO epoch # 9929 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005502063690073555
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:51:00,080 INFO epoch # 9930 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005472489174280781
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:51:00,080 INFO *** epoch 9930, rolling-avg-loss (window=10)= 0.005537203958920145
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:51:00,098 INFO epoch # 9931 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005462820066895802
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:51:00,116 INFO epoch # 9932 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0058690622354333755
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:51:00,136 INFO epoch # 9933 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005452081295516109
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:51:00,155 INFO epoch # 9934 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005535760396014666
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:51:00,173 INFO epoch # 9935 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0054434995727206115
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:51:00,192 INFO epoch # 9936 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005463767371111317
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:51:00,210 INFO epoch # 9937 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0054254904644039925
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:51:00,228 INFO epoch # 9938 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005437213490949944
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:51:00,247 INFO epoch # 9939 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005438834574306384
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:51:00,265 INFO epoch # 9940 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0054501081140188035
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:51:00,266 INFO *** epoch 9940, rolling-avg-loss (window=10)= 0.0054978637581371
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:51:00,284 INFO epoch # 9941 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005454702459246619
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:51:00,302 INFO epoch # 9942 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005452413115563104
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:51:00,321 INFO epoch # 9943 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005420549659902463
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:51:00,339 INFO epoch # 9944 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005424768467491958
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:51:00,357 INFO epoch # 9945 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00543292151633068
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:51:00,375 INFO epoch # 9946 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0055616792633372825
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:51:00,394 INFO epoch # 9947 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0054317371195793385
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:51:00,412 INFO epoch # 9948 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005429179745988222
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:51:00,430 INFO epoch # 9949 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0054507381973962765
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:51:00,448 INFO epoch # 9950 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005455516642541625
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:51:00,449 INFO *** epoch 9950, rolling-avg-loss (window=10)= 0.005451420618737757
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:51:00,467 INFO epoch # 9951 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005502255782630527
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:51:00,486 INFO epoch # 9952 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0054648540608468466
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:51:00,505 INFO epoch # 9953 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005634334302158095
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:51:00,523 INFO epoch # 9954 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005530426296900259
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:51:00,542 INFO epoch # 9955 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005496624711668119
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:51:00,560 INFO epoch # 9956 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005467336137371603
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:51:00,578 INFO epoch # 9957 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005421088946604868
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:51:00,597 INFO epoch # 9958 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005452161061839433
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:51:00,615 INFO epoch # 9959 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005446439376100898
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:51:00,633 INFO epoch # 9960 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0054369452300306875
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:51:00,633 INFO *** epoch 9960, rolling-avg-loss (window=10)= 0.005485246590615134
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:51:00,652 INFO epoch # 9961 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005498991107742768
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:51:00,670 INFO epoch # 9962 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005497128346178215
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:51:00,689 INFO epoch # 9963 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0054255064569588285
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:51:00,708 INFO epoch # 9964 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005415681484009838
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:51:00,726 INFO epoch # 9965 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005455191603687126
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:51:00,745 INFO epoch # 9966 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005451189928862732
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:51:00,763 INFO epoch # 9967 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005450552529509878
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:51:00,781 INFO epoch # 9968 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005427432857686654
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:51:00,799 INFO epoch # 9969 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005486514073709259
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:51:00,818 INFO epoch # 9970 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005484621498908382
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:51:00,818 INFO *** epoch 9970, rolling-avg-loss (window=10)= 0.005459280988725368
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:51:00,836 INFO epoch # 9971 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005541204434848623
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:51:00,854 INFO epoch # 9972 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005481811938807368
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:51:00,873 INFO epoch # 9973 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005428432203189004
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:51:00,892 INFO epoch # 9974 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005440157854536665
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:51:00,911 INFO epoch # 9975 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005420456331194146
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:51:00,929 INFO epoch # 9976 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005505646829988109
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:51:00,948 INFO epoch # 9977 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0054518262440979015
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:51:00,966 INFO epoch # 9978 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005476501406519674
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:51:00,985 INFO epoch # 9979 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005425231514891493
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:51:01,005 INFO epoch # 9980 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005422088102932321
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:51:01,005 INFO *** epoch 9980, rolling-avg-loss (window=10)= 0.005459335686100531
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:51:01,027 INFO epoch # 9981 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005809737682284322
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:51:01,047 INFO epoch # 9982 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005451039593026508
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:51:01,067 INFO epoch # 9983 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005433743990579387
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:51:01,086 INFO epoch # 9984 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005427966829302022
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:51:01,105 INFO epoch # 9985 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005445532064186409
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:51:01,124 INFO epoch # 9986 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0054707441086065955
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:51:01,143 INFO epoch # 9987 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005462802826514235
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:51:01,162 INFO epoch # 9988 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005467855044116732
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:51:01,181 INFO epoch # 9989 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0054792487771919696
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:51:01,200 INFO epoch # 9990 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0054387620111810975
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:51:01,200 INFO *** epoch 9990, rolling-avg-loss (window=10)= 0.0054887432926989275
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:51:01,219 INFO epoch # 9991 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.00548879043708439
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:51:01,239 INFO epoch # 9992 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005418242384621408
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:51:01,259 INFO epoch # 9993 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005455979091493646
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:51:01,279 INFO epoch # 9994 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005438512609543977
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:51:01,298 INFO epoch # 9995 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005421528159786249
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:51:01,317 INFO epoch # 9996 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005506350194991683
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:51:01,336 INFO epoch # 9997 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005829684956552228
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:51:01,355 INFO epoch # 9998 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005402874905485078
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:51:01,374 INFO epoch # 9999 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.0054813097485748585
[experiments_sandbox.py:748 -   <module>()] 2023-04-24 14:51:01,393 INFO epoch # 10000 - for optimizer <class 'torch.optim.sgd.SGD'> -lr : 0.001-> 0.001 -loss = 0.005441779496322852
[experiments_sandbox.py:760 -   <module>()] 2023-04-24 14:51:01,393 INFO *** epoch 10000, rolling-avg-loss (window=10)= 0.005488505198445637
[experiments_sandbox.py:768 -   <module>()] 2023-04-24 14:51:01,393 INFO training time in seconds = 186
[experiments_sandbox.py:772 -   <module>()] 2023-04-24 14:51:01,394 INFO train-epochs-loss curve df :
[experiments_sandbox.py:773 -   <module>()] 2023-04-24 14:51:01,411 INFO 
     epochs  rolling-avg-loss
0        10          0.282035
1        20          0.130197
2        30          0.106429
3        40          0.095580
4        50          0.084862
5        60          0.080948
6        70          0.070404
7        80          0.064132
8        90          0.062064
9       100          0.054737
10      110          0.050995
11      120          0.048306
12      130          0.046208
13      140          0.047067
14      150          0.041494
15      160          0.041782
16      170          0.039779
17      180          0.036942
18      190          0.035829
19      200          0.035040
20      210          0.033571
21      220          0.034383
22      230          0.031736
23      240          0.031163
24      250          0.030734
25      260          0.029830
26      270          0.032236
27      280          0.029161
28      290          0.030182
29      300          0.028406
30      310          0.027570
31      320          0.027296
32      330          0.026784
33      340          0.026330
34      350          0.026101
35      360          0.025950
36      370          0.025385
37      380          0.025132
38      390          0.024879
39      400          0.024493
40      410          0.024134
41      420          0.023948
42      430          0.025541
43      440          0.023417
44      450          0.023308
45      460          0.024449
46      470          0.022858
47      480          0.022458
48      490          0.023692
49      500          0.022472
50      510          0.021991
51      520          0.021645
52      530          0.022914
53      540          0.021331
54      550          0.021142
55      560          0.020762
56      570          0.021709
57      580          0.020363
58      590          0.020234
59      600          0.020003
60      610          0.019810
61      620          0.019770
62      630          0.019586
63      640          0.019519
64      650          0.019263
65      660          0.020319
66      670          0.018903
67      680          0.019459
68      690          0.019379
69      700          0.018319
70      710          0.018286
71      720          0.017949
72      730          0.018192
73      740          0.019129
74      750          0.017698
75      760          0.017721
76      770          0.017370
77      780          0.017400
78      790          0.018156
79      800          0.017147
80      810          0.017136
81      820          0.017041
82      830          0.017982
83      840          0.016582
84      850          0.016552
85      860          0.016494
86      870          0.016291
87      880          0.016979
88      890          0.016315
89      900          0.016019
90      910          0.016051
91      920          0.015875
92      930          0.015723
93      940          0.015639
94      950          0.015743
95      960          0.015496
96      970          0.016306
97      980          0.015217
98      990          0.015257
99     1000          0.015116
100    1010          0.016646
101    1020          0.015068
102    1030          0.014821
103    1040          0.014899
104    1050          0.014701
105    1060          0.014569
106    1070          0.014625
107    1080          0.014473
108    1090          0.014819
109    1100          0.014233
110    1110          0.014270
111    1120          0.014733
112    1130          0.014223
113    1140          0.014138
114    1150          0.014166
115    1160          0.013947
116    1170          0.013916
117    1180          0.013739
118    1190          0.013797
119    1200          0.014201
120    1210          0.013675
121    1220          0.013488
122    1230          0.013465
123    1240          0.013538
124    1250          0.013375
125    1260          0.013715
126    1270          0.013198
127    1280          0.013271
128    1290          0.013082
129    1300          0.013056
130    1310          0.013016
131    1320          0.012873
132    1330          0.012757
133    1340          0.012843
134    1350          0.012691
135    1360          0.012748
136    1370          0.013428
137    1380          0.012737
138    1390          0.012566
139    1400          0.012407
140    1410          0.012389
141    1420          0.012325
142    1430          0.012341
143    1440          0.012334
144    1450          0.012318
145    1460          0.012141
146    1470          0.012108
147    1480          0.012837
148    1490          0.011967
149    1500          0.012752
150    1510          0.011924
151    1520          0.012724
152    1530          0.011982
153    1540          0.011754
154    1550          0.011670
155    1560          0.011701
156    1570          0.011623
157    1580          0.012005
158    1590          0.011513
159    1600          0.011538
160    1610          0.011617
161    1620          0.011410
162    1630          0.011365
163    1640          0.011291
164    1650          0.011338
165    1660          0.011333
166    1670          0.011211
167    1680          0.011194
168    1690          0.011159
169    1700          0.011121
170    1710          0.011139
171    1720          0.011118
172    1730          0.011014
173    1740          0.011276
174    1750          0.010918
175    1760          0.010920
176    1770          0.010874
177    1780          0.010835
178    1790          0.010885
179    1800          0.010735
180    1810          0.011136
181    1820          0.012095
182    1830          0.010599
183    1840          0.010691
184    1850          0.010660
185    1860          0.010575
186    1870          0.010504
187    1880          0.010494
188    1890          0.010442
189    1900          0.010527
190    1910          0.010579
191    1920          0.011124
192    1930          0.010348
193    1940          0.010972
194    1950          0.010250
195    1960          0.010244
196    1970          0.010232
197    1980          0.010788
198    1990          0.010251
199    2000          0.010148
200    2010          0.010146
201    2020          0.010120
202    2030          0.010121
203    2040          0.009992
204    2050          0.010068
205    2060          0.010034
206    2070          0.009908
207    2080          0.009913
208    2090          0.009933
209    2100          0.010023
210    2110          0.010011
211    2120          0.009792
212    2130          0.009799
213    2140          0.009754
214    2150          0.010470
215    2160          0.010562
216    2170          0.009702
217    2180          0.009720
218    2190          0.009844
219    2200          0.009643
220    2210          0.009646
221    2220          0.010329
222    2230          0.010607
223    2240          0.009531
224    2250          0.009519
225    2260          0.009449
226    2270          0.009598
227    2280          0.009458
228    2290          0.009526
229    2300          0.009357
230    2310          0.009398
231    2320          0.009481
232    2330          0.009308
233    2340          0.009325
234    2350          0.009565
235    2360          0.009634
236    2370          0.009253
237    2380          0.009259
238    2390          0.009301
239    2400          0.009167
240    2410          0.009214
241    2420          0.009430
242    2430          0.009137
243    2440          0.009130
244    2450          0.009725
245    2460          0.009048
246    2470          0.009061
247    2480          0.009079
248    2490          0.008979
249    2500          0.009114
250    2510          0.008947
251    2520          0.009063
252    2530          0.008973
253    2540          0.008942
254    2550          0.008893
255    2560          0.008910
256    2570          0.008864
257    2580          0.008797
258    2590          0.008823
259    2600          0.008809
260    2610          0.008817
261    2620          0.008753
262    2630          0.008750
263    2640          0.008714
264    2650          0.008821
265    2660          0.008796
266    2670          0.009050
267    2680          0.008693
268    2690          0.008685
269    2700          0.008693
270    2710          0.008591
271    2720          0.008605
272    2730          0.008563
273    2740          0.008611
274    2750          0.008620
275    2760          0.009090
276    2770          0.008536
277    2780          0.008788
278    2790          0.008578
279    2800          0.008620
280    2810          0.008770
281    2820          0.008571
282    2830          0.008475
283    2840          0.008514
284    2850          0.008494
285    2860          0.008509
286    2870          0.008547
287    2880          0.008831
288    2890          0.008456
289    2900          0.008434
290    2910          0.008312
291    2920          0.008369
292    2930          0.008445
293    2940          0.008543
294    2950          0.008345
295    2960          0.008255
296    2970          0.008561
297    2980          0.008675
298    2990          0.008303
299    3000          0.008220
300    3010          0.008235
301    3020          0.008195
302    3030          0.008796
303    3040          0.008423
304    3050          0.008229
305    3060          0.008632
306    3070          0.008136
307    3080          0.008117
308    3090          0.008124
309    3100          0.008136
310    3110          0.008122
311    3120          0.008105
312    3130          0.008540
313    3140          0.008068
314    3150          0.008138
315    3160          0.008077
316    3170          0.008117
317    3180          0.007986
318    3190          0.008411
319    3200          0.007986
320    3210          0.008297
321    3220          0.008032
322    3230          0.007968
323    3240          0.008073
324    3250          0.007904
325    3260          0.007955
326    3270          0.007942
327    3280          0.007977
328    3290          0.007975
329    3300          0.007874
330    3310          0.008156
331    3320          0.007927
332    3330          0.007905
333    3340          0.007827
334    3350          0.007840
335    3360          0.007958
336    3370          0.007839
337    3380          0.007832
338    3390          0.008298
339    3400          0.008292
340    3410          0.008277
341    3420          0.007747
342    3430          0.007793
343    3440          0.007804
344    3450          0.007770
345    3460          0.007792
346    3470          0.007771
347    3480          0.007777
348    3490          0.007936
349    3500          0.007743
350    3510          0.007710
351    3520          0.008208
352    3530          0.007693
353    3540          0.007708
354    3550          0.007708
355    3560          0.007698
356    3570          0.007638
357    3580          0.007645
358    3590          0.007608
359    3600          0.007602
360    3610          0.007606
361    3620          0.007786
362    3630          0.007645
363    3640          0.007624
364    3650          0.008030
365    3660          0.007615
366    3670          0.007614
367    3680          0.007600
368    3690          0.007543
369    3700          0.007590
370    3710          0.007611
371    3720          0.007935
372    3730          0.007581
373    3740          0.007548
374    3750          0.007514
375    3760          0.007551
376    3770          0.007489
377    3780          0.007558
378    3790          0.007516
379    3800          0.007491
380    3810          0.007569
381    3820          0.007556
382    3830          0.007556
383    3840          0.007559
384    3850          0.007523
385    3860          0.007450
386    3870          0.007856
387    3880          0.007475
388    3890          0.007480
389    3900          0.007627
390    3910          0.007406
391    3920          0.007661
392    3930          0.007414
393    3940          0.007380
394    3950          0.007797
395    3960          0.007424
396    3970          0.007381
397    3980          0.007818
398    3990          0.007420
399    4000          0.007385
400    4010          0.007409
401    4020          0.007389
402    4030          0.007364
403    4040          0.007320
404    4050          0.007408
405    4060          0.007334
406    4070          0.007520
407    4080          0.007413
408    4090          0.007333
409    4100          0.007699
410    4110          0.007678
411    4120          0.007457
412    4130          0.007293
413    4140          0.007523
414    4150          0.007346
415    4160          0.007318
416    4170          0.007257
417    4180          0.007310
418    4190          0.007273
419    4200          0.007240
420    4210          0.007284
421    4220          0.007632
422    4230          0.007277
423    4240          0.007214
424    4250          0.007279
425    4260          0.007249
426    4270          0.007200
427    4280          0.007203
428    4290          0.007236
429    4300          0.007207
430    4310          0.007261
431    4320          0.007228
432    4330          0.007258
433    4340          0.007173
434    4350          0.007152
435    4360          0.007188
436    4370          0.007237
437    4380          0.007161
438    4390          0.007272
439    4400          0.007671
440    4410          0.007160
441    4420          0.007169
442    4430          0.007144
443    4440          0.007473
444    4450          0.007236
445    4460          0.007209
446    4470          0.007159
447    4480          0.007179
448    4490          0.007143
449    4500          0.007161
450    4510          0.007121
451    4520          0.007164
452    4530          0.007097
453    4540          0.007114
454    4550          0.007349
455    4560          0.007154
456    4570          0.007072
457    4580          0.007145
458    4590          0.007119
459    4600          0.007158
460    4610          0.007344
461    4620          0.007115
462    4630          0.007204
463    4640          0.007095
464    4650          0.007106
465    4660          0.007158
466    4670          0.007075
467    4680          0.007087
468    4690          0.007141
469    4700          0.007047
470    4710          0.007074
471    4720          0.007064
472    4730          0.007024
473    4740          0.007036
474    4750          0.007127
475    4760          0.007600
476    4770          0.007048
477    4780          0.007223
478    4790          0.007063
479    4800          0.007008
480    4810          0.007000
481    4820          0.007238
482    4830          0.007001
483    4840          0.007004
484    4850          0.007095
485    4860          0.007048
486    4870          0.007069
487    4880          0.007347
488    4890          0.007058
489    4900          0.006957
490    4910          0.007011
491    4920          0.007384
492    4930          0.006987
493    4940          0.007382
494    4950          0.006947
495    4960          0.007006
496    4970          0.006973
497    4980          0.007338
498    4990          0.006996
499    5000          0.007021
500    5010          0.007138
501    5020          0.006998
502    5030          0.006942
503    5040          0.007327
504    5050          0.006903
505    5060          0.006934
506    5070          0.007003
507    5080          0.006918
508    5090          0.006905
509    5100          0.006934
510    5110          0.006923
511    5120          0.006905
512    5130          0.007160
513    5140          0.006890
514    5150          0.006893
515    5160          0.006905
516    5170          0.006916
517    5180          0.007093
518    5190          0.007164
519    5200          0.006862
520    5210          0.007120
521    5220          0.006861
522    5230          0.006908
523    5240          0.006900
524    5250          0.006874
525    5260          0.006892
526    5270          0.007026
527    5280          0.006883
528    5290          0.006852
529    5300          0.006820
530    5310          0.006832
531    5320          0.006953
532    5330          0.007113
533    5340          0.007411
534    5350          0.006823
535    5360          0.006998
536    5370          0.007156
537    5380          0.006835
538    5390          0.006809
539    5400          0.007056
540    5410          0.006794
541    5420          0.006787
542    5430          0.006831
543    5440          0.006765
544    5450          0.006799
545    5460          0.007498
546    5470          0.006773
547    5480          0.006809
548    5490          0.006788
549    5500          0.006752
550    5510          0.006765
551    5520          0.006777
552    5530          0.006775
553    5540          0.006769
554    5550          0.006958
555    5560          0.006823
556    5570          0.007014
557    5580          0.006757
558    5590          0.006705
559    5600          0.006764
560    5610          0.006716
561    5620          0.006766
562    5630          0.006757
563    5640          0.006885
564    5650          0.006719
565    5660          0.006757
566    5670          0.006745
567    5680          0.006698
568    5690          0.007167
569    5700          0.007001
570    5710          0.006737
571    5720          0.007285
572    5730          0.006733
573    5740          0.006781
574    5750          0.006687
575    5760          0.006661
576    5770          0.006648
577    5780          0.006738
578    5790          0.006675
579    5800          0.006677
580    5810          0.006655
581    5820          0.006710
582    5830          0.006659
583    5840          0.006649
584    5850          0.006641
585    5860          0.006822
586    5870          0.006649
587    5880          0.006627
588    5890          0.006678
589    5900          0.006640
590    5910          0.006680
591    5920          0.006950
592    5930          0.006863
593    5940          0.006860
594    5950          0.006625
595    5960          0.006757
596    5970          0.006650
597    5980          0.006634
598    5990          0.006698
599    6000          0.006636
600    6010          0.006580
601    6020          0.006674
602    6030          0.006889
603    6040          0.006624
604    6050          0.006603
605    6060          0.006568
606    6070          0.007257
607    6080          0.006588
608    6090          0.006752
609    6100          0.006592
610    6110          0.006539
611    6120          0.006614
612    6130          0.006557
613    6140          0.006590
614    6150          0.006623
615    6160          0.006757
616    6170          0.006535
617    6180          0.006505
618    6190          0.006558
619    6200          0.006517
620    6210          0.006508
621    6220          0.006562
622    6230          0.006547
623    6240          0.006603
624    6250          0.006532
625    6260          0.006513
626    6270          0.006497
627    6280          0.006710
628    6290          0.006884
629    6300          0.006760
630    6310          0.006554
631    6320          0.006478
632    6330          0.006528
633    6340          0.006541
634    6350          0.006759
635    6360          0.006478
636    6370          0.006608
637    6380          0.006794
638    6390          0.006527
639    6400          0.006513
640    6410          0.006659
641    6420          0.006451
642    6430          0.006563
643    6440          0.006533
644    6450          0.006507
645    6460          0.006473
646    6470          0.006489
647    6480          0.006472
648    6490          0.006449
649    6500          0.006441
650    6510          0.006585
651    6520          0.006580
652    6530          0.006448
653    6540          0.006594
654    6550          0.006622
655    6560          0.006406
656    6570          0.006391
657    6580          0.006401
658    6590          0.006498
659    6600          0.006592
660    6610          0.006415
661    6620          0.006399
662    6630          0.006432
663    6640          0.006433
664    6650          0.006607
665    6660          0.006393
666    6670          0.006384
667    6680          0.006649
668    6690          0.006391
669    6700          0.006470
670    6710          0.006407
671    6720          0.006380
672    6730          0.006343
673    6740          0.006366
674    6750          0.006408
675    6760          0.006342
676    6770          0.006360
677    6780          0.006326
678    6790          0.006396
679    6800          0.006411
680    6810          0.006654
681    6820          0.006416
682    6830          0.006348
683    6840          0.006389
684    6850          0.006310
685    6860          0.006328
686    6870          0.006396
687    6880          0.006313
688    6890          0.006379
689    6900          0.006498
690    6910          0.006383
691    6920          0.006363
692    6930          0.006298
693    6940          0.006375
694    6950          0.006297
695    6960          0.006322
696    6970          0.006336
697    6980          0.006321
698    6990          0.006609
699    7000          0.006276
700    7010          0.006602
701    7020          0.006303
702    7030          0.006290
703    7040          0.006260
704    7050          0.006272
705    7060          0.006265
706    7070          0.006259
707    7080          0.006450
708    7090          0.006265
709    7100          0.006491
710    7110          0.006229
711    7120          0.006268
712    7130          0.006241
713    7140          0.006217
714    7150          0.006263
715    7160          0.006537
716    7170          0.006216
717    7180          0.006276
718    7190          0.006250
719    7200          0.006303
720    7210          0.006440
721    7220          0.006235
722    7230          0.006199
723    7240          0.006273
724    7250          0.006211
725    7260          0.006245
726    7270          0.006224
727    7280          0.006557
728    7290          0.006234
729    7300          0.006223
730    7310          0.006204
731    7320          0.006197
732    7330          0.006175
733    7340          0.006180
734    7350          0.006174
735    7360          0.006252
736    7370          0.006364
737    7380          0.006168
738    7390          0.006370
739    7400          0.006181
740    7410          0.006176
741    7420          0.006173
742    7430          0.006174
743    7440          0.006279
744    7450          0.006169
745    7460          0.006185
746    7470          0.006218
747    7480          0.006512
748    7490          0.006121
749    7500          0.006124
750    7510          0.006111
751    7520          0.006118
752    7530          0.006147
753    7540          0.006100
754    7550          0.006122
755    7560          0.006107
756    7570          0.006132
757    7580          0.006285
758    7590          0.006271
759    7600          0.006122
760    7610          0.006255
761    7620          0.006197
762    7630          0.006117
763    7640          0.006064
764    7650          0.006083
765    7660          0.006079
766    7670          0.006060
767    7680          0.006247
768    7690          0.006134
769    7700          0.006110
770    7710          0.006093
771    7720          0.006082
772    7730          0.006058
773    7740          0.006067
774    7750          0.006088
775    7760          0.006047
776    7770          0.006026
777    7780          0.006103
778    7790          0.006067
779    7800          0.006226
780    7810          0.006065
781    7820          0.006043
782    7830          0.006100
783    7840          0.006037
784    7850          0.006204
785    7860          0.006205
786    7870          0.006119
787    7880          0.006006
788    7890          0.006319
789    7900          0.006031
790    7910          0.006032
791    7920          0.006015
792    7930          0.006206
793    7940          0.006031
794    7950          0.006285
795    7960          0.005986
796    7970          0.006338
797    7980          0.006023
798    7990          0.006049
799    8000          0.006122
800    8010          0.006007
801    8020          0.005967
802    8030          0.006006
803    8040          0.006263
804    8050          0.006006
805    8060          0.005970
806    8070          0.006005
807    8080          0.006005
808    8090          0.005989
809    8100          0.005941
810    8110          0.005960
811    8120          0.005966
812    8130          0.006023
813    8140          0.006211
814    8150          0.005929
815    8160          0.005937
816    8170          0.006112
817    8180          0.006189
818    8190          0.005983
819    8200          0.005947
820    8210          0.006008
821    8220          0.005940
822    8230          0.005975
823    8240          0.005946
824    8250          0.005933
825    8260          0.005955
826    8270          0.005897
827    8280          0.006127
828    8290          0.005912
829    8300          0.005951
830    8310          0.006169
831    8320          0.005912
832    8330          0.005899
833    8340          0.005860
834    8350          0.006327
835    8360          0.005934
836    8370          0.005862
837    8380          0.006224
838    8390          0.005913
839    8400          0.005898
840    8410          0.005855
841    8420          0.005959
842    8430          0.005865
843    8440          0.005872
844    8450          0.006188
845    8460          0.005901
846    8470          0.005861
847    8480          0.005880
848    8490          0.005861
849    8500          0.005856
850    8510          0.005850
851    8520          0.005852
852    8530          0.005822
853    8540          0.005873
854    8550          0.006123
855    8560          0.005830
856    8570          0.005855
857    8580          0.005832
858    8590          0.005845
859    8600          0.005812
860    8610          0.006324
861    8620          0.006189
862    8630          0.005790
863    8640          0.005807
864    8650          0.005862
865    8660          0.005797
866    8670          0.005798
867    8680          0.006090
868    8690          0.006038
869    8700          0.005971
870    8710          0.005782
871    8720          0.005803
872    8730          0.005926
873    8740          0.005861
874    8750          0.005997
875    8760          0.005971
876    8770          0.005764
877    8780          0.005773
878    8790          0.005775
879    8800          0.005834
880    8810          0.005774
881    8820          0.005783
882    8830          0.005815
883    8840          0.005751
884    8850          0.005804
885    8860          0.005773
886    8870          0.005754
887    8880          0.005767
888    8890          0.005964
889    8900          0.005731
890    8910          0.005760
891    8920          0.005718
892    8930          0.005723
893    8940          0.005720
894    8950          0.006025
895    8960          0.005710
896    8970          0.005763
897    8980          0.005715
898    8990          0.005768
899    9000          0.005751
900    9010          0.005696
901    9020          0.005719
902    9030          0.005735
903    9040          0.005741
904    9050          0.005690
905    9060          0.005693
906    9070          0.005684
907    9080          0.005721
908    9090          0.005898
909    9100          0.005692
910    9110          0.005784
911    9120          0.005678
912    9130          0.005892
913    9140          0.005674
914    9150          0.005789
915    9160          0.005652
916    9170          0.005653
917    9180          0.005800
918    9190          0.005668
919    9200          0.005705
920    9210          0.005719
921    9220          0.005827
922    9230          0.005642
923    9240          0.005945
924    9250          0.005973
925    9260          0.005693
926    9270          0.005700
927    9280          0.005644
928    9290          0.005675
929    9300          0.005788
930    9310          0.005671
931    9320          0.005745
932    9330          0.005862
933    9340          0.005793
934    9350          0.005718
935    9360          0.005810
936    9370          0.005643
937    9380          0.005609
938    9390          0.005690
939    9400          0.005611
940    9410          0.005673
941    9420          0.005853
942    9430          0.005652
943    9440          0.005589
944    9450          0.005657
945    9460          0.005614
946    9470          0.005583
947    9480          0.005665
948    9490          0.005573
949    9500          0.005596
950    9510          0.005713
951    9520          0.005583
952    9530          0.005558
953    9540          0.005597
954    9550          0.006029
955    9560          0.005584
956    9570          0.005584
957    9580          0.005553
958    9590          0.005660
959    9600          0.005547
960    9610          0.005749
961    9620          0.005608
962    9630          0.005555
963    9640          0.005546
964    9650          0.005584
965    9660          0.005549
966    9670          0.005511
967    9680          0.005588
968    9690          0.005557
969    9700          0.005518
970    9710          0.005539
971    9720          0.005543
972    9730          0.005501
973    9740          0.005544
974    9750          0.005529
975    9760          0.005550
976    9770          0.005498
977    9780          0.005506
978    9790          0.005816
979    9800          0.005819
980    9810          0.005557
981    9820          0.005685
982    9830          0.005637
983    9840          0.005674
984    9850          0.005524
985    9860          0.005514
986    9870          0.005522
987    9880          0.005557
988    9890          0.005566
989    9900          0.005533
990    9910          0.005557
991    9920          0.005495
992    9930          0.005537
993    9940          0.005498
994    9950          0.005451
995    9960          0.005485
996    9970          0.005459
997    9980          0.005459
998    9990          0.005489
999   10000          0.005489
[experiments_sandbox.py:776 -   <module>()] 2023-04-24 14:51:01,411 INFO Out-of sample batch-test
[experiments_sandbox.py:781 -   <module>()] 2023-04-24 14:51:01,412 INFO test-batch  # 0 => test-loss = 0.009358939714729786
[experiments_sandbox.py:781 -   <module>()] 2023-04-24 14:51:01,412 INFO test-batch  # 1 => test-loss = 0.009816030040383339
[experiments_sandbox.py:781 -   <module>()] 2023-04-24 14:51:01,412 INFO test-batch  # 2 => test-loss = 0.009545262902975082
[experiments_sandbox.py:781 -   <module>()] 2023-04-24 14:51:01,413 INFO test-batch  # 3 => test-loss = 0.009452896192669868
[experiments_sandbox.py:781 -   <module>()] 2023-04-24 14:51:01,413 INFO test-batch  # 4 => test-loss = 0.00839507021009922
[experiments_sandbox.py:781 -   <module>()] 2023-04-24 14:51:01,413 INFO test-batch  # 5 => test-loss = 0.04422624036669731
[experiments_sandbox.py:781 -   <module>()] 2023-04-24 14:51:01,414 INFO test-batch  # 6 => test-loss = 0.15387631952762604
[experiments_sandbox.py:781 -   <module>()] 2023-04-24 14:51:01,414 INFO test-batch  # 7 => test-loss = 0.007505635265260935
[experiments_sandbox.py:781 -   <module>()] 2023-04-24 14:51:01,414 INFO test-batch  # 8 => test-loss = 0.012242142111063004
[experiments_sandbox.py:781 -   <module>()] 2023-04-24 14:51:01,415 INFO test-batch  # 9 => test-loss = 0.014212645590305328
[experiments_sandbox.py:781 -   <module>()] 2023-04-24 14:51:01,415 INFO test-batch  # 10 => test-loss = 0.012497554533183575
[experiments_sandbox.py:781 -   <module>()] 2023-04-24 14:51:01,415 INFO test-batch  # 11 => test-loss = 0.008293839171528816
[experiments_sandbox.py:781 -   <module>()] 2023-04-24 14:51:01,416 INFO test-batch  # 12 => test-loss = 0.029432374984025955
[experiments_sandbox.py:781 -   <module>()] 2023-04-24 14:51:01,416 INFO test-batch  # 13 => test-loss = 0.014598624780774117
[experiments_sandbox.py:781 -   <module>()] 2023-04-24 14:51:01,416 INFO test-batch  # 14 => test-loss = 0.02607588656246662
[experiments_sandbox.py:781 -   <module>()] 2023-04-24 14:51:01,417 INFO test-batch  # 15 => test-loss = 0.006922876928001642
[experiments_sandbox.py:781 -   <module>()] 2023-04-24 14:51:01,417 INFO test-batch  # 16 => test-loss = 0.010469118133187294
[experiments_sandbox.py:781 -   <module>()] 2023-04-24 14:51:01,417 INFO test-batch  # 17 => test-loss = 0.01578107662498951
[experiments_sandbox.py:781 -   <module>()] 2023-04-24 14:51:01,418 INFO test-batch  # 18 => test-loss = 0.007021748460829258
[experiments_sandbox.py:781 -   <module>()] 2023-04-24 14:51:01,418 INFO test-batch  # 19 => test-loss = 0.009687534533441067
[experiments_sandbox.py:781 -   <module>()] 2023-04-24 14:51:01,418 INFO test-batch  # 20 => test-loss = 0.015987923368811607
[experiments_sandbox.py:781 -   <module>()] 2023-04-24 14:51:01,419 INFO test-batch  # 21 => test-loss = 0.08727973699569702
[experiments_sandbox.py:781 -   <module>()] 2023-04-24 14:51:01,419 INFO test-batch  # 22 => test-loss = 0.009401435032486916
[experiments_sandbox.py:781 -   <module>()] 2023-04-24 14:51:01,419 INFO test-batch  # 23 => test-loss = 0.003691877005621791
[experiments_sandbox.py:781 -   <module>()] 2023-04-24 14:51:01,420 INFO test-batch  # 24 => test-loss = 0.01901811733841896
[experiments_sandbox.py:781 -   <module>()] 2023-04-24 14:51:01,420 INFO test-batch  # 25 => test-loss = 0.07291440665721893
[experiments_sandbox.py:781 -   <module>()] 2023-04-24 14:51:01,420 INFO test-batch  # 26 => test-loss = 0.012873735278844833
[experiments_sandbox.py:781 -   <module>()] 2023-04-24 14:51:01,421 INFO test-batch  # 27 => test-loss = 0.012386704795062542
[experiments_sandbox.py:781 -   <module>()] 2023-04-24 14:51:01,421 INFO test-batch  # 28 => test-loss = 0.005485734436661005
[experiments_sandbox.py:781 -   <module>()] 2023-04-24 14:51:01,421 INFO test-batch  # 29 => test-loss = 0.010217556729912758
[experiments_sandbox.py:781 -   <module>()] 2023-04-24 14:51:01,422 INFO test-batch  # 30 => test-loss = 0.009458623826503754
[experiments_sandbox.py:781 -   <module>()] 2023-04-24 14:51:01,422 INFO test-batch  # 31 => test-loss = 0.006409736350178719
